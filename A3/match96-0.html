<HTML>
<HEAD>
<TITLE>./A3_processed_new_hash/combined_G9KZF.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A3_processed_new_hash/combined_G9KZF.py<p><PRE>


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from decision_tree import Node, DCTree, plot_accuracies, preprocess_b
import sys
import time

def q1(train_data, valid_data, test_data):
    train_data.columns = train_data.columns.str.strip()
    valid_data.columns = valid_data.columns.str.strip()
    test_data.columns = test_data.columns.str.strip()

    categorical_cols = train_data.select_dtypes(include=['object']).columns.drop('income')
    cat_col_names = categorical_cols.tolist()

    for col in categorical_cols:
        categories = train_data[col].astype('category').cat.categories
        cat_mapping = {cat: i for i, cat in enumerate(categories)}
        
        train_data[col] = train_data[col].map(cat_mapping).fillna(-1).astype(int)
        valid_data[col] = valid_data[col].map(cat_mapping).fillna(-1).astype(int)
        test_data[col] = test_data[col].map(cat_mapping).fillna(-1).astype(int)

    train_data['income'] = (train_data['income'] == ' &gt;50K').astype(int)
    valid_data['income'] = (valid_data['income'] == ' &gt;50K').astype(int)
    test_data['income'] = (test_data['income'] == ' &gt;50K').astype(int)
    
    X_train, y_train = train_data.iloc[:, :-1], train_data.iloc[:, -1]
    X_valid, y_valid = valid_data.iloc[:, :-1], valid_data.iloc[:, -1]
    X_test, y_test = test_data.iloc[:, :-1], test_data.iloc[:, -1]
    
    depths = [5, 10, 15, 20]
    train_accuracies = []
    valid_accuracies = []
    test_accuracies = []

    for depth in depths:
        start = time.time()
        tree = DCTree(cat_col_names,max_depth=depth)
        tree.fit(X_train, y_train)
        train_preds = tree.predict(X_train)
        valid_preds = tree.predict(X_valid)
        test_preds = tree.predict(X_test)
        train_acc = accuracy_score(y_train, train_preds)
        valid_acc = accuracy_score(y_valid, valid_preds)
        test_acc = accuracy_score(y_test, test_preds)
        train_accuracies.append(train_acc)
        valid_accuracies.append(valid_acc)
        test_accuracies.append(test_acc)
        print(f"Depth: {depth}, Train Accuracy: {train_acc:.4f}, Valid Accuracy: {valid_acc:.4f}, Test Accuracy: {test_acc:.4f}, Time : {time.time()-start:.4f}")

    plot_accuracies(depths, train_accuracies, valid_accuracies, test_accuracies, 'q1.png', "Tree Depth", "Tree Depth")
    best_depth = depths[np.argmax(valid_accuracies)]
    print(f"Best Depth: {best_depth}")

def q2(train_data, valid_data, test_data):    
    X_train, y_train, X_valid, y_valid, X_test, y_test, cat_col_names = preprocess_b(train_data, valid_data, test_data)
    depths = [25, 35, 45, 55]
    train_accuracies, test_accuracies, valid_accuracies = [], [], []
    
    for depth in depths:
        tree = DCTree(cat_col_names, max_depth=depth)
        tree.fit(X_train, y_train)
        train_preds = tree.predict(X_train)
        valid_preds = tree.predict(X_valid)
        test_preds = tree.predict(X_test)
        train_acc = accuracy_score(y_train, train_preds) 
        valid_acc = accuracy_score(y_valid, valid_preds) 
        test_acc = accuracy_score(y_test, test_preds) 
        train_accuracies.append(train_acc)
        valid_accuracies.append(valid_acc)
        test_accuracies.append(test_acc)
        print(f"Depth: {depth}, Train Accuracy: {train_acc:.4f}, Validation Accuracy: {valid_acc:.4f}, Test Accuracy: {test_acc:.4f}")

    plot_accuracies(depths, train_accuracies, valid_accuracies, test_accuracies, 'q2.png', "One-Hot Encoding", "Tree Depth")
    best_depth = depths[np.argmax(valid_accuracies)]
    print(f"Best Depth: {best_depth}")

def q4_a(train_data, valid_data, test_data):
    X_train, y_train, X_valid, y_valid, X_test, y_test, _ = preprocess_b(train_data, valid_data, test_data)
<A NAME="1"></A><FONT color = #00FF00><A HREF="match96-1.html#1" TARGET="1"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    max_depths = [25, 35, 45, 55]
    train_accuracies, test_accuracies, valid_accuracies = [], [], []

    for depth in max_depths:
        model = DecisionTreeClassifier(criterion="entropy", max_depth=depth)
        model.fit(X_train, y_train)
</FONT>        train_acc = accuracy_score(y_train, model.predict(X_train))
        valid_acc = accuracy_score(y_valid, model.predict(X_valid))
        test_acc = accuracy_score(y_test, model.predict(X_test))
        train_accuracies.append(train_acc)
        valid_accuracies.append(valid_acc)
        test_accuracies.append(test_acc)
        print(f"Max Depth: {depth} -&gt; Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, Test: {test_acc:.4f}")

    best_depth = max_depths[np.argmax(valid_accuracies)]
    plot_accuracies(max_depths, train_accuracies, valid_accuracies, test_accuracies, 'q4_a.png', "SKlearn", "Max Depth")
    print(f"Best max depth: {best_depth}")

def q4_b(train_data, valid_data, test_data):
    X_train, y_train, X_valid, y_valid, X_test, y_test, _ = preprocess_b(train_data, valid_data, test_data)
<A NAME="0"></A><FONT color = #FF0000><A HREF="match96-1.html#0" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    ccp_alphas = [0.001, 0.01, 0.1, 0.2]
    train_accuracies, test_accuracies, valid_accuracies = [], [], []

    for alpha in ccp_alphas:
        model = DecisionTreeClassifier(criterion="entropy", ccp_alpha=alpha)
        model.fit(X_train, y_train)
</FONT>        train_acc = accuracy_score(y_train, model.predict(X_train))
        valid_acc = accuracy_score(y_valid, model.predict(X_valid))
        test_acc = accuracy_score(y_test, model.predict(X_test))
        train_accuracies.append(train_acc)
        valid_accuracies.append(valid_acc)
        test_accuracies.append(test_acc)
        print(f"CCP Alpha: {alpha} -&gt; Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, Test: {test_acc:.4f}")

    best_alpha = ccp_alphas[np.argmax(valid_accuracies)]
    plot_accuracies(ccp_alphas, train_accuracies, valid_accuracies, test_accuracies,'q4_b.png',"Sklearn", "CCP Alpha",)
    print(f"Best ccp_alpha: {best_alpha}")

def q5(train_data, valid_data, test_data):
    
    X_train, y_train, X_valid, y_valid, X_test, y_test, _ = preprocess_b(train_data, valid_data, test_data)
    
    n_estimators_range = [50, 150, 250, 350]
    max_features_range = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]
    min_samples_split_range = [2, 4, 6, 8, 10]
    
    best_params = None
    best_oob_acc = 0
    
    results = []
    
    for n_estimators in n_estimators_range:
        for max_features in max_features_range:
            for min_samples_split in min_samples_split_range:
                
                model = RandomForestClassifier(
                    n_estimators=n_estimators,
                    max_features=max_features,
                    min_samples_split=min_samples_split,
                    oob_score=True,
                    criterion='entropy',
                    random_state=42,
                    n_jobs=-1
                )
                model.fit(X_train, y_train)
                
                train_acc = accuracy_score(y_train, model.predict(X_train))
                oob_acc = model.oob_score_
                valid_acc = accuracy_score(y_valid, model.predict(X_valid))
                test_acc = accuracy_score(y_test, model.predict(X_test))
                
                results.append((n_estimators, max_features, min_samples_split, train_acc, oob_acc, valid_acc, test_acc))
                
                if oob_acc &gt; best_oob_acc:
                    best_oob_acc = oob_acc
                    best_params = (n_estimators, max_features, min_samples_split)
                    
                print(f"n_estimators={n_estimators}, max_features={max_features}, min_samples_split={min_samples_split}, Train Acc={train_acc:.4f}, OOB Acc={oob_acc:.4f}, Valid Acc={valid_acc:.4f}, Test Acc={test_acc:.4f}")
    
    print(best_params)

def accuracy(y_true, y_pred):
    return np.mean(y_true == y_pred)
    
def q3(train_data, valid_data, test_data):
    X_train, y_train, X_valid, y_valid, X_test, y_test, cat_cols = preprocess_b(train_data, valid_data, test_data)
    depths = [25, 35, 45, 55]
    
    train_accuracies = []
    val_accuracies = []
    test_accuracies = []
    for d in depths:
        print("Building Tree with depth: ",d)
        tree = DCTree(categorical_features=cat_cols, max_depth=d)
        tree.fit(X_train, y_train)
        print("Total Nodes: ",tree.total_nodes)
        print("Pruning...")
        tree.annotate_tree(X_valid, y_valid)
        tree.propagate_validation_stats(tree.tree)
        tree.prune_node(tree.tree)
        # tree.greedy_prune(X_valid, y_valid)
        print("Pruning completed.")
        train_acc = accuracy(y_train, tree.predict(X_train))
        val_acc = accuracy(y_valid, tree.predict(X_valid))
        test_acc = accuracy(y_test, tree.predict(X_test))

        train_accuracies.append(train_acc)
        val_accuracies.append(val_acc)
        test_accuracies.append(test_acc)
        
        print(f"Depth {d}: Train Acc = {train_acc:.4f}, Val Acc = {val_acc:.4f}, Test Acc = {test_acc:.4f}")

    plot_accuracies(depths,train_accuracies,val_accuracies, test_accuracies, 'q3.png',"Pruning",'Tree Depth')

def main():
    if len(sys.argv) != 2:
        print("Usage: python decision_tree.py &lt;train_data_path&gt; &lt;validation_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
        sys.exit(1)

    train_path = "./data/Q1/train.csv"
    val_path = "./data/Q1/valid.csv"
    test_path = "./data/Q1/test.csv"
    part = sys.argv[1].lower()
    train_df = pd.read_csv(train_path)
    val_df = pd.read_csv(val_path)
    test_df = pd.read_csv(test_path)
    if part == 'q1':
        q1(train_df, val_df, test_df)
    elif part == 'q2':
        q2(train_df, val_df, test_df)
    elif part == 'q3':
        q3(train_df, val_df, test_df)
    elif part == 'q4_a':
        q4_a(train_df, val_df, test_df)
    elif part == 'q4_b':
        q4_b(train_df, val_df, test_df)
    elif part == 'q5':
        q5(train_df, val_df, test_df)

if __name__ == "__main__":
    main()



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, f1_score, precision_recall_fscore_support
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.neural_network import MLPClassifier
from neural_network import NeuralNetwork
import os
import sys
import cv2    
    
def load_data_gtsrb_train(folder):
    X_train, y_train = [], []
    for class_id in range(43):
        class_folder = os.path.join(folder, f"{class_id:05d}")
        for img_name in os.listdir(class_folder):
            img_path = os.path.join(class_folder, img_name)
            img = cv2.imread(img_path)
            img = cv2.resize(img, (28, 28))
            X_train.append(img.flatten())
            y_train.append(class_id)
        print(f"{class_id:05d} Done")
    return np.array(X_train), np.array(y_train)

def load_data_gtsrb_test(folder, labels_csv):
    X_test = []
    df = pd.read_csv(labels_csv)
    y_test = df['label'].values
    for img_name in os.listdir(folder):
        img_path = os.path.join(folder, img_name)
        img = cv2.imread(img_path)
        img = cv2.resize(img, (28, 28))
        X_test.append(img.flatten())
    return np.array(X_test), np.array(y_test)

def q1(train_path, test_path, test_csv_path):
    X_train, y_train = load_data_gtsrb_train(train_path)
    X_test, y_test = load_data_gtsrb_test(test_path, test_csv_path)
    print("Done loading.")
    X_train = X_train / 255.0
    X_test = X_test / 255.0
    enc = OneHotEncoder(sparse_output=False)
    y_train_onehot = enc.fit_transform(y_train.reshape(-1, 1)).T
    y_test_onehot = enc.transform(y_test.reshape(-1, 1)).T
    hidden_units_list = [[1],[5],[10],[50],[100]]
    avg_f1_scores = []

    for hidden_units in hidden_units_list:
        print(f"\nTraining with {hidden_units} hidden units...")
        nn = NeuralNetwork(input_size=2352, hidden_layers=hidden_units, output_size=43, batch_size=32, learning_rate=0.01)
        nn.fit(X_train, y_train_onehot, epochs=50)
        y_train_pred = nn.predict(X_train)
        y_test_pred = nn.predict(X_test)
        train_report = classification_report(y_train, y_train_pred, output_dict=True,zero_division=0)
        test_report = classification_report(y_test, y_test_pred, output_dict=True, zero_division=0)
        print(classification_report(y_train, y_train_pred, zero_division=0))
        print("---------------")
        print(classification_report(y_test, y_test_pred, zero_division=0))
        train_f1 = [train_report[str(i)]['f1-score'] for i in range(43)]
        test_f1 = [test_report[str(i)]['f1-score'] for i in range(43)]
        avg_f1 = np.mean(test_f1)
        avg_f1_scores.append(avg_f1)
        train_precision = [train_report[str(i)]['precision'] for i in range(43)]
        train_recall = [train_report[str(i)]['recall'] for i in range(43)]
        test_precision = [test_report[str(i)]['precision'] for i in range(43)]
        test_recall = [test_report[str(i)]['recall'] for i in range(43)]
        train_acc = accuracy_score(y_train, y_train_pred)
        test_acc = accuracy_score(y_test, y_test_pred)
        print(f"Hidden units: {hidden_units}")
        print(f"Train - Accuracy: {train_acc:.4f}, Precision: {np.mean(train_precision):.4f}, Recall: {np.mean(train_recall):.4f}, F1: {np.mean(train_f1):.4f}")
        print(f"Test  - Accuracy: {test_acc:.4f}, Precision: {np.mean(test_precision):.4f}, Recall: {np.mean(test_recall):.4f}, F1: {avg_f1:.4f}")
        print(f"Avg F1 (train): {np.mean(train_f1):.4f}")
        print(f"Avg F1 (test): {avg_f1:.4f}")

    plt.plot([1,5,10,50,100], avg_f1_scores, marker='o')
    plt.title("Average F1 Score vs Number of Hidden Units")
    plt.xlabel("Number of Hidden Units")
    plt.ylabel("Average F1 Score (Test Data)")
    plt.grid(True)
    plt.savefig('b.png')
    return avg_f1_scores

def q2(train_path, test_path, test_csv_path):
    X_train, y_train = load_data_gtsrb_train(train_path)
    X_test, y_test = load_data_gtsrb_test(test_path, test_csv_path)
    print("Done loading.")
    X_train = X_train / 255.0
    X_test = X_test / 255.0
    enc = OneHotEncoder(sparse_output=False)
    y_train_onehot = enc.fit_transform(y_train.reshape(-1, 1)).T
    y_test_onehot = enc.transform(y_test.reshape(-1, 1)).T
    hidden_units_list = [[512],[512,256],[512,256,128],[512,256,128,64]]
    avg_f1_scores = []

    for hidden_units in hidden_units_list:
        print(f"\nTraining with {hidden_units} hidden units...")
        nn = NeuralNetwork(input_size=2352, hidden_layers=hidden_units, output_size=43, batch_size=32, learning_rate=0.01)
        nn.fit(X_train, y_train_onehot, epochs=50)
        y_train_pred = nn.predict(X_train)
        y_test_pred = nn.predict(X_test)
        train_report = classification_report(y_train, y_train_pred, output_dict=True,zero_division=0)
        test_report = classification_report(y_test, y_test_pred, output_dict=True, zero_division=0)
        print(classification_report(y_train, y_train_pred, zero_division=0))
        print("---------------")
        print(classification_report(y_test, y_test_pred, zero_division=0))
        train_f1 = [train_report[str(i)]['f1-score'] for i in range(43)]
        test_f1 = [test_report[str(i)]['f1-score'] for i in range(43)]
        avg_f1 = np.mean(test_f1)
        avg_f1_scores.append(avg_f1)
        train_precision = [train_report[str(i)]['precision'] for i in range(43)]
        train_recall = [train_report[str(i)]['recall'] for i in range(43)]
        test_precision = [test_report[str(i)]['precision'] for i in range(43)]
        test_recall = [test_report[str(i)]['recall'] for i in range(43)]
        train_acc = accuracy_score(y_train, y_train_pred)
        test_acc = accuracy_score(y_test, y_test_pred)
        print(f"Hidden units: {hidden_units}")
        print(f"Train - Accuracy: {train_acc:.4f}, Precision: {np.mean(train_precision):.4f}, Recall: {np.mean(train_recall):.4f}, F1: {np.mean(train_f1):.4f}")
        print(f"Test  - Accuracy: {test_acc:.4f}, Precision: {np.mean(test_precision):.4f}, Recall: {np.mean(test_recall):.4f}, F1: {avg_f1:.4f}")
        print(f"Avg F1 (train): {np.mean(train_f1):.4f}")
        print(f"Avg F1 (test): {avg_f1:.4f}")

    plt.plot([1,2,3,4], avg_f1_scores, marker='o')
    plt.title("Average F1 Score vs Number of Hidden Layer Depths")
    plt.xlabel("Number of Hidden Layer Depths")
    plt.ylabel("Average F1 Score (Test Data)")
    plt.grid(True)
    plt.savefig('c.png')
    return avg_f1_scores

def q3(train_path, test_path, test_csv_path, activation_function = 'sigmoid'):
    X_train, y_train = load_data_gtsrb_train(train_path)
    X_test, y_test = load_data_gtsrb_test(test_path, test_csv_path)
    print("Done loading.")
    X_train = X_train / 255.0
    X_test = X_test / 255.0
    enc = OneHotEncoder(sparse_output=False)
    y_train_onehot = enc.fit_transform(y_train.reshape(-1, 1)).T
    y_test_onehot = enc.transform(y_test.reshape(-1, 1)).T
    hidden_units_list = [[512],[512,256],[512,256,128],[512,256,128,64]]
    avg_f1_scores = []

    for hidden_units in hidden_units_list:
        print(f"\nTraining with {hidden_units} hidden units...")
        nn = NeuralNetwork(input_size=2352, hidden_layers=hidden_units, output_size=43, batch_size=32, learning_rate=0.01, activation_fxn=activation_function)
        nn.fit(X_train, y_train_onehot, epochs=75,adaptive_learning=True)
        y_train_pred = nn.predict(X_train)
        y_test_pred = nn.predict(X_test)
        train_report = classification_report(y_train, y_train_pred, output_dict=True, zero_division=0)
        test_report = classification_report(y_test, y_test_pred, output_dict=True, zero_division=0)
        print(classification_report(y_train, y_train_pred, zero_division=0))
        print("---------------")
        print(classification_report(y_test, y_test_pred, zero_division=0))
        train_f1 = [train_report[str(i)]['f1-score'] for i in range(43)]
        test_f1 = [test_report[str(i)]['f1-score'] for i in range(43)]
        avg_f1 = np.mean(test_f1)
        avg_f1_scores.append(avg_f1)
        train_precision = [train_report[str(i)]['precision'] for i in range(43)]
        train_recall = [train_report[str(i)]['recall'] for i in range(43)]
        test_precision = [test_report[str(i)]['precision'] for i in range(43)]
        test_recall = [test_report[str(i)]['recall'] for i in range(43)]
        train_acc = accuracy_score(y_train, y_train_pred)
        test_acc = accuracy_score(y_test, y_test_pred)
        print(f"Hidden units: {hidden_units}")
        print(f"Train - Accuracy: {train_acc:.4f}, Precision: {np.mean(train_precision):.4f}, Recall: {np.mean(train_recall):.4f}, F1: {np.mean(train_f1):.4f}")
        print(f"Test  - Accuracy: {test_acc:.4f}, Precision: {np.mean(test_precision):.4f}, Recall: {np.mean(test_recall):.4f}, F1: {avg_f1:.4f}")
        print(f"Avg F1 (train): {np.mean(train_f1):.4f}")
        print(f"Avg F1 (test): {avg_f1:.4f}")

    plt.plot([1,2,3,4], avg_f1_scores, marker='o')
    plt.title("Average F1 Score vs Number of Hidden Layer Depths")
    plt.xlabel("Number of Hidden Layer Depths")
    plt.ylabel("Average F1 Score (Test Data)")
    plt.grid(True)
    if (activation_function == 'sigmoid'):
        plt.savefig('d.png')
    else:
        plt.savefig('e.png')
    return avg_f1_scores
    
def q4(train_path, test_path, test_csv_path):
    X_train, y_train = load_data_gtsrb_train(train_path)
    X_test, y_test = load_data_gtsrb_test(test_path, test_csv_path)
    print("Done loading.")
    X_train = X_train / 255.0
    X_test = X_test / 255.0
    y_train = y_train.flatten()
<A NAME="5"></A><FONT color = #FF0000><A HREF="match96-1.html#5" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    y_test = y_test.flatten()
    hidden_units_list = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]
</FONT>    avg_f1_scores = []

    for hidden_units in hidden_units_list:
        print(f"\nTraining with {hidden_units} hidden units...")
        clf = MLPClassifier(
            hidden_layer_sizes=tuple(hidden_units),
            activation='relu',
            solver='sgd',
            alpha=0.0,
            batch_size=32,
            learning_rate='invscaling',
            early_stopping=True,
            max_iter=100,
            random_state=42
        )
        clf.fit(X_train, y_train)
        y_train_pred = clf.predict(X_train)
        y_test_pred = clf.predict(X_test)
        train_report = classification_report(y_train, y_train_pred, output_dict=True, zero_division=0)
        test_report = classification_report(y_test, y_test_pred, output_dict=True, zero_division=0)
        print(classification_report(y_train, y_train_pred, zero_division=0))
        print("---------------")
        print(classification_report(y_test, y_test_pred, zero_division=0))
        train_f1 = [train_report[str(i)]['f1-score'] for i in range(43)]
        test_f1 = [test_report[str(i)]['f1-score'] for i in range(43)]
        avg_f1 = np.mean(test_f1)
        avg_f1_scores.append(avg_f1)
        train_precision = [train_report[str(i)]['precision'] for i in range(43)]
        train_recall = [train_report[str(i)]['recall'] for i in range(43)]
        test_precision = [test_report[str(i)]['precision'] for i in range(43)]
        test_recall = [test_report[str(i)]['recall'] for i in range(43)]
        train_acc = accuracy_score(y_train, y_train_pred)
        test_acc = accuracy_score(y_test, y_test_pred)
        print(f"Hidden units: {hidden_units}")
        print(f"Train - Accuracy: {train_acc:.4f}, Precision: {np.mean(train_precision):.4f}, Recall: {np.mean(train_recall):.4f}, F1: {np.mean(train_f1):.4f}")
        print(f"Test  - Accuracy: {test_acc:.4f}, Precision: {np.mean(test_precision):.4f}, Recall: {np.mean(test_recall):.4f}, F1: {avg_f1:.4f}")
        print(f"Avg F1 (train): {np.mean(train_f1):.4f}")
        print(f"Avg F1 (test): {avg_f1:.4f}")

    plt.plot([1, 2, 3, 4], avg_f1_scores, marker='o')
    plt.title("Average F1 Score vs Number of Hidden Layer Depths")
    plt.xlabel("Architecture Index")
    plt.ylabel("Average F1 Score (Test Data)")
    plt.grid(True)
    plt.savefig("f.png")
    return avg_f1_scores

def main():
    if len(sys.argv) != 2:
        print("Usage: python decision_tree.py &lt;train_data_path&gt; &lt;validation_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
        sys.exit(1)

    part = sys.argv[1].lower()

    train_path = "./data/Q2/train"
    test_path = "./data/Q2/test"
    test_label_path = "./data/Q2/test_labels.csv"

    if part == 'b':
        q1(train_path, test_path, test_label_path)
    elif part == 'c':
        q2(train_path, test_path, test_label_path)
    elif part == 'd':
        q3(train_path, test_path, test_label_path)
    elif part == 'e':
        q3(train_path, test_path, test_label_path, 'relu')
    elif part == 'f':
        q4(train_path, test_path, test_label_path)


if __name__ == "__main__":
    main()




import pandas as pd
import numpy as np
from collections import Counter
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import sys
import os
import time

class Node:
    def __init__(self, feature=None, threshold=None, children=None, value=None, max_sample=None):
        self.feature = feature
        self.threshold = threshold
        self.children = children if children else {}
        self.value = value
        self.max_sample = max_sample
        
        self.val_correct_0 = 0
        self.val_correct_1 = 0
        self.val_incorrect_0 = 0
        self.val_incorrect_1 = 0

class DCTree:
    def __init__(self,categorical_features, max_depth=10):
        self.max_depth = max_depth
        self.tree = None
        self.cat_cols = categorical_features
        self.total_nodes = 0
    
    def entropy(self, y):
        counts = np.bincount(y)
        probs = counts / len(y)
        return -np.sum([p * np.log2(p) for p in probs if p &gt; 0])
    
    def information_gain(self, X, y, feature):

        if feature in self.cat_cols:
            
            unique_vals = X[feature].unique()
            split_entropy = 0
            for val in unique_vals:
                subset_y = y[X[feature] == val]
                split_entropy += (len(subset_y) / len(y)) * self.entropy(subset_y)
        else:  
            
            median_val = X[feature].median()
            left_y = y[X[feature] &lt;= median_val]
            right_y = y[X[feature] &gt; median_val]
            split_entropy = (len(left_y) / len(y)) * self.entropy(left_y) + (len(right_y) / len(y)) * self.entropy(right_y)
        return self.entropy(y) - split_entropy
    
    def best_split(self, X, y):
        self.total_nodes += 1
        best_feature, best_gain = None, 0
        for feature in X.columns:
            gain = self.information_gain(X, y, feature)
            if gain &gt; best_gain:
                best_feature, best_gain = feature, gain
        return best_feature
    
    def build_tree(self, X, y, depth=0):
        max_freq = Counter(y).most_common(1)[0][0] 
        
        if len(set(y)) == 1 or depth == self.max_depth:
            return Node(value=max_freq, max_sample=max_freq)
        
        best_feature = self.best_split(X, y)
        if best_feature is None:
            return Node(value=max_freq, max_sample=max_freq)
        
        node = Node(feature=best_feature, max_sample=max_freq)
        
        if best_feature in self.cat_cols:
            for val in X[best_feature].unique():
                subset_X = X[X[best_feature] == val].drop(columns=[best_feature])
                subset_y = y[X[best_feature] == val]
                node.children[val] = self.build_tree(subset_X, subset_y, depth + 1)
        else: 
            median_val = X[best_feature].median()
            node.threshold = median_val
            left_X, right_X = X[X[best_feature] &lt;= median_val], X[X[best_feature] &gt; median_val]
            left_y, right_y = y[X[best_feature] &lt;= median_val], y[X[best_feature] &gt; median_val]
            node.children['&lt;='] = self.build_tree(left_X, left_y, depth + 1)
            node.children['&gt;'] = self.build_tree(right_X, right_y, depth + 1)
        return node
    
    def fit(self, X, y):
        self.tree = self.build_tree(X, y)
    
    def predict_one(self, x, node):
        if node.value is not None:
            return node.value

        if node.feature in x:
            feature_value = x[node.feature]
            if node.threshold is not None: 
                return self.predict_one(x, node.children['&lt;='] if feature_value &lt;= node.threshold else node.children['&gt;'])
            elif feature_value in node.children: 
                return self.predict_one(x, node.children[feature_value])
            else:
                child_preds = [self.predict_one(x, child) for child in node.children.values()]
                return Counter(child_preds).most_common(1)[0][0]

        child_preds = [self.predict_one(x, child) for child in node.children.values()]
        return Counter(child_preds).most_common(1)[0][0]

    def predict(self, X):
        return np.array([self.predict_one(x, self.tree) for _, x in X.iterrows()])
    
    def annotate_with_validation(self, node, x, y_true):
        if node.value is not None:
            pred = node.value
            actual = y_true
            if pred == actual:
                if actual == 0:
                    node.val_correct_0 += 1
                else:
                    node.val_correct_1 += 1
            else:
                if actual == 0:
                    node.val_incorrect_0 += 1
                else:
                    node.val_incorrect_1 += 1
            return

        feat_val = x[node.feature]
        if node.threshold is not None:
            branch = '&lt;=' if feat_val &lt;= node.threshold else '&gt;'
        else:
            branch = feat_val if feat_val in node.children else list(node.children.keys())[0]

        self.annotate_with_validation(node.children[branch], x, y_true)
        
    def annotate_tree(self, X_val, y_val):
        for i in range(len(X_val)):
            self.annotate_with_validation(self.tree, X_val.iloc[i], y_val[i])
            
    def propagate_validation_stats(self, node):
        if node is None or node.value is not None:
            return (
                node.val_correct_0,
                node.val_correct_1,
                node.val_incorrect_0,
                node.val_incorrect_1
            )

        total_correct_0 = 0
        total_correct_1 = 0
        total_incorrect_0 = 0
        total_incorrect_1 = 0

        for child in node.children.values():
            c0, c1, ic0, ic1 = self.propagate_validation_stats(child)
            total_correct_0 += c0
            total_correct_1 += c1
            total_incorrect_0 += ic0
            total_incorrect_1 += ic1

        node.val_correct_0 = total_correct_0
        node.val_correct_1 = total_correct_1
        node.val_incorrect_0 = total_incorrect_0
        node.val_incorrect_1 = total_incorrect_1

        return (total_correct_0, total_correct_1, total_incorrect_0, total_incorrect_1)
            
    def prune_node(self, node):
        if node is None or node.value is not None:
            return

        for key in list(node.children.keys()):
            self.prune_node(node.children[key])

        correct_before = node.val_correct_0 + node.val_correct_1
        total_0 = node.val_correct_0 + node.val_incorrect_0
        total_1 = node.val_correct_1 + node.val_incorrect_1
        if total_0 + total_1 == 0:
            return

        maj_label = node.max_sample if node.max_sample is not None else 0
        if (maj_label == 0):
            correct_after = total_0
        else:
            correct_after = total_1        
            
        if correct_after &gt;= correct_before:
            node.children = {}
            node.threshold = None
            node.feature = None
            node.value = maj_label
            
            if (maj_label == 0):
                node.val_correct_0 = total_0
                node.val_incorrect_1 = total_1
                node.val_incorrect_0 = 0
                node.val_correct_1 = 0
            else:
                node.val_correct_1 = total_1
                node.val_incorrect_0 = total_0
                node.val_incorrect_1 = 0
                node.val_correct_0 = 0
                
            self.propagate_validation_stats(self.tree)
    
    def collect_internal_nodes(self, node, internal_nodes):
        if node is None or node.value is not None:
            return
        internal_nodes.append(node)
        for child in node.children.values():
            self.collect_internal_nodes(child, internal_nodes)
            
    def evaluate_prune_gain(self, node):
        correct_before = node.val_correct_0 + node.val_correct_1
        total_0 = node.val_correct_0 + node.val_incorrect_0
        total_1 = node.val_correct_1 + node.val_incorrect_1
        if total_0 + total_1 == 0:
            return 0,0,0
        

        maj_label = node.max_sample if node.max_sample is not None else 0
        
        if (maj_label == 0):
            correct_after = total_0
        else:
            correct_after = total_1
        
        return maj_label, correct_after, correct_before
    
    def greedy_prune(self, X_val, y_val):
        self.annotate_tree(X_val, y_val)
        self.propagate_validation_stats(self.tree)

        best_gain = 1  
        while best_gain &gt; 0:
            internal_nodes = []
            self.collect_internal_nodes(self.tree, internal_nodes)

            best_node = None
            best_gain = 0  

            for node in internal_nodes:
                maj_label, correct_after, correct_before = self.evaluate_prune_gain(node)
                gain = correct_after - correct_before
                if gain &gt; best_gain:
                    best_gain = gain
                    best_node = node

            if best_node:
                total_0 = best_node.val_correct_0 + best_node.val_incorrect_0
                total_1 = best_node.val_correct_1 + best_node.val_incorrect_1
                best_node.threshold = None
                best_node.feature = None
                best_node.value = maj_label
            
                if (maj_label == 0):
                    best_node.val_correct_0 = total_0
                    best_node.val_incorrect_1 = total_1
                    best_node.val_incorrect_0 = 0
                    best_node.val_correct_1 = 0
                else:
                    best_node.val_correct_1 = total_1
                    best_node.val_incorrect_0 = total_0
                    best_node.val_incorrect_1 = 0
                    best_node.val_correct_0 = 0
                
                self.propagate_validation_stats(self.tree)

def plot_accuracies(x_labels, train_acc, valid_acc, test_acc, file_name, Title, x_label):
    plt.plot(x_labels, train_acc, label="Train Accuracy", marker='o')
    plt.plot(x_labels, valid_acc, label="Validation Accuracy", marker='s')
    plt.plot(x_labels, test_acc, label="Test Accuracy", marker='^')  
    plt.xlabel(x_label)
    plt.ylabel("Accuracy")
    plt.legend()
    plt.title(Title)
    plt.savefig(file_name)
   
def preprocess_b(train_data, valid_data, test_data, test_income = True):
    train_data.columns = train_data.columns.str.strip()
    valid_data.columns = valid_data.columns.str.strip()
    test_data.columns = test_data.columns.str.strip()
    
    y_train = train_data['income'].copy()
    y_valid = valid_data['income'].copy()
    
    if (test_income):
        y_test = test_data['income'].copy()
    
    categorical_cols = train_data.select_dtypes(include=['object']).columns.drop('income')
    cat_col_names = categorical_cols.tolist()
    
    train_data = pd.get_dummies(train_data.drop(columns=['income']), columns=categorical_cols)
    valid_data = pd.get_dummies(valid_data.drop(columns=['income']), columns=categorical_cols)
    
    if ('income' in test_data.columns):
        test_data = pd.get_dummies(test_data.drop(columns=['income']), columns=categorical_cols)
    else:
        test_data = pd.get_dummies(test_data, columns=categorical_cols)

    common_cols = train_data.columns.intersection(valid_data.columns).intersection(test_data.columns)
    train_data = train_data[common_cols]
    valid_data = valid_data[common_cols]
    test_data = test_data[common_cols]

    y_train = (y_train == ' &gt;50K').astype(int)
    y_valid = (y_valid == ' &gt;50K').astype(int)
    
    if (test_income):
        y_test = (y_test == ' &gt;50K').astype(int)

    X_train, X_valid, X_test = train_data, valid_data, test_data
    
    if (test_income):
        return X_train, y_train, X_valid, y_valid, X_test, y_test, cat_col_names
    else:
        return X_train, y_train, X_valid, y_valid, X_test, cat_col_names

def q1_cmd(train_data, valid_data, test_data):
    train_data.columns = train_data.columns.str.strip()
    valid_data.columns = valid_data.columns.str.strip()
    test_data.columns = test_data.columns.str.strip()

    categorical_cols = train_data.select_dtypes(include=['object']).columns.drop('income')
    cat_col_names = categorical_cols.tolist()

    for col in categorical_cols:
        categories = train_data[col].astype('category').cat.categories
        cat_mapping = {cat: i for i, cat in enumerate(categories)}
        
        train_data[col] = train_data[col].map(cat_mapping).fillna(-1).astype(int)
        valid_data[col] = valid_data[col].map(cat_mapping).fillna(-1).astype(int)
        test_data[col] = test_data[col].map(cat_mapping).fillna(-1).astype(int)

    train_data['income'] = (train_data['income'] == ' &gt;50K').astype(int)
    valid_data['income'] = (valid_data['income'] == ' &gt;50K').astype(int)
    
    if ('income' in test_data.columns):
        test_data['income'] = (test_data['income'] == ' &gt;50K').astype(int)
    
    X_train, y_train = train_data.iloc[:, :-1], train_data.iloc[:, -1]
    X_valid, y_valid = valid_data.iloc[:, :-1], valid_data.iloc[:, -1]
    X_test = test_data.iloc[:, :-1]
    depth = 20
    start = time.time()
    tree = DCTree(cat_col_names,max_depth=depth)
    tree.fit(X_train, y_train)
    test_preds = tree.predict(X_test)
    train_preds = tree.predict(X_train)
    test_acc = accuracy_score(y_train, train_preds)
    print(f"Train Accuracy: {test_acc:.4f}, Time : {time.time()-start:.4f}")
    return test_preds

def q2_cmd(train_data, valid_data, test_data):    
    X_train, y_train, X_valid, y_valid, X_test, cat_col_names = preprocess_b(train_data, valid_data, test_data, False)
    depth = 55
    
    tree = DCTree(cat_col_names, max_depth=depth)
    tree.fit(X_train, y_train)
    print("Total Nodes: ",tree.total_nodes)
    train_preds = tree.predict(X_train)
    valid_preds = tree.predict(X_valid)
    test_preds = tree.predict(X_test)
    train_acc = accuracy_score(y_train, train_preds)
    valid_acc = accuracy_score(y_valid, valid_preds) 
    
    print(f"Depth: {depth}, Train Accuracy: {train_acc:.4f}, Validation Accuracy: {valid_acc:.4f}")
    return test_preds

def q3_cmd(train_data, valid_data, test_data):
    X_train, y_train, X_valid, y_valid, X_test, cat_cols = preprocess_b(train_data, valid_data, test_data, False)
    d = 55
    
    print("Building Tree with depth: ",d)
    tree = DCTree(categorical_features=cat_cols, max_depth=d)
    tree.fit(X_train, y_train)
    print("Total Nodes: ",tree.total_nodes)
    print("Pruning...")
    tree.annotate_tree(X_valid, y_valid)
    tree.propagate_validation_stats(tree.tree)
    tree.prune_node(tree.tree)
    # tree.greedy_prune(X_valid, y_valid)
    print("Pruning completed.")
    train_preds = tree.predict(X_train)
    valid_preds = tree.predict(X_valid)
    test_preds = tree.predict(X_test)
    train_acc = accuracy_score(y_train, train_preds)
    valid_acc = accuracy_score(y_valid, valid_preds)
    print(f"Depth {d}: Train Acc = {train_acc:.4f}, Val Acc = {valid_acc:.4f}")
    return test_preds
    
def q4_cmd(train_data, valid_data, test_data):
    X_train, y_train, X_valid, y_valid, X_test, _ = preprocess_b(train_data, valid_data, test_data, False)
    alpha = 0.001
    
    model = DecisionTreeClassifier(criterion="entropy", ccp_alpha=alpha)
    model.fit(X_train, y_train)
    train_preds = model.predict(X_train)
    valid_preds = model.predict(X_valid)
    test_preds = model.predict(X_test)
    train_acc = accuracy_score(y_train, train_preds)
    valid_acc = accuracy_score(y_valid, valid_preds)
    
    print(f"CCP Alpha: {alpha} -&gt; Train: {train_acc:.4f}, Valid: {valid_acc:.4f}")
    return test_preds

def q5_cmd(train_data, valid_data, test_data):
    X_train, y_train, X_valid, y_valid, X_test, _ = preprocess_b(train_data, valid_data, test_data, False)
    n_estimators = 350
    max_features = 0.3
    min_samples_split = 10
    
    model = RandomForestClassifier(
        n_estimators=n_estimators,
        max_features=max_features,
        min_samples_split=min_samples_split,
        oob_score=True,
        criterion='entropy',
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train, y_train)
    oob_acc = model.oob_score_
    train_preds = model.predict(X_train)
    valid_preds = model.predict(X_valid)
    test_preds = model.predict(X_test)
    train_acc = accuracy_score(y_train, train_preds)
    valid_acc = accuracy_score(y_valid, valid_preds)
        
    print(f"n_estimators={n_estimators}, max_features={max_features}, min_samples_split={min_samples_split}, Train Acc={train_acc:.4f}, OOB Acc={oob_acc:.4f}, Valid Acc={valid_acc:.4f}")
    return test_preds

def accuracy(y_true, y_pred):
    return np.mean(y_true == y_pred)


def main():
    if len(sys.argv) != 6:
        print("Usage: python decision_tree.py &lt;train_data_path&gt; &lt;validation_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
        sys.exit(1)

    train_path = sys.argv[1]
    val_path = sys.argv[2]
    test_path = sys.argv[3]
    output_folder = sys.argv[4]
    part = sys.argv[5].lower()
    train_df = pd.read_csv(train_path)
    val_df = pd.read_csv(val_path)
    test_df = pd.read_csv(test_path)
    if part == 'a':
        predictions = q1_cmd(train_df, val_df, test_df)
    elif part == 'b':
        predictions = q2_cmd(train_df, val_df, test_df)
    elif part == 'c':
        predictions = q3_cmd(train_df, val_df, test_df)
    elif part == 'd':
        predictions = q4_cmd(train_df, val_df, test_df)
    elif part == 'e':
        predictions = q5_cmd(train_df, val_df, test_df)

    if (part == 'a' or part == 'b' or part == 'c' or part == 'd' or part =='e'):
        label_map = {0: '&lt;=50K', 1: '&gt;50K'}
        predictions = [label_map[p] for p in predictions]
<A NAME="3"></A><FONT color = #00FFFF><A HREF="match96-1.html#3" TARGET="1"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        os.makedirs(output_folder, exist_ok=True)
        output_path = os.path.join(output_folder, f"prediction_{part}.csv")
        pd.DataFrame({'prediction': predictions}).to_csv(output_path, index=False)
</FONT>
if __name__ == "__main__":
    main()



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, f1_score, precision_recall_fscore_support
<A NAME="2"></A><FONT color = #0000FF><A HREF="match96-1.html#2" TARGET="1"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.neural_network import MLPClassifier
import os
import sys
import cv2
</FONT>
class NeuralNetwork:
    def __init__(self, input_size, hidden_layers, output_size, batch_size, learning_rate=0.01, activation_fxn = 'sigmoid'):
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.activation_function = activation_fxn
        self.layer_sizes = [input_size] + hidden_layers + [output_size]
        self.num_layers = len(self.layer_sizes)
        self.weights = [np.random.randn(self.layer_sizes[i + 1], self.layer_sizes[i]) * np.sqrt(1. / self.layer_sizes[i])
                        for i in range(self.num_layers - 1)]
        self.biases = [np.zeros((self.layer_sizes[i + 1], 1)) for i in range(self.num_layers - 1)]

    def sigmoid(self, z):
        return 1 / (1 + np.exp(-z))

    def sigmoid_derivative(self, z):
        s = self.sigmoid(z)
        return s * (1 - s)
    
    def relu(self, z):
        return np.maximum(0, z)
    
    def relu_derivative(self, z):
        return (z&gt;0).astype(int)

    def softmax(self, z):
        exp_z = np.exp(z - np.max(z, axis=0, keepdims=True))  
        return exp_z / np.sum(exp_z, axis=0, keepdims=True)  

    def forward(self, x):
        activations = [x]
        zs = []

        for i in range(self.num_layers - 2):
            z = self.weights[i] @ activations[-1] + self.biases[i]
            zs.append(z)
            if (self.activation_function == 'sigmoid'):
                a = self.sigmoid(z)
                activations.append(a)
            else:
                a = self.relu(z)
                activations.append(a)

        z = self.weights[-1] @ activations[-1] + self.biases[-1]
        zs.append(z)
        a = self.softmax(z)
        activations.append(a)

        return activations, zs

    def compute_loss(self, y_true, y_pred):
        m = y_true.shape[0]
        return -np.sum(y_true * np.log(y_pred + 1e-8)) / m

    def backward(self, x, y, activations, zs):
        m = x.shape[1]
        grads_w = [None] * (self.num_layers - 1)
        grads_b = [None] * (self.num_layers - 1)
        delta = activations[-1] - y
        grads_w[-1] = (delta @ activations[-2].T) / m
        grads_b[-1] = np.sum(delta, axis=1, keepdims=True) / m

        for l in range(2, self.num_layers):
            z = zs[-l]
            sp = 0
            if (self.activation_function == 'sigmoid'):
                sp = self.sigmoid_derivative(z)
            else:
                sp = self.relu_derivative(z)
            delta = (self.weights[-l + 1].T @ delta) * sp
            grads_w[-l] = (delta @ activations[-l - 1].T) / m
            grads_b[-l] = np.sum(delta, axis=1, keepdims=True) / m

        return grads_w, grads_b

    def update_parameters(self, grads_w, grads_b):
        for i in range(self.num_layers - 1):
            self.weights[i] -= self.learning_rate * grads_w[i]
<A NAME="6"></A><FONT color = #00FF00><A HREF="match96-1.html#6" TARGET="1"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

            self.biases[i] -= self.learning_rate * grads_b[i]
    
    def fit(self, X_train, Y_train, epochs=10,tolerance=1e-4, patience=5,adaptive_learning = False):
</FONT>        n_samples = X_train.shape[0]
        loss_history = []
        iterations = 4
        
        for epoch in range(epochs):
            if (adaptive_learning):
                self.learning_rate = 0.01/np.sqrt(epoch+1)

            permutation = np.random.permutation(n_samples)
            X_shuffled = X_train[permutation]
            Y_shuffled = Y_train[:, permutation]

            for i in range(0, n_samples, self.batch_size):
                start = i
                end = i + self.batch_size
                x_batch = X_shuffled[start:end].T  # shape: (input_dim, batch)
                y_batch = Y_shuffled[:, start:end]  # shape: (output_dim, batch)

                activations, zs = self.forward(x_batch)
                grads_w, grads_b = self.backward(x_batch, y_batch, activations, zs)
                self.update_parameters(grads_w, grads_b)

            output, _ = self.forward(X_train.T)
            loss = self.compute_loss(Y_train.T, output[-1].T)
            loss_history.append(loss)
            print(f"Epoch {epoch + 1}, Loss: {loss:.4f}")

            if len(loss_history) &gt;= 2 * patience:
                old_avg = np.mean(loss_history[-2*patience:-patience])
                new_avg = np.mean(loss_history[-patience:])
                # print(abs(old_avg - new_avg) , 0.01 * old_avg)
                if abs(old_avg - new_avg) &lt; 1e-3:
                    iterations += 1
                else:
                    iterations = 0
                
                if (iterations &gt;= 4):
                    print(f"Early stopping at epoch {epoch + 1}: loss change {abs(old_avg - new_avg):.6f} &lt; {tolerance}")
                    break
                
    def predict(self, X):
        output, _ = self.forward(X.T)
        return np.argmax(output[-1], axis=0)
    
    
def load_data_gtsrb_train(folder):
    X_train, y_train = [], []
    for class_id in range(43):
        class_folder = os.path.join(folder, f"{class_id:05d}")
        for img_name in os.listdir(class_folder):
            img_path = os.path.join(class_folder, img_name)
            img = cv2.imread(img_path)
            img = cv2.resize(img, (28, 28))
            X_train.append(img.flatten())
            y_train.append(class_id)
        print(f"{class_id:05d} Done")
    return np.array(X_train), np.array(y_train)

def load_data_gtsrb_test(folder, labels_csv = None):
    X_test = []
    if (labels_csv):
        df = pd.read_csv(labels_csv)
        y_test = df['label'].values
        
    for img_name in os.listdir(folder):
        img_path = os.path.join(folder, img_name)
        img = cv2.imread(img_path)
        img = cv2.resize(img, (28, 28))
        X_test.append(img.flatten())
    
    if (labels_csv):
        return np.array(X_test), np.array(y_test)
    else:
        return np.array(X_test)

def q1_cmd(train_path, test_path):
    X_train, y_train = load_data_gtsrb_train(train_path)
    X_test = load_data_gtsrb_test(test_path)
    X_train = X_train / 255.0
    X_test = X_test / 255.0
    enc = OneHotEncoder(sparse_output=False)
    y_train_onehot = enc.fit_transform(y_train.reshape(-1, 1)).T
    hidden_units = [100]
    print(f"\nTraining with {hidden_units} hidden units...")
    nn = NeuralNetwork(input_size=2352, hidden_layers=hidden_units, output_size=43, batch_size=32, learning_rate=0.01)
    nn.fit(X_train, y_train_onehot, epochs=50)
    y_train_pred = nn.predict(X_train)
    y_test_pred = nn.predict(X_test)
    train_report = classification_report(y_train, y_train_pred, output_dict=True,zero_division=0)
    print(classification_report(y_train, y_train_pred, zero_division=0))
    train_f1 = [train_report[str(i)]['f1-score'] for i in range(43)]
    train_precision = [train_report[str(i)]['precision'] for i in range(43)]
    train_recall = [train_report[str(i)]['recall'] for i in range(43)]
    train_acc = accuracy_score(y_train, y_train_pred)
    print(f"Hidden units: {hidden_units}")
    print(f"Train - Accuracy: {train_acc:.4f}, Precision: {np.mean(train_precision):.4f}, Recall: {np.mean(train_recall):.4f}, F1: {np.mean(train_f1):.4f}")
    print(f"Avg F1 (train): {np.mean(train_f1):.4f}")
    return y_test_pred

def q2_cmd(train_path, test_path):
    X_train, y_train = load_data_gtsrb_train(train_path)
    X_test = load_data_gtsrb_test(test_path)
    print("Done loading.")
    X_train = X_train / 255.0
    X_test = X_test / 255.0
    enc = OneHotEncoder(sparse_output=False)
    y_train_onehot = enc.fit_transform(y_train.reshape(-1, 1)).T
    hidden_units = [512,256,128,64]
    print(f"\nTraining with {hidden_units} hidden units...")
    nn = NeuralNetwork(input_size=2352, hidden_layers=hidden_units, output_size=43, batch_size=32, learning_rate=0.01)
    nn.fit(X_train, y_train_onehot, epochs=50)
    y_train_pred = nn.predict(X_train)
    y_test_pred = nn.predict(X_test)
    train_report = classification_report(y_train, y_train_pred, output_dict=True,zero_division=0)
    print(classification_report(y_train, y_train_pred, zero_division=0))
    train_f1 = [train_report[str(i)]['f1-score'] for i in range(43)]
    train_precision = [train_report[str(i)]['precision'] for i in range(43)]
    train_recall = [train_report[str(i)]['recall'] for i in range(43)]
    train_acc = accuracy_score(y_train, y_train_pred)
    print(f"Hidden units: {hidden_units}")
    print(f"Train - Accuracy: {train_acc:.4f}, Precision: {np.mean(train_precision):.4f}, Recall: {np.mean(train_recall):.4f}, F1: {np.mean(train_f1):.4f}")
    print(f"Avg F1 (train): {np.mean(train_f1):.4f}")
    return y_test_pred

def q3_cmd(train_path, test_path, activation_function = 'sigmoid'):
    X_train, y_train = load_data_gtsrb_train(train_path)
    X_test = load_data_gtsrb_test(test_path)
    print("Done loading.")
    X_train = X_train / 255.0
    X_test = X_test / 255.0
    enc = OneHotEncoder(sparse_output=False)
    y_train_onehot = enc.fit_transform(y_train.reshape(-1, 1)).T
    hidden_units = [512,256,128,64]
    print(f"\nTraining with {hidden_units} hidden units...")
    nn = NeuralNetwork(input_size=2352, hidden_layers=hidden_units, output_size=43, batch_size=32, learning_rate=0.01, activation_fxn=activation_function)
    nn.fit(X_train, y_train_onehot, epochs=75,adaptive_learning=True)
    y_train_pred = nn.predict(X_train)
    y_test_pred = nn.predict(X_test)
    train_report = classification_report(y_train, y_train_pred, output_dict=True, zero_division=0)
    print(classification_report(y_train, y_train_pred, zero_division=0))
    train_f1 = [train_report[str(i)]['f1-score'] for i in range(43)]
    train_precision = [train_report[str(i)]['precision'] for i in range(43)]
    train_recall = [train_report[str(i)]['recall'] for i in range(43)]
    train_acc = accuracy_score(y_train, y_train_pred)
    print(f"Hidden units: {hidden_units}")
    print(f"Train - Accuracy: {train_acc:.4f}, Precision: {np.mean(train_precision):.4f}, Recall: {np.mean(train_recall):.4f}, F1: {np.mean(train_f1):.4f}")
    print(f"Avg F1 (train): {np.mean(train_f1):.4f}")
    return y_test_pred

def q4_cmd(train_path, test_path):
    X_train, y_train = load_data_gtsrb_train(train_path)
    X_test = load_data_gtsrb_test(test_path)
    print("Done loading.")
    X_train = X_train / 255.0
    X_test = X_test / 255.0
    y_train = y_train.flatten()
    hidden_units = [512, 256, 128, 64]
    print(f"\nTraining with {hidden_units} hidden units...")
    clf = MLPClassifier(
        hidden_layer_sizes=tuple(hidden_units),
        activation='relu',
        solver='sgd',
        alpha=0.0,
        batch_size=32,
        learning_rate='invscaling',
        early_stopping=True,
        max_iter=50,
        random_state=42
    )
    clf.fit(X_train, y_train)
    y_train_pred = clf.predict(X_train)
    y_test_pred = clf.predict(X_test)
    train_report = classification_report(y_train, y_train_pred, output_dict=True, zero_division=0)
    print(classification_report(y_train, y_train_pred, zero_division=0))
    train_f1 = [train_report[str(i)]['f1-score'] for i in range(43)]
    train_precision = [train_report[str(i)]['precision'] for i in range(43)]
    train_recall = [train_report[str(i)]['recall'] for i in range(43)]
    train_acc = accuracy_score(y_train, y_train_pred)
    print(f"Hidden units: {hidden_units}")
    print(f"Train - Accuracy: {train_acc:.4f}, Precision: {np.mean(train_precision):.4f}, Recall: {np.mean(train_recall):.4f}, F1: {np.mean(train_f1):.4f}")
    print(f"Avg F1 (train): {np.mean(train_f1):.4f}")
    return y_test_pred

def main():
    if len(sys.argv) != 5:
        print("Usage: python decision_tree.py &lt;train_data_path&gt; &lt;validation_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
        sys.exit(1)

    train_path = sys.argv[1]
    test_path = sys.argv[2]
    output_folder = sys.argv[3]
    part = sys.argv[4].lower()

    if part == 'b':
        predictions = q1_cmd(train_path, test_path)
    elif part == 'c':
        predictions = q2_cmd(train_path, test_path)
    elif part == 'd':
        predictions = q3_cmd(train_path, test_path)
    elif part == 'e':
        predictions = q3_cmd(train_path, test_path, 'relu')
    elif part == 'f':
        predictions = q4_cmd(train_path, test_path)
    
<A NAME="4"></A><FONT color = #FF00FF><A HREF="match96-1.html#4" TARGET="1"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    os.makedirs(output_folder, exist_ok=True)
    output_path = os.path.join(output_folder, f"prediction_{part}.csv")
    pd.DataFrame({'prediction': predictions}).to_csv(output_path, index=False)
</FONT>
if __name__ == "__main__":
    main()


</PRE>
</PRE>
</BODY>
</HTML>
