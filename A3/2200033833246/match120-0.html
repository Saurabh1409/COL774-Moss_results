<HTML>
<HEAD>
<TITLE>./A3_processed_new_hash/combined_0VNUY.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A3_processed_new_hash/combined_0VNUY.py<p><PRE>


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sys
<A NAME="3"></A><FONT color = #00FFFF><A HREF="match120-1.html#3" TARGET="1"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

import os
import copy

# Define Node class for our decision tree
class Node:
    def __init__(self, attribute=None, threshold=None, is_leaf=False, value=None, class_distribution=None):
        self.attribute = attribute  # Attribute to split on
</FONT>        self.threshold = threshold  # Threshold value for numerical attributes
        self.is_leaf = is_leaf      # Flag to indicate if the node is a leaf
        self.value = value          # Prediction value for leaf nodes
        self.children = {}          # Dictionary to store child nodes for categorical attributes
        self.left = None            # Left child for numerical attributes (&lt;= threshold)
        self.right = None           # Right child for numerical attributes (&gt; threshold)
        self.class_distribution = class_distribution 

# Define DecisionTree class
class DecisionTree:
    def __init__(self, max_depth=None):
        self.root = None
        self.max_depth = max_depth
        self.categorical_attributes = []
        self.numerical_attributes = []
        
    def fit(self, X, y, categorical_attrs=None, numerical_attrs=None):
        # Identify categorical and numerical attributes if not provided
        if categorical_attrs is None or numerical_attrs is None:
            self._identify_attribute_types(X)
        else:
            self.categorical_attributes = categorical_attrs
            self.numerical_attributes = numerical_attrs
        
        # Build the tree
        self.root = self._build_tree(X, y, depth=0)
        
        return self
    
    def _identify_attribute_types(self, X):
        self.categorical_attributes = []
        self.numerical_attributes = []
        
        for i in range(X.shape[1]):
            if X.iloc[:, i].dtype == 'object' or X.iloc[:, i].dtype == 'category':
                self.categorical_attributes.append(i)
            else:
                self.numerical_attributes.append(i)
    
    def _calculate_entropy(self, y):
        _, counts = np.unique(y, return_counts=True)
        probabilities = counts / len(y)
        
        entropy = -np.sum(probabilities * np.log2(probabilities + 1e-10))
        
        return entropy
    
    def _calculate_mutual_information(self, X, y, attribute_idx):
        
        parent_entropy = self._calculate_entropy(y)
        
        if attribute_idx in self.categorical_attributes:
            attribute_values = X.iloc[:, attribute_idx].unique()
            
            weighted_entropy = 0
            for value in attribute_values:
                subset_indices = X.iloc[:, attribute_idx] == value
                subset_y = y[subset_indices]
                
                if len(subset_y) == 0:
                    continue
                weight = len(subset_y) / len(y)
                
                subset_entropy = self._calculate_entropy(subset_y)
                
                weighted_entropy += weight * subset_entropy
            
            mutual_info = parent_entropy - weighted_entropy
            
            return mutual_info, None
            
        else:
            values = X.iloc[:, attribute_idx].values
            median_value = np.median(values)
            
            left_indices = X.iloc[:, attribute_idx] &lt;= median_value
            right_indices = ~left_indices
            
            left_y = y[left_indices]
            right_y = y[right_indices]
            
            left_weight = len(left_y) / len(y)
            right_weight = len(right_y) / len(y)
            
            left_entropy = self._calculate_entropy(left_y)
            right_entropy = self._calculate_entropy(right_y)
            
            weighted_entropy = left_weight * left_entropy + right_weight * right_entropy
            
            mutual_info = parent_entropy - weighted_entropy
            
            return mutual_info, median_value
    
    def _find_best_attribute(self, X, y):
        
        best_attribute = None
        best_threshold = None
        best_mutual_info = -1
        
        for i in range(X.shape[1]):
            mutual_info, threshold = self._calculate_mutual_information(X, y, i)
            
            if mutual_info &gt; best_mutual_info:
                best_attribute = i
                best_threshold = threshold
                best_mutual_info = mutual_info
        
        return best_attribute, best_threshold, best_mutual_info
    
    def _build_tree(self, X, y, depth=0):
        
        class_dist = pd.Series(y).value_counts().to_dict()
        
        if len(np.unique(y)) == 1:
            return Node(is_leaf=True, value=y.iloc[0], class_distribution=class_dist)
        
        if self.max_depth is not None and depth &gt;= self.max_depth:
            most_common_class = pd.Series(y).mode()[0] if isinstance(y, pd.Series) else np.bincount(y).argmax()
            return Node(is_leaf=True, value=most_common_class)
        
        if X.shape[0] == 0 or X.shape[1] == 0:
            most_common_class = pd.Series(y).mode()[0] if isinstance(y, pd.Series) else np.bincount(y).argmax()
            return Node(is_leaf=True, value=most_common_class)
        
        best_attribute, best_threshold, best_mutual_info = self._find_best_attribute(X, y)
        
        if best_mutual_info &lt;= 0:
            most_common_class = pd.Series(y).mode()[0] if isinstance(y, pd.Series) else np.bincount(y).argmax()
            return Node(is_leaf=True, value=most_common_class)
        
        node = Node(attribute=best_attribute, threshold=best_threshold, class_distribution=class_dist)
        
        if best_attribute in self.categorical_attributes:
            unique_values = X.iloc[:, best_attribute].unique()
            
            for value in unique_values:
                mask = X.iloc[:, best_attribute] == value
                
                if mask.sum() == 0:
                    continue
                
                subset_X = X[mask].reset_index(drop=True)
<A NAME="5"></A><FONT color = #FF0000><A HREF="match120-1.html#5" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

                subset_y = y[mask].reset_index(drop=True) if isinstance(y, pd.Series) else y[mask]
                
                node.children[value] = self._build_tree(subset_X, subset_y, depth + 1)
        else:
            left_mask = X.iloc[:, best_attribute] &lt;= best_threshold
</FONT>            right_mask = ~left_mask
            
            left_X = X[left_mask].reset_index(drop=True)
            left_y = y[left_mask].reset_index(drop=True) if isinstance(y, pd.Series) else y[left_mask]
            
            right_X = X[right_mask].reset_index(drop=True)
            right_y = y[right_mask].reset_index(drop=True) if isinstance(y, pd.Series) else y[right_mask]
            
            node.left = self._build_tree(left_X, left_y, depth + 1)
            node.right = self._build_tree(right_X, right_y, depth + 1)
        
        return node
    
    def predict(self, X):
        predictions = [self._predict_single(x, self.root) for _, x in X.iterrows()]
        return np.array(predictions)
    
    def _predict_single(self, x, node):
        
        if node.is_leaf:
            return node.value
        
        attribute_value = x.iloc[node.attribute] if isinstance(x, pd.Series) else x[node.attribute]
        
        if node.attribute in self.categorical_attributes:
            if attribute_value in node.children:
                return self._predict_single(x, node.children[attribute_value])
            else:
                most_common_values = [child.value for child in node.children.values() if child.is_leaf]
                if most_common_values:
                    return max(set(most_common_values), key=most_common_values.count)
                else:
                    first_child = next(iter(node.children.values()))
                    return self._predict_single(x, first_child)
        else:
            if attribute_value &lt;= node.threshold:
                return self._predict_single(x, node.left)
            else:
                return self._predict_single(x, node.right)

    def count_nodes(self):
        
        return self._count_nodes(self.root)
    
    def _count_nodes(self, node):
        
        if node is None:
            return 0
        
        if node.is_leaf:
            return 1
        
        if node.attribute in self.categorical_attributes:
            return 1 + sum(self._count_nodes(child) for child in node.children.values())
        else:
            return 1 + self._count_nodes(node.left) + self._count_nodes(node.right)

def calculate_accuracy(y_true, y_pred):
    return np.mean(y_true == y_pred)

def part_a(train_data, valid_data, test_data, output_path):
    
    train_data['income'] = train_data['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
    valid_data['income'] = valid_data['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
    test_data['income'] = test_data['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
    
    X_train = train_data.iloc[:, :-1]
    y_train = train_data.iloc[:, -1]
    
    X_test = test_data.iloc[:, :-1]
    y_test = test_data.iloc[:, -1]

    X_valid = valid_data.iloc[:, :-1]
<A NAME="0"></A><FONT color = #FF0000><A HREF="match120-1.html#0" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    y_valid = valid_data.iloc[:, -1]
    
    max_depths = [5, 10, 15, 20]
    train_accuracies = []
    test_accuracies = []
    valid_accuracies = []
    
    for depth in max_depths:
        tree = DecisionTree(max_depth=depth)
</FONT>        tree.fit(X_train, y_train)
        
        train_pred = tree.predict(X_train)
        test_pred = tree.predict(X_test)
        val_pred = tree.predict(X_valid)
        
        train_acc = calculate_accuracy(y_train, train_pred)
        test_acc = calculate_accuracy(y_test, test_pred)
        valid_acc = calculate_accuracy(y_valid, val_pred)
        
        train_accuracies.append(train_acc)
        test_accuracies.append(test_acc)
        valid_accuracies.append(valid_acc)

        test_pred_str = ['&gt;50K' if pred == 1 else '&lt;=50K' for pred in test_pred]
        
        print(f"Max Depth: {depth}")
        print(f"Train Accuracy: {train_acc:.4f}")
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Validation accuracy : {valid_acc:.4f}")
        print()
        
        pd.DataFrame({'prediction': test_pred_str}).to_csv(
            os.path.join(output_path, f'prediction_a_{depth}.csv'), index=False
        )

    pd.DataFrame({'prediction': test_pred_str}).to_csv(
        os.path.join(output_path, 'prediction_a.csv'), index=False
    )
    
    plt.figure(figsize=(10, 6))
    plt.plot(max_depths, train_accuracies, 'o-', label='Train Accuracy')
    plt.plot(max_depths, test_accuracies, 'o-', label='Test Accuracy')
    plt.plot(max_depths, valid_accuracies, 'o-', label = 'Valid Accuracies')
    plt.xlabel('Maximum Depth')
    plt.ylabel('Accuracy')
    plt.title('Accuracy vs. Maximum Depth')
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(output_path, 'accuracy_vs_depth_a.png'))
    plt.close()
    
    return train_accuracies, test_accuracies, max_depths

def one_hot_encode(data):
    encoded_data = data.copy()
    
    categorical_cols = encoded_data.select_dtypes(include=['object', 'category']).columns
    
    for col in categorical_cols:
        if col == 'income':
            continue
            
        unique_values = encoded_data[col].unique()
        if len(unique_values) &gt;= 2:
            # Create one-hot encoded columns
            for value in unique_values:
                new_col_name = f"{col}_{value}"
                encoded_data[new_col_name] = (encoded_data[col] == value).astype(int)
            
            # Remove the original column
            encoded_data = encoded_data.drop(col, axis=1)
            
        
    return encoded_data

def part_b(train_data, valid_data, test_data, output_path):
    
    # Convert the target variable to binary (0 for "&lt;=50K", 1 for "&gt;50K")
    train_data['income'] = train_data['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
    valid_data['income'] = valid_data['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
    test_data['income'] = test_data['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
    
    # Save the target variables before one-hot encoding
    y_train = train_data['income']
    y_valid = valid_data['income']
    y_test = test_data['income']
    
    # Remove target variable before one-hot encoding
    X_train = train_data.drop('income', axis=1)
    X_valid = valid_data.drop('income', axis=1)
    X_test = test_data.drop('income', axis=1)
    
    # Apply one-hot encoding to features only
    encoded_X_train = one_hot_encode(X_train)
    encoded_X_valid = one_hot_encode(X_valid)
    encoded_X_test = one_hot_encode(X_test)

    print(f"train no of columns {encoded_X_train.shape[1]} ")
    
    # Ensure that test and validation data have the same columns as train data
    train_columns = set(encoded_X_train.columns)
    
    for dataset in [encoded_X_valid, encoded_X_test]:
        # Add missing columns with zeros
        for col in train_columns:
            if col not in dataset.columns:
                dataset[col] = 0
        
        # Remove extra columns that aren't in the training data
        extra_cols = [col for col in dataset.columns if col not in train_columns]
        if extra_cols:
            dataset.drop(extra_cols, axis=1, inplace=True)
    
    # Ensure columns are in the same order
    encoded_X_valid = encoded_X_valid[encoded_X_train.columns]
    encoded_X_test = encoded_X_test[encoded_X_train.columns]
    
    # Experiment with different maximum depths
    max_depths = [25, 35, 45, 55]
    train_accuracies = []
    test_accuracies = []
    valid_accuracies = []
    
    for depth in max_depths:
        # Create and train a decision tree
        tree = DecisionTree(max_depth=depth)
        tree.fit(encoded_X_train, y_train)
        
        # Make predictions
        train_pred = tree.predict(encoded_X_train)
        test_pred = tree.predict(encoded_X_test)
        valid_pred = tree.predict(encoded_X_valid)
        
        # Calculate accuracies
        train_acc = calculate_accuracy(y_train, train_pred)
        test_acc = calculate_accuracy(y_test, test_pred)
        valid_acc = calculate_accuracy(y_valid, valid_pred)
        
        # Store accuracies
        train_accuracies.append(train_acc)
        test_accuracies.append(test_acc)
        valid_accuracies.append(valid_acc)


        test_pred_str = ['&gt;50K' if pred == 1 else '&lt;=50K' for pred in test_pred]
        
        print(f"Max Depth: {depth}")
        print(f"Train Accuracy: {train_acc:.4f}")
        print(f"Test Accuracy: {test_acc:.4f}")
        print(f"Valid Accuracy: {valid_acc:.4f}")
        print()
        
        # Save test predictions for this depth
        pd.DataFrame({'prediction': test_pred_str}).to_csv(
            os.path.join(output_path, f'prediction_b_{depth}.csv'), index=False
        )
    
    
    # Save the final predictions as required by the auto-evaluation
    pd.DataFrame({'prediction': test_pred_str}).to_csv(
        os.path.join(output_path, 'prediction_b.csv'), index=False
    )
    
    # Plot accuracies
    plt.figure(figsize=(10, 6))
    plt.plot(max_depths, train_accuracies, 'o-', label='Train Accuracy')
    plt.plot(max_depths, test_accuracies, 'o-', label='Test Accuracy')
    plt.plot(max_depths, valid_accuracies, 'o-', label='Validation Accuracy')
    plt.xlabel('Maximum Depth')
    plt.ylabel('Accuracy')
    plt.title('Accuracy vs. Maximum Depth (One-Hot Encoding)')
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(output_path, 'accuracy_vs_depth_b.png'))
    plt.close()
    
    return train_accuracies, test_accuracies, max_depths

def part_c(train_data, valid_data, test_data, output_path):
    
    # Convert the target variable to binary (0 for "&lt;=50K", 1 for "&gt;50K")
    train_data['income'] = train_data['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
    valid_data['income'] = valid_data['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
    test_data['income'] = test_data['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
    
    # Save the target variables before one-hot encoding
    y_train = train_data['income']
    y_valid = valid_data['income']
    y_test = test_data['income']
    
    # Remove target variable before one-hot encoding
    X_train = train_data.drop('income', axis=1)
    X_valid = valid_data.drop('income', axis=1)
    X_test = test_data.drop('income', axis=1)
    
    # Apply one-hot encoding to features only
    encoded_X_train = one_hot_encode(X_train)
    encoded_X_valid = one_hot_encode(X_valid)
    encoded_X_test = one_hot_encode(X_test)
    
    # Ensure that validation and test data have the same columns as train data
    train_columns = set(encoded_X_train.columns)
    
    for dataset in [encoded_X_valid, encoded_X_test]:
        # Add missing columns with zeros
        for col in train_columns:
            if col not in dataset.columns:
                dataset[col] = 0
        
        # Remove extra columns that aren't in the training data
        extra_cols = [col for col in dataset.columns if col not in train_columns]
        if extra_cols:
            dataset.drop(extra_cols, axis=1, inplace=True)
    
    # Ensure columns are in the same order
    encoded_X_valid = encoded_X_valid[encoded_X_train.columns]
    encoded_X_test = encoded_X_test[encoded_X_train.columns]
    
    # Maximum depths to experiment with (same as part b)
    max_depths = [25, 35, 45, 55]
    
    # Store results for plotting
    results = []
    
    for depth in max_depths:
        print(f"\nProcessing tree with max_depth = {depth}")
        
        # Create and train a decision tree
        tree = DecisionTree(max_depth=depth)
<A NAME="4"></A><FONT color = #FF00FF><A HREF="match120-1.html#4" TARGET="1"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        tree.fit(encoded_X_train, y_train)
        
        # Initial node count and accuracies before pruning
        initial_node_count = tree.count_nodes()
        
        # Initial predictions and accuracies
        train_pred = tree.predict(encoded_X_train)
        valid_pred = tree.predict(encoded_X_valid)
        test_pred = tree.predict(encoded_X_test)
        
        train_acc = calculate_accuracy(y_train, train_pred)
</FONT>        valid_acc = calculate_accuracy(y_valid, valid_pred)
        test_acc = calculate_accuracy(y_test, test_pred)

        
        print(f"Initial - Nodes: {initial_node_count}, Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, Test: {test_acc:.4f}")
        
        # Store initial results
        results.append({
            'depth': depth,
            'node_count': initial_node_count,
            'train_acc': train_acc,
            'valid_acc': valid_acc,
            'test_acc': test_acc,
            'pruned': False
        })
        
        # Post-pruning using validation set
        pruned_tree = post_prune_tree(tree, encoded_X_valid, y_valid, encoded_X_train, y_train, encoded_X_test, y_test)
        
        # Final node count after pruning
        final_node_count = pruned_tree.count_nodes()
        
        # Final predictions and accuracies
        train_pred = pruned_tree.predict(encoded_X_train)
        valid_pred = pruned_tree.predict(encoded_X_valid)
        test_pred = pruned_tree.predict(encoded_X_test)
        
        train_acc = calculate_accuracy(y_train, train_pred)
        valid_acc = calculate_accuracy(y_valid, valid_pred)
        test_acc = calculate_accuracy(y_test, test_pred)
        
        print(f"After Pruning - Nodes: {final_node_count}, Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, Test: {test_acc:.4f}")
        
        # Store final results
        results.append({
            'depth': depth,
            'node_count': final_node_count,
            'train_acc': train_acc,
            'valid_acc': valid_acc,
            'test_acc': test_acc,
            'pruned': True
        })
        test_pred_str = ['&gt;50K' if pred == 1 else '&lt;=50K' for pred in test_pred]
        # Save test predictions for this depth after pruning
        pd.DataFrame({'prediction': test_pred_str}).to_csv(
            os.path.join(output_path, f'prediction_c_{depth}.csv'), index=False
        )
    
    # Save the final predictions as required by the auto-evaluation (using the last depth)
    pd.DataFrame({'prediction': test_pred_str}).to_csv(
        os.path.join(output_path, 'prediction_c.csv'), index=False
    )
    
    # Create results DataFrame for plotting
    results_df = pd.DataFrame(results)
    
    # Plot accuracies vs node count for each original and pruned tree
    plt.figure(figsize=(12, 8))
    
    # Plot original trees (larger markers)
    original_trees = results_df[~results_df['pruned']]
    plt.scatter(original_trees['node_count'], original_trees['train_acc'], marker='o', s=100, label='Original Train', color='blue')
    plt.scatter(original_trees['node_count'], original_trees['valid_acc'], marker='o', s=100, label='Original Valid', color='green')
    plt.scatter(original_trees['node_count'], original_trees['test_acc'], marker='o', s=100, label='Original Test', color='red')
    
    # Plot pruned trees (smaller markers)
    pruned_trees = results_df[results_df['pruned']]
    plt.scatter(pruned_trees['node_count'], pruned_trees['train_acc'], marker='x', s=80, label='Pruned Train', color='blue')
    plt.scatter(pruned_trees['node_count'], pruned_trees['valid_acc'], marker='x', s=80, label='Pruned Valid', color='green')
    plt.scatter(pruned_trees['node_count'], pruned_trees['test_acc'], marker='x', s=80, label='Pruned Test', color='red')
    
    # Connect original and pruned trees for each depth with lines
    for depth in max_depths:
        orig = results_df[(results_df['depth'] == depth) & (~results_df['pruned'])]
        pruned = results_df[(results_df['depth'] == depth) & (results_df['pruned'])]
        
        # Connect train accuracies
        plt.plot([orig['node_count'].values[0], pruned['node_count'].values[0]], 
                [orig['train_acc'].values[0], pruned['train_acc'].values[0]], 
                'b--', alpha=0.5)
        
        # Connect valid accuracies
        plt.plot([orig['node_count'].values[0], pruned['node_count'].values[0]], 
                [orig['valid_acc'].values[0], pruned['valid_acc'].values[0]], 
                'g--', alpha=0.5)
        
        # Connect test accuracies
        plt.plot([orig['node_count'].values[0], pruned['node_count'].values[0]], 
                [orig['test_acc'].values[0], pruned['test_acc'].values[0]], 
                'r--', alpha=0.5)
    
    plt.xlabel('Number of Nodes')
    plt.ylabel('Accuracy')
    plt.title('Accuracy vs Number of Nodes (Before and After Pruning)')
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(output_path, 'accuracy_vs_nodes_c.png'))
    plt.close()


    # Generate separate plots for each max_depth
    for depth in max_depths:
        plt.figure(figsize=(8, 6))

        orig = results_df[(results_df['depth'] == depth) & (~results_df['pruned'])]
        pruned = results_df[(results_df['depth'] == depth) & (results_df['pruned'])]

        if not orig.empty:
            plt.scatter(orig['node_count'], orig['train_acc'], marker='o', s=100, label='Original Train', color='blue')
            plt.scatter(orig['node_count'], orig['valid_acc'], marker='o', s=100, label='Original Valid', color='green')
            plt.scatter(orig['node_count'], orig['test_acc'], marker='o', s=100, label='Original Test', color='red')

        if not pruned.empty:
            plt.scatter(pruned['node_count'], pruned['train_acc'], marker='x', s=80, label='Pruned Train', color='blue')
            plt.scatter(pruned['node_count'], pruned['valid_acc'], marker='x', s=80, label='Pruned Valid', color='green')
            plt.scatter(pruned['node_count'], pruned['test_acc'], marker='x', s=80, label='Pruned Test', color='red')

        if not orig.empty and not pruned.empty:
            plt.plot([orig['node_count'].values[0], pruned['node_count'].values[0]], 
                    [orig['train_acc'].values[0], pruned['train_acc'].values[0]], 
                    'b--', alpha=0.5)
            plt.plot([orig['node_count'].values[0], pruned['node_count'].values[0]], 
                    [orig['valid_acc'].values[0], pruned['valid_acc'].values[0]], 
                    'g--', alpha=0.5)
            plt.plot([orig['node_count'].values[0], pruned['node_count'].values[0]], 
                    [orig['test_acc'].values[0], pruned['test_acc'].values[0]], 
                    'r--', alpha=0.5)

        plt.xlabel('Number of Nodes')
        plt.ylabel('Accuracy')
        plt.title(f'Accuracy vs Number of Nodes (Depth={depth})')
        plt.legend()
        plt.grid(True)
        plt.savefig(os.path.join(output_path, f'accuracy_vs_nodes_depth_{depth}.png'))
        plt.close()

    
    return results_df

from collections import defaultdict

def post_prune_tree(tree, X_valid, y_valid, X_train, y_train, X_test, y_test):
    pruned_tree = copy.deepcopy(tree)
    y_valid = pd.Series(y_valid).reset_index(drop=True)
    total_examples = len(y_valid)
    
    improved = True
    while improved:
        improved = False
        best_delta = 0
        best_node = None
        best_majority = None
        
        # Precompute current paths and node-example mappings
        node_example_map = defaultdict(set)
        example_predictions = []
        for idx, (_, example) in enumerate(X_valid.iterrows()):
            path = []
            current_node = pruned_tree.root
            prediction = None
            while True:
                path.append(current_node)
                if current_node.is_leaf:
                    prediction = current_node.value
                    break
                attr_val = example.iloc[current_node.attribute]
                if current_node.attribute in pruned_tree.categorical_attributes:
                    if attr_val in current_node.children:
                        current_node = current_node.children[attr_val]
                    else:
                        # Handle unseen values using majority class
                        prediction = max(current_node.class_distribution, key=current_node.class_distribution.get)
                        break
                else:
                    if attr_val &lt;= current_node.threshold:
                        current_node = current_node.left
                    else:
                        current_node = current_node.right
                if current_node is None:
                    prediction = max(path[-1].class_distribution, key=path[-1].class_distribution.get)
                    break
            example_predictions.append(prediction)
            for node in path:
                node_example_map[node].add(idx)
        
        # Collect non-leaf nodes
        non_leaf_nodes = get_non_leaf_nodes(pruned_tree.root, pruned_tree)
        
        # Evaluate each non-leaf node
        for node in non_leaf_nodes:
            if node not in node_example_map:
                continue
            majority = max(node.class_distribution, key=node.class_distribution.get)
            example_indices = node_example_map[node]
            delta = 0
            for idx in example_indices:
                original_correct = (example_predictions[idx] == y_valid[idx])
                new_correct = (majority == y_valid[idx])
                delta += (new_correct.astype(int) - original_correct.astype(int))
            delta /= total_examples
            
            if delta &gt; best_delta:
                best_delta = delta
                best_node = node
                best_majority = majority
        
        # Prune the best node if improves accuracy
        if best_delta &gt; 0:
            best_node.is_leaf = True
            best_node.value = best_majority
            best_node.children = {}
            best_node.left = None
            best_node.right = None
            improved = True
            
    return pruned_tree
def get_non_leaf_nodes(node, tree, nodes=None):
    if nodes is None:
        nodes = []
    if node is None or node.is_leaf:
        return nodes
    nodes.append(node)
    if node.attribute in tree.categorical_attributes:
        for child in node.children.values():
            get_non_leaf_nodes(child, tree, nodes)
    else:
        get_non_leaf_nodes(node.left, tree, nodes)
        get_non_leaf_nodes(node.right, tree, nodes)
    return nodes

def get_majority_class_at_node(node, X, y, tree, memo=None):
    if memo is None:
        memo = {}
    
    if node in memo:
        return memo[node]
    
    # Simplified - in practice you'd want to track the actual examples that reach this node
    majority_class = pd.Series(y).mode()[0]
    memo[node] = majority_class
    return majority_class

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

def part_d(train_data, valid_data, test_data, output_path):
   
    # Convert target variable to binary
    for df in [train_data, valid_data, test_data]:
        df['income'] = df['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
    
    # Separate features and target
    X_train_raw = train_data.drop('income', axis=1)
    y_train = train_data['income']
    
    X_valid_raw = valid_data.drop('income', axis=1)
    y_valid = valid_data['income']
    
    X_test_raw = test_data.drop('income', axis=1)
    y_test = test_data['income']

    # Apply one-hot encoding (same as part b)
    X_train = one_hot_encode(X_train_raw)
    X_valid = one_hot_encode(X_valid_raw)
    X_test = one_hot_encode(X_test_raw)
    
    # Align columns across datasets
    train_columns = set(X_train.columns)
    for dataset in [X_valid, X_test]:
        # Add missing columns
        for col in train_columns:
            if col not in dataset.columns:
                dataset[col] = 0
        # Remove extra columns
        extra_cols = [col for col in dataset.columns if col not in train_columns]
        if extra_cols:
            dataset.drop(extra_cols, axis=1, inplace=True)
        # Ensure column order matches
        dataset = dataset[X_train.columns]
    
    # Convert to numpy arrays for scikit-learn
    X_train = X_train.values
    X_valid = X_valid.values
    X_test = X_test.values
    y_train = y_train.values
    y_valid = y_valid.values
    y_test = y_test.values
    
    # Part (i): Vary max_depth
    max_depths = [25, 35, 45, 55]
    results_i = []
    
    for depth in max_depths:
        clf = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=27)
        clf.fit(X_train, y_train)
        
        # Calculate accuracies
        train_acc = accuracy_score(y_train, clf.predict(X_train))
        valid_acc = accuracy_score(y_valid, clf.predict(X_valid))
        test_acc = accuracy_score(y_test, clf.predict(X_test))
        
        results_i.append({
            'max_depth': depth,
            'train_acc': train_acc,
            'valid_acc': valid_acc,
            'test_acc': test_acc,
            'nodes': clf.tree_.node_count
        })
        
        print(f"Depth {depth}: Train={train_acc:.4f}, Valid={valid_acc:.4f}, Test={test_acc:.4f}, Nodes={clf.tree_.node_count}")
    
    # Find best depth based on validation accuracy
    best_depth = max(results_i, key=lambda x: x['valid_acc'])['max_depth']
    
    # Plot results for part (i)
    plt.figure(figsize=(10, 6))
    plt.plot([r['max_depth'] for r in results_i], [r['train_acc'] for r in results_i], 'o-', label='Train')
    plt.plot([r['max_depth'] for r in results_i], [r['valid_acc'] for r in results_i], 'o-', label='Validation')
    plt.plot([r['max_depth'] for r in results_i], [r['test_acc'] for r in results_i], 'o-', label='Test')
    plt.xlabel('Max Depth')
    plt.ylabel('Accuracy')
    plt.title('Accuracy vs Max Depth (Sci-kit Learn)')
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(output_path, 'd_part_i.png'))
    plt.close()
    
    # Part (ii): Vary ccp_alpha
    ccp_alphas = [0.001, 0.01, 0.1, 0.2]
    results_ii = []
    
    for ccp_alpha in ccp_alphas:
        clf = DecisionTreeClassifier(criterion='entropy', ccp_alpha=ccp_alpha, random_state=42)
        clf.fit(X_train, y_train)
        
        # Calculate accuracies
        train_acc = accuracy_score(y_train, clf.predict(X_train))
        valid_acc = accuracy_score(y_valid, clf.predict(X_valid))
        test_acc = accuracy_score(y_test, clf.predict(X_test))
        
        results_ii.append({
            'ccp_alpha': ccp_alpha,
            'train_acc': train_acc,
            'valid_acc': valid_acc,
            'test_acc': test_acc,
            'nodes': clf.tree_.node_count
        })
        
        print(f"CCP Alpha {ccp_alpha}: Train={train_acc:.4f}, Valid={valid_acc:.4f}, Test={test_acc:.4f}, Nodes={clf.tree_.node_count}")
    
    # Find best ccp_alpha based on validation accuracy
    best_ccp = max(results_ii, key=lambda x: x['valid_acc'])['ccp_alpha']
    
    # Plot results for part (ii)
    plt.figure(figsize=(10, 6))
    plt.plot([r['ccp_alpha'] for r in results_ii], [r['train_acc'] for r in results_ii], 'o-', label='Train')
    plt.plot([r['ccp_alpha'] for r in results_ii], [r['valid_acc'] for r in results_ii], 'o-', label='Validation')
    plt.plot([r['ccp_alpha'] for r in results_ii], [r['test_acc'] for r in results_ii], 'o-', label='Test')
    plt.xlabel('CCP Alpha')
    plt.ylabel('Accuracy')
    plt.title('Accuracy vs CCP Alpha (Sci-kit Learn)')
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(output_path, 'd_part_ii.png'))
    plt.close()
    
    # Comparison with previous parts
    print("\nFinal Comparison:")
    print(f"Sci-kit Learn (Best Depth {best_depth}): Test Accuracy = {max(results_i, key=lambda x: x['valid_acc'])['test_acc']:.4f}")
    print(f"Sci-kit Learn (Best CCP {best_ccp}): Test Accuracy = {max(results_ii, key=lambda x: x['valid_acc'])['test_acc']:.4f}")
    
    #  Save the final predictions using the best ccp_alpha
    final_model = DecisionTreeClassifier(criterion='entropy', ccp_alpha=best_ccp, random_state=42)
    final_model.fit(X_train, y_train)
    test_predictions = final_model.predict(X_test)
    
    # Map predictions to strings
    test_pred_str = ['&gt;50K' if pred == 1 else '&lt;=50K' for pred in test_predictions]
    
    # Save predictions to a CSV file
    pd.DataFrame({'prediction': test_pred_str}).to_csv(
        os.path.join(output_path, 'prediction_d.csv'), index=False
    )

    return results_i, results_ii

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

def part_e(train_data, valid_data, test_data, output_path):
    
    # Convert target variable to binary
    train_data['income'] = train_data['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
    valid_data['income'] = valid_data['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
    test_data['income'] = test_data['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
    
    # Save the target variables
    y_train = train_data['income']
    y_valid = valid_data['income']
    y_test = test_data['income']
    
    # Remove target variable before one-hot encoding
    X_train_raw = train_data.drop('income', axis=1)
    X_valid_raw = valid_data.drop('income', axis=1)
    X_test_raw = test_data.drop('income', axis=1)
    
    # Apply one-hot encoding to features only (same as part b/c/d)
    encoded_X_train = one_hot_encode(X_train_raw)
    encoded_X_valid = one_hot_encode(X_valid_raw)
    encoded_X_test = one_hot_encode(X_test_raw)
    
    # Ensure validation/test columns match training data
    train_columns = set(encoded_X_train.columns)
    for dataset in [encoded_X_valid, encoded_X_test]:
        # Add missing columns
        for col in train_columns:
            if col not in dataset.columns:
                dataset[col] = 0
        # Remove extra columns
        extra_cols = [col for col in dataset.columns if col not in train_columns]
        if extra_cols:
            dataset.drop(extra_cols, axis=1, inplace=True)
        # Reorder columns
        dataset = dataset[encoded_X_train.columns]
    
    # Convert to numpy arrays for sklearn
    X_train = encoded_X_train.values
    X_valid = encoded_X_valid.values
    X_test = encoded_X_test.values
    y_train = y_train.values
    y_valid = y_valid.values
    y_test = y_test.values
    
    # Parameter grid for grid search
    param_grid = {
        'n_estimators': [50, 150, 250, 350],
        'max_features': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0],
        'min_samples_split': [2, 4, 6, 8, 10]
    }
    
    best_oob = -1
    best_params = None
    best_model = None
    
    # Grid search over parameters using OOB accuracy
    print("Starting grid search for Random Forest...")
    for n_est in param_grid['n_estimators']:
        for mf in param_grid['max_features']:
            for mss in param_grid['min_samples_split']:
                print(f"n_estimators={n_est}, max_features={mf}, min_samples_split={mss}")
                rf = RandomForestClassifier(
                    n_estimators=n_est,
                    max_features=mf,
                    min_samples_split=mss,
                    criterion='entropy',
                    oob_score=True,
                    n_jobs=-1,
                    random_state=42
                )
                rf.fit(X_train, y_train)
                oob_acc = rf.oob_score_
                print(f"OOB Accuracy: {oob_acc:.4f}")
                
                if oob_acc &gt; best_oob:
                    best_oob = oob_acc
                    best_params = {'n_estimators': n_est, 'max_features': mf, 'min_samples_split': mss}
                    best_model = rf
                    print("New best model found!")
    
    
    # Evaluate the best model
    train_pred = best_model.predict(X_train)
    train_acc = accuracy_score(y_train, train_pred)
    oob_acc = best_model.oob_score_
    valid_pred = best_model.predict(X_valid)
    valid_acc = accuracy_score(y_valid, valid_pred)
    test_pred = best_model.predict(X_test)
    test_acc = accuracy_score(y_test, test_pred)
    
    # Print results
    print("\n=== Best Model ===")
    print(f"Parameters: {best_params}")
    print(f"Training Accuracy: {train_acc:.4f}")
    print(f"OOB Accuracy: {oob_acc:.4f}")
    print(f"Validation Accuracy: {valid_acc:.4f}")
    print(f"Test Accuracy: {test_acc:.4f}")
    
    # Save test predictions
    test_pred_str = ['&gt;50K' if pred == 1 else '&lt;=50K' for pred in test_pred]
    pd.DataFrame({'prediction': test_pred_str}).to_csv(
        os.path.join(output_path, 'prediction_e.csv'), index=False
    )
    
    return best_params, train_acc, oob_acc, valid_acc, test_acc

def main():
    # Parse command-line arguments
    if len(sys.argv) != 6:
        print("Usage: python decision_tree.py &lt;train_data_path&gt; &lt;validation_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
        sys.exit(1)
    
    train_path = sys.argv[1]
    val_path = sys.argv[2]
    test_path = sys.argv[3]
    output_path = sys.argv[4]
    question_part = sys.argv[5]
    
    # Create output directory if it doesn't exist
    os.makedirs(output_path, exist_ok=True)
    
    # Load data
    train_data = pd.read_csv(train_path, skipinitialspace=True)
    valid_data = pd.read_csv(val_path, skipinitialspace=True)
    test_data = pd.read_csv(test_path, skipinitialspace=True)
    
    # Execute specific part
    if question_part == 'a':
        part_a(train_data, valid_data, test_data, output_path)
        
    if question_part == 'b':
        part_b(train_data, valid_data, test_data, output_path)
        
    if question_part == 'c':
        part_c(train_data, valid_data, test_data, output_path)

    if question_part == 'd':
        part_d(train_data, valid_data, test_data, output_path)

    if question_part == 'e':
        part_e(train_data, valid_data, test_data, output_path)
    
if __name__ == "__main__":
    main()



import os
import sys
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
from PIL import Image

class NeuralNetwork:
    def __init__(self, input_size, hidden_layers, output_size, activation="sigmoid", learning_rate=0.01):
        self.layers = [input_size] + hidden_layers + [output_size]
        self.learning_rate = learning_rate
        self.weights = []
        self.biases = []
        self.activation = activation

        # Xavier Initialization for weights
        for i in range(len(self.layers) - 1):
            limit = np.sqrt(6 / (self.layers[i] + self.layers[i + 1]))
            self.weights.append(np.random.uniform(-limit, limit, (self.layers[i], self.layers[i+1])))
            self.biases.append(np.zeros((1, self.layers[i+1])))

    def sigmoid(self, z):
        return 1 / (1 + np.exp(-z))

    def sigmoid_derivative(self, a):
        return a * (1 - a)
    
    def relu(self, z):
        return np.maximum(0, z)

<A NAME="1"></A><FONT color = #00FF00><A HREF="match120-1.html#1" TARGET="1"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    def relu_derivative(self, z):
        return (z &gt; 0).astype(float) 


    def softmax(self, z):
        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # For numerical stability
</FONT>        return exp_z / np.sum(exp_z, axis=1, keepdims=True)
    
    def forward(self, X):
        a = X
        activations = [X]
        zs = []

        for w, b in zip(self.weights[:-1], self.biases[:-1]):
            z = np.dot(a, w) + b
            zs.append(z)
            if self.activation == "relu":
                a = self.relu(z)
            else:
                a = self.sigmoid(z)
            activations.append(a)

        # Output layer
        z = np.dot(a, self.weights[-1]) + self.biases[-1]
<A NAME="2"></A><FONT color = #0000FF><A HREF="match120-1.html#2" TARGET="1"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        zs.append(z)
        a = self.softmax(z)
        activations.append(a)

        return activations, zs


    def compute_loss(self, y_true, y_pred):
        # Cross entropy
        m = y_true.shape[0]
</FONT>        loss = -np.sum(y_true * np.log(y_pred + 1e-9)) / m  # Avoid log(0)
        return loss

    def backward(self, activations, zs, y_true):
        grads_w = [0] * len(self.weights)
        grads_b = [0] * len(self.biases)

        # Output layer gradient
        delta = activations[-1] - y_true  # (ok - 1{k=label})
        grads_w[-1] = np.dot(activations[-2].T, delta)
        grads_b[-1] = np.sum(delta, axis=0, keepdims=True)

        # Hidden layers
        for l in range(len(self.layers) - 2, 0, -1):
            if self.activation == "relu":
                delta = np.dot(delta, self.weights[l].T) * self.relu_derivative(zs[l - 1])
            else:
                delta = np.dot(delta, self.weights[l].T) * self.sigmoid_derivative(activations[l])            
            grads_w[l-1] = np.dot(activations[l-1].T, delta)
            grads_b[l-1] = np.sum(delta, axis=0, keepdims=True)

        return grads_w, grads_b

    def update_params(self, grads_w, grads_b, batch_size):
        for i in range(len(self.weights)):
            self.weights[i] -= self.learning_rate * grads_w[i] / batch_size
            self.biases[i] -= self.learning_rate * grads_b[i] / batch_size

    def train(self, X_train, y_train, X_val=None, y_val=None, batch_size=32, epochs=10, patience=10):
        best_val_acc = 0
        best_weights = None
        best_biases = None
        wait = 0
        train_accuracies = []
        prev_val_acc = None  # Track previous val_acc
        prev_val_loss = 0

        y_val_onehot = one_hot_encode(y_val, self.layers[-1]) if y_val is not None else None
        y_train_onehot = one_hot_encode(y_train, self.layers[-1])

        for epoch in range(epochs):
            permutation = np.random.permutation(X_train.shape[0])
            X_shuffled = X_train[permutation]
            y_shuffled = y_train[permutation]

            for i in range(0, X_train.shape[0], batch_size):
                X_batch = X_shuffled[i:i+batch_size]
                y_batch = y_shuffled[i:i+batch_size]
                y_batch_onehot = one_hot_encode(y_batch, self.layers[-1])

                activations, zs = self.forward(X_batch)
                loss = self.compute_loss(y_batch_onehot, activations[-1])
                grads_w, grads_b = self.backward(activations, zs, y_batch_onehot)
                self.update_params(grads_w, grads_b, X_batch.shape[0])

            # Full epoch metrics
            train_pred_probs, _ = self.forward(X_train)
            train_loss = self.compute_loss(y_train_onehot, train_pred_probs[-1])
            train_acc = self.accuracy(X_train, y_train)
            train_accuracies.append(train_acc)

            val_loss = val_acc = None
            if X_val is not None and y_val is not None:
                val_pred_probs, _ = self.forward(X_val)
                val_loss = self.compute_loss(y_val_onehot, val_pred_probs[-1])
                val_acc = self.accuracy(X_val, y_val)

                print(f"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, "
                    f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")
                
                # Save best weights for final restore
                if val_acc &gt; best_val_acc:
                    best_val_acc = val_acc
                    best_weights = [w.copy() for w in self.weights]
                    best_biases = [b.copy() for b in self.biases]

                if abs(prev_val_loss - val_loss) &lt; 1e-6:
                    wait += 1
                else:
                    wait = 0

                prev_val_loss = val_loss

                if wait &gt;= patience:
                    print(f"Early stopping at epoch {epoch+1}.")
                    if best_weights is not None:
                        self.weights = best_weights
                        self.biases = best_biases
                    return train_accuracies
                
            else:
                print(f"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}")

        return train_accuracies
    
    def train_d(self, X_train, y_train, X_val=None, y_val=None, batch_size=32, epochs=10, patience=10):
        best_val_acc = 0
        best_weights = None
        best_biases = None
        wait = 0
        train_accuracies = []
        prev_val_loss = 0

        y_val_onehot = one_hot_encode(y_val, self.layers[-1]) if y_val is not None else None
        y_train_onehot = one_hot_encode(y_train, self.layers[-1])

        for epoch in range(epochs):

            self.learning_rate = np.sqrt(0.01)/np.sqrt(epoch + 1)

            permutation = np.random.permutation(X_train.shape[0])
            X_shuffled = X_train[permutation]
            y_shuffled = y_train[permutation]

            for i in range(0, X_train.shape[0], batch_size):
                X_batch = X_shuffled[i:i+batch_size]
                y_batch = y_shuffled[i:i+batch_size]
                y_batch_onehot = one_hot_encode(y_batch, self.layers[-1])

                activations, zs = self.forward(X_batch)
                loss = self.compute_loss(y_batch_onehot, activations[-1])
                grads_w, grads_b = self.backward(activations, zs, y_batch_onehot)
                self.update_params(grads_w, grads_b, X_batch.shape[0])

            # Full epoch metrics
            train_pred_probs, _ = self.forward(X_train)
            train_loss = self.compute_loss(y_train_onehot, train_pred_probs[-1])
            train_acc = self.accuracy(X_train, y_train)
            train_accuracies.append(train_acc)

            val_loss = val_acc = None
            if X_val is not None and y_val is not None:
                val_pred_probs, _ = self.forward(X_val)
                val_loss = self.compute_loss(y_val_onehot, val_pred_probs[-1])
                val_acc = self.accuracy(X_val, y_val)

                print(f"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, "
                    f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")
                
                # Save best weights for final restore
                if val_acc &gt; best_val_acc:
                    best_val_acc = val_acc
                    best_weights = [w.copy() for w in self.weights]
                    best_biases = [b.copy() for b in self.biases]

                if abs(prev_val_loss - val_loss) &lt; 1e-6:
                    wait += 1
                else:
                    wait = 0

                prev_val_loss = val_loss

                if wait &gt;= patience:
                    print(f"Early stopping at epoch {epoch+1}.")
                    if best_weights is not None:
                        self.weights = best_weights
                        self.biases = best_biases
                    return train_accuracies
                
            else:
                print(f"Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}")

        return train_accuracies


    def predict(self, X):
        activations, _ = self.forward(X)
        return np.argmax(activations[-1], axis=1)

    def accuracy(self, X, y_true_labels):
        y_pred_labels = self.predict(X)
        return np.mean(y_pred_labels == y_true_labels)
    


def one_hot_encode(y, num_classes):
    return np.eye(num_classes)[y]

def load_dataset(train_path, test_path):
    X_train, y_train = [], []
    for label in sorted(os.listdir(train_path)):
        label_dir = os.path.join(train_path, label)
        if not os.path.isdir(label_dir): continue
        for fname in os.listdir(label_dir):
            img_path = os.path.join(label_dir, fname)
            img = Image.open(img_path).resize((28, 28))
            X_train.append(np.array(img).flatten())
            y_train.append(int(label))

    X_train = np.array(X_train) / 255.0
    y_train = np.array(y_train)

    # For test data: no labels
    X_test = []
    test_image_paths = []
    for fname in sorted(os.listdir(test_path)):
        if fname.endswith('.ppm') or fname.endswith('.jpg') or fname.endswith('.png'):
            img_path = os.path.join(test_path, fname)
            img = Image.open(img_path).resize((28, 28))
            X_test.append(np.array(img).flatten())
            test_image_paths.append(fname)

    X_test = np.array(X_test) / 255.0

    return X_train, y_train, X_test, test_image_paths

import csv

def evaluate_and_save(model, X_train, y_train, X_test, y_test, output_dir, hidden_units, question_part, test_image_names):
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)

    output_path = os.path.join(output_dir, f"prediction_{question_part}.csv")
    with open(output_path, mode='w', newline='') as csv_file:
        writer = csv.writer(csv_file)
        writer.writerow(["prediction"]) 
        for fname, pred in zip(test_image_names, y_test_pred):
            writer.writerow([pred])

    print(f"Predictions saved to {output_path}")

    precision_train = precision_score(y_train, y_train_pred, average=None, zero_division=0)
    recall_train = recall_score(y_train, y_train_pred, average=None, zero_division=0)
    f1_train = f1_score(y_train, y_train_pred, average=None, zero_division=0)

    precision_test = precision_score(y_test, y_test_pred, average=None, zero_division=0)
    recall_test = recall_score(y_test, y_test_pred, average=None, zero_division=0)
    f1_test = f1_score(y_test, y_test_pred, average=None, zero_division=0)

    avg_f1 = np.mean(f1_test)

    np.savez(os.path.join(output_dir, f"metrics_hidden_{hidden_units}.npz"),
             precision_train=precision_train, recall_train=recall_train, f1_train=f1_train,
             precision_test=precision_test, recall_test=recall_test, f1_test=f1_test,
             avg_f1=avg_f1)

    # Save to CSV files directly
    # Training data metrics
    train_df = pd.DataFrame({
        'Class': range(len(precision_train)),
        'Precision': precision_train,
        'Recall': recall_train,
        'F1_Score': f1_train
    })
    train_df.to_csv(os.path.join(output_dir, f"train_metrics_hidden_{hidden_units}.csv"), index=False)
    
    # Test data metrics
    test_df = pd.DataFrame({
        'Class': range(len(precision_test)),
        'Precision': precision_test,
        'Recall': recall_test,
        'F1_Score': f1_test
    })
    test_df.to_csv(os.path.join(output_dir, f"test_metrics_hidden_{hidden_units}.csv"), index=False)
    
    # Print summary
    print(f"\nMetrics for hidden units: {hidden_units}")
    print(f"Average Train F1: {np.mean(f1_train):.4f}")
    print(f"Average Test F1: {avg_f1:.4f}")
    
    # Find best and worst performing classes
    best_class = np.argmax(f1_test)
    worst_class = np.argmin(f1_test)
    print(f"Best performing class: {best_class} (F1={f1_test[best_class]:.4f})")
    print(f"Worst performing class: {worst_class} (F1={f1_test[worst_class]:.4f})")

    return avg_f1

import pandas as pd

def load_test_labels(test_labels_csv, test_image_names):
    df = pd.read_csv(test_labels_csv)
    name_to_label = dict(zip(df['image'], df['label']))
    return np.array([name_to_label[name] for name in test_image_names])

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
import pandas as pd

def run_mlp_classifier(X_train, y_train, X_val, y_val, X_test, y_test, hidden_layers, output_path):
    # Concatenate train and validation sets
    X_combined = np.vstack((X_train, X_val))
    y_combined = np.concatenate((y_train, y_val))

    clf = MLPClassifier(
        hidden_layer_sizes=tuple(hidden_layers),
        activation='relu',
        solver='sgd',
        alpha=0,
        batch_size=32,
        learning_rate='invscaling',
        max_iter=30,
        early_stopping=True,
        n_iter_no_change=10,
        verbose=True
    )

    clf.fit(X_combined, y_combined)

    y_pred = clf.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average="macro", zero_division=0)
    recall = recall_score(y_test, y_pred, average="macro", zero_division=0)
    f1 = f1_score(y_test, y_pred, average="macro", zero_division=0)

    print("\n=== MLPClassifier Results ===")
    print(f"Accuracy:  {acc:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall:    {recall:.4f}")
    print(f"F1 Score:  {f1:.4f}")

    # Save predictions
    df = pd.DataFrame({'prediction': y_pred})
    df.to_csv(os.path.join(output_path, 'prediction_f.csv'), index=False)
    print("Predictions saved to prediction_f.csv.")

<A NAME="6"></A><FONT color = #00FF00><A HREF="match120-1.html#6" TARGET="1"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    return clf



def main():
    if len(sys.argv) != 5:
        print("Usage: python neural_network.py &lt;train_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
        sys.exit(1)

    train_path = sys.argv[1]
</FONT>    test_path = sys.argv[2]
    output_path = sys.argv[3]
    part = sys.argv[4]

    os.makedirs(output_path, exist_ok=True)


    print("Loading data...")
    X_train_full, y_train_full, X_test_full, test_image_names = load_dataset(train_path, test_path)

    test_labels_csv = "test_labels.csv"
    y_test_full = load_test_labels(test_labels_csv, test_image_names)

    # Split some test data from train for evaluation
    X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=42)

    if part == "b":
        hidden_units_list = [1, 5, 10, 50, 100]
        avg_f1_scores = []
        test_accuracies =[]

        for hidden_units in hidden_units_list:
            print(f"\nTraining NN with hidden layer size: {hidden_units}")
            model = NeuralNetwork(
                input_size=2352,
                hidden_layers=[hidden_units],
                output_size=43,
                learning_rate=0.01
            )
            train_accuracies = model.train(X_train, y_train,X_val,y_val ,batch_size=32, epochs=100)
            # Evaluate on test set
            test_acc = model.accuracy(X_test_full, y_test_full)
            print(f"Test Accuracy (hidden={hidden_units}): {test_acc:.4f}")
            avg_f1 = evaluate_and_save(model, X_train, y_train, X_test_full, y_test_full, output_path, hidden_units, 'b', test_image_names)
            avg_f1_scores.append(avg_f1)
            test_accuracies.append(test_acc)

        # Plot average F1 score
        plt.figure(figsize=(8, 5))
        plt.plot(hidden_units_list, avg_f1_scores, marker='o')
        plt.title('Average F1 Score vs Hidden Layer Size')
        plt.xlabel('Number of Hidden Units')
        plt.ylabel('Average F1 Score (Test Set)')
        plt.grid(True)
        plt.savefig(os.path.join(output_path, "f1_vs_hidden_units.png"))
        plt.close()

        plt.figure(figsize=(8, 5))
        plt.plot(hidden_units_list, test_accuracies, marker='s', color='green')
        plt.title('Test Accuracy vs Hidden Layer Size')
        plt.xlabel('Hidden Layer Size')
        plt.ylabel('Test Accuracy')
        plt.grid(True)
        plt.savefig(os.path.join(output_path, "test_acc_vs_hidden.png"))
        plt.show()


        print("Finished Part (b). All metrics and plot saved.")

    elif part == "c":
        layer_configs = [
            [512],
            [512, 256],
            [512, 256, 128],
            [512, 256, 128, 64]
        ]
        avg_f1_scores = []
        test_accuracies = []

        for hidden_layers in layer_configs:
            print(f"\nTraining NN with hidden layers: {hidden_layers}")
            model = NeuralNetwork(
                input_size=2352,
                hidden_layers=hidden_layers,
                output_size=43,
                learning_rate=0.01
            )
            train_accuracies = model.train(X_train, y_train, X_val, y_val, batch_size=32, epochs=100, patience=10)
            test_acc = model.accuracy(X_test_full, y_test_full)
            print(f"Test Accuracy (hidden={hidden_layers}): {test_acc:.4f}")
            avg_f1 = evaluate_and_save(
                model,
                X_train,
                y_train,
                X_test_full,
                y_test_full,
                output_path,
                '_'.join(map(str, hidden_layers)),
                'c',
                test_image_names
            )
            avg_f1_scores.append(avg_f1)
            test_accuracies.append(test_acc)

        # Plotting average F1 vs depth
        depths = [len(config) for config in layer_configs]
        plt.figure(figsize=(8, 6))
        plt.plot(depths, avg_f1_scores, marker='o')
        plt.xlabel("Network Depth (Number of Hidden Layers)")
        plt.ylabel("Average F1 Score (Test)")
        plt.title("F1 Score vs Network Depth")
        plt.grid(True)
        plt.savefig(os.path.join(output_path, "f1_vs_depth.png"))
        plt.show()

    elif part == "d":
        layer_configs = [
            [512],
            [512, 256],
            [512, 256, 128],
            [512, 256, 128, 64]
        ]
        avg_f1_scores = []
        test_accuracies = []

        for hidden_layers in layer_configs:
            print(f"\nTraining NN with hidden layers: {hidden_layers}")
            model = NeuralNetwork(
                input_size=2352,
                hidden_layers=hidden_layers,
                output_size=43,
                learning_rate=0.01
            )
            train_accuracies = model.train_d(X_train, y_train, X_val, y_val, batch_size=32, epochs=100, patience=10)
            test_acc = model.accuracy(X_test_full, y_test_full)
            print(f"Test Accuracy (hidden={hidden_layers}): {test_acc:.4f}")
            avg_f1 = evaluate_and_save(
                model,
                X_train,
                y_train,
                X_test_full,
                y_test_full,
                output_path,
                '_'.join(map(str, hidden_layers)),
                'd',
                test_image_names
            )
            avg_f1_scores.append(avg_f1)
            test_accuracies.append(test_acc)

        # Plotting average F1 vs depth
        depths = [len(config) for config in layer_configs]
        plt.figure(figsize=(8, 6))
        plt.plot(depths, avg_f1_scores, marker='o')
        plt.xlabel("Network Depth (Number of Hidden Layers)")
        plt.ylabel("Average F1 Score (Test)")
        plt.title("F1 Score vs Network Depth")
        plt.grid(True)
        plt.savefig(os.path.join(output_path, "d_f1_vs_depth.png"))
        plt.show()

    elif part == "e":
        layer_configs = [
            [512],
            [512, 256],
            [512, 256, 128],
            [512, 256, 128, 64]
        ]
        avg_f1_scores = []
        test_accuracies = []

        for hidden_layers in layer_configs:
            print(f"\nTraining NN with hidden layers: {hidden_layers}")
            model = NeuralNetwork(
                input_size=2352,
                hidden_layers=hidden_layers,
                output_size=43,
                learning_rate=0.01,
                activation="relu"
            )
            train_accuracies = model.train_d(X_train, y_train, X_val, y_val, batch_size=32, epochs=100, patience=10)
            test_acc = model.accuracy(X_test_full, y_test_full)
            print(f"Test Accuracy (hidden={hidden_layers}): {test_acc:.4f}")
            avg_f1 = evaluate_and_save(
                model,
                X_train,
                y_train,
                X_test_full,
                y_test_full,
                output_path,
                '_'.join(map(str, hidden_layers)),
                'e',
                test_image_names
            )
            avg_f1_scores.append(avg_f1)
            test_accuracies.append(test_acc)

        # Plotting average F1 vs depth
        depths = [len(config) for config in layer_configs]
        plt.figure(figsize=(8, 6))
        plt.plot(depths, avg_f1_scores, marker='o')
        plt.xlabel("Network Depth (Number of Hidden Layers)")
        plt.ylabel("Average F1 Score (Test)")
        plt.title("F1 Score vs Network Depth")
        plt.grid(True)
        plt.savefig(os.path.join(output_path, "e_f1_vs_depth.png"))
        plt.show()

    elif part=='f':
        layer_configs = [
            [512],
            [512, 256],
            [512, 256, 128],
            [512, 256, 128, 64]
        ]
        avg_f1_scores = []
        test_accuracies = []

        for hidden_layers in layer_configs:
            print(f"\nTraining NN with hidden layers: {hidden_layers}")
            clf = run_mlp_classifier(X_train, y_train, X_val, y_val, X_test_full, y_test_full, hidden_layers, output_path)

        plt.plot(clf.loss_curve_)
        plt.title("MLPClassifier Training Loss Curve")
        plt.xlabel("Epochs")
        plt.ylabel("Loss")
        plt.grid(True)
        plt.savefig(os.path.join(output_path, "f_loss_vs_epochs.png"))
        

if __name__ == "__main__":
    main()

</PRE>
</PRE>
</BODY>
</HTML>
