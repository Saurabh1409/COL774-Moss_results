<HTML>
<HEAD>
<TITLE>./A3_processed_new_hash/combined_0VNUY.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A3_processed_new_hash/combined_IC2J6.py<p><PRE>


import os
import numpy as np
import pandas as pd
from PIL import Image
from sklearn.utils import shuffle
from neural_network import GNN
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, f1_score

def load_gtsrb_data(data_dir='data2', img_size=(28, 28)):
    def load_images_from_folder(folder_path, label):
        images = []
        labels = []
        for filename in os.listdir(folder_path):
            if filename.endswith('.jpg') or filename.endswith('.png'):
                img_path = os.path.join(folder_path, filename)
                img = Image.open(img_path).resize(img_size)
                img = np.array(img).astype(np.float32) / 255.0
                if img.shape == (28, 28):  # grayscale to RGB
                    print("here")
                    img = np.stack([img]*3, axis=-1)
                images.append(img.flatten())
                labels.append(label)
        return images, labels

    # Load training data
    X_train, y_train = [], []
    train_root = os.path.join(data_dir, 'train')
    for class_id in range(43):
        class_folder = os.path.join(train_root, f"{class_id:05d}")
        imgs, labels = load_images_from_folder(class_folder, class_id)
        X_train.extend(imgs)
        y_train.extend(labels)

    # Load test data
    test_labels_df = pd.read_csv(os.path.join(data_dir, 'test_labels.csv'))
    X_test, y_test = [], []
    test_root = os.path.join(data_dir, 'test')
    for _, row in test_labels_df.iterrows():
        img_path = os.path.join(test_root, row['image'])
        img = Image.open(img_path).resize(img_size)
        img = np.array(img).astype(np.float32) / 255.0
        if img.shape == (28, 28):
            img = np.stack([img]*3, axis=-1)
        X_test.append(img.flatten())
        y_test.append(int(row['label']))

    # Shuffle training data
    X_train, y_train = shuffle(np.array(X_train), np.array(y_train), random_state=42)
    X_test, y_test = np.array(X_test), np.array(y_test)

    return X_train, y_train, X_test, y_test

X_train, y_train, X_test, y_test = load_gtsrb_data('data2')
def one_hot(y, num_classes=43):
    return np.eye(num_classes)[y]
y_train_oh = one_hot(y_train)
y_test_oh = one_hot(y_test)


# ---- Part (b)----
# M = 32
# n = 28 * 28 * 3  # 2352
# r = 43
# hidden_sizes = [1, 5, 10, 50, 100]
# lr = 0.01
# epochs = 200  # or use early stopping

# avg_f1_scores = []

# for h in hidden_sizes:
#     print(f"\nTraining with hidden size: {h}")
#     model = GNN(input_size=n, hidden_layers=[h], output_size=r)
#     model.fit(X_train, y_train_oh, epochs=epochs, lr=lr, batch_size=M)

#     # ---- Predictions ----
#     train_preds = model.predict(X_train)
#     test_preds = model.predict(X_test)

#     # ---- Metrics ----
#     print(f"\n[Train Metrics for hidden size {h}]")
#     train_report = classification_report(y_train, train_preds, zero_division=0)
#     print(train_report)

#     print(f"\n[Test Metrics for hidden size {h}]")
#     test_report = classification_report(y_test, test_preds, zero_division=0)
#     print(test_report)

#     with open(f"reports/b/train_{h}.txt", "w") as f:
#         f.write(f"Train Classification Report (hidden units = {h})\n")
#         f.write(train_report)

#     with open(f"reports/b/test_{h}.txt", "w") as f:
#         f.write(f"Test Classification Report (hidden units = {h})\n")
#         f.write(test_report)

#     # Store average F1 for plotting
#     avg_f1_scores.append(classification_report(y_test, test_preds, output_dict=True, zero_division=0)['weighted avg']['f1-score'])

# print(avg_f1_scores)
# # ---- Plot ----
# plt.figure(figsize=(8, 5))
# plt.plot(hidden_sizes, avg_f1_scores, marker='o', linestyle='-', color='b')
# plt.title("Average F1 Score vs Hidden Layer Size")
# plt.xlabel("Hidden Layer Size")
# plt.ylabel("Average F1 Score (Test Set)")
# plt.grid(True)
# plt.savefig("f1_score_vs_hidden_size.png")
# plt.show()

# ---- Part (c)----
# M = 32
# n = 28 * 28 * 3  # 2352
# r = 43
# lr = 0.01
# epochs = 100
# depth_configs = [
#     [512],
#     [512, 256],
#     [512, 256, 128],
#     [512, 256, 128, 64]
# ]
# avg_f1_scores = []
# avg_f1_scores2 = []
# for config in depth_configs:
#     print(f"\nTraining with hidden size: {config}")
#     model = GNN(input_size=n, hidden_layers=config, output_size=r)
#     model.fit(X_train, y_train_oh, epochs=epochs, lr=lr, batch_size=M)

#     # ---- Predictions ----
#     train_preds = model.predict(X_train)
#     test_preds = model.predict(X_test)

#     # ---- Metrics ----
#     print(f"\n[Train Metrics for hidden size {config}]")
#     train_report = classification_report(y_train, train_preds, zero_division=0)
#     print(train_report)

#     print(f"\n[Test Metrics for hidden size {config}]")
#     test_report = classification_report(y_test, test_preds, zero_division=0)
#     print(test_report)

#     with open(f"reports/c/train_{len(config)}.txt", "w") as f:
#         f.write(f"Train Classification Report (hidden units = {len(config)})\n")
#         f.write(train_report)

#     with open(f"reports/c/test_{len(config)}.txt", "w") as f:
#         f.write(f"Test Classification Report (hidden units = {len(config)})\n")
#         f.write(test_report)

#     # Store average F1 for plotting
#     avg_f1_scores.append(f1_score(y_test, test_preds, average='weighted'))
#     avg_f1_scores2.append(f1_score(y_train, train_preds, average='weighted'))

# print(avg_f1_scores)
# print(avg_f1_scores2)
# # ---- Plot ----
# depths = [len(config) for config in depth_configs]
# plt.figure(figsize=(8, 5))
# plt.plot(depths, avg_f1_scores2, label="Train F1", marker='o')
# plt.plot(depths, avg_f1_scores, label="Test F1", marker='o')
# plt.xlabel("Network Depth (# of Hidden Layers)")
# plt.ylabel("Average F1 Score")
# plt.title("F1 Score vs Network Depth")
# plt.legend()
# plt.grid(True)
# plt.savefig("depth_vs_f1.png")
# plt.show()

# Part D
M = 32
n = 28 * 28 * 3  # 2352
r = 43
lr = 0.01
epochs = 100
depth_configs = [
    [512],
    [512, 256],
    [512, 256, 128],
<A NAME="6"></A><FONT color = #00FF00><A HREF="match165-0.html#6" TARGET="0"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    [512, 256, 128, 64]
]
avg_f1_scores = []
avg_f1_scores2 = []
for config in depth_configs:
    print(f"\nTraining with hidden size: {config}")
    model = GNN(input_size=n, hidden_layers=config, output_size=r)
</FONT>    model.fit(X_train, y_train_oh, epochs=epochs, lr=lr, batch_size=M, alr=True)

    # ---- Predictions ----
    train_preds = model.predict(X_train)
    test_preds = model.predict(X_test)

    # ---- Metrics ----
    print(f"\n[Train Metrics for hidden size {config}]")
    train_report = classification_report(y_train, train_preds, zero_division=0)
    print(train_report)

    print(f"\n[Test Metrics for hidden size {config}]")
    test_report = classification_report(y_test, test_preds, zero_division=0)
    print(test_report)

    with open(f"reports/d/train_{len(config)}.txt", "w") as f:
        f.write(f"Train Classification Report (hidden units = {len(config)})\n")
        f.write(train_report)

    with open(f"reports/d/test_{len(config)}.txt", "w") as f:
        f.write(f"Test Classification Report (hidden units = {len(config)})\n")
        f.write(test_report)

    # Store average F1 for plotting
    avg_f1_scores.append(f1_score(y_test, test_preds, average='weighted'))
    avg_f1_scores2.append(f1_score(y_train, train_preds, average='weighted'))

print(avg_f1_scores)
print(avg_f1_scores2)
# ---- Plot ----
depths = [len(config) for config in depth_configs]
plt.figure(figsize=(8, 5))
plt.plot(depths, avg_f1_scores2, label="Train F1", marker='o')
plt.plot(depths, avg_f1_scores, label="Test F1", marker='o')
plt.xlabel("Network Depth (Adapted LR) (# of Hidden Layers)")
plt.ylabel("Average F1 Score")
plt.title("F1 Score vs Network Depth")
plt.legend()
plt.grid(True)
plt.savefig("depth_vs_f1_adapted.png")
plt.show()



import numpy as np
import pandas as pd
from collections import Counter
import matplotlib.pyplot as plt
<A NAME="2"></A><FONT color = #0000FF><A HREF="match165-0.html#2" TARGET="0"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

import os

class DecisionTreeNode:
	def __init__(self, is_leaf=False, prediction=None, split_feature=None, split_value=None, children=None):
		self.is_leaf = is_leaf
</FONT>		self.prediction = prediction
		self.split_feature = split_feature
		self.split_value = split_value
		self.children = children or {}


class DecisionTreeClassifier:
	def __init__(self, max_depth=None, one_hot=False):
		self.max_depth = max_depth
		self.root = None
		self.feature_types = {}
		self.one_hot = one_hot
		self.categorical_mapping = {}

	def fit(self, X, y):
		if self.one_hot:
			X = self._apply_one_hot_encoding(X)
		
		df = X.copy()
		df['label'] = y
		self.feature_types = self._infer_feature_types(X)
		self.root = self._build_tree(df, depth=0)

	def _apply_one_hot_encoding(self, X):
		X_encoded = X.copy()
		
		categorical_cols = [col for col in X.columns if X[col].dtype == 'object' or X[col].nunique() &lt;= 10]
		
		for col in categorical_cols:
			unique_values = X[col].unique()
			self.categorical_mapping[col] = unique_values
			
<A NAME="1"></A><FONT color = #00FF00><A HREF="match165-0.html#1" TARGET="0"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

			for value in unique_values:
				new_col_name = f"{col}_{value}"
				X_encoded[new_col_name] = (X[col] == value).astype(int)
			
			X_encoded = X_encoded.drop(columns=[col])
</FONT>		
		return X_encoded

	def predict(self, X):
		if self.one_hot:
			X = self._transform_one_hot(X)
		
		return X.apply(self._predict_single, axis=1)

	def _transform_one_hot(self, X):
		X_encoded = X.copy()
		
		for col, unique_values in self.categorical_mapping.items():
			if col in X.columns:
				for value in unique_values:
					new_col_name = f"{col}_{value}"
					X_encoded[new_col_name] = (X[col] == value).astype(int)
				
				X_encoded = X_encoded.drop(columns=[col])
		
		return X_encoded

	def _predict_single(self, x):
		node = self.root
		while not node.is_leaf:
			feature = node.split_feature
			if self.feature_types[feature] == 'categorical':
				value = x[feature]
				if value in node.children:
					node = node.children[value]
				else:
					return node.prediction  # unseen category → default to current node's prediction
			else:
				value = x[feature]
				node = node.children['leq'] if value &lt;= node.split_value else node.children['gt']
		return node.prediction

	def _build_tree(self, df, depth):
		labels = df['label']
		if len(set(labels)) == 1 or (self.max_depth is not None and depth &gt;= self.max_depth):
			return DecisionTreeNode(is_leaf=True, prediction=labels.mode()[0])

		best_feature, best_split = self._choose_best_split(df)

		if best_feature is None:
			return DecisionTreeNode(is_leaf=True, prediction=labels.mode()[0])

		node = DecisionTreeNode(split_feature=best_feature, split_value=best_split)

		if self.feature_types[best_feature] == 'categorical':
			for value, subset in df.groupby(best_feature):
				child = self._build_tree(subset.drop(columns=[best_feature]), depth + 1)
				node.children[value] = child
		else:
			left = df[df[best_feature] &lt;= best_split]
			right = df[df[best_feature] &gt; best_split]
			node.children['leq'] = self._build_tree(left, depth + 1)
			node.children['gt'] = self._build_tree(right, depth + 1)

		node.prediction = labels.mode()[0]
		return node

	def _choose_best_split(self, df):
		best_info_gain = -1
		best_feature = None
		best_split_value = None

		base_entropy = self._entropy(df['label'])

		for feature in df.columns:
			if feature == 'label':
				continue
			if self.feature_types[feature] == 'categorical':
				subsets = [df[df[feature] == val] for val in df[feature].unique()]
				weighted_entropy = sum((len(subset) / len(df)) * self._entropy(subset['label']) for subset in subsets)
				info_gain = base_entropy - weighted_entropy
				if info_gain &gt; best_info_gain:
					best_info_gain = info_gain
					best_feature = feature
					best_split_value = None
			else:
				median = df[feature].median()
				left = df[df[feature] &lt;= median]
				right = df[df[feature] &gt; median]
				if len(left) == 0 or len(right) == 0:
					continue
				weighted_entropy = (
					len(left) / len(df) * self._entropy(left['label']) +
					len(right) / len(df) * self._entropy(right['label'])
				)
				info_gain = base_entropy - weighted_entropy
				if info_gain &gt; best_info_gain:
					best_info_gain = info_gain
					best_feature = feature
					best_split_value = median

		return best_feature, best_split_value

	def _entropy(self, labels):
		total = len(labels)
		counts = Counter(labels)
		probs = [count / total for count in counts.values()]
		return -sum(p * np.log2(p + 1e-9) for p in probs)

	def _infer_feature_types(self, X):
		types = {}
		for col in X.columns:
			if X[col].dtype == 'object' or X[col].nunique() &lt;= 10:
				types[col] = 'categorical'
			else:
				types[col] = 'continuous'
		return types

	def post_prune(self, X_val, y_val, X_train=None, y_train=None, X_test=None, y_test=None, 
			   min_improvement=1e-6, plot_filename="prune.png"):
		if len(X_val) == 0 or len(y_val) == 0:
			raise ValueError("Validation set cannot be empty")
		
		if self.one_hot:
			X_val = self._transform_one_hot(X_val)
			if X_train is not None:
				X_train = self._transform_one_hot(X_train)
			if X_test is not None:
				X_test = self._transform_one_hot(X_test)

		val_indices = X_val.index.tolist()
		current_predictions = self.predict(X_val)
		best_accuracy = (current_predictions == y_val).mean()
		
		node_counts = [self._count_nodes()]
		val_accuracies = [best_accuracy]
		train_accuracies = [(self.predict(X_train)== y_train).mean() if X_train is not None else []]
		test_accuracies = [(self.predict(X_test)== y_test).mean() if X_test is not None else []]
		
		node_examples = self._compute_node_examples(X_val)

		while True:
			best_node = None
			best_impact = 0
			best_majority_label = None
			
			for node in self._get_all_nodes():
				if node.is_leaf:
					continue
					
				examples = node_examples.get(node, [])
				if not examples:
					continue
					
				node_labels = y_val.loc[examples]
				majority_label = node_labels.mode()[0]
				
				correct_before = (current_predictions.loc[examples] == y_val.loc[examples]).sum()
				correct_after = (node_labels == majority_label).sum()
				impact = correct_after - correct_before
				
				if impact &gt; best_impact:
					best_impact = impact
					best_node = node
					best_majority_label = majority_label
			
			if best_node is None or best_impact/len(y_val) &lt; min_improvement:
				break
				
			best_node.is_leaf = True
			best_node.children = {}
			best_node.prediction = best_majority_label
			
			affected_examples = node_examples[best_node]
			current_predictions.loc[affected_examples] = best_majority_label
			
			best_accuracy += best_impact / len(y_val)
			
			node_counts.append(self._count_nodes())
			val_accuracies.append(best_accuracy)
			if X_train is not None:
				train_accuracies.append((self.predict(X_train)== y_train).mean())
			if X_test is not None:
				test_accuracies.append((self.predict(X_test)== y_test).mean())
		
		# Plotting
		if (plot_filename is not None) and (len(train_accuracies)&gt;0):
			plt.figure(figsize=(10, 6))
			plt.plot(node_counts, val_accuracies, label='Validation Accuracy', marker='o')
			
			if X_train is not None:
				plt.plot(node_counts[:len(train_accuracies)], train_accuracies, 
						label='Train Accuracy', marker='s')
			if X_test is not None:
				plt.plot(node_counts[:len(test_accuracies)], test_accuracies, 
<A NAME="4"></A><FONT color = #FF00FF><A HREF="match165-0.html#4" TARGET="0"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

						label='Test Accuracy', marker='^')
				
			plt.xlabel('Number of Nodes in Tree')
			plt.ylabel('Accuracy')
			plt.title('Accuracy vs. Tree Complexity During Pruning')
			plt.legend()
			plt.grid(True)
			plt.savefig(plot_filename)
</FONT>			plt.close()
		
		return best_accuracy

	def _count_nodes(self):
		count = 0
		if not self.root:
			return count
		
		queue = [self.root]
		while queue:
			node = queue.pop(0)
			count += 1
			if not node.is_leaf:
				queue.extend(node.children.values())
		return count

	def _compute_node_examples(self, X_val):
		node_examples = {}
		val_indices = X_val.index.tolist()
		
		if not val_indices: return node_examples

		node_examples[self.root] = val_indices.copy()
		queue = [(self.root, val_indices)]
		
		while queue:
			node, examples = queue.pop(0)
			if node.is_leaf:
				continue
				
			for key, child in node.children.items():
				child_examples = []
				feature = node.split_feature
				
				for idx in examples:
					row = X_val.loc[idx]
					if self.feature_types.get(feature) == 'categorical':
						if row[feature] == key:
							child_examples.append(idx)
					else:
						if (key == 'leq' and row[feature] &lt;= node.split_value) or \
						   (key == 'gt' and row[feature] &gt; node.split_value):
							child_examples.append(idx)
				
				if child_examples:
					node_examples[child] = child_examples
					queue.append((child, child_examples))
		
		return node_examples

	def _get_all_nodes(self):
		nodes = []
		if not self.root:
			return nodes
		
		queue = [self.root]
		while queue:
			node = queue.pop(0)
			nodes.append(node)
			if not node.is_leaf:
				queue.extend(node.children.values())
		return nodes


import sys
from sklearn.tree import DecisionTreeClassifier as SklearnTree

def load_df(path):
	df = pd.read_csv(path, skipinitialspace=True)
	df.dropna(inplace=True)
	df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)
	X = df.drop(columns=['income'])
	y = df['income']
	return X, y

def main():
	if len(sys.argv) != 6:
		print("Usage: python decision_tree.py &lt;train_data_path&gt; &lt;validation_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
		return

	train_path, val_path, test_path, output_folder, question_part = sys.argv[1:]

	train_df = pd.read_csv(train_path)
	val_df = pd.read_csv(val_path)
	test_df = pd.read_csv(test_path)

	train_df = train_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)
	val_df = val_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)
	test_df = test_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

	X_train = train_df.drop(columns=['income'])
	y_train = train_df['income']

	X_val = val_df.drop(columns=['income'])
	y_val = val_df['income']

	X_test = test_df.copy()  # Keep index intact for prediction order

	# Initialize models based on question part
	if question_part == 'a':
		model = DecisionTreeClassifier(max_depth=20)
		model.fit(X_train, y_train)

	elif question_part == 'b':
		model = DecisionTreeClassifier(max_depth=55, one_hot=True)
		model.fit(X_train, y_train)

	elif question_part == 'c':
		model = DecisionTreeClassifier(max_depth=55, one_hot=True)
		model.fit(X_train, y_train)
		model.post_prune(X_val, y_val)

	elif question_part == 'd':
		X_train = pd.get_dummies(X_train)
		X_test = pd.get_dummies(X_test)
		X_test = X_test.reindex(columns=X_train.columns, fill_value=0)
		
		model = SklearnTree(criterion='entropy', ccp_alpha=0.001)
		model.fit(X_train, y_train)
	else:
		print("Invalid question part. Must be one of 'a', 'b', 'c', 'd'. NOTE: 'e' not implemented")
		return

	predictions = model.predict(X_test)
	output_df = pd.DataFrame({'prediction': predictions})
	output_file = os.path.join(output_folder, f'prediction_{question_part}.csv')
	output_df.to_csv(output_file, index=False)

if __name__ == "__main__":
	main()





import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score
from decision_tree import DecisionTreeClassifier
from sklearn.tree import DecisionTreeClassifier as SklearnTree

train_file = "data1/train.csv"
test_file = "data1/test.csv"
valid_file = "data1/valid.csv"

def load_and_preprocess(path):
    df = pd.read_csv(path, skipinitialspace=True)
    df.dropna(inplace=True)
    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    X = df.drop(columns=['income'])
    y = df['income']
    return X, y

def run_experiments(depths, train_path, test_path, one_hot = False):
    X_train, y_train = load_and_preprocess(train_path)
    X_test, y_test = load_and_preprocess(test_path)

    train_accuracies = []
    test_accuracies = []

    for depth in depths:
        print(f"Training with max_depth = {depth}")
        clf = DecisionTreeClassifier(max_depth=depth, one_hot=one_hot)
        clf.fit(X_train, y_train)

        y_train_pred = clf.predict(X_train)
        y_test_pred = clf.predict(X_test)

        train_acc = accuracy_score(y_train, y_train_pred)
        test_acc = accuracy_score(y_test, y_test_pred)

        print(f"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}")

        train_accuracies.append(train_acc)
        test_accuracies.append(test_acc)

    return train_accuracies, test_accuracies

def run_experiments_v(depths, train_path, test_path, valid_path):
    X_train, y_train = load_and_preprocess(train_path)
    X_test, y_test = load_and_preprocess(test_path)
    X_valid, y_valid = load_and_preprocess(valid_path)

    train_accuracies = []
    test_accuracies = []
    valid_accuracies = []

    for depth in depths:
        print(f"Training with max_depth = {depth}")
        clf = DecisionTreeClassifier(max_depth=depth, one_hot=True)
        clf.fit(X_train, y_train)
        clf.post_prune(X_valid, y_valid, X_train, y_train, X_test, y_test)
        y_train_pred = clf.predict(X_train)
<A NAME="3"></A><FONT color = #00FFFF><A HREF="match165-0.html#3" TARGET="0"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        y_test_pred = clf.predict(X_test)
        y_valid_pred = clf.predict(X_valid)

        train_acc = accuracy_score(y_train, y_train_pred)
        test_acc = accuracy_score(y_test, y_test_pred)
        valid_acc = accuracy_score(y_valid, y_valid_pred)

        print(f"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}, Valid Accuracy: {test_acc:.4f}")

        train_accuracies.append(train_acc)
</FONT>        test_accuracies.append(test_acc)
        valid_accuracies.append(valid_acc)

    return train_accuracies, test_accuracies, valid_accuracies

def plot_accuracies(depths, train_accuracies, test_accuracies):
    plt.figure(figsize=(8, 5))
    plt.plot(depths, train_accuracies, marker='o', label='Train Accuracy')
    plt.plot(depths, test_accuracies, marker='o', label='Test Accuracy')
    plt.xlabel('Maximum Tree Depth')
    plt.ylabel('Accuracy')
    plt.title('Train and Test Accuracies vs. Tree Depth')
    plt.ylim(0, 1.1)
    plt.xticks(depths)
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.legend()
    plt.tight_layout()
    plt.savefig("depth_vs_accuracy.png")
    plt.show()

def plot_accuracies_v(depths, train_accuracies, test_accuracies, valid_accuracies):
    plt.figure(figsize=(8, 5))
    plt.plot(depths, train_accuracies, marker='o', label='Train Accuracy')
    plt.plot(depths, test_accuracies, marker='o', label='Test Accuracy')
    plt.plot(depths, valid_accuracies, marker='o', label='Validation Accuracy')
    plt.xlabel('Maximum Tree Depth')
    plt.ylabel('Accuracy')
    plt.title('Accuracies vs. Tree Depth')
    plt.ylim(0, 1.1)
    plt.xticks(depths)
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.legend()
    plt.tight_layout()
    plt.savefig("depth_vs_accuracy.png")
    plt.show()

def parta():
    depths = [5, 10, 15, 20]
    train_accs, test_accs = run_experiments(depths, train_file, test_file)
    plot_accuracies(depths, train_accs, test_accs)
    for d, acc in zip(depths, test_accs):
        print(f"Depth {d} → Test Accuracy: {acc:.4f}")

def partb():
    depths = [15, 25, 35, 45, 55]
    train_accs, test_accs = run_experiments(depths, train_file, test_file, one_hot=True)
    plot_accuracies(depths, train_accs, test_accs)
    for d, acc in zip(depths, test_accs):
        print(f"Depth {d} → Test Accuracy: {acc:.4f}")

def partc():
    depths = [15, 25, 35, 45, 55]
    train_accs, test_accs, valid_accs = run_experiments_v(depths, train_file, test_file, valid_file)
    plot_accuracies_v(depths, train_accs, test_accs, valid_accs)
    for d, acc in zip(depths, test_accs):
        print(f"Depth {d} → Test Accuracy: {acc:.4f}")

def partd():
    depths = [25, 35, 45, 55]
    X_train, y_train = load_and_preprocess(train_file)
    X_test, y_test = load_and_preprocess(test_file)
    X_valid, y_valid = load_and_preprocess(valid_file)

    X_train = pd.get_dummies(X_train)
    X_valid = pd.get_dummies(X_valid)
    X_test = pd.get_dummies(X_test)

    X_valid = X_valid.reindex(columns=X_train.columns, fill_value=0)
    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)

    train_accs_depth = []
    test_accs_depth = []
    valid_accs_depth = []

    for depth in depths:
        clf = SklearnTree(criterion='entropy', max_depth=depth)
        clf.fit(X_train, y_train)

        train_acc = clf.score(X_train, y_train)
        test_acc = clf.score(X_test, y_test)
        valid_acc = clf.score(X_valid, y_valid)

        train_accs_depth.append(train_acc)
        test_accs_depth.append(test_acc)
        valid_accs_depth.append(valid_acc)

        print(f"[max_depth={depth}] Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, Test: {test_acc:.4f}")

    plt.figure(figsize=(8, 5))
    plt.plot(depths, train_accs_depth, marker='o', label='Train')
    plt.plot(depths, valid_accs_depth, marker='o', label='Validation')
    plt.plot(depths, test_accs_depth, marker='o', label='Test')
    plt.xlabel('Max Depth')
    plt.ylabel('Accuracy')
    plt.title('Accuracy vs Max Depth (criterion=entropy)')
    plt.ylim(0, 1.1)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('partd_max_depth.png')
    plt.show()

    best_depth = depths[valid_accs_depth.index(max(valid_accs_depth))]
    print(f"Best max_depth (based on validation): {best_depth}")

    alphas = [0.001, 0.01, 0.1, 0.2]
    train_accs_alpha = []
    test_accs_alpha = []
    valid_accs_alpha = []

    for alpha in alphas:
        clf = SklearnTree(criterion='entropy', ccp_alpha=alpha)
        clf.fit(X_train, y_train)

        train_acc = clf.score(X_train, y_train)
        test_acc = clf.score(X_test, y_test)
        valid_acc = clf.score(X_valid, y_valid)

        train_accs_alpha.append(train_acc)
        test_accs_alpha.append(test_acc)
        valid_accs_alpha.append(valid_acc)

        print(f"[ccp_alpha={alpha}] Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, Test: {test_acc:.4f}")

    plt.figure(figsize=(8, 5))
    plt.plot(alphas, train_accs_alpha, marker='o', label='Train')
    plt.plot(alphas, valid_accs_alpha, marker='o', label='Validation')
    plt.plot(alphas, test_accs_alpha, marker='o', label='Test')
    plt.xlabel('ccp_alpha')
    plt.ylabel('Accuracy')
    plt.title('Accuracy vs ccp_alpha (full depth)')
    plt.ylim(0, 1.1)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('partd_ccp_alpha.png')
    plt.show()

    best_alpha = alphas[valid_accs_alpha.index(max(valid_accs_alpha))]
    print(f"Best ccp_alpha (based on validation): {best_alpha}")

if __name__ == "__main__":
    parta()
    partb()
    partc()
    partd()




import numpy as np

class GNN:
    def __init__(self, input_size, hidden_layers, output_size):
        self.layers = [input_size] + hidden_layers + [output_size]
        self.num_layers = len(self.layers) - 1
        
        self.weights = [np.random.randn(self.layers[i], self.layers[i+1]) * np.sqrt(1. / self.layers[i])
                        for i in range(self.num_layers)]
<A NAME="5"></A><FONT color = #FF0000><A HREF="match165-0.html#5" TARGET="0"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        self.biases = [np.zeros((1, self.layers[i+1])) for i in range(self.num_layers)]

    def sigmoid(self, z):
        return 1 / (1 + np.exp(-z))

    def sigmoid_derivative(self, a):
        return a * (1 - a)
</FONT>
    def softmax(self, z):
        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))
        return exp_z / np.sum(exp_z, axis=1, keepdims=True)

    def forward(self, X):
        activations = [X]
        zs = []

        for i in range(self.num_layers - 1):
            z = activations[-1] @ self.weights[i] + self.biases[i]
            zs.append(z)
            a = self.sigmoid(z)
            activations.append(a)

        z = activations[-1] @ self.weights[-1] + self.biases[-1]
<A NAME="0"></A><FONT color = #FF0000><A HREF="match165-0.html#0" TARGET="0"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        zs.append(z)
        a = self.softmax(z)
        activations.append(a)

        return activations, zs

    def compute_loss(self, y_true, y_pred):
        m = y_true.shape[0]
</FONT>        return -np.sum(y_true * np.log(y_pred + 1e-9)) / m 

    def backward(self, activations, zs, y_true):
        grads_w = [None] * self.num_layers
        grads_b = [None] * self.num_layers

        delta = activations[-1] - y_true
        grads_w[-1] = activations[-2].T @ delta
        grads_b[-1] = np.sum(delta, axis=0, keepdims=True)

        for l in reversed(range(self.num_layers - 1)):
            delta = (delta @ self.weights[l+1].T) * self.sigmoid_derivative(activations[l+1])
            grads_w[l] = activations[l].T @ delta
            grads_b[l] = np.sum(delta, axis=0, keepdims=True)

        return grads_w, grads_b

    def fit(self, X, y, epochs=100, batch_size=32, lr=0.01, verbose=True, tol=1e-4, patience=3, alr = False):
        prev_loss = float('inf')
        no_improve_epochs = 0

        for epoch in range(epochs):
            indices = np.arange(X.shape[0])
            np.random.shuffle(indices)
            X_shuffled = X[indices]
            y_shuffled = y[indices]
            epoch_loss = 0
            lr2 = lr
            if alr:
                lr2 /= ((epoch+1)**0.5)

            for i in range(0, X.shape[0], batch_size):
                X_batch = X_shuffled[i:i+batch_size]
                y_batch = y_shuffled[i:i+batch_size]

                activations, zs = self.forward(X_batch)
                loss = self.compute_loss(y_batch, activations[-1])
                epoch_loss += loss * X_batch.shape[0]

                grads_w, grads_b = self.backward(activations, zs, y_batch)

                for j in range(self.num_layers):
                    self.weights[j] -= lr2 * grads_w[j] / batch_size
                    self.biases[j] -= lr2 * grads_b[j] / batch_size

            epoch_loss /= X.shape[0]

            if verbose:
                print(f"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}")

            if abs(prev_loss - epoch_loss) &lt; tol:
                no_improve_epochs += 1
                if no_improve_epochs &gt;= patience:
                    if verbose:
                        print(f"Early stopping at epoch {epoch+1} (change in loss &lt; {tol} for {patience} epochs)")
                    break
            else:
                no_improve_epochs = 0
                prev_loss = epoch_loss


    def predict(self, X):
        activations, _ = self.forward(X)
        return np.argmax(activations[-1], axis=1)

    def predict_proba(self, X):
        activations, _ = self.forward(X)
        return activations[-1]

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
import pandas as pd
import sys
import os

def load_data(path):
    df = pd.read_csv(path)
    X = df.drop(columns=['label']).values
    y = df['label'].values
    return X, y

def preprocess_labels(y, num_classes=None):
    encoder = LabelEncoder()
    y_encoded = encoder.fit_transform(y)
    if num_classes is None:
        num_classes = np.max(y_encoded) + 1
    onehot = np.eye(num_classes)[y_encoded]
    return onehot, encoder

def main():
    if len(sys.argv) != 5:
        print("Usage: python neural_network.py &lt;train_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
        sys.exit(1)

    train_path = sys.argv[1]
    test_path = sys.argv[2]
    output_folder = sys.argv[3]
    part = sys.argv[4].lower()

    if part not in ['b', 'c', 'd']:
        print("Question part must be one of 'b', 'c', or 'd'. 'e' not implemented.")
        sys.exit(1)

    X_train, y_train = load_data(train_path)
    X_test_df = pd.read_csv(test_path)
    X_test = X_test_df.values

    y_train_onehot, label_encoder = preprocess_labels(y_train)
    input_size = X_train.shape[1]
    output_size = y_train_onehot.shape[1]

    if part == 'b':
        hidden_layers = [100]
        alr = False
    elif part == 'c':
        hidden_layers = [512, 256, 128, 64]
        alr = False
    elif part == 'd':
        hidden_layers = [512, 256, 128, 64]
        alr = True

    nn = GNN(input_size=input_size, hidden_layers=hidden_layers, output_size=output_size)
    nn.fit(X_train, y_train_onehot, epochs=100, batch_size=32, lr=0.01, verbose=True, patience=5, alr=alr)

    y_pred = nn.predict(X_test)
    y_pred_labels = label_encoder.inverse_transform(y_pred)

    output_df = pd.DataFrame({'prediction': y_pred_labels})
    output_file = os.path.join(output_folder, f"prediction_{part}.csv")
    output_df.to_csv(output_file, index=False)

if __name__ == "__main__":
    main()


</PRE>
</PRE>
</BODY>
</HTML>
