<HTML>
<HEAD>
<TITLE>./A3_processed_new_hash/combined_BKVDM.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A3_processed_new_hash/combined_XA187.py<p><PRE>


import sys
import os
import pandas as pd
from DT import DecisionTree
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import accuracy_score

def compute_test_accuracy(preds, y_true):
    acc = accuracy_score(y_true, preds)
    print(f"Test Accuracy: {acc * 100:.2f}%")

def load_data(path):
    return pd.read_csv(path)

def save_predictions(preds, output_file):
    pd.DataFrame({'prediction': preds}).to_csv(output_file, index=False)

if __name__ == '__main__':
    train_path = sys.argv[1]
    val_path = sys.argv[2]
    test_path = sys.argv[3]
    output_path = sys.argv[4]
    part = sys.argv[5]
    train_data = pd.read_csv(train_path)
    valid_data = pd.read_csv(val_path)
    test_data = pd.read_csv(test_path)
    for df in [train_data, valid_data, test_data]:
        df['income'] = df['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)


    X_train, y_train = train_data.drop(columns='income'), train_data['income']
    X_val, y_val = valid_data.drop(columns='income'), valid_data['income']
    X_test, y_test = test_data.drop(columns='income'), test_data['income']

    X_train_enc = pd.get_dummies(X_train)
    X_valid_enc = pd.get_dummies(X_val)
    X_test_enc = pd.get_dummies(X_test)
    X_train_enc, X_valid_enc = X_train_enc.align(X_valid_enc, join='left', axis=1, fill_value=0)
    X_train_enc, X_test_enc = X_train_enc.align(X_test_enc, join='left', axis=1, fill_value=0)

    if part == 'a':
        model = DecisionTree(max_depth=20)
        model.fit(X_train, y_train)
        preds = model.predict(X_test)

    elif part == 'b':
        model = DecisionTree(max_depth=55)
        model.fit(X_train_enc, y_train)
        preds = model.predict(X_test_enc)

    elif part == 'c':
        model = DecisionTree(max_depth=55)
        model.set_eval_sets(X_train_enc, y_train, X_test_enc, y_val)  # We use val to prune
        model.fit(X_train_enc, y_train)
        model.set_eval_sets(X_train_enc, y_train, X_test_enc, y_val)  # set again for pruning
        model.prune(X_valid_enc, y_val)
        preds = model.predict(X_test_enc)

    elif part == 'd':
        clf = DecisionTreeClassifier(criterion='entropy', max_depth=55, ccp_alpha=0.001)
        clf.fit(X_train_enc, y_train)
        preds = clf.predict(X_test_enc)

    elif part == 'e':
        clf = RandomForestClassifier(
            n_estimators=150,
            max_features=0.3,
            min_samples_split=10,
            criterion='entropy',
            oob_score=True,
            random_state=42
        )
        clf.fit(X_train_enc, y_train)
        preds = clf.predict(X_test_enc)

    else:
        raise ValueError("Invalid part. Choose from 'a' to 'e'.")

    compute_test_accuracy(preds, y_test)
    os.makedirs(output_path, exist_ok=True)
    save_predictions(preds, os.path.join(output_path, f"prediction_{part}.csv"))




import numpy as np
import pandas as pd
from collections import Counter

class Node:
    def __init__(self, feature=None, threshold=None, children=None, value=None):
        self.feature = feature
        self.threshold = threshold
        self.children = children if children is not None else {}
        self.value = value

class DecisionTree:
    def __init__(self, max_depth=None):
        self.max_depth = max_depth
        self.tree = None

    def entropy(self, y):
        counter = Counter(y)
        total = len(y)
        return -sum((count / total) * np.log2(count / total) for count in counter.values() if count &gt; 0)

    def information_gain(self, X_column, y, is_numeric):
        entropy_before = self.entropy(y)
        if is_numeric:
            threshold = np.median(X_column)
            left_mask = X_column &lt;= threshold
            right_mask = X_column &gt; threshold
            y_left, y_right = y[left_mask], y[right_mask]
            if len(y_left) == 0 or len(y_right) == 0:
                return 0, threshold
            entropy_after = (len(y_left) / len(y)) * self.entropy(y_left) + (len(y_right) / len(y)) * self.entropy(y_right)
            return entropy_before - entropy_after, threshold
        else:
            entropy_after = 0
            for val in X_column.unique():
                y_subset = y[X_column == val]
                entropy_after += (len(y_subset) / len(y)) * self.entropy(y_subset)
            return entropy_before - entropy_after, None

    def best_split(self, X, y):
        best_gain = -1
        best_feature = None
        best_threshold = None
        is_numeric_split = False
        for feature in X.columns:
            is_numeric = np.issubdtype(X[feature].dtype, np.number)
            gain, threshold = self.information_gain(X[feature], y, is_numeric)
            if gain &gt; best_gain:
                best_gain = gain
                best_feature = feature
                best_threshold = threshold
                is_numeric_split = is_numeric
        return best_feature, best_threshold, is_numeric_split

    def build_tree(self, X, y, depth=0):
        if len(y) == 0:
            return Node(value=0)
        if len(set(y)) == 1:
            return Node(value=y.iloc[0])
        if self.max_depth is not None and depth &gt;= self.max_depth:
            return Node(value=y.mode()[0])
        best_feature, best_threshold, is_numeric_split = self.best_split(X, y)
        if best_feature is None:
            return Node(value=y.mode()[0])
        if is_numeric_split:
            left_mask = X[best_feature] &lt;= best_threshold
<A NAME="0"></A><FONT color = #FF0000><A HREF="match68-0.html#0" TARGET="0"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

            right_mask = X[best_feature] &gt; best_threshold
            left_subtree = self.build_tree(X[left_mask], y[left_mask], depth + 1)
            right_subtree = self.build_tree(X[right_mask], y[right_mask], depth + 1)
            return Node(feature=best_feature, threshold=best_threshold, children={'&lt;=': left_subtree, '&gt;': right_subtree})
</FONT>        else:
            children = {}
            for val in X[best_feature].unique():
                mask = X[best_feature] == val
                children[val] = self.build_tree(X[mask], y[mask], depth + 1)
            return Node(feature=best_feature, children=children)

    def fit(self, X, y):
        self.tree = self.build_tree(X, y)

    def predict_row(self, node, row):
        if node.value is not None:
            return node.value
        val = row[node.feature]
        if node.threshold is not None:
            branch = '&lt;=' if val &lt;= node.threshold else '&gt;'
            return self.predict_row(node.children[branch], row)
        else:
            if val in node.children:
                return self.predict_row(node.children[val], row)
            else:
                votes = [child.value for child in node.children.values() if child.value is not None]
                return Counter(votes).most_common(1)[0][0] if votes else 0

    def predict(self, X):
        return np.array([self.predict_row(self.tree, row) for _, row in X.iterrows()])

    def count_nodes(self, node=None):
        if node is None:
            node = self.tree
        if node.value is not None:
            return 1
        return 1 + sum(self.count_nodes(child) for child in node.children.values())

    def prune(self, X_val, y_val):
        def prune_node(node, X, y):
            if node.value is not None:
                return node, False
            # Recursively try to prune children
            improved = False
            for key, child in node.children.items():
                X_subset = X.copy()
                if node.threshold is not None:
                    X_subset = X[X[node.feature] &lt;= node.threshold] if key == '&lt;=' else X[X[node.feature] &gt; node.threshold]
                else:
                    X_subset = X[X[node.feature] == key]
                y_subset = y.loc[X_subset.index]
                new_child, child_improved = prune_node(child, X_subset, y_subset)
                node.children[key] = new_child
                improved = improved or child_improved
            original_preds = self.predict(X_val)
            if len(y) == 0:
                return node, False  

            original_acc = np.mean(original_preds == y_val)
            majority_class = Counter(y).most_common(1)[0][0]
            backup = node.children.copy(), node.feature, node.threshold
            node.value = majority_class
            node.children = {}
            node.feature = None
            node.threshold = None
            new_preds = self.predict(X_val)
            new_acc = np.mean(new_preds == y_val)
            if new_acc &gt;= original_acc:
                return node, True
            else:
                node.children, node.feature, node.threshold = backup
                node.value = None
                return node, improved

        improved = True
        nodes, train_accs, val_accs, test_accs = [], [], [], []
        while improved:
            nodes.append(self.count_nodes())
            train_accs.append(np.mean(self.predict(self.X_train) == self.y_train))
            val_accs.append(np.mean(self.predict(X_val) == y_val))
            test_accs.append(np.mean(self.predict(self.X_test) == self.y_test))
            self.tree, improved = prune_node(self.tree, X_val, y_val)
        return nodes, train_accs, val_accs, test_accs

    def set_eval_sets(self, X_train, y_train, X_test, y_test):
        self.X_train = X_train
        self.y_train = y_train
        self.X_test = X_test
        self.y_test = y_test




from DT import DecisionTree
from utils import load_data
import numpy as np
import matplotlib.pyplot as plt

train_data, valid_data, test_data = load_data()

for df in [train_data, valid_data, test_data]:
    df['income'] = df['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

X_train, y_train = train_data.drop(columns=['income']), train_data['income']
X_test, y_test = test_data.drop(columns=['income']), test_data['income']

depths = [3,5, 10,15,20]
train_accuracies = []
test_accuracies = []

for depth in depths:
    print(f"\nTraining tree with max_depth = {depth}")
    tree = DecisionTree(max_depth=depth)
    tree.fit(X_train, y_train)

<A NAME="3"></A><FONT color = #00FFFF><A HREF="match68-0.html#3" TARGET="0"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    train_preds = tree.predict(X_train)
    test_preds = tree.predict(X_test)

    train_acc = np.mean(train_preds == y_train)
    test_acc = np.mean(test_preds == y_test)

    train_accuracies.append(train_acc)
</FONT>    test_accuracies.append(test_acc)

    print(f"Train Accuracy: {train_acc:.4f}")
    print(f"Test Accuracy:  {test_acc:.4f}")

plt.figure(figsize=(8, 5))
plt.plot(depths, train_accuracies, marker='o', label='Train Accuracy')
plt.plot(depths, test_accuracies, marker='o', label='Test Accuracy')
plt.xlabel("Max Depth")
plt.ylabel("Accuracy")
plt.title("Train vs Test Accuracy vs Max Depth")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()






from DT import DecisionTree
from utils import load_data
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

train_data, valid_data, test_data = load_data()
for df in [train_data, valid_data, test_data]:
    df['income'] = df['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

X_train, y_train = train_data.drop(columns=['income']), train_data['income']
X_test, y_test = test_data.drop(columns=['income']), test_data['income']

X_train_encoded = pd.get_dummies(X_train)
X_test_encoded = pd.get_dummies(X_test)

X_train_encoded, X_test_encoded = X_train_encoded.align(X_test_encoded, join='left', axis=1, fill_value=0)

depths = [25, 35, 45, 55]
train_accuracies = []
test_accuracies = []

for depth in depths:
    print(f"\nTraining tree with max_depth = {depth}")
    tree = DecisionTree(max_depth=depth)
    tree.fit(X_train_encoded, y_train)

<A NAME="4"></A><FONT color = #FF00FF><A HREF="match68-0.html#4" TARGET="0"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    train_preds = tree.predict(X_train_encoded)
    test_preds = tree.predict(X_test_encoded)

    train_acc = np.mean(train_preds == y_train)
    test_acc = np.mean(test_preds == y_test)

    train_accuracies.append(train_acc)
</FONT>    test_accuracies.append(test_acc)

    print(f"Train Accuracy: {train_acc:.4f}")
    print(f"Test Accuracy:  {test_acc:.4f}")

# Plotting results
plt.figure(figsize=(8, 5))
plt.plot(depths, train_accuracies, marker='o', label='Train Accuracy (OHE)')
plt.plot(depths, test_accuracies, marker='o', label='Test Accuracy (OHE)')
plt.xlabel("Max Depth")
plt.ylabel("Accuracy")
plt.title("Accuracy vs Depth with One-Hot Encoding")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()




from DT import DecisionTree
from utils import load_data
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

train_data, valid_data, test_data = load_data()
for df in [train_data, valid_data, test_data]:
    df['income'] = df['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

X_train, y_train = train_data.drop(columns='income'), train_data['income']
X_valid, y_valid = valid_data.drop(columns='income'), valid_data['income']
X_test, y_test = test_data.drop(columns='income'), test_data['income']

X_train_enc = pd.get_dummies(X_train)
X_valid_enc = pd.get_dummies(X_valid)
X_test_enc = pd.get_dummies(X_test)
X_train_enc, X_valid_enc = X_train_enc.align(X_valid_enc, join='left', axis=1, fill_value=0)
X_train_enc, X_test_enc = X_train_enc.align(X_test_enc, join='left', axis=1, fill_value=0)

depths = [25, 35, 45, 55]

for depth in depths:
    print(f"\nTraining and pruning tree with max_depth = {depth}")
    tree = DecisionTree(max_depth=depth)
    tree.fit(X_train_enc, y_train)
    tree.set_eval_sets(X_train_enc, y_train, X_test_enc, y_test)

    nodes, train_accs, val_accs, test_accs = tree.prune(X_valid_enc, y_valid)

    plt.figure(figsize=(8, 5))
    plt.plot(nodes, train_accs, label='Train Accuracy')
    plt.plot(nodes, val_accs, label='Validation Accuracy')
    plt.plot(nodes, test_accs, label='Test Accuracy')
    plt.xlabel("Number of Nodes")
    plt.ylabel("Accuracy")
    plt.title(f"Pruning Progress (Max Depth = {depth})")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()




from sklearn.tree import DecisionTreeClassifier
from utils import load_data
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

train_data, valid_data, test_data = load_data()
for df in [train_data, valid_data, test_data]:
    df['income'] = df['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

X_train, y_train = train_data.drop(columns='income'), train_data['income']
X_valid, y_valid = valid_data.drop(columns='income'), valid_data['income']
X_test, y_test = test_data.drop(columns='income'), test_data['income']

X_train_enc = pd.get_dummies(X_train)
X_valid_enc = pd.get_dummies(X_valid)
X_test_enc = pd.get_dummies(X_test)
X_train_enc, X_valid_enc = X_train_enc.align(X_valid_enc, join='left', axis=1, fill_value=0)
X_train_enc, X_test_enc = X_train_enc.align(X_test_enc, join='left', axis=1, fill_value=0)

depths = [25, 35, 45, 55]
train_accs = []
val_accs = []
test_accs = []

for depth in depths:
<A NAME="5"></A><FONT color = #FF0000><A HREF="match68-0.html#5" TARGET="0"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    clf = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42)
    clf.fit(X_train_enc, y_train)

    train_accs.append(clf.score(X_train_enc, y_train))
    val_accs.append(clf.score(X_valid_enc, y_valid))
</FONT>    test_accs.append(clf.score(X_test_enc, y_test))

    print(f"max_depth = {depth} | Train Acc = {train_accs[-1]:.4f} | Val Acc = {val_accs[-1]:.4f} | Test Acc = {test_accs[-1]:.4f}")

# Plot
plt.figure(figsize=(8, 5))
plt.plot(depths, train_accs, marker='o', label='Train Accuracy')
plt.plot(depths, val_accs, marker='o', label='Validation Accuracy')
plt.plot(depths, test_accs, marker='o', label='Test Accuracy')
plt.xlabel("Max Depth")
plt.ylabel("Accuracy")
plt.title("Sklearn Decision Tree Accuracy vs Max Depth")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

ccp_alphas = [0.001, 0.01, 0.1, 0.2]
train_accs_ccp = []
val_accs_ccp = []
test_accs_ccp = []

for alpha in ccp_alphas:
<A NAME="6"></A><FONT color = #00FF00><A HREF="match68-0.html#6" TARGET="0"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    clf = DecisionTreeClassifier(criterion='entropy', ccp_alpha=alpha, random_state=42)
    clf.fit(X_train_enc, y_train)

    train_accs_ccp.append(clf.score(X_train_enc, y_train))
    val_accs_ccp.append(clf.score(X_valid_enc, y_valid))
</FONT>    test_accs_ccp.append(clf.score(X_test_enc, y_test))

    print(f"ccp_alpha = {alpha} | Train Acc = {train_accs_ccp[-1]:.4f} | Val Acc = {val_accs_ccp[-1]:.4f} | Test Acc = {test_accs_ccp[-1]:.4f}")


plt.figure(figsize=(8, 5))
plt.plot(ccp_alphas, train_accs_ccp, marker='o', label='Train Accuracy')
plt.plot(ccp_alphas, val_accs_ccp, marker='o', label='Validation Accuracy')
plt.plot(ccp_alphas, test_accs_ccp, marker='o', label='Test Accuracy')
plt.xlabel("ccp_alpha")
plt.ylabel("Accuracy")
plt.title("Sklearn Decision Tree Accuracy vs CCP Alpha")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()




from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import ParameterGrid
from utils import load_data
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

train_data, valid_data, test_data = load_data()
for df in [train_data, valid_data, test_data]:
    df['income'] = df['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

X_train, y_train = train_data.drop(columns='income'), train_data['income']
X_valid, y_valid = valid_data.drop(columns='income'), valid_data['income']
X_test, y_test = test_data.drop(columns='income'), test_data['income']

X_train_enc = pd.get_dummies(X_train)
X_valid_enc = pd.get_dummies(X_valid)
X_test_enc = pd.get_dummies(X_test)
X_train_enc, X_valid_enc = X_train_enc.align(X_valid_enc, join='left', axis=1, fill_value=0)
X_train_enc, X_test_enc = X_train_enc.align(X_test_enc, join='left', axis=1, fill_value=0)

param_grid = {
    'n_estimators': [50, 150, 250, 350],
    'max_features': [0.1, 0.3, 0.5, 0.7, 1.0],
    'min_samples_split': [2, 4, 6, 8, 10]
}

best_oob_score = 0
best_model = None
best_params = {}

for params in ParameterGrid(param_grid):
    print(f"Trying: {params}")
    rf = RandomForestClassifier(
        criterion='entropy',
        oob_score=True,
        bootstrap=True,
        n_estimators=params['n_estimators'],
        max_features=params['max_features'],
        min_samples_split=params['min_samples_split'],
        random_state=42,
        n_jobs=-1
    )
    rf.fit(X_train_enc, y_train)
    if rf.oob_score_ &gt; best_oob_score:
        best_oob_score = rf.oob_score_
        best_model = rf
        best_params = params

train_acc = best_model.score(X_train_enc, y_train)
val_acc = best_model.score(X_valid_enc, y_valid)
test_acc = best_model.score(X_test_enc, y_test)

print("\nBest Parameters:", best_params)
print(f"OOB Accuracy     : {best_oob_score:.4f}")
print(f"Train Accuracy   : {train_acc:.4f}")
print(f"Valid Accuracy   : {val_acc:.4f}")
print(f"Test Accuracy    : {test_acc:.4f}")




from xgboost import XGBClassifier
from utils import load_data
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

train_data, valid_data, test_data = load_data()
for df in [train_data, valid_data, test_data]:
    df['income'] = df['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

X_train, y_train = train_data.drop(columns='income'), train_data['income']
X_valid, y_valid = valid_data.drop(columns='income'), valid_data['income']
X_test, y_test = test_data.drop(columns='income'), test_data['income']

X_train_enc = pd.get_dummies(X_train)
X_valid_enc = pd.get_dummies(X_valid)
X_test_enc = pd.get_dummies(X_test)
X_train_enc, X_valid_enc = X_train_enc.align(X_valid_enc, join='left', axis=1, fill_value=0)
X_train_enc, X_test_enc = X_train_enc.align(X_test_enc, join='left', axis=1, fill_value=0)

xgb = XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    use_label_encoder=False,
    max_depth=6,
    n_estimators=200,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

xgb.fit(X_train_enc, y_train, eval_set=[(X_valid_enc, y_valid)], verbose=False)

train_acc = xgb.score(X_train_enc, y_train)
val_acc = xgb.score(X_valid_enc, y_valid)
test_acc = xgb.score(X_test_enc, y_test)

print("\nXGBoost Results:")
print(f"Train Accuracy : {train_acc:.4f}")
print(f"Valid Accuracy : {val_acc:.4f}")
print(f"Test Accuracy  : {test_acc:.4f}")




import pandas as pd
data_path = '../COL774 Assignment-3 Dataset'
def load_data():
    train_data = pd.read_csv(data_path + '/train.csv')
    valid_data = pd.read_csv(data_path + '/valid.csv')
    test_data = pd.read_csv(data_path + '/test.csv')
    return train_data, valid_data , test_data





import os
import numpy as np
import pandas as pd
import torch
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
from PIL import Image

train_dir = "../Traffic sign board/train"
test_dir = "../Traffic sign board/test"  
test_labels_path = "../Traffic sign board/test_labels.csv"

to_tensor_transform = transforms.ToTensor()

train_dataset = datasets.ImageFolder(
    root=train_dir,
    transform=to_tensor_transform
)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

class GTSTestDataset(Dataset):
    def __init__(self, img_dir, label_csv, transform=None):
        self.img_dir = img_dir
        self.labels_df = pd.read_csv(label_csv)
        self.image_names = self.labels_df["image"].tolist()
        self.labels = self.labels_df["label"].tolist()
        self.transform = transform

    def __len__(self):
        return len(self.image_names)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.image_names[idx])
        image = Image.open(img_path)
        label = self.labels[idx]
        
        if self.transform:
            image = self.transform(image)
        return image, label

test_dataset = GTSTestDataset(
    img_dir=test_dir,
    label_csv=test_labels_path,
    transform=to_tensor_transform
)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

def loader_to_numpy(data_loader, num_classes):
    X_list, Y_list = [], []
    
    for images, labels in data_loader:

        images = images.view(images.size(0), -1)  
        X_list.append(images.numpy())
        
        one_hot = np.zeros((labels.size(0), num_classes))
        one_hot[np.arange(labels.size(0)), labels.numpy()] = 1
        Y_list.append(one_hot)
    
    X = np.vstack(X_list)
    Y = np.vstack(Y_list)
    return X, Y

def load_data():
    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    X_train, Y_train = loader_to_numpy(train_loader, num_classes=43)

    test_dataset = GTSTestDataset(
        img_dir=test_dir,
        label_csv=test_labels_path,
        transform=to_tensor_transform
    )
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
    X_test, Y_test = loader_to_numpy(test_loader, num_classes=43)

    return X_train, Y_train, X_test, Y_test

if __name__ == "__main__":
    print(f"Train dataset size: {len(train_dataset)}")
    print(f"Test dataset size: {len(test_dataset)}")




import sys
import os
import pandas as pd
import numpy as np
from sklearn.neural_network import MLPClassifier
from NN import NeuralNetwork
from NNRelu import NeuralNetworkReLU
from load import load_data


X_train,y_train,X_test,y_test = load_data()




def one_hot_encode(y_train,something):
    return y_train



def save_predictions(preds, output_file):
    pd.DataFrame({'prediction': preds}).to_csv(output_file, index=False)


def preprocess_data(train_path, test_path):
    '''
    Hello !
    I am leaving this function empty because I am unable to figure out where the images are and what is meant by csv path. 
    The instructions are unclear, I went to piazza but could not figure out either.
    I have written a function like this in load.py.
    If necessary, change that and use it.
    Thanks !
    '''
    return X_train, y_train, X_test, y_test

if __name__ == '__main__':
    train_path = sys.argv[1]
    test_path = sys.argv[2]
    output_path = sys.argv[3]
    part = sys.argv[4]

    X_train, y_train, X_test, y_test = preprocess_data(train_path, test_path)

    input_size = X_train.shape[1]
    output_size = 43
    batch_size = 32
    learning_rate = 0.01
    epochs = 200

    if part == 'b':
        hidden_layers = [100]
        model = NeuralNetwork(input_size, hidden_layers, output_size, batch_size, learning_rate)
        model.train(X_train, one_hot_encode(y_train, output_size), epochs=epochs)
        preds = np.argmax(model.predict(X_test), axis=1)

    elif part == 'c':
        hidden_layers = [512, 256, 128, 64]
        model = NeuralNetwork(input_size, hidden_layers, output_size, batch_size, learning_rate)
        model.train(X_train, one_hot_encode(y_train, output_size), epochs=epochs)
        preds = np.argmax(model.predict(X_test), axis=1)

    elif part == 'd':
        hidden_layers = [512, 256, 128, 64]
        model = NeuralNetwork(input_size, hidden_layers, output_size, batch_size, learning_rate)
        model.train_adaptive_lr(X_train, one_hot_encode(y_train, output_size), epochs=epochs)
        preds = np.argmax(model.predict(X_test), axis=1)

    elif part == 'e':
        hidden_layers = [512, 256, 128, 64]
        model = NeuralNetworkReLU(input_size, hidden_layers, output_size, batch_size, learning_rate)
        model.train(X_train, one_hot_encode(y_train, output_size), epochs=epochs, adaptive_lr=True)
        preds = np.argmax(model.predict(X_test), axis=1)

    elif part == 'f':
        hidden_layers = (512, 256, 128, 64)
        clf = MLPClassifier(
            hidden_layer_sizes=hidden_layers,
            activation='relu',
            solver='sgd',
            alpha=0.0,
            batch_size=batch_size,
            learning_rate='invscaling',
            learning_rate_init=learning_rate,
            max_iter=150,
            early_stopping=True,
            n_iter_no_change=3,
            random_state=42,
            verbose=False
        )
        clf.fit(X_train, y_train)
        preds = clf.predict(X_test)

    else:
        raise ValueError("Invalid part. Choose from 'b' to 'f'.")

    os.makedirs(output_path, exist_ok=True)
    save_predictions(preds, os.path.join(output_path, f"prediction_{part}.csv"))



import numpy as np

class NeuralNetwork:
    def __init__(self, input_size, hidden_layers, output_size, batch_size,learning_rate=0.01):
        self.input_size = input_size
        self.hidden_layers = hidden_layers
        self.output_size = output_size
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        layer_sizes = [input_size] + hidden_layers + [output_size]
        self.seed_lr = learning_rate
        
        self.weights = []
        self.biases = []
        
        for i in range(len(layer_sizes) - 1):
            fan_in = layer_sizes[i]
            fan_out = layer_sizes[i + 1]
            self.weights.append(np.random.randn(fan_out, fan_in) * np.sqrt(1 / fan_in))
            self.biases.append(np.zeros((fan_out, 1)))

    def sigmoid(self, z):
        return 1 / (1 + np.exp(-z))

    def softmax(self, z):
        exp_z = np.exp(z - np.max(z, axis=0, keepdims=True))  
        return exp_z / np.sum(exp_z, axis=0, keepdims=True)

    def forward(self, X):
        activations = [X.T]  
        zs = []  

        for i in range(len(self.weights) - 1):  
            z = np.dot(self.weights[i], activations[-1]) + self.biases[i]
            zs.append(z)
            activations.append(self.sigmoid(z))

        z = np.dot(self.weights[-1], activations[-1]) + self.biases[-1]
        zs.append(z)
        activations.append(self.softmax(z))

        return activations, zs 

    def compute_loss(self, Y_true, Y_pred):

        m = Y_true.shape[0]
        return -np.sum(Y_true * np.log(Y_pred.T + 1e-8)) / m  

    def backward(self, activations, zs, X, Y_true):

        m = X.shape[0]  
        grads_w = [np.zeros_like(w) for w in self.weights]
        grads_b = [np.zeros_like(b) for b in self.biases]


        Y_pred = activations[-1]  
        delta = Y_pred - Y_true.T  

        grads_w[-1] = np.dot(delta, activations[-2].T) / m
        grads_b[-1] = np.sum(delta, axis=1, keepdims=True) / m

        for l in range(len(self.hidden_layers), 0, -1):  # Reverse from last hidden layer
            delta = np.dot(self.weights[l].T, delta) * (activations[l] * (1 - activations[l]))  # Sigmoid derivative
            grads_w[l-1] = np.dot(delta, activations[l-1].T) / m
<A NAME="1"></A><FONT color = #00FF00><A HREF="match68-0.html#1" TARGET="0"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

            grads_b[l-1] = np.sum(delta, axis=1, keepdims=True) / m

        for i in range(len(self.weights)):
            self.weights[i] -= self.learning_rate * grads_w[i]
            self.biases[i] -= self.learning_rate * grads_b[i]
</FONT>
    def train(self, X_train, Y_train,epochs=10,loss_diff=1e-5):

        m = X_train.shape[0]  
        num_batches = m // self.batch_size
        prev_avg_loss = 1e10

        for epoch in range(epochs):
            # Shuffle data
            indices = np.random.permutation(m)
            X_train, Y_train = X_train[indices], Y_train[indices]

            total_loss = 0
            for i in range(num_batches):
                X_batch = X_train[i*self.batch_size : (i+1)*self.batch_size]
                Y_batch = Y_train[i*self.batch_size : (i+1)*self.batch_size]

                activations, zs = self.forward(X_batch)
                total_loss += self.compute_loss(Y_batch, activations[-1])
                self.backward(activations, zs, X_batch, Y_batch)

            avg_loss = total_loss / num_batches
            if abs(prev_avg_loss - avg_loss) &lt; loss_diff:
                break
            print(f"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}")
    def train_adaptive_lr(self, X_train, Y_train, epochs=10):

        m = X_train.shape[0]
        num_batches = m // self.batch_size

        for epoch in range(1, epochs+1):

            current_lr = self.seed_lr / np.sqrt(epoch)
            
            indices = np.random.permutation(m)
            X_train_shuffled = X_train[indices]
            Y_train_shuffled = Y_train[indices]

            total_loss = 0
            for i in range(num_batches):
                X_batch = X_train_shuffled[i*self.batch_size:(i+1)*self.batch_size]
                Y_batch = Y_train_shuffled[i*self.batch_size:(i+1)*self.batch_size]
                
                activations, zs = self.forward(X_batch)
                total_loss += self.compute_loss(Y_batch, activations[-1])
                
                self.backward_adaptive_lr(activations, zs, X_batch, Y_batch, current_lr)
            
            avg_loss = total_loss / num_batches
            print(f"Epoch {epoch}/{epochs}, LR={current_lr:.6f}, Loss={avg_loss:.4f}")

    def backward_adaptive_lr(self, activations, zs, X, Y_true, lr):

        m = X.shape[0]
        grads_w = [np.zeros_like(w) for w in self.weights]
        grads_b = [np.zeros_like(b) for b in self.biases]

        Y_pred = activations[-1]
        delta = Y_pred - Y_true.T  

        grads_w[-1] = np.dot(delta, activations[-2].T) / m
        grads_b[-1] = np.sum(delta, axis=1, keepdims=True) / m

        for l in range(len(self.hidden_layers), 0, -1):
            delta = np.dot(self.weights[l].T, delta) * (activations[l] * (1 - activations[l]))
            grads_w[l-1] = np.dot(delta, activations[l-1].T) / m
            grads_b[l-1] = np.sum(delta, axis=1, keepdims=True) / m

        for i in range(len(self.weights)):
            self.weights[i] -= lr * grads_w[i]
            self.biases[i]  -= lr * grads_b[i]

    def predict(self, X):
        activations, _ = self.forward(X)
        return activations[-1].T 

    def evaluate(self, X_test, Y_test):

        Y_pred = self.predict(X_test)
        Y_pred_labels = np.argmax(Y_pred, axis=1)
        Y_true_labels = np.argmax(Y_test, axis=1)
        accuracy = np.mean(Y_pred_labels == Y_true_labels)
        print(f"Accuracy: {accuracy * 100:.2f}%")





import numpy as np

class NeuralNetworkReLU:
    def __init__(self, input_size, hidden_layers, output_size, batch_size, learning_rate=0.01):
        self.input_size = input_size
        self.hidden_layers = hidden_layers
        self.output_size = output_size
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        
        layer_sizes = [input_size] + hidden_layers + [output_size]
        
        self.weights = []
        self.biases = []
        for i in range(len(layer_sizes) - 1):
            fan_in = layer_sizes[i]
            fan_out = layer_sizes[i + 1]

            self.weights.append(np.random.randn(fan_out, fan_in) * np.sqrt(2.0 / fan_in))
            self.biases.append(np.zeros((fan_out, 1)))

    def relu(self, z):
        return np.maximum(0, z)

    def relu_derivative(self, z):
        return (z &gt; 0).astype(float)

    def softmax(self, z):
        exp_z = np.exp(z - np.max(z, axis=0, keepdims=True))
        return exp_z / np.sum(exp_z, axis=0, keepdims=True)

    def forward(self, X):

        activations = [X.T]  
        zs = []  

        for i in range(len(self.weights) - 1):
            z = self.weights[i] @ activations[-1] + self.biases[i]
            zs.append(z)
            a = self.relu(z)
            activations.append(a)

        z = self.weights[-1] @ activations[-1] + self.biases[-1]
        zs.append(z)
        out = self.softmax(z)  
        activations.append(out)

        return activations, zs

    def compute_loss(self, Y_true, Y_pred):

        m = Y_true.shape[0]
        return -np.sum(Y_true * np.log(Y_pred.T + 1e-8)) / m

    def backward(self, activations, zs, X, Y_true):

        m = X.shape[0]
        grads_w = [np.zeros_like(w) for w in self.weights]
        grads_b = [np.zeros_like(b) for b in self.biases]


        Y_pred = activations[-1] 
        delta = Y_pred - Y_true.T 

        grads_w[-1] = (delta @ activations[-2].T) / m
        grads_b[-1] = np.sum(delta, axis=1, keepdims=True) / m

        for l in range(len(self.hidden_layers), 0, -1):
            delta = (self.weights[l].T @ delta)
            d_relu = self.relu_derivative(zs[l-1])  
            delta = delta * d_relu

            grads_w[l-1] = (delta @ activations[l-1].T) / m
<A NAME="2"></A><FONT color = #0000FF><A HREF="match68-0.html#2" TARGET="0"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

            grads_b[l-1] = np.sum(delta, axis=1, keepdims=True) / m

        for i in range(len(self.weights)):
            self.weights[i] -= self.learning_rate * grads_w[i]
            self.biases[i]  -= self.learning_rate * grads_b[i]
</FONT>
    def train(self, X_train, Y_train, epochs=10, adaptive_lr=False):
        m = X_train.shape[0]
        num_batches = m // self.batch_size

        for epoch in range(1, epochs + 1):
            indices = np.random.permutation(m)
            X_train, Y_train = X_train[indices], Y_train[indices]

            if adaptive_lr:
                eta = self.learning_rate / np.sqrt(epoch)
            else:
                eta = self.learning_rate

            total_loss = 0
            for i in range(num_batches):
                start = i * self.batch_size
                end = (i + 1) * self.batch_size
                X_batch = X_train[start:end]
                Y_batch = Y_train[start:end]

                activations, zs = self.forward(X_batch)
                total_loss += self.compute_loss(Y_batch, activations[-1])
                
                original_lr = self.learning_rate
                self.learning_rate = eta
                self.backward(activations, zs, X_batch, Y_batch)
                self.learning_rate = original_lr

            avg_loss = total_loss / num_batches
            print(f"Epoch {epoch}/{epochs}, Learning Rate = {eta:.6f}, Loss = {avg_loss:.4f}")

    def predict(self, X):
        activations, zs = self.forward(X)
        return activations[-1].T

    def evaluate(self, X, Y):

        y_probs = self.predict(X)  
        y_pred = np.argmax(y_probs, axis=1)
        y_true = np.argmax(Y, axis=1)
        acc = np.mean(y_pred == y_true)
        print(f"Accuracy: {acc * 100:.2f}%")
        return acc




# Example usage
from NN import NeuralNetwork
from load import load_data
input_size = 28 * 28 * 3  # 28x28 RGB images
hidden_layers = [100, 50]  # Example hidden layer structure
output_size = 43  # 43 traffic sign classes
batch_size = 64

nn = NeuralNetwork(input_size, hidden_layers, output_size, batch_size)

X_train, Y_train, X_test, Y_test = load_data()

# Assuming X_train is (num_samples, 28*28*3) and Y_train is one-hot encoded (num_samples, 43)
nn.train(X_train, Y_train, 100)

# Evaluate on test set

print("Evaluating on train : ")
nn.evaluate(X_train, Y_train)

print("Evaluating on validation : ")
nn.evaluate(X_test, Y_test)

print("Evaluating on test : ")
nn.evaluate(X_test, Y_test)





import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_fscore_support
from NN import NeuralNetwork  
from load import load_data    


X_train, Y_train, X_test, Y_test = load_data()
print("Train data shape:", X_train.shape, Y_train.shape)
print("Test  data shape:", X_test.shape,  Y_test.shape)

hidden_sizes = [1, 5, 10, 50, 100]
learning_rate = 0.01
batch_size = 32
input_size = 2352
output_size = 43

avg_f1_train_list = []
avg_f1_test_list = []

def train_single_layer(hidden_units):
    nn = NeuralNetwork(
        input_size=input_size,
        hidden_layers=[hidden_units],  
        output_size=output_size,
        batch_size=batch_size,
        learning_rate=learning_rate
    )
    nn.train(X_train, Y_train, epochs=200)
    return nn

def evaluate_metrics(model, X, Y):

    y_probs = model.predict(X)                
    y_pred = np.argmax(y_probs, axis=1)  
    y_true = np.argmax(Y, axis=1)      
    precision, recall, f1, _ = precision_recall_fscore_support(
        y_true, y_pred, average=None, labels=range(43)
    )
    
    avg_f1 = np.mean(f1)
    
    return precision, recall, f1, avg_f1

for hidden_units in hidden_sizes:
    model = train_single_layer(hidden_units)

    train_precision, train_recall, train_f1, avg_f1_train = evaluate_metrics(model, X_train, Y_train)
    test_precision, test_recall, test_f1, avg_f1_test = evaluate_metrics(model, X_test, Y_test)

    with open(f"results_part2.txt", "a") as f:
        f.write(f"\n=== Training single layer NN with {hidden_units} hidden units ===\n")
        f.write(f"Train set: Avg F1 = {avg_f1_train:.4f}\n")
        f.write(f"Test  set: Avg F1 = {avg_f1_test:.4f}\n\n")

    avg_f1_train_list.append(avg_f1_train)
    avg_f1_test_list.append(avg_f1_test)


avg_f1_train_list = avg_f1_train_list[-5:]
avg_f1_test_list = avg_f1_test_list[-5:]

import matplotlib.pyplot as plt

plt.plot(hidden_sizes, avg_f1_train_list, marker='o', label='Train Avg F1')
plt.plot(hidden_sizes, avg_f1_test_list, marker='o', label='Test Avg F1')
plt.xlabel('Hidden Layer Units')
plt.ylabel('Average F1 Score')
plt.title('Single Hidden Layer: Avg F1 vs #units')
plt.legend()
plt.show()






import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_fscore_support
from NN import NeuralNetwork
from load import load_data

X_train, Y_train, X_test, Y_test = load_data()
# print("X_train shape:", X_train.shape)
# print("Y_train shape:", Y_train.shape)
# print("X_test shape:",  X_test.shape)
# print("Y_test shape:",  Y_test.shape)

architectures = [
    [512],           
    [512, 256],        
    [512, 256, 128],   
    [512, 256, 128, 64] 
]

def train_network(hidden_layers):
    input_size = 2352  # 28*28*3
    output_size = 43
    batch_size = 32
    learning_rate = 0.01
    
    nn = NeuralNetwork(
        input_size=input_size,
        hidden_layers=hidden_layers,
        output_size=output_size,
        batch_size=batch_size,
        learning_rate=learning_rate
    )
    nn.train(X_train, Y_train, epochs=100)
    return nn


def evaluate_metrics(model, X, Y):
    Y_pred_probs = model.predict(X)  
    Y_pred_labels = np.argmax(Y_pred_probs, axis=1)

    if len(Y.shape) &gt; 1 and Y.shape[1] &gt; 1:
        Y_true_labels = np.argmax(Y, axis=1)
    else:
        Y_true_labels = Y

    precision, recall, f1, _ = precision_recall_fscore_support(Y_true_labels, Y_pred_labels, average='macro')
    return precision, recall, f1


depth_list = []            
avg_f1_train_list = []
avg_f1_test_list = []

for hidden_layers in architectures:
    model = train_network(hidden_layers)
    with open("results_part_3.txt", "a") as f:
        depth = len(hidden_layers)
        f.write(f"\n=== Training network with depth={depth}, hidden layers={hidden_layers} ===\n")
        print(f"\n=== Training network with depth={depth}, hidden layers={hidden_layers} ===")


        train_precision, train_recall, train_f1 = evaluate_metrics(model, X_train, Y_train)
        test_precision, test_recall, test_f1 = evaluate_metrics(model, X_test, Y_test)

        f.write(f"Train set: Precision = {train_precision:.4f}, Recall = {train_recall:.4f}, F1 = {train_f1:.4f}\n")
        f.write(f"Test  set: Precision = {test_precision:.4f}, Recall = {test_recall:.4f}, F1 = {test_f1:.4f}\n\n")
        print(f"Train set: Precision = {train_precision:.4f}, Recall = {train_recall:.4f}, F1 = {train_f1:.4f}")
        print(f"Test  set: Precision = {test_precision:.4f}, Recall = {test_recall:.4f}, F1 = {test_f1:.4f}")

        depth_list.append(depth)
        avg_f1_train_list.append(train_f1)
        avg_f1_test_list.append(test_f1)

import matplotlib.pyplot as plt

plt.plot(depth_list, avg_f1_train_list, marker='o', label='Train Avg F1')
plt.plot(depth_list, avg_f1_test_list, marker='o', label='Test Avg F1')
plt.xlabel('Depth of Network (Number of Hidden Layers)')
plt.ylabel('Average F1 Score')
plt.title('Depth vs Average F1 (Single or Multiple Hidden Layers)')
plt.legend()
plt.show()





from NN import NeuralNetwork
from load import load_data
from sklearn.metrics import precision_recall_fscore_support
import numpy as np
import matplotlib.pyplot as plt

architectures = [
    [512],
    [512, 256],
    [512, 256, 128],
    [512, 256, 128, 64]
]

X_train, Y_train, X_test, Y_test = load_data()


def evaluate_metrics(model, X, Y):
    Y_pred_probs = model.predict(X)  
    Y_pred_labels = np.argmax(Y_pred_probs, axis=1)

    if len(Y.shape) &gt; 1 and Y.shape[1] &gt; 1:
        Y_true_labels = np.argmax(Y, axis=1)
    else:
        Y_true_labels = Y

    precision, recall, f1, _ = precision_recall_fscore_support(Y_true_labels, Y_pred_labels, average='macro')
    return precision, recall, f1
def train_model(hidden_layers):
    nn = NeuralNetwork(
        input_size=2352,
        hidden_layers=hidden_layers,
        output_size=43,
        batch_size=32,
        learning_rate=0.01
    )
    nn.train_adaptive_lr(X_train, Y_train, epochs=200)
    return nn

# depth_values = []
# avg_f1_train_list = []
# avg_f1_test_list = []

# for hidden_layers in architectures:
#     depth = len(hidden_layers)
#     print(f"\n=== Depth {depth}, hidden layers = {hidden_layers} ===")

#     # Create and train with adaptive LR
#     nn = NeuralNetwork(
#         input_size=2352,
#         hidden_layers=hidden_layers,
#         output_size=43,
#         batch_size=32,
#         learning_rate=0.01
#     )
#     # Use our new train method
#     nn.train_adaptive_lr(X_train, Y_train, epochs=10)

#     # Evaluate train
#     p_tr, r_tr, f1_tr, avg_f1_tr = evaluate_metrics(nn, X_train, Y_train)
#     # Evaluate test
#     p_te, r_te, f1_te, avg_f1_te = evaluate_metrics(nn, X_test, Y_test)

#     print(f"Train Avg F1 = {avg_f1_tr:.4f}")
#     print(f"Test  Avg F1 = {avg_f1_te:.4f}")

#     depth_values.append(depth)
#     avg_f1_train_list.append(avg_f1_tr)
#     avg_f1_test_list.append(avg_f1_te)




depth_list = []
avg_f1_train_list = []
avg_f1_test_list = []

for hidden_layers in architectures:
    model = train_model(hidden_layers)  

    depth = len(hidden_layers)
    print(f"\n=== Training network with depth={depth}, hidden layers={hidden_layers} ===")

    with open("results_part4.txt", "a") as f:
        f.write(f"\n=== Training network with depth={depth}, hidden layers={hidden_layers} ===\n")

        train_precision, train_recall, train_f1 = evaluate_metrics(model, X_train, Y_train)
        test_precision, test_recall, test_f1 = evaluate_metrics(model, X_test, Y_test)

        f.write(f"Train set: Precision = {train_precision:.4f}, Recall = {train_recall:.4f}, F1 = {train_f1:.4f}\n")
        f.write(f"Test  set: Precision = {test_precision:.4f}, Recall = {test_recall:.4f}, F1 = {test_f1:.4f}\n\n")
        print(f"Train set: Precision = {train_precision:.4f}, Recall = {train_recall:.4f}, F1 = {train_f1:.4f}")
        print(f"Test  set: Precision = {test_precision:.4f}, Recall = {test_recall:.4f}, F1 = {test_f1:.4f}")

        depth_list.append(depth)
        avg_f1_train_list.append(train_f1)
        avg_f1_test_list.append(test_f1)



# Plot
# plt.plot(depth_values, avg_f1_train_list, marker='o', label='Train Avg F1')
# plt.plot(depth_values, avg_f1_test_list, marker='o', label='Test Avg F1')
# plt.title("Average F1 vs. Network Depth with Adaptive LR")
# plt.xlabel("Depth (Number of Hidden Layers)")
# plt.ylabel("Average F1 Score")
# plt.legend()
# plt.show()







import numpy as np 
from NNRelu import NeuralNetworkReLU

from load import load_data
from sklearn.metrics import precision_recall_fscore_support
X_train, y_train, X_test, y_test = load_data()
def evaluate_metrics(model, X, Y):
    Y_pred_probs = model.predict(X)  
    Y_pred_labels = np.argmax(Y_pred_probs, axis=1)

    if len(Y.shape) &gt; 1 and Y.shape[1] &gt; 1:
        Y_true_labels = np.argmax(Y, axis=1)
    else:
        Y_true_labels = Y

    precision, recall, f1, _ = precision_recall_fscore_support(Y_true_labels, Y_pred_labels, average='macro')
    return precision, recall, f1
depth_list = []
avg_f1_train_list = []
avg_f1_test_list = []

architectures = [
    [512],
    [512, 256],
    [512, 256, 128],
    [512, 256, 128, 64]
]

for hidden_layers in architectures:
    depth = len(hidden_layers)
    print(f"\n=== Training ReLU network with depth={depth}, hidden layers={hidden_layers} ===")

    model = NeuralNetworkReLU(
        input_size=2352,
        hidden_layers=hidden_layers,
        output_size=43,
        batch_size=32,
        learning_rate=0.01
    )
    
    model.train(X_train, y_train, epochs=150, adaptive_lr=True)

    train_precision, train_recall, train_f1 = evaluate_metrics(model, X_train, y_train)
    test_precision, test_recall, test_f1 = evaluate_metrics(model, X_test, y_test)

    with open("results_part_5.txt", "a") as f:
        f.write(f"\n=== Training ReLU network with depth={depth}, hidden layers={hidden_layers} ===\n")
        f.write(f"Train set: Precision = {train_precision:.4f}, Recall = {train_recall:.4f}, F1 = {train_f1:.4f}\n")
        f.write(f"Test  set: Precision = {test_precision:.4f}, Recall = {test_recall:.4f}, F1 = {test_f1:.4f}\n\n")

    print(f"Train set: Precision = {train_precision:.4f}, Recall = {train_recall:.4f}, F1 = {train_f1:.4f}")
    print(f"Test  set: Precision = {test_precision:.4f}, Recall = {test_recall:.4f}, F1 = {test_f1:.4f}")

    depth_list.append(depth)
    avg_f1_train_list.append(train_f1)
    avg_f1_test_list.append(test_f1)







from sklearn.neural_network import MLPClassifier
from sklearn.metrics import precision_recall_fscore_support
import matplotlib.pyplot as plt
import numpy as np
from load import load_data
X_train, Y_train, X_test, Y_test = load_data()
y_train_int = np.argmax(Y_train, axis=1)
y_test_int  = np.argmax(Y_test,  axis=1)


architectures = [
    (512,),
    (512, 256),
    (512, 256, 128),
    (512, 256, 128, 64)
]

# from sklearn.metrics import precision_recall_fscore_support
# import numpy as np
# from sklearn.neural_network import MLPClassifier

# # We'll track the average F1 for train and test
# depths = []
# avg_f1_train_list = []
# avg_f1_test_list = []

# architectures = [
#     [512],
#     [512, 256],
#     [512, 256, 128],
#     [512, 256, 128, 64]
# ]

# for arch in architectures:
#     depth = len(arch)  # number of hidden layers
#     print(f"\n=== Training MLP with hidden_layer_sizes={arch}, Depth={depth} ===")

#     # Create the MLPClassifier
#     mlp = MLPClassifier(
#         hidden_layer_sizes=arch,
#         activation='relu',
#         solver='sgd',
#         alpha=0,
#         batch_size=32,
#         learning_rate='invscaling',
#         max_iter=100,
#         shuffle=True,
#         random_state=42
#     )

#     # Train
#     mlp.fit(X_train, y_train_int)

#     # Predict on train
#     y_pred_train = mlp.predict(X_train)
#     precision_tr, recall_tr, f1_tr, _ = precision_recall_fscore_support(
#         y_train_int, y_pred_train, average='macro'
#     )

#     # Predict on test
#     y_pred_test = mlp.predict(X_test)
#     precision_te, recall_te, f1_te, _ = precision_recall_fscore_support(
#         y_test_int, y_pred_test, average='macro'
#     )

#     # Print to console
#     print(f"Train set: Precision = {precision_tr:.4f}, Recall = {recall_tr:.4f}, F1 = {f1_tr:.4f}")
#     print(f"Test  set: Precision = {precision_te:.4f}, Recall = {recall_te:.4f}, F1 = {f1_te:.4f}")

#     # Append for plotting
#     depths.append(depth)
#     avg_f1_train_list.append(f1_tr)
#     avg_f1_test_list.append(f1_te)

#     # Write to file
#     with open("report_part_6.txt", "a") as f:
#         f.write(f"\n=== Training MLP with hidden_layer_sizes={arch}, Depth={depth} ===\n")
#         f.write(f"Train set: Precision = {precision_tr:.4f}, Recall = {recall_tr:.4f}, F1 = {f1_tr:.4f}\n")
#         f.write(f"Test  set: Precision = {precision_te:.4f}, Recall = {recall_te:.4f}, F1 = {f1_te:.4f}\n\n")

from sklearn.metrics import precision_recall_fscore_support
from sklearn.neural_network import MLPClassifier
import numpy as np

depths = []
avg_f1_train_list = []
avg_f1_test_list = []

architectures = [
    [512],
    [512, 256],
    [512, 256, 128],
    [512, 256, 128, 64]
]

for arch in architectures:
    depth = len(arch)
    print(f"\n=== Training MLPClassifier with hidden_layer_sizes={arch}, Depth={depth} ===")

    mlp = MLPClassifier(hidden_layer_sizes=arch, 
                        activation='relu',
                          solver='sgd', alpha = 0.0,
                            batch_size=32, learning_rate='invscaling', 
                            learning_rate_init=0.01, max_iter = 100, 
                            shuffle = True,
                            early_stopping=True, 
                            n_iter_no_change=3, 
                            random_state=42,
                              verbose=False)
    mlp.fit(X_train, y_train_int)

    y_pred_train = mlp.predict(X_train)
    precision_tr, recall_tr, f1_tr, _ = precision_recall_fscore_support(
        y_train_int, y_pred_train, average='macro'
    )

    y_pred_test = mlp.predict(X_test)
    precision_te, recall_te, f1_te, _ = precision_recall_fscore_support(
        y_test_int, y_pred_test, average='macro'
    )

    print(f"Train set: Precision = {precision_tr:.4f}, Recall = {recall_tr:.4f}, F1 = {f1_tr:.4f}")
    print(f"Test  set: Precision = {precision_te:.4f}, Recall = {recall_te:.4f}, F1 = {f1_te:.4f}")

    depths.append(depth)
    avg_f1_train_list.append(f1_tr)
    avg_f1_test_list.append(f1_te)

    with open("report_part_6.txt", "a") as f:
        f.write(f"\n=== Training MLPClassifier with hidden_layer_sizes={arch}, Depth={depth} ===\n")
        f.write(f"Train set: Precision = {precision_tr:.4f}, Recall = {recall_tr:.4f}, F1 = {f1_tr:.4f}\n")
        f.write(f"Test  set: Precision = {precision_te:.4f}, Recall = {recall_te:.4f}, F1 = {f1_te:.4f}\n\n")


# y_pred_test = mlp.predict(X_test)
# precision_te, recall_te, f1_te, _ = precision_recall_fscore_support(
#     y_test_int, y_pred_test, average=None, labels=range(43)
# )
# avg_f1_test = np.mean(f1_te)
# print(f"Test set:  Avg F1 = {avg_f1_test:.4f}")




#!/usr/bin/env python
# coding: utf-8

# In[1]:


import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_fscore_support
from NN import NeuralNetwork  # Your from-scratch NN code
from load import load_data    # Your data loading code


# In[2]:


X_train, Y_train, X_test, Y_test = load_data()
print("Train data shape:", X_train.shape, Y_train.shape)
print("Test  data shape:", X_test.shape,  Y_test.shape)


# In[3]:


hidden_sizes = [1, 5, 10, 50, 100]
learning_rate = 0.01
batch_size = 32
input_size = 2352
output_size = 43

# We'll store average F1 for plotting later
avg_f1_train_list = []
avg_f1_test_list = []


# In[15]:


def train_single_layer(hidden_units):
    """
    Trains a single-hidden-layer network with `hidden_units` units in that layer.
    Returns the trained model.
    """
    nn = NeuralNetwork(
        input_size=input_size,
        hidden_layers=[hidden_units],  # Single hidden layer
        output_size=output_size,
        batch_size=batch_size,
        learning_rate=learning_rate
    )
    # You could also do an early-stopping approach. For demonstration, we'll do fixed epochs=10.
    nn.train(X_train, Y_train, epochs=200)
    return nn


# In[16]:


def evaluate_metrics(model, X, Y):
    """
    Returns precision, recall, f1 for each class (arrays of length 43).
    Also returns the average F1 across all classes.
    """
    # Model predictions
    y_probs = model.predict(X)                # shape (num_samples, 43)
    y_pred = np.argmax(y_probs, axis=1)       # predicted labels
    y_true = np.argmax(Y, axis=1)            # true labels

    # Arrays of shape (43,) for each metric
    precision, recall, f1, _ = precision_recall_fscore_support(
        y_true, y_pred, average=None, labels=range(43)
    )
    
    # You can compute the average across classes in different ways:
    # macro-average, weighted-average, etc. We'll do macro-average for simplicity:
    avg_f1 = np.mean(f1)
    
    return precision, recall, f1, avg_f1


# In[17]:


for hidden_units in hidden_sizes:
    model = train_single_layer(hidden_units)

    # Evaluate on train data
    train_precision, train_recall, train_f1, avg_f1_train = evaluate_metrics(model, X_train, Y_train)
    # Evaluate on test data
    test_precision, test_recall, test_f1, avg_f1_test = evaluate_metrics(model, X_test, Y_test)

    # Save results
    with open(f"results_part2.txt", "a") as f:
        f.write(f"\n=== Training single layer NN with {hidden_units} hidden units ===\n")
        f.write(f"Train set: Avg F1 = {avg_f1_train:.4f}\n")
        f.write(f"Test  set: Avg F1 = {avg_f1_test:.4f}\n\n")

        # f.write("Per-class metrics (Train):\n")
        # for i, (p, r, f1) in enumerate(zip(train_precision, train_recall, train_f1)):
        #     f.write(f"Class {i:2d}: Precision = {p:.4f}, Recall = {r:.4f}, F1 = {f1:.4f}\n")

        # f.write("\nPer-class metrics (Test):\n")
        # for i, (p, r, f1) in enumerate(zip(test_precision, test_recall, test_f1)):
        #     f.write(f"Class {i:2d}: Precision = {p:.4f}, Recall = {r:.4f}, F1 = {f1:.4f}\n")

    avg_f1_train_list.append(avg_f1_train)
    avg_f1_test_list.append(avg_f1_test)


# In[23]:


avg_f1_train_list = avg_f1_train_list[-5:]
avg_f1_test_list = avg_f1_test_list[-5:]


# In[24]:


import matplotlib.pyplot as plt

plt.plot(hidden_sizes, avg_f1_train_list, marker='o', label='Train Avg F1')
plt.plot(hidden_sizes, avg_f1_test_list, marker='o', label='Test Avg F1')
plt.xlabel('Hidden Layer Units')
plt.ylabel('Average F1 Score')
plt.title('Single Hidden Layer: Avg F1 vs #units')
plt.legend()
plt.show()


# In[ ]:





# In[ ]:








#!/usr/bin/env python
# coding: utf-8

# In[4]:


import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_fscore_support
from NN import NeuralNetwork
from load import load_data


# In[5]:


X_train, Y_train, X_test, Y_test = load_data()
print("X_train shape:", X_train.shape)
print("Y_train shape:", Y_train.shape)
print("X_test shape:",  X_test.shape)
print("Y_test shape:",  Y_test.shape)


# In[18]:


architectures = [
    # [512],             # 1 hidden layer
    # [512, 256],        # 2 hidden layers
    # [512, 256, 128],   # 3 hidden layers
    [512, 256, 128, 64]# 4 hidden layers
]


# In[22]:


def train_network(hidden_layers):
    """
    Creates a NeuralNetwork with the specified hidden layer sizes.
    Trains it and returns the trained model.
    """
    # Hyperparameters
    input_size = 2352  # 28*28*3
    output_size = 43
    batch_size = 32
    learning_rate = 0.01
    
    nn = NeuralNetwork(
        input_size=input_size,
        hidden_layers=hidden_layers,
        output_size=output_size,
        batch_size=batch_size,
        learning_rate=learning_rate
    )
    # For demonstration, let's use a fixed number of epochs as our stopping criterion
    nn.train(X_train, Y_train, epochs=100)
    return nn


# In[23]:


from sklearn.metrics import precision_recall_fscore_support
import numpy as np

def evaluate_metrics(model, X, Y):
    Y_pred_probs = model.predict(X)  # shape: (N, num_classes)
    Y_pred_labels = np.argmax(Y_pred_probs, axis=1)

    # If Y is one-hot encoded, convert it to class labels
    if len(Y.shape) &gt; 1 and Y.shape[1] &gt; 1:
        Y_true_labels = np.argmax(Y, axis=1)
    else:
        Y_true_labels = Y

    precision, recall, f1, _ = precision_recall_fscore_support(Y_true_labels, Y_pred_labels, average='macro')
    return precision, recall, f1


# In[25]:


depth_list = []            # We'll measure depth as len(hidden_layers)
avg_f1_train_list = []
avg_f1_test_list = []

for hidden_layers in architectures:
    model = train_network(hidden_layers)
    with open("results_part3_new_new.txt", "a") as f:
        depth = len(hidden_layers)
        f.write(f"\n=== Training network with depth={depth}, hidden layers={hidden_layers} ===\n")
        print(f"\n=== Training network with depth={depth}, hidden layers={hidden_layers} ===")


        # Evaluate on train set
        train_precision, train_recall, train_f1 = evaluate_metrics(model, X_train, Y_train)
        # Evaluate on test set
        test_precision, test_recall, test_f1 = evaluate_metrics(model, X_test, Y_test)

        # Log and print summary
        f.write(f"Train set: Precision = {train_precision:.4f}, Recall = {train_recall:.4f}, F1 = {train_f1:.4f}\n")
        f.write(f"Test  set: Precision = {test_precision:.4f}, Recall = {test_recall:.4f}, F1 = {test_f1:.4f}\n\n")
        print(f"Train set: Precision = {train_precision:.4f}, Recall = {train_recall:.4f}, F1 = {train_f1:.4f}")
        print(f"Test  set: Precision = {test_precision:.4f}, Recall = {test_recall:.4f}, F1 = {test_f1:.4f}")

        depth_list.append(depth)
        avg_f1_train_list.append(train_f1)
        avg_f1_test_list.append(test_f1)


# In[ ]:


import matplotlib.pyplot as plt

plt.plot(depth_list, avg_f1_train_list, marker='o', label='Train Avg F1')
plt.plot(depth_list, avg_f1_test_list, marker='o', label='Test Avg F1')
plt.xlabel('Depth of Network (Number of Hidden Layers)')
plt.ylabel('Average F1 Score')
plt.title('Depth vs Average F1 (Single or Multiple Hidden Layers)')
plt.legend()
plt.show()


# In[ ]:








#!/usr/bin/env python
# coding: utf-8

# In[1]:


from NN import NeuralNetwork
from load import load_data
from sklearn.metrics import precision_recall_fscore_support
import numpy as np
import matplotlib.pyplot as plt

architectures = [
    [512],
    [512, 256],
    [512, 256, 128],
    [512, 256, 128, 64]
]

X_train, Y_train, X_test, Y_test = load_data()


# In[2]:



def evaluate_metrics(model, X, Y):
    Y_pred_probs = model.predict(X)  # shape: (N, num_classes)
    Y_pred_labels = np.argmax(Y_pred_probs, axis=1)

    # If Y is one-hot encoded, convert it to class labels
    if len(Y.shape) &gt; 1 and Y.shape[1] &gt; 1:
        Y_true_labels = np.argmax(Y, axis=1)
    else:
        Y_true_labels = Y

    precision, recall, f1, _ = precision_recall_fscore_support(Y_true_labels, Y_pred_labels, average='macro')
    return precision, recall, f1


# In[6]:


def train_model(hidden_layers):
    nn = NeuralNetwork(
        input_size=2352,
        hidden_layers=hidden_layers,
        output_size=43,
        batch_size=32,
        learning_rate=0.01
    )
    nn.train_adaptive_lr(X_train, Y_train, epochs=200)
    return nn


# In[7]:



# depth_values = []
# avg_f1_train_list = []
# avg_f1_test_list = []

# for hidden_layers in architectures:
#     depth = len(hidden_layers)
#     print(f"\n=== Depth {depth}, hidden layers = {hidden_layers} ===")

#     # Create and train with adaptive LR
#     nn = NeuralNetwork(
#         input_size=2352,
#         hidden_layers=hidden_layers,
#         output_size=43,
#         batch_size=32,
#         learning_rate=0.01
#     )
#     # Use our new train method
#     nn.train_adaptive_lr(X_train, Y_train, epochs=10)

#     # Evaluate train
#     p_tr, r_tr, f1_tr, avg_f1_tr = evaluate_metrics(nn, X_train, Y_train)
#     # Evaluate test
#     p_te, r_te, f1_te, avg_f1_te = evaluate_metrics(nn, X_test, Y_test)

#     print(f"Train Avg F1 = {avg_f1_tr:.4f}")
#     print(f"Test  Avg F1 = {avg_f1_te:.4f}")

#     depth_values.append(depth)
#     avg_f1_train_list.append(avg_f1_tr)
#     avg_f1_test_list.append(avg_f1_te)




depth_list = []
avg_f1_train_list = []
avg_f1_test_list = []

for hidden_layers in architectures:
    model = train_model(hidden_layers)  # Assuming this uses η₀ / √e schedule

    depth = len(hidden_layers)
    print(f"\n=== Training network with depth={depth}, hidden layers={hidden_layers} ===")

    with open("results_part4.txt", "a") as f:
        f.write(f"\n=== Training network with depth={depth}, hidden layers={hidden_layers} ===\n")

        # Evaluate on train set
        train_precision, train_recall, train_f1 = evaluate_metrics(model, X_train, Y_train)
        # Evaluate on test set
        test_precision, test_recall, test_f1 = evaluate_metrics(model, X_test, Y_test)

        # Log and print summary
        f.write(f"Train set: Precision = {train_precision:.4f}, Recall = {train_recall:.4f}, F1 = {train_f1:.4f}\n")
        f.write(f"Test  set: Precision = {test_precision:.4f}, Recall = {test_recall:.4f}, F1 = {test_f1:.4f}\n\n")
        print(f"Train set: Precision = {train_precision:.4f}, Recall = {train_recall:.4f}, F1 = {train_f1:.4f}")
        print(f"Test  set: Precision = {test_precision:.4f}, Recall = {test_recall:.4f}, F1 = {test_f1:.4f}")

        depth_list.append(depth)
        avg_f1_train_list.append(train_f1)
        avg_f1_test_list.append(test_f1)


# In[ ]:



# Plot
plt.plot(depth_values, avg_f1_train_list, marker='o', label='Train Avg F1')
plt.plot(depth_values, avg_f1_test_list, marker='o', label='Test Avg F1')
plt.title("Average F1 vs. Network Depth with Adaptive LR")
plt.xlabel("Depth (Number of Hidden Layers)")
plt.ylabel("Average F1 Score")
plt.legend()
plt.show()


# In[ ]:





# In[ ]:





# In[ ]:








#!/usr/bin/env python
# coding: utf-8

# In[5]:


import numpy as np 
from NNRelu import NeuralNetworkReLU

from load import load_data
from sklearn.metrics import precision_recall_fscore_support


# In[6]:


X_train, y_train, X_test, y_test = load_data()


# In[7]:


def evaluate_metrics(model, X, Y):
    Y_pred_probs = model.predict(X)  # shape: (N, num_classes)
    Y_pred_labels = np.argmax(Y_pred_probs, axis=1)

    # If Y is one-hot encoded, convert it to class labels
    if len(Y.shape) &gt; 1 and Y.shape[1] &gt; 1:
        Y_true_labels = np.argmax(Y, axis=1)
    else:
        Y_true_labels = Y

    precision, recall, f1, _ = precision_recall_fscore_support(Y_true_labels, Y_pred_labels, average='macro')
    return precision, recall, f1


# In[8]:


depth_list = []
avg_f1_train_list = []
avg_f1_test_list = []

architectures = [
    [512],
    [512, 256],
    [512, 256, 128],
    [512, 256, 128, 64]
]

for hidden_layers in architectures:
    depth = len(hidden_layers)
    print(f"\n=== Training ReLU network with depth={depth}, hidden layers={hidden_layers} ===")

    model = NeuralNetworkReLU(
        input_size=2352,
        hidden_layers=hidden_layers,
        output_size=43,
        batch_size=32,
        learning_rate=0.01
    )
    
    model.train(X_train, y_train, epochs=150, adaptive_lr=True)

    # Evaluate on train and test sets
    train_precision, train_recall, train_f1 = evaluate_metrics(model, X_train, y_train)
    test_precision, test_recall, test_f1 = evaluate_metrics(model, X_test, y_test)

    # Log results
    with open("results_part_5.txt", "a") as f:
        f.write(f"\n=== Training ReLU network with depth={depth}, hidden layers={hidden_layers} ===\n")
        f.write(f"Train set: Precision = {train_precision:.4f}, Recall = {train_recall:.4f}, F1 = {train_f1:.4f}\n")
        f.write(f"Test  set: Precision = {test_precision:.4f}, Recall = {test_recall:.4f}, F1 = {test_f1:.4f}\n\n")

    print(f"Train set: Precision = {train_precision:.4f}, Recall = {train_recall:.4f}, F1 = {train_f1:.4f}")
    print(f"Test  set: Precision = {test_precision:.4f}, Recall = {test_recall:.4f}, F1 = {test_f1:.4f}")

    # Store for plotting
    depth_list.append(depth)
    avg_f1_train_list.append(train_f1)
    avg_f1_test_list.append(test_f1)


# In[ ]:





# In[ ]:





# In[ ]:








#!/usr/bin/env python
# coding: utf-8

# In[3]:


from load import load_data
from sklearn.metrics import precision_recall_fscore_support
import numpy as np
import matplotlib.pyplot as plt
from NNRelu import NeuralNetworkReLU


# In[2]:



# 1. Load data
X_train, Y_train, X_test, Y_test = load_data()


# In[4]:



# 2. Choose architecture
hidden_layers = [512, 256, 128, 64]  # for example
model = NeuralNetworkReLU(
    input_size=2352,
    hidden_layers=hidden_layers,
    output_size=43,
    batch_size=32,
    learning_rate=0.01
)


# In[5]:



# 3. Train
model.train(X_train, Y_train, epochs=10)

# 4. Evaluate
model.evaluate(X_train, Y_train)
model.evaluate(X_test, Y_test)


# In[6]:



# 5. Get precision, recall, F1
y_probs_train = model.predict(X_train)
y_pred_train = np.argmax(y_probs_train, axis=1)
y_true_train = np.argmax(Y_train, axis=1)

y_probs_test = model.predict(X_test)
y_pred_test = np.argmax(y_probs_test, axis=1)
y_true_test = np.argmax(Y_test, axis=1)


# In[7]:



from sklearn.metrics import precision_recall_fscore_support

prec_train, rec_train, f1_train, _ = precision_recall_fscore_support(
    y_true_train, y_pred_train, average=None, labels=range(43)
)
prec_test, rec_test, f1_test, _ = precision_recall_fscore_support(
    y_true_test, y_pred_test, average=None, labels=range(43)
)

# average F1
avg_f1_train = np.mean(f1_train)
avg_f1_test = np.mean(f1_test)

print(f"Train set: Avg F1={avg_f1_train:.4f}")
print(f"Test set:  Avg F1={avg_f1_test:.4f}")


# In[ ]:





# In[ ]:








#!/usr/bin/env python
# coding: utf-8

# In[2]:


from sklearn.neural_network import MLPClassifier
from sklearn.metrics import precision_recall_fscore_support
import matplotlib.pyplot as plt
import numpy as np
from load import load_data


# In[3]:


X_train, Y_train, X_test, Y_test = load_data()
# 1. Convert one-hot to integer labels
y_train_int = np.argmax(Y_train, axis=1)
y_test_int  = np.argmax(Y_test,  axis=1)


# In[4]:



# 2. Define the architectures from Part (c)
architectures = [
    (512,),
    (512, 256),
    (512, 256, 128),
    (512, 256, 128, 64)
]


# In[5]:


# from sklearn.metrics import precision_recall_fscore_support
# import numpy as np
# from sklearn.neural_network import MLPClassifier

# # We'll track the average F1 for train and test
# depths = []
# avg_f1_train_list = []
# avg_f1_test_list = []

# architectures = [
#     [512],
#     [512, 256],
#     [512, 256, 128],
#     [512, 256, 128, 64]
# ]

# for arch in architectures:
#     depth = len(arch)  # number of hidden layers
#     print(f"\n=== Training MLP with hidden_layer_sizes={arch}, Depth={depth} ===")

#     # Create the MLPClassifier
#     mlp = MLPClassifier(
#         hidden_layer_sizes=arch,
#         activation='relu',
#         solver='sgd',
#         alpha=0,
#         batch_size=32,
#         learning_rate='invscaling',
#         max_iter=100,
#         shuffle=True,
#         random_state=42
#     )

#     # Train
#     mlp.fit(X_train, y_train_int)

#     # Predict on train
#     y_pred_train = mlp.predict(X_train)
#     precision_tr, recall_tr, f1_tr, _ = precision_recall_fscore_support(
#         y_train_int, y_pred_train, average='macro'
#     )

#     # Predict on test
#     y_pred_test = mlp.predict(X_test)
#     precision_te, recall_te, f1_te, _ = precision_recall_fscore_support(
#         y_test_int, y_pred_test, average='macro'
#     )

#     # Print to console
#     print(f"Train set: Precision = {precision_tr:.4f}, Recall = {recall_tr:.4f}, F1 = {f1_tr:.4f}")
#     print(f"Test  set: Precision = {precision_te:.4f}, Recall = {recall_te:.4f}, F1 = {f1_te:.4f}")

#     # Append for plotting
#     depths.append(depth)
#     avg_f1_train_list.append(f1_tr)
#     avg_f1_test_list.append(f1_te)

#     # Write to file
#     with open("report_part_6.txt", "a") as f:
#         f.write(f"\n=== Training MLP with hidden_layer_sizes={arch}, Depth={depth} ===\n")
#         f.write(f"Train set: Precision = {precision_tr:.4f}, Recall = {recall_tr:.4f}, F1 = {f1_tr:.4f}\n")
#         f.write(f"Test  set: Precision = {precision_te:.4f}, Recall = {recall_te:.4f}, F1 = {f1_te:.4f}\n\n")


# In[6]:


from sklearn.metrics import precision_recall_fscore_support
from sklearn.neural_network import MLPClassifier
import numpy as np

# Track depth and scores
depths = []
avg_f1_train_list = []
avg_f1_test_list = []

architectures = [
    [512],
    [512, 256],
    [512, 256, 128],
    [512, 256, 128, 64]
]

for arch in architectures:
    depth = len(arch)
    print(f"\n=== Training MLPClassifier with hidden_layer_sizes={arch}, Depth={depth} ===")

    mlp = MLPClassifier(hidden_layer_sizes=arch, 
                        activation='relu',
                          solver='sgd', alpha = 0.0,
                            batch_size=32, learning_rate='invscaling', 
                            learning_rate_init=0.01, max_iter = 100, 
                            shuffle = True,
                            early_stopping=True, 
                            n_iter_no_change=3, 
                            random_state=42,
                              verbose=False)
    mlp.fit(X_train, y_train_int)

    # Evaluate train
    y_pred_train = mlp.predict(X_train)
    precision_tr, recall_tr, f1_tr, _ = precision_recall_fscore_support(
        y_train_int, y_pred_train, average='macro'
    )

    # Evaluate test
    y_pred_test = mlp.predict(X_test)
    precision_te, recall_te, f1_te, _ = precision_recall_fscore_support(
        y_test_int, y_pred_test, average='macro'
    )

    print(f"Train set: Precision = {precision_tr:.4f}, Recall = {recall_tr:.4f}, F1 = {f1_tr:.4f}")
    print(f"Test  set: Precision = {precision_te:.4f}, Recall = {recall_te:.4f}, F1 = {f1_te:.4f}")

    # Track for plotting
    depths.append(depth)
    avg_f1_train_list.append(f1_tr)
    avg_f1_test_list.append(f1_te)

    # Save to file
    with open("report_part_6.txt", "a") as f:
        f.write(f"\n=== Training MLPClassifier with hidden_layer_sizes={arch}, Depth={depth} ===\n")
        f.write(f"Train set: Precision = {precision_tr:.4f}, Recall = {recall_tr:.4f}, F1 = {f1_tr:.4f}\n")
        f.write(f"Test  set: Precision = {precision_te:.4f}, Recall = {recall_te:.4f}, F1 = {f1_te:.4f}\n\n")


# In[ ]:



    # 6. Evaluate on test
y_pred_test = mlp.predict(X_test)
precision_te, recall_te, f1_te, _ = precision_recall_fscore_support(
    y_test_int, y_pred_test, average=None, labels=range(43)
)
avg_f1_test = np.mean(f1_te)
print(f"Test set:  Avg F1 = {avg_f1_test:.4f}")

# Save for plotting
depths.append(depth)
avg_f1_train_list.append(avg_f1_train)
avg_f1_test_list.append(avg_f1_test)


# In[ ]:



# 7. Plot results: Average F1 vs Depth
plt.plot(depths, avg_f1_train_list, marker='o', label='Train Avg F1')
plt.plot(depths, avg_f1_test_list,  marker='o', label='Test Avg F1')
plt.xlabel('Depth (Number of Hidden Layers)')
plt.ylabel('Average F1')
plt.title('sklearn MLPClassifier: ReLU, sgd, alpha=0, batch=32, learning_rate=invscaling')
plt.legend()
plt.show()


# In[ ]:





# In[ ]:








import matplotlib.pyplot as plt

depths = [1, 2, 3, 4]

# Test F1 scores from Part (f): MLPClassifier (ReLU + SGD)
test_f1_f = [77.32, 78.90, 77.46, 77.93]

# Test F1 scores from Part (e): Custom ReLU + Adaptive LR (from earlier shared data)
test_f1_e = [81.75, 84.18, 84.84, 84.12]

plt.figure(figsize=(8, 5))
plt.plot(depths, test_f1_f, marker='s', label='MLPClassifier (Part f)', linewidth=2)
plt.plot(depths, test_f1_e, marker='o', label='Custom ReLU + Adaptive LR (Part e)', linewidth=2)

plt.title("Test F1 Score Comparison: Part (e) vs Part (f)")
plt.xlabel("Network Depth")
plt.ylabel("Test F1 Score (%)")
plt.xticks(depths)
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.savefig("comparison_part_e_vs_f.png")
plt.show()




import matplotlib.pyplot as plt

depths = [1, 2, 3, 4]

# Previously used test F1s
test_f1_d = [69.24, 62.54, 51.65, 39.35]  # Part (d): Sigmoid
test_f1_e = [81.75, 84.18, 84.84, 84.12]  # Part (e): ReLU
test_f1_c = [81.4,79.26,68.80,54.66]  # Part (c): Decision Tree (Post-pruned)

# -------- Part (d) vs Part (e) ---------
plt.figure(figsize=(8, 5))
plt.plot(depths, test_f1_d, marker='s', label='Sigmoid + Adaptive LR (Part d)', linewidth=2)
plt.plot(depths, test_f1_e, marker='o', label='ReLU + Adaptive LR (Part e)', linewidth=2)
plt.title("Test F1 Score Comparison: Part (d) vs Part (e)")
plt.xlabel("Network Depth")
plt.ylabel("F1 Score (%)")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.savefig("comparison_part_d_vs_e.png")
plt.show()

# -------- Part (c) vs Part (d) ---------
plt.figure(figsize=(8, 5))
plt.plot(depths, test_f1_c, marker='^', label='Sigmoid  + Fixed LR (Part c)', linewidth=2)
plt.plot(depths, test_f1_d, marker='s', label='Sigmoid + Adaptive LR (Part d)', linewidth=2)
plt.title("Test F1 Score Comparison: Part (c) vs Part (d)")
plt.xlabel("Model Depth")
plt.ylabel("F1 Score (%)")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.savefig("comparison_part_c_vs_d.png")
plt.show()




import matplotlib.pyplot as plt

# Depths corresponding to number of hidden layers
depths = [1, 2, 3, 4]

# Scores from your results
precision_scores = [96.93, 95.09, 89.23, 74.98]
recall_scores    = [95.38, 93.65, 85.50, 66.58]
f1_scores        = [96.07, 94.29, 86.85, 68.09]

plt.figure(figsize=(8, 5))
plt.plot(depths, precision_scores, marker='o', label='Precision')
plt.plot(depths, recall_scores, marker='s', label='Recall')
plt.plot(depths, f1_scores, marker='^', label='F1 Score')

plt.title('Train Metrics vs. Network Depth')
plt.xlabel('Network Depth (Number of Hidden Layers)')
plt.ylabel('Score (%)')
plt.xticks(depths)
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.savefig("depth_vs_metrics.png")
plt.show()

# import matplotlib.pyplot as plt

# Network depths
depths = [1, 2, 3, 4]

# Test set scores from your results
test_precision_scores = [85.65, 81.74, 72.84, 58.86]
test_recall_scores    = [79.52, 78.43, 67.72, 54.17]
test_f1_scores        = [81.40, 79.26, 68.80, 54.66]

plt.figure(figsize=(8, 5))
plt.plot(depths, test_precision_scores, marker='o', label='Precision')
plt.plot(depths, test_recall_scores, marker='s', label='Recall')
plt.plot(depths, test_f1_scores, marker='^', label='F1 Score')

plt.title('Test Metrics vs. Network Depth')
plt.xlabel('Network Depth (Number of Hidden Layers)')
plt.ylabel('Score (%)')
plt.xticks(depths)
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.savefig("depth_vs_test_metrics.png")
plt.show()




import matplotlib.pyplot as plt

# Depths and Part (f) Test F1 Scores
depths = [1, 2, 3, 4]
mlp_f1 = [37.90, 41.45, 35.90, 26.07]  # Part (f) Test F1

plt.figure(figsize=(8, 5))
plt.plot(depths, mlp_f1, marker='o', label='MLPClassifier (Part f)', linewidth=2)
plt.xlabel("Network Depth")
plt.ylabel("Test F1 Score (%)")
plt.title("Test F1 Score vs. Network Depth (MLPClassifier)")
plt.grid(True)
plt.xticks(depths)
plt.legend()
plt.tight_layout()
plt.savefig("mlp_f1_vs_depth.png")
plt.show()




import matplotlib.pyplot as plt

depths = [1, 2, 3, 4]

train_precision_f = [92.81, 93.40, 92.58, 90.69]
train_recall_f    = [88.04, 90.98, 90.23, 88.22]
train_f1_f        = [89.98, 92.03, 91.20, 89.10]

test_precision_f = [84.03, 83.30, 80.27, 80.82]
test_recall_f    = [74.48, 77.22, 76.59, 76.98]
test_f1_f        = [77.32, 78.90, 77.46, 77.93]

# Train Metrics Plot
plt.figure(figsize=(8, 5))
plt.plot(depths, train_f1_f, marker='o', label='Train F1')
plt.plot(depths, train_precision_f, marker='s', label='Train Precision')
plt.plot(depths, train_recall_f, marker='^', label='Train Recall')
plt.title("Part (f): Train Metrics vs Network Depth (MLPClassifier)")
plt.xlabel("Depth")
plt.ylabel("Score (%)")
plt.grid(True)
plt.xticks(depths)
plt.legend()
plt.tight_layout()
plt.savefig("mlpclassifier_train_metrics.png")
plt.show()

# Test Metrics Plot
plt.figure(figsize=(8, 5))
plt.plot(depths, test_f1_f, marker='o', label='Test F1')
plt.plot(depths, test_precision_f, marker='s', label='Test Precision')
plt.plot(depths, test_recall_f, marker='^', label='Test Recall')
plt.title("Part (f): Test Metrics vs Network Depth (MLPClassifier)")
plt.xlabel("Depth")
plt.ylabel("Score (%)")
plt.grid(True)
plt.xticks(depths)
plt.legend()
plt.tight_layout()
plt.savefig("mlpclassifier_test_metrics.png")
plt.show()




import matplotlib.pyplot as plt

depths = [1, 2, 3, 4]
train_f1_d = [74.78, 67.94, 57.33, 48.16]
test_f1_d  = [69.24, 62.54, 51.65, 39.35]

train_precision_d = [80.13, 71.28, 60.15, 50.45]
train_recall_d    = [70.10, 64.90, 54.77, 46.08]

test_precision_d = [77.41, 67.54, 55.92, 43.23]
test_recall_d    = [62.64, 58.23, 47.99, 36.12]

# Plot Train Metrics
plt.figure(figsize=(8, 5))
plt.plot(depths, train_f1_d, marker='o', label='Train F1')
plt.plot(depths, train_precision_d, marker='s', label='Train Precision')
plt.plot(depths, train_recall_d, marker='^', label='Train Recall')
plt.title("Part (d): Train Metrics vs Network Depth (Sigmoid + Adaptive LR)")
plt.xlabel("Depth")
plt.ylabel("Score (%)")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.savefig("sigmoid_train_metrics.png")
plt.show()

# Plot Test Metrics
plt.figure(figsize=(8, 5))
plt.plot(depths, test_f1_d, marker='o', label='Test F1')
plt.plot(depths, test_precision_d, marker='s', label='Test Precision')
plt.plot(depths, test_recall_d, marker='^', label='Test Recall')
plt.title("Part (d): Test Metrics vs Network Depth (Sigmoid + Adaptive LR)")
plt.xlabel("Depth")
plt.ylabel("Score (%)")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.savefig("sigmoid_test_metrics.png")
plt.show()




depths = [1, 2, 3, 4]

# Part (e) - ReLU + Adaptive LR
train_precision = [96.71, 97.12, 97.53, 97.89]
train_recall    = [94.59, 95.33, 95.79, 96.01]
train_f1        = [95.53, 96.21, 96.65, 96.94]

test_precision  = [86.24, 88.63, 89.32, 88.72]
test_recall     = [79.62, 80.17, 80.79, 79.98]
test_f1         = [81.75, 84.18, 84.84, 84.12]

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
plt.plot(depths, train_f1, marker='o', label='Train F1', linewidth=2)
plt.plot(depths, train_precision, marker='s', label='Train Precision', linewidth=2)
plt.plot(depths, train_recall, marker='^', label='Train Recall', linewidth=2)

plt.xlabel("Network Depth")
plt.ylabel("Score (%)")
plt.title("Train Metrics vs. Network Depth (ReLU + Adaptive LR)")
plt.grid(True)
plt.xticks(depths)
plt.legend()
plt.tight_layout()
plt.savefig("relu_train_metrics_vs_depth.png")
plt.show()


plt.figure(figsize=(8, 5))
plt.plot(depths, test_f1, marker='o', label='Test F1', linewidth=2)
plt.plot(depths, test_precision, marker='s', label='Test Precision', linewidth=2)
plt.plot(depths, test_recall, marker='^', label='Test Recall', linewidth=2)

plt.xlabel("Network Depth")
plt.ylabel("Score (%)")
plt.title("Test Metrics vs. Network Depth (ReLU + Adaptive LR)")
plt.grid(True)
plt.xticks(depths)
plt.legend()
plt.tight_layout()
plt.savefig("relu_test_metrics_vs_depth.png")
plt.show()




import matplotlib.pyplot as plt

# F1 scores from Part (e)
depths = [1, 2, 3, 4]
relu_test_f1 = [81.75, 84.18, 84.84, 84.12]

plt.figure(figsize=(8, 5))
plt.plot(depths, relu_test_f1, marker='o', label='ReLU (Part e)', linewidth=2)
plt.xlabel("Network Depth (Number of Hidden Layers)")
plt.ylabel("Test F1 Score (%)")
plt.title("Test F1 Score vs. Network Depth (ReLU Activation)")
plt.grid(True)
plt.xticks(depths)
plt.legend()
plt.tight_layout()
plt.savefig("relu_f1_vs_depth.png")
plt.show()


</PRE>
</PRE>
</BODY>
</HTML>
