<HTML>
<HEAD>
<TITLE>./A3_processed_new_hash/combined_46U3K.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A3_processed_new_hash/combined_46U3K.py<p><PRE>


import sys
import pandas as pd
import os
import numpy as np
import math
from collections import Counter
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier as SklearnDecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import ParameterGrid


# Helper fns
def compute_entropy(y):
    # H(y) = -Î£ p(Y=y) log2(p(Y=y))
    total = len(y)
    counts = Counter(y)
    entropy = 0
    for label, count in counts.items():
        p = count / total
        entropy -= p * math.log2(p)

    return entropy

def categorical_entropy(df, attribute, target='income'):
    total = len(df)
    weighted_entropy = 0

<A NAME="3"></A><FONT color = #00FFFF><A HREF="match224-1.html#3" TARGET="1"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    for value in df[attribute].unique():
        subset = df[df[attribute] == value]
        subset_size = len(subset)
        subset_entropy = compute_entropy(subset[target])
</FONT>        weight = subset_size / total
        weighted_entropy += weight * subset_entropy

    return weighted_entropy    

def numerical_entropy(df, attribute, target='income'):
    median_val = df[attribute].median()
    below = df[df[attribute] &lt;= median_val]
    above = df[df[attribute] &gt; median_val]
    total = len(df)
    weighted_entropy = 0
    for subset in [below, above]:
        weight = len(subset) / total
        weighted_entropy += weight * compute_entropy(subset[target])
    return weighted_entropy, median_val


def plot_accuracy_vs_depth(train_acc_dict, test_acc_dict):
    depths = list(train_acc_dict.keys())
    train_acc = [train_acc_dict[d] for d in depths]
    test_acc = [test_acc_dict[d] for d in depths]

    plt.figure(figsize=(8, 5))
    plt.plot(depths, train_acc, marker='o', label='Training Accuracy', color='blue')
    plt.plot(depths, test_acc, marker='o', label='Test Accuracy', color='green')
    plt.title("Accuracy vs Tree Depth")
    plt.xlabel("Max Depth")
    plt.ylabel("Accuracy")
    plt.xticks([5, 10, 15, 20])
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()  

       
def one_hot_encode_multicategory(df, target_column='income'):
    # Do not encode the target column
    cat_cols = df.select_dtypes(include=['object', 'category']).columns
    cat_cols = [col for col in cat_cols if col != target_column]

    for col in cat_cols:
        if df[col].nunique() &gt;= 2:
            dummies = pd.get_dummies(df[col], prefix=col, drop_first=False)
            df = pd.concat([df.drop(columns=[col]), dummies], axis=1)

    return df

def load_encoded_data(df_train, df_valid, df_test):
    df_train['__source__'] = 'train'
    df_valid['__source__'] = 'valid'
    df_test['__source__'] = 'test'

    # Concatenate all sets
    df_all = pd.concat([df_train, df_valid, df_test], axis=0)

    target = df_all['income'] if 'income' in df_all.columns else None
    features = df_all.drop(columns=['income']) if 'income' in df_all.columns else df_all.drop(columns=[])

    # One-hot encode features only
    encoded_features = pd.get_dummies(features)

    # Combine back with unencoded target if present
    concat_items = [encoded_features, df_all['__source__']]
    if target is not None:
        concat_items.insert(1, target)

    df_all_encoded = pd.concat(concat_items, axis=1)

    df_train_encoded = df_all_encoded[df_all_encoded['__source__'] == 'train'].drop(columns=['__source__'])
    df_valid_encoded = df_all_encoded[df_all_encoded['__source__'] == 'valid'].drop(columns=['__source__'])
    df_test_encoded  = df_all_encoded[df_all_encoded['__source__'] == 'test'].drop(columns=['__source__'])

    # Extract X and y
    X_train = df_train_encoded.drop(columns=['income'])
    y_train = df_train_encoded['income']

    X_val = df_valid_encoded.drop(columns=['income'])
    y_val = df_valid_encoded['income']

    # Handle test set
    if 'income' in df_test_encoded.columns:
        X_test = df_test_encoded.drop(columns=['income'])
        y_test = df_test_encoded['income']
    else:
        X_test = df_test_encoded
        y_test = None

    # Align validation and test features to training features
    X_val = X_val.reindex(columns=X_train.columns, fill_value=0)
    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)

    return X_train, X_val, X_test, y_train, y_val, y_test

def post_prune_tree(model, df_train, df_valid, df_test):
    pruned_tree = model.copy()

    node_counts = []
    train_accuracies = []
    valid_accuracies = []
    test_accuracies = []

    # Initial accuracies
    node_counts.append(pruned_tree.count_nodes())
    train_accuracies.append(pruned_tree.accuracy(df_train))
    valid_accuracies.append(pruned_tree.accuracy(df_valid))
    # test_accuracies.append(pruned_tree.accuracy(df_test))
    test_accuracies.append(1)  # Placeholder for test accuracy

    prev_valid_accuracy = valid_accuracies[-1]

    while True:
        prunable_nodes = pruned_tree.get_prunable_nodes()
        best_accuracy = prev_valid_accuracy
        best_node = None

        for node in prunable_nodes:
            temp_tree = pruned_tree.copy()
            temp_tree.prune_node(node)
            acc = temp_tree.accuracy(df_valid)
            if acc &gt;= best_accuracy:
                best_accuracy = acc
                best_node = node

        if best_node is None or best_accuracy &lt;= prev_valid_accuracy:
            break

        pruned_tree.prune_node(best_node)
        prev_valid_accuracy = best_accuracy

        node_counts.append(pruned_tree.count_nodes())
        train_accuracies.append(pruned_tree.accuracy(df_train))
        valid_accuracies.append(pruned_tree.accuracy(df_valid))
        # test_accuracies.append(pruned_tree.accuracy(df_test))
        test_accuracies.append(1)  # Placeholder for test accuracy

    return node_counts, train_accuracies, valid_accuracies, test_accuracies, pruned_tree

def plot_pruning_results(node_counts, train_acc, val_acc, test_acc, depth):
    # Limit the plot to the final number of nodes
    final_node_count = node_counts[-1]
    index_limit = node_counts.index(final_node_count) + 1

    plt.figure(figsize=(10, 6))
    plt.plot(node_counts[:index_limit], train_acc[:index_limit], label="Training Accuracy")
    plt.plot(node_counts[:index_limit], val_acc[:index_limit], label="Validation Accuracy")
    plt.plot(node_counts[:index_limit], test_acc[:index_limit], label="Test Accuracy")
    plt.xlabel("Number of Nodes")
    plt.ylabel("Accuracy")
    plt.title(f"Post-Pruning Accuracies (Max Depth = {depth})")
    plt.legend()
    plt.grid(True)
    plt.show()


# Save predictions
def train_and_save_predictions(df_train, df_valid, df_test, depth, question_part, output_folder='.'):
    model = DecisionTreeClassifier(max_depth=depth)
    model.fit(df_train.copy())

    predictions = model.predict(df_test)
    output_file = os.path.join(output_folder, f"prediction_{question_part}.csv")
    pd.DataFrame({'prediction': predictions}).to_csv(output_file, index=False)
    print(f"\n Predictions for part '{question_part}' saved successfully to: '{output_file}'\n")

def prune_and_save_predictions(df_train, df_valid, df_test, depth, question_part, output_folder='.'):
    model = DecisionTreeClassifier(max_depth=depth)
    model.fit(df_train.copy())
    node_counts, train_acc, val_acc, test_acc,  pruned_tree = post_prune_tree(
        model, df_train, df_valid, df_test
    )

    predictions = pruned_tree.predict(df_test)
    output_file = os.path.join(output_folder, f"prediction_{question_part}.csv")
    pd.DataFrame({'prediction': predictions}).to_csv(output_file, index=False)
    print(f"\n Predictions for part '{question_part}' saved successfully to: '{output_file}'\n")

def sklearn_save_predictions(X_train, X_test, y_train, depth, question_part, output_folder='.'):
    clf = SklearnDecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42)
    clf.fit(X_train, y_train)

    predictions = clf.predict(X_test)
    output_file = os.path.join(output_folder, f"prediction_{question_part}.csv")
    pd.DataFrame({'prediction': predictions}).to_csv(output_file, index=False)
    print(f"\n Predictions for part '{question_part}' saved successfully to: '{output_file}'\n")

def rf_save_predictions(best_model, X_test, question_part, output_folder='.'):
    predictions = best_model.predict(X_test)
    output_file = os.path.join(output_folder, f"prediction_{question_part}.csv")
    pd.DataFrame({'prediction': predictions}).to_csv(output_file, index=False)
    print(f"\n Predictions for part '{question_part}' saved successfully to: '{output_file}'\n")

# Tree Node class
<A NAME="4"></A><FONT color = #FF00FF><A HREF="match224-1.html#4" TARGET="1"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

class Tree_Node:
    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None, is_leaf=False):
        self.feature = feature
</FONT>        self.threshold = threshold
        self.value = value
        self.is_leaf = is_leaf
        self.children = {}  # Used for both categorical and numerical
        self.left = left
        self.right = right


class DecisionTreeClassifier:
    def __init__(self, max_depth=None):
        self.max_depth = max_depth
        self.root = None

    def fit(self, df):
        df = df.copy()
        self.root = self._build_tree(df)

    def _build_tree(self, df, depth=0):
        X = df.drop(columns=['income'])
        y = df['income']
        unique_classes = set(y)

        if len(df) == 0:
            return None  

        # base case: all labels same or depth limit reached
        unique_classes = y.unique()
        if len(unique_classes) == 1:
            return Tree_Node(is_leaf=True, value=unique_classes[0])

        if depth == self.max_depth:
            leaf_value = max(unique_classes, key=list(y).count)
            return Tree_Node(is_leaf=True, value=leaf_value)

        best_gain = -1
        best_attr = None
        best_threshold = None
        total_entropy = compute_entropy(y)

        for attribute in X.columns:
            if X[attribute].dtype == 'object':  # Categorical
                gain = total_entropy - categorical_entropy(df , attribute)
                if gain &gt; best_gain:
                    best_gain = gain
                    best_attr = attribute
                    best_threshold = None
            else:  # Numerical
                entropy, median = numerical_entropy(df, attribute)
                gain = total_entropy - entropy
                if gain &gt; best_gain:
                    best_gain = gain
                    best_attr = attribute
                    best_threshold = median

        if best_attr is None:
            leaf_value = max(unique_classes, key=list(y).count)
            return Tree_Node(value=leaf_value, is_leaf=True)

        node = Tree_Node(feature=best_attr, threshold=best_threshold)

        if best_threshold is None:  # Categorical split
            for value in X[best_attr].unique():
                subset_df = df[df[best_attr] == value]
                child = self._build_tree(subset_df, depth + 1)
                node.children[value] = child
        else:  # Numerical split using threshold
            left_df = df[df[best_attr] &lt;= best_threshold]
            right_df = df[df[best_attr] &gt; best_threshold]

            # avoid creating branches for empty splits
            if len(left_df) == 0 or len(right_df) == 0:
                leaf_value = max(unique_classes, key=list(y).count)
                return Tree_Node(is_leaf=True, value=leaf_value)
            
            node.children[f"&lt;= {best_threshold}"] = self._build_tree(left_df, depth + 1)
            node.children[f"&gt; {best_threshold}"] = self._build_tree(right_df, depth + 1)

        return node
    

    def predict_row(self, row, node=None):
        if node is None:
            node = self.root

        if node.is_leaf:
            return node.value

        val = row.get(node.feature, 0)

        if node.threshold is None:  # Categorical
            if val in node.children:
                return self.predict_row(row, node.children[val])
            else:
                # Unseen value - make current node a leaf
                child_labels = [child.value for child in node.children.values() if child.is_leaf]
                if child_labels:
                    return Counter(child_labels).most_common(1)[0][0]
                else:
                    return None  # or majority class from training data
        else:  # Numerical
            if val &lt;= node.threshold:
                return self.predict_row(row, node.children[f"&lt;= {node.threshold}"])
            else:
                return self.predict_row(row, node.children[f"&gt; {node.threshold}"])

    def predict(self, df):
        return df.apply(lambda row: self.predict_row(row), axis=1)

    def accuracy(self, df):
        y_true = df['income']
        y_pred = self.predict(df)
        return (y_true == y_pred).mean()
    
    def count_nodes(self):
        def count(node):
            if node is None:
                return 0
            return 1 + sum(count(child) for child in node.children.values())
        return count(self.root)

    def get_prunable_nodes(self):
        prunable_nodes = []
        def dfs(node):
            if node is None or node.is_leaf:
                return
            leaf_children = [child for child in node.children.values() if child and child.is_leaf]
            if len(leaf_children) == len(node.children):
                prunable_nodes.append(node)
            for child in node.children.values():
                dfs(child)
        dfs(self.root)
        return prunable_nodes

    def prune_node(self, node):
        labels = []
        def collect_labels(n):
            if n.is_leaf:
                labels.append(n.value)
            else:
                for child in n.children.values():
                    collect_labels(child)
        collect_labels(node)
        majority_label = max(set(labels), key=labels.count)
        node.is_leaf = True
        node.value = majority_label
        node.feature = None
        node.threshold = None
        node.children = {}

    def copy(self):
        new_tree = DecisionTreeClassifier(max_depth=self.max_depth)
        def clone(node):
            if node is None:
                return None
            new_node = Tree_Node(
                feature=node.feature,
                threshold=node.threshold,
                value=node.value,
                is_leaf=node.is_leaf
            )
            for key, child in node.children.items():
                new_node.children[key] = clone(child)
            return new_node
        new_tree.root = clone(self.root)
        return new_tree

# Part A
def run_part_a(df_train, df_valid, df_test, depth = 20, question_part='a', output_folder='.'):
    # Train and save predictions for part a
    train_and_save_predictions(df_train, df_valid, df_test, depth, question_part, output_folder)

    # Analysis part
    # allowed_depths = [5, 10, 15, 20]
    # train_acc_dict = {}
    # test_acc_dict = {}

    # for depth in allowed_depths:
    #     model = DecisionTreeClassifier(max_depth=depth)
    #     model.fit(df_train.copy())
    #     print(f"Decision Tree with max depth {depth}:")
    #     training_accuracy = model.accuracy(df_train)
    #     testing_accuracy = model.accuracy(df_test)
    #     train_acc_dict[depth] = training_accuracy
    #     test_acc_dict[depth] = testing_accuracy
    #     print("Training accuracy:", training_accuracy)
    #     print("Test accuracy:", testing_accuracy)

    # plot_accuracy_vs_depth(train_acc_dict, test_acc_dict)

# Part B
def run_part_b(df_train, df_valid, df_test, depth = 55, question_part='b', output_folder='.'):
    df_train_encoded = one_hot_encode_multicategory(df_train)
    df_test_encoded = one_hot_encode_multicategory(df_test)
    df_valid_encoded = one_hot_encode_multicategory(df_valid)

    # Train and save predictions for part b
    train_and_save_predictions(df_train_encoded, df_valid_encoded, df_test_encoded, depth, question_part, output_folder)

    # Analysis part
    # allowed_depths_2 = [25, 35, 45, 55]
    # train_acc_dict = {}
    # test_acc_dict = {}

    # for depth in allowed_depths_2:
    #     print(f"Decision Tree (after one hot encoding) with max depth {depth}:")
    #     model = DecisionTreeClassifier(max_depth=depth)
    #     model.fit(df_train_encoded.copy())
    #     training_accuracy = model.accuracy(df_train_encoded)
    #     testing_accuracy = model.accuracy(df_test_encoded)
    #     train_acc_dict[depth] = training_accuracy
    #     test_acc_dict[depth] = testing_accuracy
    #     print("Training accuracy:", training_accuracy)
    #     print("Test accuracy:", testing_accuracy)

    # plot_accuracy_vs_depth(train_acc_dict, test_acc_dict)

# Part C 
def run_part_c(df_train, df_valid, df_test, depth = 55, question_part='c', output_folder='.'):
    df_train_encoded = one_hot_encode_multicategory(df_train)
    df_test_encoded = one_hot_encode_multicategory(df_test)
    df_valid_encoded = one_hot_encode_multicategory(df_valid)

    # Train and save predictions for part c
    prune_and_save_predictions(df_train_encoded, df_valid_encoded, df_test_encoded, depth, question_part, output_folder)

    # Analysis part
    # allowed_depths_3 = [25,35,45,55]
    # for depth in allowed_depths_3:
    #     print(f"\nPost-Pruning Decision Tree with max depth {depth}:")
    #     model = DecisionTreeClassifier(max_depth=depth)
    #     model.fit(df_train_encoded.copy())

    #     node_counts, train_acc, val_acc, test_acc, pruned_tree = post_prune_tree(
    #         model, df_train_encoded, df_valid_encoded, df_test_encoded
    #     )

    #     plot_pruning_results(node_counts, train_acc, val_acc, test_acc, depth)

    #     print(f"Final number of nodes: {node_counts[-1]}")
    #     print(f"Final Training Accuracy: {train_acc[-1]}")
    #     print(f"Final Validation Accuracy: {val_acc[-1]}")
    #     print(f"Final Test Accuracy: {test_acc[-1]}")


def run_part_d(df_train, df_valid, df_test, depth = 55, question_part='d', output_folder='.'):
    # Load datasets
    X_train , X_val , X_test , y_train , y_val , y_test = load_encoded_data(df_train.copy(), df_valid.copy(), df_test.copy())

    # ---------- Part (i) Varying max_depth ----------
    print("Using Scikit-learn DecisionTreeClassifier...\n")
<A NAME="1"></A><FONT color = #00FF00><A HREF="match224-1.html#1" TARGET="1"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    depths = [25, 35, 45, 55]
    train_accuracies = []
    val_accuracies = []
    test_accuracies = []

    print("Tuning max_depth...")
    for d in depths:
        clf = SklearnDecisionTreeClassifier(criterion='entropy', max_depth=d, random_state=42)
        clf.fit(X_train, y_train)
</FONT>        
        train_acc = accuracy_score(y_train, clf.predict(X_train))
        val_acc = accuracy_score(y_val, clf.predict(X_val))
        # test_acc = accuracy_score(y_test, clf.predict(X_test))
        
        train_accuracies.append(train_acc)
        val_accuracies.append(val_acc)
        # test_accuracies.append(test_acc)
        
        print(f"max_depth = {d}: Train Acc = {train_acc:.4f}, Val Acc = {val_acc:.4f}")

    # Plotting accuracies vs max_depth
    # plt.figure(figsize=(8,5))
    # plt.plot(depths, train_accuracies, marker='o', label='Train Accuracy')
    # plt.plot(depths, val_accuracies, marker='o', label='Validation Accuracy')
    # plt.plot(depths, test_accuracies, marker='o', label='Test Accuracy')
    # plt.xlabel("Max Depth")
    # plt.ylabel("Accuracy")
    # plt.title("Scikit-learn Decision Tree Accuracy vs Max Depth (Entropy)")
    # plt.grid(True)
    # plt.legend()
    # plt.show()

    # Get best model by max validation accuracy
    best_depth_idx = np.argmax(val_accuracies)
    best_depth = depths[best_depth_idx]

    final_clf_depth = SklearnDecisionTreeClassifier(criterion='entropy', max_depth=best_depth, random_state=42)
    final_clf_depth.fit(X_train, y_train)
    final_train_acc_depth = accuracy_score(y_train, final_clf_depth.predict(X_train))
    # final_test_acc_depth = accuracy_score(y_test, final_clf_depth.predict(X_test))

    print(f"\nBest max_depth = {best_depth}")
    print(f"Train Accuracy (best max_depth): {final_train_acc_depth:.4f}")
    # print(f"Test Accuracy (best max_depth): {final_test_acc_depth:.4f}")

    # Save predictions
    sklearn_save_predictions(X_train, X_test, y_train, best_depth, question_part, output_folder)

    # ccp_alphas = [0.001, 0.01, 0.1, 0.2]
    # train_accuracies_alpha = []
    # val_accuracies_alpha = []
    # test_accuracies_alpha = []

    # print("\nTuning ccp_alpha...")
    # for alpha in ccp_alphas:
    #     clf = SklearnDecisionTreeClassifier(criterion='entropy', ccp_alpha=alpha, random_state=42)
    #     clf.fit(X_train, y_train)
        
    #     train_acc = accuracy_score(y_train, clf.predict(X_train))
    #     val_acc = accuracy_score(y_val, clf.predict(X_val))
    #     test_acc = accuracy_score(y_test, clf.predict(X_test))
        
    #     train_accuracies_alpha.append(train_acc)
    #     val_accuracies_alpha.append(val_acc)
    #     test_accuracies_alpha.append(test_acc)
        
    #     print(f"ccp_alpha = {alpha}: Train Acc = {train_acc:.4f}, Val Acc = {val_acc:.4f}, Test Acc = {test_acc:.4f}")

    # # Plotting accuracies vs ccp_alpha
    # plt.figure(figsize=(8,5))
    # plt.plot(ccp_alphas, train_accuracies_alpha, marker='o', label='Train Accuracy')
    # plt.plot(ccp_alphas, val_accuracies_alpha, marker='o', label='Validation Accuracy')
    # plt.plot(ccp_alphas, test_accuracies_alpha, marker='o', label='Test Accuracy')
    # plt.xlabel("ccp_alpha")
    # plt.ylabel("Accuracy")
    # plt.title("Scikit-learn Decision Tree Accuracy vs CCP Alpha (Entropy)")
    # plt.grid(True)
    # plt.legend()
    # plt.show()

    # # Get best model by max validation accuracy
    # best_alpha_idx = np.argmax(val_accuracies_alpha)
    # best_alpha = ccp_alphas[best_alpha_idx]

    # final_clf_alpha = SklearnDecisionTreeClassifier(criterion='entropy', ccp_alpha=best_alpha, random_state=42)
    # final_clf_alpha.fit(X_train, y_train)
    # final_train_acc_alpha = accuracy_score(y_train, final_clf_alpha.predict(X_train))
    # final_test_acc_alpha = accuracy_score(y_test, final_clf_alpha.predict(X_test))

    # print(f"\nBest ccp_alpha = {best_alpha}")
    # print(f"Train Accuracy (best ccp_alpha): {final_train_acc_alpha:.4f}")
    # print(f"Test Accuracy (best ccp_alpha): {final_test_acc_alpha:.4f}")

# Part E
def run_part_e(df_train, df_valid, df_test, depth = 55, question_part='e', output_folder='.'):
    # Load datasets
<A NAME="2"></A><FONT color = #0000FF><A HREF="match224-1.html#2" TARGET="1"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    X_train , X_val , X_test , y_train , y_val , y_test = load_encoded_data(df_train.copy(), df_valid.copy(), df_test.copy())

    # Random Forest Classifier
    param_grid = {
        'n_estimators': [50, 150, 250, 350],
        'max_features': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0],
</FONT>        'min_samples_split': [2, 4, 6, 8, 10]
    }

    best_oob_score = 0
    best_model = None
    best_params = None

    for params in ParameterGrid(param_grid):
        # print(f"checking for parameter {params}")
        rf = RandomForestClassifier(
            **params,
            criterion='entropy',
            oob_score=True,
            n_jobs=-1,
            random_state=42,
            bootstrap=True
        )
        rf.fit(X_train, y_train)

        # Check OOB accuracy
        if hasattr(rf, "oob_score_"):
            oob_acc = rf.oob_score_
        else:
            continue

        if oob_acc &gt; best_oob_score:
            best_oob_score = oob_acc
            best_model = rf
            best_params = params

    # Final evaluation with best model
    train_acc = best_model.score(X_train, y_train)
    valid_acc = accuracy_score(y_val, best_model.predict(X_val))
    # test_acc = accuracy_score(y_test, best_model.predict(X_test))

    print("Best Parameters:", best_params)
    print(f"Training Accuracy: {train_acc:.4f}")
    print(f"OOB Accuracy: {best_oob_score:.4f}")
    print(f"Validation Accuracy: {valid_acc:.4f}")
    # print(f"Test Accuracy: {test_acc:.4f}")
    
    rf_save_predictions(best_model, X_test, question_part, output_folder)

def main():
    train_path = sys.argv[1]
    val_path = sys.argv[2]
    test_path = sys.argv[3]
    output_folder = sys.argv[4]
    question_part = sys.argv[5]

    # Load datasets
    train_data = pd.read_csv(train_path)
    val_data = pd.read_csv(val_path)
    test_data = pd.read_csv(test_path)
    df_train = train_data.copy()
    df_valid = val_data.copy()
    df_test = test_data.copy()

    # Run the corresponding part of the code based on the question part
    run_part = {
        'a': run_part_a,
        'b': run_part_b,
        'c': run_part_c,
        'd': run_part_d,
        'e': run_part_e
    }.get(question_part)
    if run_part is None:
        print(f"Invalid question part: {question_part}")
        return
    print(f"Running part {question_part}...\n")
    run_part(df_train, df_valid, df_test, question_part=question_part, output_folder=output_folder)
    print(f"Part {question_part} completed.\n")


if __name__ == "__main__":
    main()





import numpy as np
import pandas as pd
import sys
# from tqdm import tqdm
from PIL import Image
import os
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
import numpy as np


# Helper functions
def evaluate_model(model, X, y, split=''):
    y_pred = model.predict(X)
    report = classification_report(y, y_pred, digits=4, zero_division=0)
    print(f"\n=== {split} Classification Report ===")
    print(report)
    report_dict = classification_report(y, y_pred, output_dict=True, zero_division=0)
    avg_f1 = report_dict['weighted avg']['f1-score']
    return avg_f1, report_dict

def save_predictions_to_csv(model, X_train_full, y_train_full, X_test, max_epochs, tolerance, question_part, output_dir="."):
    # Train on full data
    model.fit(X_train_full, y_train_full, X_val=X_train_full, y_val=y_train_full, max_epochs=max_epochs, tolerance=tolerance)
    # Predict
    predictions = model.predict(X_test)
    # Save predictions to CSV
    output_df = pd.DataFrame({'prediction': predictions})
    output_file = os.path.join(output_dir, f'prediction_{question_part}.csv')
    output_df.to_csv(output_file, index=False)
    print(f"Saved predictions to {output_file}")


def manual_split(X, y, val_ratio=0.2, seed=42):
    indices = np.arange(X.shape[0])
    split = int(X.shape[0] * (1 - val_ratio))
    train_idx, val_idx = indices[:split], indices[split:]
    return X[train_idx], y[train_idx], X[val_idx], y[val_idx]


# Activation Functions
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    s = sigmoid(x)
    return s * (1 - s)

def relu(x):
    return np.maximum(0, x)

def relu_derivative(x):
    # Sub-gradient for x = 0, otherwise standard derivative
    return np.where(x &gt; 0, 1, np.where(x &lt; 0, 0, 0.5))

# Softmax and Cross-Entropy
def softmax(x):
    exps = np.exp(x - np.max(x, axis=1, keepdims=True))
    return exps / np.sum(exps, axis=1, keepdims=True)

def cross_entropy(y_true, y_pred):
    m = y_true.shape[0]
    return -np.sum(np.log(y_pred[range(m), y_true])) / m

def one_hot(y, num_classes):
    one_hot = np.zeros((y.size, num_classes))
    one_hot[np.arange(y.size), y] = 1
    return one_hot

# Global Activation function 
ACTIVATION = sigmoid
ACTIVATION_DERIVATIVE = sigmoid_derivative

class NeuralNetwork:
    def __init__(self, input_size, hidden_layers, output_size, batch_size, learning_rate=0.01, activation='sigmoid'):
        global ACTIVATION, ACTIVATION_DERIVATIVE
        if activation == 'relu':
            ACTIVATION = relu
            ACTIVATION_DERIVATIVE = relu_derivative
        else:
            ACTIVATION = sigmoid
<A NAME="0"></A><FONT color = #FF0000><A HREF="match224-1.html#0" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

            ACTIVATION_DERIVATIVE = sigmoid_derivative

        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.initial_lr = learning_rate
        self.layer_sizes = [input_size] + hidden_layers + [output_size]
        self.num_layers = len(self.layer_sizes)
        self.weights = [np.random.randn(self.layer_sizes[i], self.layer_sizes[i + 1]) * np.sqrt(1. / self.layer_sizes[i]) for i in range(len(self.layer_sizes) - 1)]
</FONT>        self.biases = [np.zeros((1, self.layer_sizes[i + 1])) for i in range(len(self.layer_sizes) - 1)]
        self.adaptive_lr = False

    def forward(self, X):
        activations = [X]
        zs = []
        for i in range(self.num_layers - 2):
            z = activations[-1] @ self.weights[i] + self.biases[i]
            zs.append(z)
            a = ACTIVATION(z)
            activations.append(a)
        z = activations[-1] @ self.weights[-1] + self.biases[-1]
        zs.append(z)
        a = softmax(z)
        activations.append(a)
        return activations, zs

    def backward(self, activations, zs, y_true):
        grads_w = [0] * (self.num_layers - 1)
        grads_b = [0] * (self.num_layers - 1)
        m = y_true.shape[0]
        y_one_hot = one_hot(y_true, self.layer_sizes[-1])
        delta = activations[-1] - y_one_hot
        grads_w[-1] = (activations[-2].T @ delta) / m
        grads_b[-1] = np.sum(delta, axis=0, keepdims=True) / m
        for l in range(2, self.num_layers):
            delta = (delta @ self.weights[-l + 1].T) * ACTIVATION_DERIVATIVE(zs[-l])
            grads_w[-l] = (activations[-l - 1].T @ delta) / m
            grads_b[-l] = np.sum(delta, axis=0, keepdims=True) / m
        return grads_w, grads_b

    def update_params(self, grads_w, grads_b):
        for i in range(len(self.weights)):
            self.weights[i] -= self.learning_rate * grads_w[i]
            self.biases[i] -= self.learning_rate * grads_b[i]

    def fit(self, X_train, y_train, X_val, y_val, max_epochs=100, tolerance=1e-4):
        prev_val_loss = float('inf')
        for epoch in range(max_epochs):
            if self.adaptive_lr:
                self.learning_rate = self.initial_lr / np.sqrt(epoch + 1)

            permutation = np.random.permutation(X_train.shape[0])
            X_train = X_train[permutation]
            y_train = y_train[permutation]

            for i in range(0, X_train.shape[0], self.batch_size):
                X_batch = X_train[i:i+self.batch_size]
                y_batch = y_train[i:i+self.batch_size]
                activations, zs = self.forward(X_batch)
                grads_w, grads_b = self.backward(activations, zs, y_batch)
                self.update_params(grads_w, grads_b)

            val_loss = cross_entropy(y_val, self.predict_proba(X_val))
            print(f"Epoch {epoch + 1}, Validation Loss: {val_loss:.4f}")

            if abs(prev_val_loss - val_loss) &lt; tolerance:
                print(f"Early stopping at epoch {epoch + 1} (ÎValLoss &lt; {tolerance})")
                break
            prev_val_loss = val_loss


    def predict_proba(self, X):
        activations, _ = self.forward(X)
        return activations[-1]

    def predict(self, X):
        probs = self.predict_proba(X)
        return np.argmax(probs, axis=1)


def load_training_data(train_dir, image_size=(28, 28)):
    X, y = [], []
    for class_label in sorted(os.listdir(train_dir)):
        class_path = os.path.join(train_dir, class_label)
        if not os.path.isdir(class_path):
            continue
        try:
            label = int(class_label)
        except ValueError:
            continue
        for img_file in os.listdir(class_path):
            if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                continue
            try:
                with Image.open(os.path.join(class_path, img_file)) as img:
                    img = img.resize(image_size).convert('RGB')
                    X.append(np.array(img) / 255.0)
                    y.append(label)
            except:
                continue
    return np.array(X), np.array(y)

# def load_test_data_2(test_dir, labels_csv, image_size=(28, 28)):
#     labels_df = pd.read_csv(labels_csv)
#     X, y = [], []
#     for _, row in tqdm(labels_df.iterrows(), total=len(labels_df)):
#         img_path = os.path.join(test_dir, row['image'])
#         try:
#             img = Image.open(img_path).resize(image_size).convert('RGB')
#             X.append(np.array(img) / 255.0)
#             y.append(int(row['label']))
#         except:
#             continue
#     return np.array(X), np.array(y)

def load_test_data(test_dir, image_size=(28, 28)):
    X = []
    y = []
    image_names = []

    for img_file in sorted(os.listdir(test_dir)):  # Sorted for consistency
        if not img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
            continue
        try:
            img_path = os.path.join(test_dir, img_file)
            with Image.open(img_path) as img:
                img = img.resize(image_size).convert('RGB')
                X.append(np.array(img) / 255.0)
                y.append(int(os.path.splitext(img_file)[0]))  
                image_names.append(img_file)
        except:
            continue

    return np.array(X), np.array(y)

# Part B
def run_part_b(X_train_full, y_train_full, X_train, y_train, X_val, y_val, X_test, y_test, max_epochs = 100, tolerance = 1e-4, question_part = "b", output_dir="."):
    print("Running PART B")
    hidden_units_list = [1, 5, 10, 50, 100]
    # avg_f1_train, avg_f1_test = [], []

    # for units in hidden_units_list:
    #     print(f"\n--- Hidden units: {units} ---")
    #     model = NeuralNetwork(
    #         input_size=X_train.shape[1],
    #         hidden_layers=[units],
    #         output_size=43,
    #         batch_size=32,
    #         learning_rate=0.01,
    #         activation='sigmoid'
    #     )
    #     model.fit(X_train, y_train, X_val, y_val, max_epochs=max_epochs, tolerance=tolerance)

    #     f1_train, _ = evaluate_model(model, X_train, y_train, split='Train')
    #     f1_test, _ = evaluate_model(model, X_test, y_test, split='Test')
    #     avg_f1_train.append(f1_train)
    #     avg_f1_test.append(f1_test)
    #     print(f"Hidden Units: {units} | Train F1: {f1_train:.4f} | Test F1: {f1_test:.4f}")

    # plt.plot(hidden_units_list, avg_f1_train, label='Train Avg F1', marker='o')
    # plt.plot(hidden_units_list, avg_f1_test, label='Test Avg F1', marker='o')
    # plt.xlabel('Number of Hidden Units')
    # plt.ylabel('Average F1 Score')
    # plt.title('Part (b): F1 Score vs Hidden Units')
    # plt.legend()
    # plt.grid(True)
    # plt.tight_layout()
    # plt.savefig("part_b_f1_vs_hidden_units.png")
    # plt.show()

    # Final prediction model for 100 units
    final_model = NeuralNetwork(
        input_size=X_train.shape[1],
        hidden_layers=[100],
        output_size=43,
        batch_size=32,
        learning_rate=0.01,
        activation='sigmoid'
    )
    save_predictions_to_csv(final_model, X_train_full, y_train_full, X_test, max_epochs=max_epochs, tolerance=tolerance, question_part=question_part, output_dir=output_dir)
    print("Finished PART B")

# Part C
def run_part_c(X_train_full, y_train_full, X_train, y_train, X_val, y_val, X_test, y_test,max_epochs = 100, tolerance = 1e-4, question_part = "c", output_dir="."):
    print("Running PART C")
    hidden_layer_configs = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]

    # avg_f1_train, avg_f1_test = [], []

    # for config in hidden_layer_configs:
    #     print(f"\n--- Hidden layers: {config} ---")
    #     model = NeuralNetwork(
    #         input_size=X_train.shape[1],
    #         hidden_layers=config,
    #         output_size=43,
    #         batch_size=32,
    #         learning_rate=0.01,
    #         activation='sigmoid'
    #     )
    #     model.fit(X_train, y_train, X_val, y_val, max_epochs=max_epochs, tolerance=tolerance)

    #     f1_train, _ = evaluate_model(model, X_train, y_train, split='Train')
    #     f1_test, _ = evaluate_model(model, X_test, y_test, split='Test')
    #     avg_f1_train.append(f1_train)
    #     avg_f1_test.append(f1_test)
    #     print(f"Hidden Layers: {config} | Train F1: {f1_train:.4f} | Test F1: {f1_test:.4f}")
        
    # depths = [len(cfg) for cfg in hidden_layer_configs]
    # plt.plot(depths, avg_f1_train, label='Train Avg F1', marker='o')
    # plt.plot(depths, avg_f1_test, label='Test Avg F1', marker='o')
    # plt.xlabel('Network Depth (Number of Hidden Layers)')
    # plt.ylabel('Average F1 Score')
    # plt.title('Part (c): F1 Score vs Network Depth')
    # plt.legend()
    # plt.grid(True)
    # plt.tight_layout()
    # plt.savefig("part_c_f1_vs_network_depth.png")
    # plt.show()

    # Final prediction model using [512, 256, 128, 64]
    final_model = NeuralNetwork(
        input_size=X_train.shape[1],
        hidden_layers=[512, 256, 128, 64],
        output_size=43,
        batch_size=32,
        learning_rate=0.01,
        activation='sigmoid'
    )
    save_predictions_to_csv(final_model, X_train_full, y_train_full, X_test, max_epochs=max_epochs, tolerance=tolerance, question_part=question_part, output_dir=output_dir)
    print("Finished PART C")

# Part D
def run_part_d(X_train_full, y_train_full, X_train, y_train, X_val, y_val, X_test, y_test, max_epochs = 100, tolerance = 1e-4, question_part = "d", output_dir="."):
    print("Running PART D")
    hidden_layer_configs = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]

    # avg_f1_train, avg_f1_test = [], []

    # for config in hidden_layer_configs:
    #     print(f"\n--- Hidden layers: {config} (Adaptive LR) ---")
    #     model = NeuralNetwork(
    #         input_size=X_train.shape[1],
    #         hidden_layers=config,
    #         output_size=43,
    #         batch_size=32,
    #         learning_rate=0.01,
    #         activation='sigmoid'
    #     )
    #     model.adaptive_lr = True  
    #     model.fit(X_train, y_train, X_val, y_val, max_epochs=max_epochs, tolerance=tolerance)

    #     f1_train, _ = evaluate_model(model, X_train, y_train, split='Train')
    #     f1_test, _ = evaluate_model(model, X_test, y_test, split='Test')
    #     avg_f1_train.append(f1_train)
    #     avg_f1_test.append(f1_test)
    #     print(f"Hidden Layers: {config} | Train F1: {f1_train:.4f} | Test F1: {f1_test:.4f}")

    # depths = [len(cfg) for cfg in hidden_layer_configs]
    # plt.plot(depths, avg_f1_train, label='Train Avg F1', marker='o')
    # plt.plot(depths, avg_f1_test, label='Test Avg F1', marker='o')
    # plt.xlabel('Network Depth (Number of Hidden Layers)')
    # plt.ylabel('Average F1 Score')
    # plt.title('Part (d): F1 Score vs Network Depth (Adaptive LR)')
    # plt.legend()
    # plt.grid(True)
    # plt.tight_layout()
    # plt.savefig("part_d_f1_vs_network_depth.png")
    # plt.show()

    # Final prediction model using [512, 256, 128, 64] and adaptive LR
    final_model = NeuralNetwork(
        input_size=X_train.shape[1],
        hidden_layers=[512, 256, 128, 64],
        output_size=43,
        batch_size=32,
        learning_rate=0.01,
        activation='sigmoid'
    )
    final_model.adaptive_lr = True
    save_predictions_to_csv(final_model, X_train_full, y_train_full, X_test, max_epochs=max_epochs, tolerance=tolerance, question_part=question_part, output_dir=output_dir)
    print("Finished PART D")

# Part E
def run_part_e(X_train_full, y_train_full, X_train, y_train, X_val, y_val, X_test, y_test, max_epochs=100, tolerance=1e-4, question_part="e", output_dir="."):
    print("Running PART E")
    hidden_layer_configs = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]
    
    # avg_f1_train, avg_f1_test = [], []

    # for config in hidden_layer_configs:
    #     print(f"\n--- Hidden layers: {config} (ReLU Activation) ---")
    #     # Initialize model with ReLU activation
    #     model = NeuralNetwork(
    #         input_size=X_train.shape[1],
    #         hidden_layers=config,
    #         output_size=43,
    #         batch_size=32,
    #         learning_rate=0.01,
    #         activation='relu'  # Using ReLU instead of Sigmoid
    #     )
    #     model.adaptive_lr = True  
    #     model.fit(X_train, y_train, X_val, y_val, max_epochs=max_epochs, tolerance=tolerance)

    #     f1_train, _ = evaluate_model(model, X_train, y_train, split='Train')
    #     f1_test, _ = evaluate_model(model, X_test, y_test, split='Test')
    #     avg_f1_train.append(f1_train)
    #     avg_f1_test.append(f1_test)
    #     print(f"Hidden Layers: {config} | Train F1: {f1_train:.4f} | Test F1: {f1_test:.4f}")

    # depths = [len(cfg) for cfg in hidden_layer_configs]
    # plt.plot(depths, avg_f1_train, label='Train Avg F1', marker='o')
    # plt.plot(depths, avg_f1_test, label='Test Avg F1', marker='o')
    # plt.xlabel('Network Depth (Number of Hidden Layers)')
    # plt.ylabel('Average F1 Score')
    # plt.title('Part (e): F1 Score vs Network Depth (ReLU Activation)')
    # plt.legend()
    # plt.grid(True)
    # plt.tight_layout()
    # plt.savefig("part_e_f1_vs_network_depth.png")
    # plt.show()

    # Final prediction model using [512, 256, 128, 64] and ReLU activation
    final_model = NeuralNetwork(
        input_size=X_train.shape[1],
        hidden_layers=[512, 256, 128, 64],
        output_size=43,
        batch_size=32,
        learning_rate=0.01,
        activation='relu'  # ReLU activation
    )
    final_model.adaptive_lr = True
    save_predictions_to_csv(final_model, X_train_full, y_train_full, X_test, max_epochs=max_epochs, tolerance=tolerance, question_part=question_part, output_dir=output_dir)
    print("Finished PART E")

# Part F
def run_part_f(X_train_full, y_train_full, X_train, y_train, X_val, y_val, X_test, y_test):
    from sklearn.neural_network import MLPClassifier
    from sklearn.metrics import precision_score, recall_score, f1_score
    print("Running PART F (Using MLPClassifier)")

    hidden_layer_configs = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]

    # avg_f1_train, avg_f1_test = [], []

    # for config in hidden_layer_configs:
    #     print(f"\n--- Hidden Layers: {config} (MLPClassifier) ---")
    #     model = MLPClassifier(
    #         hidden_layer_sizes=config,
    #         activation='relu',
    #         solver='sgd',
    #         alpha=0.0,
    #         batch_size=32,
    #         learning_rate='invscaling',
    #         random_state=42,
    #         max_iter=200,              
    #         verbose=False
    #     )

    #     model.fit(X_train_full, y_train_full)

    #     # Predictions
    #     y_pred_train = model.predict(X_train_full)
    #     y_pred_test = model.predict(X_test)

    #     # Metrics
    #     f1_train = f1_score(y_train_full, y_pred_train, average='macro')
    #     f1_test = f1_score(y_test, y_pred_test, average='macro')
    #     prec = precision_score(y_test, y_pred_test, average='macro', zero_division=0)
    #     rec = recall_score(y_test, y_pred_test, average='macro')

    #     avg_f1_train.append(f1_train)
    #     avg_f1_test.append(f1_test)

    #     print(f"Train F1: {f1_train:.4f}, Test F1: {f1_test:.4f}")
    #     print(f"Test Precision: {prec:.4f}, Test Recall: {rec:.4f}")

    # # Plotting F1 Score vs Network Depth
    # depths = [len(cfg) for cfg in hidden_layer_configs]
    # plt.plot(depths, avg_f1_train, label='Train Avg F1', marker='o')
    # plt.plot(depths, avg_f1_test, label='Test Avg F1', marker='o')
    # plt.xlabel('Network Depth (Number of Hidden Layers)')
    # plt.ylabel('Average F1 Score')
    # plt.title('Part (f): F1 Score vs Network Depth (MLPClassifier)')
    # plt.legend()
    # plt.grid(True)
    # plt.tight_layout()
    # plt.savefig("part_f_f1_vs_network_depth.png")
    # plt.show()
    print("Finished PART F")

def main():
    train_dir = sys.argv[1] 
    test_dir = sys.argv[2]
    # test_labels_csv = "./data/test_labels.csv"
    output_path = sys.argv[3] 
    question_part = sys.argv[4]

    print("loading train data")
    X_train_full, y_train_full = load_training_data(train_dir)
    print("loaded train data")
    # X_test, y_test = load_test_data_2(test_dir, test_labels_csv)
    X_test, y_test = load_test_data(test_dir)

    X_train_full = X_train_full.reshape(X_train_full.shape[0], -1)
    X_test = X_test.reshape(X_test.shape[0], -1)

    X_train, y_train, X_val, y_val = manual_split(X_train_full, y_train_full)

    # Run the corresponding part of the code based on the question part
    print(f"Running part {question_part}...\n")

    if question_part == 'b':
        run_part_b(X_train_full, y_train_full, X_train, y_train, X_val, y_val, X_test, y_test,
                            max_epochs=200, tolerance=1e-4, question_part=question_part, output_dir=output_path)
    elif question_part == 'c':
        run_part_c(X_train_full, y_train_full, X_train, y_train, X_val, y_val, X_test, y_test,
                            max_epochs=200, tolerance=1e-4, question_part=question_part, output_dir=output_path)
    elif question_part == 'd':
        run_part_d(X_train_full, y_train_full, X_train, y_train, X_val, y_val, X_test, y_test,
                            max_epochs=200, tolerance=1e-6, question_part=question_part, output_dir=output_path)
    elif question_part == 'e':
        run_part_e(X_train_full, y_train_full, X_train, y_train, X_val, y_val, X_test, y_test,
                            max_epochs=200, tolerance=1e-6, question_part=question_part, output_dir=output_path)
    elif question_part == 'f':
        run_part_f(X_train_full, y_train_full, X_train, y_train, X_val, y_val, X_test, y_test)
    else:
        raise ValueError(f"Invalid question part: {question_part}")
    
   

if __name__ == "__main__":
    main()


</PRE>
</PRE>
</BODY>
</HTML>
