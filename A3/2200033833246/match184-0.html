<HTML>
<HEAD>
<TITLE>./A3_processed_new_hash/combined_AAPWP.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A3_processed_new_hash/combined_AAPWP.py<p><PRE>


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import argparse
from collections import Counter,deque
import math
import os
import copy
from copy import deepcopy
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import ParameterGrid
from sklearn.metrics import accuracy_score

class dtnode:
    def _init_(self, depth=0):
<A NAME="5"></A><FONT color = #FF0000><A HREF="match184-1.html#5" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        self.left = None
        self.right = None
        self.split_at = None
        self.split_val_at = None
        self.children = {} 
        self.prediction = None
</FONT>        self.leafhaikya = False
        self.depth = depth
        self.node_id=None

def ent(yy):
    if len(yy) == 0:
        return 0
    cnts = Counter(yy)
    probss=[ct / len(yy) for ct in cnts.values()]
    return -sum(prob * math.log2(prob) for prob in probss)
def mutual_information(X, y, attr):
    total_ent = ent(y)
    if X[attr].dtype == 'object':
        values = X[attr].value_counts()
        weighted_ent = 0
        for value, count in values.items():
            subset_indices = X[attr] == value
            subset_y = y[subset_indices]
            weighted_ent += (count / len(y)) * ent(subset_y)
        return total_ent - weighted_ent
    else:
        median_value = X[attr].median()
        left_indices = X[attr] &lt;= median_value
        right_indices = X[attr] &gt; median_value
        left_ent = ent(y[left_indices])
        right_ent = ent(y[right_indices])
        left_weight = sum(left_indices) / len(y)
        right_weight = sum(right_indices) / len(y)
        weighted_ent = left_weight * left_ent + right_weight * right_ent
        return total_ent - weighted_ent

def find_best_split(X, y, attrs):
    best_attr = None
    best_mi = -1
    for attr in attrs:
        mi = mutual_information(X, y, attr)
        if mi &gt; best_mi:
            best_mi = mi
            best_attr = attr
    return best_attr

def build_tree(X, y, attrs, max_depth,curr_d=0):
    node = dtnode(depth=curr_d)
    node.prediction = Counter(y).most_common(1)[0][0]
    if len(set(y)) == 1:
        node.leafhaikya = True
        return node
    
    if len(attrs) == 0 or curr_d &gt;= max_depth:
        node.leafhaikya = True
        return node
    
    best_attr = find_best_split(X, y, attrs)
    
    if best_attr is None:
        node.leafhaikya = True
        # node.prediction = Counter(y).most_common(1)[0][0]
        return node
    node.split_at = best_attr
    if X[best_attr].dtype == 'object':
        unique_values = X[best_attr].unique()
        for value in unique_values:
            subset_indices = X[best_attr] == value
            if sum(subset_indices) == 0:
                continue
            subset_X = X[subset_indices]
            subset_y = y[subset_indices]
            child_node = build_tree(subset_X, subset_y, attrs, max_depth, curr_d + 1)
            node.children[value] = child_node
    else:
        median_value = X[best_attr].median()
        node.split_val_at = median_value
        left_indices = X[best_attr] &lt;= median_value
        if sum(left_indices) &gt; 0:
            left_X = X[left_indices]
            left_y = y[left_indices]
            node.left = build_tree(left_X, left_y, attrs, max_depth, curr_d + 1)
        else:
            node.left = dtnode(depth=curr_d + 1)
            node.left.leafhaikya = True
            node.left.prediction = Counter(y).most_common(1)[0][0]
        right_indices = X[best_attr] &gt; median_value
        if sum(right_indices) &gt; 0:
            right_X = X[right_indices]
            right_y = y[right_indices]
            node.right = build_tree(right_X, right_y, attrs, max_depth, curr_d + 1)
        else:
            node.right = dtnode(depth=curr_d + 1)
            node.right.leafhaikya = True
            node.right.prediction = Counter(y).most_common(1)[0][0]
    return node

def build_tree_c(X, y, attrs, max_depth, current_depth=0, node_id_counter=[0]):
    node = dtnode(depth=current_depth)
    node.node_id = node_id_counter[0]
    node_id_counter[0] += 1
    node.prediction = Counter(y).most_common(1)[0][0]
    if len(set(y)) == 1:
        node.leafhaikya = True
        return node
    if len(attrs) == 0 or current_depth &gt;= max_depth:
        node.leafhaikya = True
        return node
    best_attr = find_best_split(X, y, attrs)
    
    if best_attr is None:
        node.leafhaikya = True
        return node
    node.split_at = best_attr
    median_value = X[best_attr].median()
    node.split_val_at = median_value
    left_indices = X[best_attr] &lt;= median_value
    if sum(left_indices) &gt; 0:
        left_X = X[left_indices]
        left_y = y[left_indices]
        node.left = build_tree_c(left_X, left_y, attrs, max_depth, current_depth + 1, node_id_counter)
    else:
        node.left = dtnode(depth=current_depth + 1)
        node.left.leafhaikya = True
        node.left.prediction = node.prediction
        node.left.node_id = node_id_counter[0]
        node_id_counter[0] += 1
    right_indices = X[best_attr] &gt; median_value
    if sum(right_indices) &gt; 0:
        right_X = X[right_indices]
        right_y = y[right_indices]
        node.right = build_tree_c(right_X, right_y, attrs, max_depth, current_depth + 1, node_id_counter)
    else:
        node.right = dtnode(depth=current_depth + 1)
        node.right.leafhaikya = True
        node.right.prediction = node.prediction
        node.right.node_id = node_id_counter[0]
        node_id_counter[0] += 1
    
    return node

def prediction_sample(node, x):
    if node.leafhaikya:
        return node.prediction
    
    if node.split_at in x:
        attribute_value = x[node.split_at]
        if isinstance(node.split_val_at, (int, float)):
            if attribute_value &lt;= node.split_val_at:
                return prediction_sample(node.left, x)
            else:
                return prediction_sample(node.right, x)
        else:
            # print("hi")
            if attribute_value in node.children:
                return prediction_sample(node.children[attribute_value], x)
            else:
                return node.prediction
    else:
        return node.prediction

def predict(tree, X):
    predictions = []
    for _, row in X.iterrows():
        predictions.append(prediction_sample(tree, row))
    return predictions

def accuracy(y_true, y_pred):
    if(len(y_true)!=len(y_pred)):
        print("oh no")
        return -1
    crct = sum(y_true[i] == y_pred[i] for i in range(len(y_true)))
    return crct / len(y_true)

def count_nodes(tree):
    if tree is None:
        return 0
    count = 1  
    if not tree.leafhaikya:
        count += count_nodes(tree.left)
        count += count_nodes(tree.right)
    cntt=count
    return cntt

def get_non_leaf_nodes(tr):
    if tr is None:
        return []
    res = []
    qu = deque([tr])
    while qu:
        node = qu.popleft()
        if not node.leafhaikya:
            res.append(node)
            if node.left:
                qu.append(node.left)
            if node.right:
                qu.append(node.right)
    return res

def prune_the_node(tree, node_id):

    qu = deque([tree])
    node_to_prune = None
    
    while qu and node_to_prune is None:
        node = qu.popleft()
        
        if node.node_id == node_id:
            node_to_prune = node
        else:
            if node.left:
                qu.append(node.left)
            if node.right:
                qu.append(node.right)
    
    if node_to_prune:
        # Convert to leaf node
        orig_leafhaikya=node_to_prune.leafhaikya
        orig_left=node_to_prune.left
        orig_right=node_to_prune.right

        node_to_prune.leafhaikya = True
        node_to_prune.left = None
        node_to_prune.right = None

        return (node_to_prune, orig_leafhaikya, orig_left, orig_right)
    
    return None

# def post_prune_tree(tree, val_X, y_valid):
#     """
#     Post-prune the tree based on validation accuracy.
#     Returns a list of trees with progressively more pruning, and their node counts.
#     """

#     best_tree=tree
#     best_accuracy = accuracy(y_valid, predict(tree, val_X))
#     trees = [copy.deepcopy(tree)]
#     node_counts = [count_nodes(tree)]
#     accuracies = [best_accuracy]
    
#     # current_tree = copy.deepcopy(tree)
#     improvement = True
#     itr=0
#     while improvement:
#         improvement = False
#         non_leaf_nodes = get_non_leaf_nodes(best_tree)
#         print(len(non_leaf_nodes))
#         # If no more non-leaf nodes, we're done
#         if not non_leaf_nodes:
#             break
#         print(itr)
        
#         best_pruned_tree = None
#         best_pruned_accuracy = best_accuracy
#         print(itr)
        
#         # Try pruning each non-leaf node and select the one that improves accuracy the most
#         i=0
#         for node in non_leaf_nodes:
#             pruned_info = prunethenode(best_tree, node.node_id)
#             # pruned_tree = prunethenode(current_tree, node.node_id)
#             pruned_accuracy = accuracy(y_valid, predict(best_tree, val_X))
            
#             if pruned_accuracy &gt; best_pruned_accuracy:
#                 best_pruned_accuracy = pruned_accuracy
#                 best_pruned_node = node.node_id 

#             node, _, original_left, original_right = pruned_info
#             node.leafhaikya = False
#             node.left = original_left
#             node.right = original_right

#             if( i%10==0):
#                 print(i)
#             i+=1
#         print(itr)
        
#         # If we found a better tree, update and continue
#         if best_pruned_node and best_pruned_accuracy &gt; best_accuracy:
#             prunethenode(best_tree,best_pruned_node)
#             best_accuracy = best_pruned_accuracy
#             trees.append(copy.deepcopy(best_tree))
#             node_counts.append(count_nodes(best_tree))
#             accuracies.append(best_accuracy)
#             improvement = True
#         print(itr)
#     print("hii")
#     return trees, node_counts, accuracies


def post_prune_tree(tree, val_X, y_valid):
    from collections import defaultdict
    import copy

    n = len(y_valid)
    predictions = [None] * n
    node_to_samples = defaultdict(list)

    def traverse_and_record(node, x, idx):
        node_to_samples[node.node_id].append(idx)
        if node.leafhaikya:
            return node.prediction
        if x[node.split_at] &lt;= node.split_val_at:
            return traverse_and_record(node.left, x, idx)
        else:
            return traverse_and_record(node.right, x, idx)

    for i, (_,x) in enumerate(val_X.iterrows()):
        predictions[i] = traverse_and_record(tree, x, i)

    correct = [int(predictions[i] == y_valid[i]) for i in range(n)]
    best_accuracy = sum(correct) / n

    trees = [copy.deepcopy(tree)]
    node_counts = [count_nodes(tree)]
    accuracies = [best_accuracy]

    def po_prune_kar(node):
        if node.leafhaikya:
            return

        if node.left:
            po_prune_kar(node.left)
        if node.right:
            po_prune_kar(node.right)

        indices = node_to_samples[node.node_id]
        old_correct = sum(correct[i] for i in indices)
        new_correct = sum(int(y_valid[i] == node.prediction) for i in indices)

        if new_correct &gt;= old_correct:
            node.leafhaikya = True
            node.left = None
            node.right = None
            node.split_at = None
            node.split_val_at = None
            for i in indices:
                correct[i] = int(y_valid[i] == node.prediction)

    po_prune_kar(tree)

    trees.append(copy.deepcopy(tree))
    node_counts.append(count_nodes(tree))
    accuracies.append(sum(correct) / n)

    return trees, node_counts, accuracies



def I_hot_encodes(df):
    df = df.copy()
    target_col = 'income' if 'income' in df.columns else None
    if target_col:
        target = df[target_col]
        df = df.drop(columns=[target_col])
    else:
        target = None
    categorical_columns = df.select_dtypes(include=['object']).columns
    df = pd.get_dummies(df, columns=categorical_columns)
    if target is not None:
        df[target_col] = target
    return df


def main(tr_pth, val_pth, tst_pth, output_folder, q_prt):
    tr_dt = pd.read_csv(tr_pth)
    vl_dt = pd.read_csv(val_pth)
    tst_dt = pd.read_csv(tst_pth)
    
    tr_X = tr_dt.drop(['income'], axis=1)   
    tr_y = tr_dt['income']
    
    val_X = vl_dt.drop(['income'], axis=1)
    y_valid = vl_dt['income']
    
    tst_X = tst_dt.drop(['income'], axis=1) if 'income' in tst_dt.columns else tst_dt
    y_test = tst_dt['income'] if 'income' in tst_dt.columns else None
    
    attrs = tr_X.columns.tolist()
    os.makedirs(output_folder, exist_ok=True)

    if q_prt == 'a':
        max_ds = [5, 10, 15, 20]
        tr_accuracies = []
        test_accuracies = []
        
        for max_depth in max_ds:
            print(f"training decision tree with max_depth={max_depth}")
            tree = build_tree(tr_X, tr_y, attrs, max_depth)
            
            # Make predictions
            tr_predictions = predict(tree, tr_X)
            tr_acc = accuracy(tr_y, tr_predictions)
            tr_accuracies.append(tr_acc)
            
            valid_predictions = predict(tree, val_X)
            valid_acc = accuracy(y_valid, valid_predictions)
            # valid_accuracies.append(valid_acc)
            
            print(f"  train accuracy: {tr_acc:.4f}")
            print(f"  Validation accuracy: {valid_acc:.4f}")
            
            if y_test is not None:
                test_predictions = predict(tree, tst_X)
                test_acc = accuracy(y_test, test_predictions)
                test_accuracies.append(test_acc)
                print(f"  Test accuracy: {test_acc:.4f}")
            
            # Save predictions for max_depth=15 (as required)
            if max_depth == 20:
                test_predictions = predict(tree, tst_X)
                
                # Create output directory if it doesn't exist
                os.makedirs(output_folder, exist_ok=True)
                
                # Save predictions
                pred_df = pd.DataFrame({'prediction': test_predictions})
                pred_df.to_csv(os.path.join(output_folder, f'prediction_{q_prt}.csv'), index=False)
        
        # Plot accuracies
        plt.figure(figsize=(10, 6))
        plt.plot(max_ds, tr_accuracies, 'o-', label='train Accuracy')
        plt.plot(max_ds, test_accuracies, 'o-', label='Test Accuracy')
        plt.xlabel('Maximum Depth')
        plt.ylabel('Accuracy')
        plt.title('Decision Tree Performance vs. Maximum Depth')
        plt.grid(True)
        plt.legend()
        plt.savefig(os.path.join(output_folder, 'decision_tree_accuracy.png'))
        plt.close()
        
        print("Results:")
        print(f"train accuracies: {tr_accuracies}")
        print(f"Test accuracies: {test_accuracies}")
        
        # Additional analysis and comments
        print("\nObservations:")
        print("1. As the maximum depth increases, the training accuracy tends to increase because the tree can capture more complex patterns.")
        print("2. The validation accuracy may plateau or decrease at higher depths due to overfitting.")
        print("3. The optimal depth appears to be around the point where validation accuracy is highest.")
    
    if q_prt == 'b':

        print("Applying one-hot encoding to categorical features...")
        
        tr_dt_encoded = I_hot_encodes(tr_dt)
        
        vl_dt_encoded = I_hot_encodes(vl_dt)
        
        tst_dt_encoded = I_hot_encodes(tst_dt)
        
        tr_columns = set(tr_dt_encoded.columns)
        
        for col in tr_columns:
            if col not in vl_dt_encoded.columns and col != 'income':
                vl_dt_encoded[col] = 0
        
        vl_dt_encoded = vl_dt_encoded[[col for col in vl_dt_encoded.columns 
                                             if col in tr_columns or col == 'income']]
        for col in tr_columns:
            if col not in tst_dt_encoded.columns and col != 'income':
                tst_dt_encoded[col] = 0
        
        test_columns = [col for col in tst_dt_encoded.columns 
                     if col in tr_columns or col == 'income']
        if test_columns: 
            tst_dt_encoded = tst_dt_encoded[test_columns]
        
        tr_X = tr_dt_encoded.drop(['income'], axis=1)
        tr_y = tr_dt_encoded['income']
        
        val_X = vl_dt_encoded.drop(['income'], axis=1) if 'income' in vl_dt_encoded.columns else vl_dt_encoded
        y_valid = vl_dt_encoded['income'] if 'income' in vl_dt_encoded.columns else None
        
        tst_X = tst_dt_encoded.drop(['income'], axis=1) if 'income' in tst_dt_encoded.columns else tst_dt_encoded
        y_test = tst_dt_encoded['income'] if 'income' in tst_dt_encoded.columns else None
        
        attrs = tr_X.columns.tolist()
        
        max_ds = [25, 35, 45, 55]
        tr_accuracies = []
        valid_accuracies = []
        
        for max_depth in max_ds:
            print(f"training decision tree with max_depth={max_depth}")
            tree = build_tree(tr_X, tr_y, attrs, max_depth)
            
            # Make predictions
            tr_predictions = predict(tree, tr_X)
            tr_acc = accuracy(tr_y, tr_predictions)
            tr_accuracies.append(tr_acc)
            
            if y_valid is not None:
                valid_predictions = predict(tree, val_X)
                valid_acc = accuracy(y_valid, valid_predictions)
                valid_accuracies.append(valid_acc)
                print(f"  Validation accuracy: {valid_acc:.4f}")
            else:
                print("  Warning: No validation labels available")
                valid_accuracies.append(0)
            
            print(f"  train accuracy: {tr_acc:.4f}")
            
            if y_test is not None:
                test_predictions = predict(tree, tst_X)
                test_acc = accuracy(y_test, test_predictions)
                print(f"  Test accuracy: {test_acc:.4f}")
            
            if max_depth == 55:  # Assuming 35 is the best depth based on experiments
                test_predictions = predict(tree, tst_X)
                
                os.makedirs(output_folder, exist_ok=True)
                pred_df = pd.DataFrame({'prediction': test_predictions})
                pred_df.to_csv(os.path.join(output_folder, f'prediction_{q_prt}.csv'), index=False)
        
        plt.figure(figsize=(10, 6))
        plt.plot(max_ds, tr_accuracies, 'o-', label='train Accuracy')
        if all(acc &gt; 0 for acc in valid_accuracies):
            plt.plot(max_ds, valid_accuracies, 'o-', label='Validation Accuracy')
        plt.xlabel('Maximum Depth')
        plt.ylabel('Accuracy')
        plt.title('One-Hot Encoded Decision Tree Performance vs. Maximum Depth')
        plt.grid(True)
        plt.legend()
        plt.savefig(os.path.join(output_folder, 'one_hot_decision_tree_accuracy.png'))
        plt.close()
        
        print("Results:")
        print(f"train accuracies: {tr_accuracies}")
        if all(acc &gt; 0 for acc in valid_accuracies):
            print(f"Validation accuracies: {valid_accuracies}")
        else:
            print("No validation accuracies available")
        
        print("\nObservations:")
        print("1. One-hot encoding expands the feature space significantly by creating a binary feature for each category.")
        print("2. This allows for more granular splits but can lead to a more complex tree structure.")
        print("3. Compared to part (a), one-hot encoding might yield different patterns in model performance:")
        print("   - Potentially better handling of categorical features with many values")
        print("   - Possibly requiring greater tree depth to achieve similar performance")
        print("   - Different optimal depth points due to the changed feature representation")
        print("4. The tree can now make more precise splits on specific category values rather than treating all categories equally.")


    if q_prt == 'c':
        print("Applying one-hot encoding to categorical features...")
        tr_dt_encoded = I_hot_encodes(tr_dt)
        vl_dt_encoded = I_hot_encodes(vl_dt)
        tst_dt_encoded = I_hot_encodes(tst_dt)
        tr_columns = set(tr_dt_encoded.columns)
        for col in tr_columns:
            if col not in vl_dt_encoded.columns and col != 'income':
                vl_dt_encoded[col] = 0
        vl_dt_encoded = vl_dt_encoded[[col for col in vl_dt_encoded.columns 
                                             if col in tr_columns or col == 'income']]
        for col in tr_columns:
            if col not in tst_dt_encoded.columns and col != 'income':
                tst_dt_encoded[col] = 0
        test_columns = [col for col in tst_dt_encoded.columns 
                     if col in tr_columns or col == 'income']
        if test_columns:  # Check if test_columns is not empty
            tst_dt_encoded = tst_dt_encoded[test_columns]
        tr_X = tr_dt_encoded.drop(['income'], axis=1)
        tr_y = tr_dt_encoded['income']
        val_X = vl_dt_encoded.drop(['income'], axis=1) if 'income' in vl_dt_encoded.columns else vl_dt_encoded
        y_valid = vl_dt_encoded['income'] if 'income' in vl_dt_encoded.columns else None
        tst_X = tst_dt_encoded.drop(['income'], axis=1) if 'income' in tst_dt_encoded.columns else tst_dt_encoded
        y_test = tst_dt_encoded['income'] if 'income' in tst_dt_encoded.columns else None
        attrs = tr_X.columns.tolist()
        max_ds = [25, 35, 45, 55]
        results = []
        
        for max_depth in max_ds:
            print(f"\ntraining decision tree with max_depth={max_depth}")
            
            # Build the initial tree
            tree = build_tree_c(tr_X, tr_y, attrs, max_depth)
            initial_nodes = count_nodes(tree)
            
            initial_tr_acc = accuracy(tr_y, predict(tree, tr_X))
            initial_valid_acc = accuracy(y_valid, predict(tree, val_X)) if y_valid is not None else 0
            initial_test_acc = accuracy(y_test, predict(tree, tst_X)) if y_test is not None else 0
            
            print(f"Initial tree: {initial_nodes} nodes")
            print(f"  Initial train accuracy: {initial_tr_acc:.4f}")
            print(f"  Initial Validation accuracy: {initial_valid_acc:.4f}")
            if y_test is not None:
                print(f"  Initial Test accuracy: {initial_test_acc:.4f}")
            
            # Post-prune the tree
            print("Post-pruning the tree...")
            pruned_trees, node_counts, valid_accuracies = post_prune_tree(tree, val_X, y_valid)
            
            # Calculate accuracies for each pruned tree
            tr_accuracies = [accuracy(tr_y, predict(t, tr_X)) for t in pruned_trees]
            test_accuracies = [accuracy(y_test, predict(t, tst_X)) for t in pruned_trees] if y_test is not None else [0] * len(pruned_trees)
            
            # Plot results
            plt.figure(figsize=(12, 8))
            plt.plot(node_counts, tr_accuracies, 'o-', label='train Accuracy')
            plt.plot(node_counts, valid_accuracies, 'o-', label='Validation Accuracy')
            if y_test is not None:
                plt.plot(node_counts, test_accuracies, 'o-', label='Test Accuracy')
            
            plt.xlabel('Number of Nodes')
            plt.ylabel('Accuracy')
            plt.title(f'Accuracy vs. Tree Size (Initial Depth={max_depth})')
            plt.grid(True)
            plt.legend()
            plt.savefig(os.path.join(output_folder, f'pruning_depth_{max_depth}.png'))
            plt.close()
            
            # Save information about the best pruned tree (based on validation accuracy)
            best_idx = valid_accuracies.index(max(valid_accuracies))
            best_tree = pruned_trees[best_idx]
            best_nodes = node_counts[best_idx]
            
            final_tr_acc = tr_accuracies[best_idx]
            final_valid_acc = valid_accuracies[best_idx]
            final_test_acc = test_accuracies[best_idx] if y_test is not None else 0
            
            print(f"Best pruned tree: {best_nodes} nodes (reduction of {initial_nodes - best_nodes} nodes)")
            print(f"  Final train accuracy: {final_tr_acc:.4f} (change: {final_tr_acc - initial_tr_acc:.4f})")
            print(f"  Final Validation accuracy: {final_valid_acc:.4f} (change: {final_valid_acc - initial_valid_acc:.4f})")
            if y_test is not None:
                print(f"  Final Test accuracy: {final_test_acc:.4f} (change: {final_test_acc - initial_test_acc:.4f})")
            
            # Save results
            results.append({
                'max_depth': max_depth,
                'initial_nodes': initial_nodes,
                'best_pruned_nodes': best_nodes,
                'node_reduction': initial_nodes - best_nodes,
                'initial_train_acc': initial_tr_acc,
                'initial_valid_acc': initial_valid_acc,
                'initial_test_acc': initial_test_acc,
                'final_train_acc': final_tr_acc,
                'final_valid_acc': final_valid_acc, 
                'final_test_acc': final_test_acc,
                'train_acc_change': final_tr_acc - initial_tr_acc,
                'valid_acc_change': final_valid_acc - initial_valid_acc,
                'test_acc_change': final_test_acc - initial_test_acc
            })
            
            # Save predictions for the best model across all depths
            if max_depth == 55:  # Assuming depth 35 gives the best model
                test_predictions = predict(best_tree, tst_X)
                
                # Create output directory if it doesn't exist
                os.makedirs(output_folder, exist_ok=True)
                
                # Save predictions
                pred_df = pd.DataFrame({'prediction': test_predictions})
                pred_df.to_csv(os.path.join(output_folder, f'prediction_{q_prt}.csv'), index=False)
        
        plt.figure(figsize=(12, 8))
        
        depths = [r['max_depth'] for r in results]
        initial_nodes = [r['initial_nodes'] for r in results]
        best_nodes = [r['best_pruned_nodes'] for r in results]
        initial_valid_accs = [r['initial_valid_acc'] for r in results]
        final_valid_accs = [r['final_valid_acc'] for r in results]
        initial_test_accs = [r['initial_test_acc'] for r in results]
        final_test_accs = [r['final_test_acc'] for r in results]
        
        plt.subplot(2, 1, 1)
        plt.plot(depths, initial_nodes, 'o-', label='Initial Nodes')
        plt.plot(depths, best_nodes, 'o-', label='After Pruning')
        plt.xlabel('Max Depth')
        plt.ylabel('Number of Nodes')
        plt.title('Tree Size Before and After Pruning')
        plt.grid(True)
        plt.legend()
        
        plt.subplot(2, 1, 2)
        plt.plot(depths, initial_valid_accs, 'o-', label='Initial Validation Accuracy')
        plt.plot(depths, final_valid_accs, 'o-', label='Final Validation Accuracy')
        plt.plot(depths, initial_test_accs, 'o-', label='Initial Test Accuracy')
        plt.plot(depths, final_test_accs, 'o-', label='Final Test Accuracy')
        plt.xlabel('Max Depth')
        plt.ylabel('Accuracy')
        plt.title('Accuracy Before and After Pruning')
        plt.grid(True)
        plt.legend()
        
        plt.tight_layout()
        plt.savefig(os.path.join(output_folder, 'pruning_summary.png'))
        plt.close()
        
        print("\nPruning Summary:")
        for r in results:
            print(f"Max Depth {r['max_depth']}: Nodes {r['initial_nodes']} → {r['best_pruned_nodes']}, " +
                  f"Valid Acc {r['initial_valid_acc']:.4f} → {r['final_valid_acc']:.4f}, " +
                  f"Test Acc {r['initial_test_acc']:.4f} → {r['final_test_acc']:.4f}")
        
        # print("\nObservations:")
        # print("1. Post-pruning helps reduce the tree size significantly while maintaining or improving validation accuracy.")
        # print("2. The amount of pruning increases with tree depth - deeper trees have more nodes that can be pruned.")
        # print("3. Pruning typically causes a small decrease in training accuracy but improves generalization.")
        # print("4. The gap between training and test accuracy narrows after pruning, indicating reduced overfitting.")
        # print("5. The optimal pruned tree size is considerably smaller than the initial tree, showing many nodes were unnecessary.")

    if q_prt == 'd':

        print("Applying one-hot encoding to categorical features...")
        tr_dt_encoded = I_hot_encodes(tr_dt)
        vl_dt_encoded = I_hot_encodes(vl_dt)
        tst_dt_encoded = I_hot_encodes(tst_dt)
        tr_columns = tr_dt_encoded.columns.tolist()
        
        vl_dt_encoded = vl_dt_encoded.reindex(columns=tr_columns, fill_value=0)
        tst_dt_encoded = tst_dt_encoded.reindex(columns=tr_columns, fill_value=0)

        tr_X = tr_dt_encoded.drop(['income'], axis=1)
        tr_y = tr_dt_encoded['income']
        
        val_X = vl_dt_encoded.drop(['income'], axis=1) if 'income' in vl_dt_encoded.columns else vl_dt_encoded
        y_valid = vl_dt_encoded['income'] if 'income' in vl_dt_encoded.columns else None
        
        tst_X = tst_dt_encoded.drop(['income'], axis=1) if 'income' in tst_dt_encoded.columns else tst_dt_encoded
        y_test = tst_dt_encoded['income'] if 'income' in tst_dt_encoded.columns else None
        
        max_ds = [25, 35, 45, 55]
        depth_tr = []
        depth_val = []
        depth_tes = []

        for depth in max_ds:
            clf = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42)
            clf.fit(tr_X, tr_y)

            tr_pred = clf.predict(tr_X)
            valid_pred = clf.predict(val_X)
            test_pred = clf.predict(tst_X)

            tr_acc = accuracy_score(tr_y, tr_pred)
            valid_acc = accuracy_score(y_valid, valid_pred)
            test_acc = accuracy_score(y_test, test_pred)

            depth_tr.append(tr_acc)
            depth_val.append(valid_acc)
            depth_tes.append(test_acc)

            print(f"Depth={depth}: train={tr_acc:.4f}, Valid={valid_acc:.4f}, Test={test_acc:.4f}")
        plt.figure(figsize=(8, 5))
        plt.plot(max_ds, depth_tr, label='train Accuracy', marker='o')
        plt.plot(max_ds, depth_val, label='Validation Accuracy', marker='o')
        plt.plot(max_ds, depth_tes, label='Test Accuracy', marker='o')
        plt.xlabel('Max Depth')
        plt.ylabel('Accuracy')
        plt.title('Accuracy vs Max Depth (criterion="entropy")')
        plt.legend()
        plt.grid(True)
        plt.tight_layout()
        plt.savefig(os.path.join(output_folder, 'depth.png'))

<A NAME="3"></A><FONT color = #00FFFF><A HREF="match184-1.html#3" TARGET="1"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        best_depth = max_ds[np.argmax(depth_val)]    
        print(f"Best max_depth based on validation set: {best_depth}")  

        ccp_alp = [0.001, 0.01, 0.1, 0.2]
        alpha_tr = []
</FONT>        alpha_val = []
        alpha_tes = []

        for alpha in ccp_alp:
            clf = DecisionTreeClassifier(criterion='entropy', ccp_al=alpha, random_state=42)
            clf.fit(tr_X, tr_y)

            tr_pred = clf.predict(tr_X)
            valid_pred = clf.predict(val_X)
            test_pred = clf.predict(tst_X)

            tr_acc = accuracy_score(tr_y, tr_pred)
            valid_acc = accuracy_score(y_valid, valid_pred)
            test_acc = accuracy_score(y_test, test_pred)

            alpha_tr.append(tr_acc)
            alpha_val.append(valid_acc)
            alpha_tes.append(test_acc)

            print(f"ccp_al={alpha}: Tree Size (number of nodes): {clf.tree_.node_count} train={tr_acc:.4f}, Valid={valid_acc:.4f}, Test={test_acc:.4f}")


        plt.figure(figsize=(8, 5))
        plt.plot(ccp_alp, alpha_tr, label='train Accuracy', marker='o')
        plt.plot(ccp_alp, alpha_val, label='Validation Accuracy', marker='o')
        plt.plot(ccp_alp, alpha_tes, label='Test Accuracy', marker='o')
        plt.xlabel('ccp_al')
        plt.ylabel('Accuracy')
        plt.title('Accuracy vs ccp_al (pruning)')
        plt.legend()
        plt.grid(True)
        plt.tight_layout()        
        plt.savefig(os.path.join(output_folder, 'ccp_alpha.png'))
        best_alpha = ccp_alp[np.argmax(alpha_val)]
        print(f"Best ccp_al based on validation set: {best_alpha}")

        clf_best = DecisionTreeClassifier(max_depth=best_depth, ccp_alpha=best_alpha, random_state=42)
        clf_best.fit(tr_X, tr_y)

        # Predict on test data
        test_predictions = clf_best.predict(tst_X)
        os.makedirs(output_folder, exist_ok=True)
        
        # Save predictions
        pred_df = pd.DataFrame({'prediction': test_predictions})
        pred_df.to_csv(os.path.join(output_folder, f'prediction_{q_prt}.csv'), index=False)

    if q_prt == 'e':
        print("Applying one-hot encoding to categorical features...")
        tr_dt_encoded = I_hot_encodes(tr_dt)
        vl_dt_encoded = I_hot_encodes(vl_dt)
        tst_dt_encoded = I_hot_encodes(tst_dt)
        tr_columns = tr_dt_encoded.columns.tolist()
        
        vl_dt_encoded = vl_dt_encoded.reindex(columns=tr_columns, fill_value=0)
        tst_dt_encoded = tst_dt_encoded.reindex(columns=tr_columns, fill_value=0)

        tr_X = tr_dt_encoded.drop(['income'], axis=1)
        tr_y = tr_dt_encoded['income']
        
        val_X = vl_dt_encoded.drop(['income'], axis=1) if 'income' in vl_dt_encoded.columns else vl_dt_encoded
        y_valid = vl_dt_encoded['income'] if 'income' in vl_dt_encoded.columns else None
        
        tst_X = tst_dt_encoded.drop(['income'], axis=1) if 'income' in tst_dt_encoded.columns else tst_dt_encoded
        y_test = tst_dt_encoded['income'] if 'income' in tst_dt_encoded.columns else None

        param_grid = {
            'n_est': [50, 150, 250, 350],           
            'max_ftr': [0.1, 0.3, 0.5, 0.7, 0.9],    
            'min_samples_split': [2, 4, 6, 8, 10]
        }

        best_model = None
        best_oob_score = -1
        results = []
        best_params = None        

        for params in ParameterGrid(param_grid):
            clf = RandomForestClassifier(
                oob_score=True,
<A NAME="1"></A><FONT color = #00FF00><A HREF="match184-1.html#1" TARGET="1"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

                criterion="entropy",
                bootstrap=True,
                random_state=42,
                **params
            )
            clf.fit(tr_X, tr_y)
            tr_acc = accuracy_score(tr_y, clf.predict(tr_X))
            valid_acc = accuracy_score(y_valid, clf.predict(val_X))
            test_acc = accuracy_score(y_test, clf.predict(tst_X))
</FONT>            oob_acc = clf.oob_score_
            results.append({
                'n_est': params['n_est'],
                'max_ftr': params['max_ftr'],
                'min_samples_split': params['min_samples_split'],
                'tr_acc': tr_acc,
                'oob_acc': clf.oob_score_,
                'valid_acc': valid_acc,
                'test_acc': test_acc
            })
            if clf.oob_score_ &gt; best_oob_score:
                best_oob_score = clf.oob_score_
                best_model = clf
                best_params = params
            print(f"  training Acc: {tr_acc:.4f}, OOB Acc: {oob_acc:.4f}, Validation Acc: {valid_acc:.4f}, Test Acc: {test_acc:.4f}")
        
        print("\nBest Parameters:", best_params)
        print("Best OOB Score:", best_oob_score)

        tr_acc = accuracy_score(tr_y, best_model.predict(tr_X))
        valid_acc = accuracy_score(y_valid, best_model.predict(val_X))
        test_acc = accuracy_score(y_test, best_model.predict(tst_X))

        print("\nFinal Accuracy Results:")
        print("train Accuracy:", tr_acc)
        print("Validation Accuracy:", valid_acc)
        print("Test Accuracy:", test_acc)

        test_predictions = best_model.predict(tst_X)
        
        # Create output directory if it doesn't exist
        os.makedirs(output_folder, exist_ok=True)
        
        # Save predictions
        pred_df = pd.DataFrame({'prediction': test_predictions})
        pred_df.to_csv(os.path.join(output_folder, f'prediction_{q_prt}.csv'), index=False)


        
        


    



if __name__ == "_main_":
    parser = argparse.ArgumentParser(description='DT Classifier')
    parser.add_argument('tr_pth', type=str, help='Path to train.csv')
    parser.add_argument('val_pth', type=str, help='Path to val.csv')
    parser.add_argument('tst_pth', type=str, help='Path to test.csv')
    parser.add_argument('output_folder', type=str, help='Path to output_folder')
    parser.add_argument('q_prt', type=str, choices=['a', 'b', 'c', 'd', 'e'], help='Q_part')
    
    args = parser.parse_args()
    main(args.tr_pth, args.val_pth, args.tst_pth, args.output_folder, args.q_prt)



import numpy as np
import os
from PIL import Image
import pandas as pd
from sklearn.metrics import precision_recall_fscore_support
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier

import matplotlib.pyplot as plt
import time
import csv

class NN:
    def _init_(self, n_features, hidden_layers, n_classes, learning_rate=0.01, batch_size=32, adaptive_lr=False, activation='sigmoid'):
        self.n_features = n_features
        self.hidden_layers = hidden_layers
        self.n_classes = n_classes
        self.activation=activation
        self.learning_rate = learning_rate
        self.batch_size = batch_size
        self.adaptive_lr = adaptive_lr
        self.epoch_count = 0
        self.params = {}
        self.grads = {}
        self.activations = {}
        self.net_inputs = {}
        layer_sizes = [n_features] + hidden_layers + [n_classes]
        for i in range(len(layer_sizes) - 1):
            scale = np.sqrt(2.0 / (layer_sizes[i] + layer_sizes[i+1]))
            self.params[f'W{i+1}'] = np.random.randn(layer_sizes[i], layer_sizes[i+1]) * scale
            self.params[f'b{i+1}'] = np.zeros((1, layer_sizes[i+1]))
    
    def sigmoid(self, z):
        z = np.clip(z, -500, 500)
        return 1 / (1 + np.exp(-z))
    
    def sigmoid_derivative(self, z):
        sig = self.sigmoid(z)
        return sig * (1 - sig)
    
    def relu(self, z):
        return np.maximum(0, z)
    
    def relu_derivative(self, z):
        return np.where(z &gt; 0, 1, 0)
    
    def tanh(self, z):
        return np.tanh(z)
    
    def tanh_derivative(self, z):
        return 1 - np.power(np.tanh(z), 2)
    
    def softmax(self, z):
        shifted_z = z - np.max(z, axis=1, keepdims=True)
        exp_z = np.exp(shifted_z)
        return exp_z / np.sum(exp_z, axis=1, keepdims=True)
    
    def forward_pass(self, X):
        self.activations['A0'] = X
        num_layers = len(self.hidden_layers) + 1
        
        for i in range(1, num_layers):
            self.net_inputs[f'Z{i}'] = np.dot(self.activations[f'A{i-1}'], self.params[f'W{i}']) + self.params[f'b{i}']
            if self.activation=="sigmoid":
                self.activations[f'A{i}'] = self.sigmoid(self.net_inputs[f'Z{i}'])
            elif self.activation=="relu":
                self.activations[f'A{i}'] = self.relu(self.net_inputs[f'Z{i}'])
        
        self.net_inputs[f'Z{num_layers}'] = np.dot(self.activations[f'A{num_layers-1}'], 
                                                  self.params[f'W{num_layers}']) + self.params[f'b{num_layers}']
        self.activations[f'A{num_layers}'] = self.softmax(self.net_inputs[f'Z{num_layers}'])
        
        return self.activations[f'A{num_layers}']
    
    def computing_loss(self, y_true, y_pred):
        epsilon = 1e-15
        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)
        loss = -np.sum(y_true * np.log(y_pred)) / y_true.shape[0]
        return loss
    
    def backward_pass(self, y_true):
        num_layers = len(self.hidden_layers) + 1
        batch_size = y_true.shape[0]
        
        for i in range(1, num_layers + 1):
            self.grads[f'dW{i}'] = None
            self.grads[f'db{i}'] = None
        
        self.grads[f'dZ{num_layers}'] = self.activations[f'A{num_layers}'] - y_true
        
        for i in range(num_layers, 0, -1):
            self.grads[f'dW{i}'] = np.dot(self.activations[f'A{i-1}'].T, self.grads[f'dZ{i}']) / batch_size
            self.grads[f'db{i}'] = np.sum(self.grads[f'dZ{i}'], axis=0, keepdims=True) / batch_size
            
            if i &gt; 1:
                if self.activation=="sigmoid":
                    dA = np.dot(self.grads[f'dZ{i}'], self.params[f'W{i}'].T)
                    self.grads[f'dZ{i-1}'] = dA * self.sigmoid_derivative(self.net_inputs[f'Z{i-1}'])
                elif self.activation=="relu":
                    dA = np.dot(self.grads[f'dZ{i}'], self.params[f'W{i}'].T)
                    self.grads[f'dZ{i-1}'] = dA * self.relu_derivative(self.net_inputs[f'Z{i-1}'])

    def updating_parameters(self):
        current_lr = self.learning_rate
        if self.adaptive_lr:
            current_lr = self.learning_rate / np.sqrt(self.epoch_count + 1)
        
        num_layers = len(self.hidden_layers) + 1
        for i in range(1, num_layers + 1):
            self.params[f'W{i}'] -= current_lr * self.grads[f'dW{i}']
            self.params[f'b{i}'] -= current_lr * self.grads[f'db{i}']
    
    def I_hot_encode(self, y, num_classes):
        
        y_one_hot = np.zeros((y.shape[0], num_classes))
        y_one_hot[np.arange(y.shape[0]), y] = 1
        return y_one_hot
    
    def tr(self, X, y, X_val=None, y_val=None, epochs=100, verbose=True, 
              early_stopping=True, patience=5):
        
        n_samples = X.shape[0]
        n_batches = int(np.ceil(n_samples / self.batch_size))
        
        y_one_hot = self.I_hot_encode(y, self.n_classes)
        
        if X_val is not None and y_val is not None:
            y_val_one_hot = self.I_hot_encode(y_val, self.n_classes)
        
        history = {
            'loss': [],
            'val_loss': [],
            'val_accuracy': []
        }
        
        best_val_loss = float('inf')
        no_improvement_count = 0
        
        for epoch in range(epochs):
            self.epoch_count = epoch + 1
            start_time = time.time()
            
            indices = np.random.permutation(n_samples)
            X_shuffled = X[indices]
            y_shuffled = y_one_hot[indices]
            
            epoch_loss = 0
            for batch in range(n_batches):
                start_idx = batch * self.batch_size
                end_idx = min((batch + 1) * self.batch_size, n_samples)
                
                X_batch = X_shuffled[start_idx:end_idx]
                y_batch = y_shuffled[start_idx:end_idx]
                
                y_pred = self.forward_pass(X_batch)
                batch_loss = self.computing_loss(y_batch, y_pred)
                epoch_loss += batch_loss * (end_idx - start_idx) / n_samples
                self.backward_pass(y_batch)
                self.updating_parameters()
            history['loss'].append(epoch_loss)
            if X_val is not None and y_val is not None:
                val_predictions = self.predict_proba(X_val)
                val_loss = self.computing_loss(y_val_one_hot, val_predictions)
                val_predictions_classes = np.argmax(val_predictions, axis=1)
                val_accuracy = np.mean(val_predictions_classes == y_val)
                history['val_loss'].append(val_loss)
                history['val_accuracy'].append(val_accuracy)
                if early_stopping:
                    if val_loss &lt; best_val_loss:
                        best_val_loss = val_loss
                        no_improvement_count = 0
                    else:
                        no_improvement_count += 1
                    
                    if no_improvement_count &gt;= patience:
                        if verbose:
                            print(f"Early stopping at epoch {epoch+1}")
                        break
                
                if verbose and (epoch % 5 == 0 or epoch == epochs - 1):
                    end_time = time.time()
                    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, "
                          f"Val Accuracy: {val_accuracy:.4f}, Time: {end_time - start_time:.2f}s")
            else:
                if verbose and (epoch % 5 == 0 or epoch == epochs - 1):
                    end_time = time.time()
                    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Time: {end_time - start_time:.2f}s")
        
        return history
    
    def predict_proba(self, X):
        return self.forward_pass(X)
    
<A NAME="4"></A><FONT color = #FF00FF><A HREF="match184-1.html#4" TARGET="1"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    def predicting(self, X):
        probas = self.predict_proba(X)
        return np.argmax(probas, axis=1)


def load_traf_sign_data(train_path, test_path, test_labels_path=None):
    X_train = []
</FONT>    y_train = []
    for class_id in range(43):  # 43 classes from 00000 to 00042
        class_dir = os.path.join(train_path, f"{class_id:05d}")
        if os.path.isdir(class_dir):
            for img_file in os.listdir(class_dir):
                if img_file.endswith('.jpg') or img_file.endswith('.png'):
                    img_path = os.path.join(class_dir, img_file)
                    try:
                        img = Image.open(img_path)
                        # img = img.resize((28, 28))  # Resize to 28x28 as mentioned in assignment
                        img_array = np.array(img) / 255.0  # Normalize to [0, 1]
                        X_train.append(img_array.flatten())  # Flatten to 1D array
                        y_train.append(class_id)
                    except Exception as e:
                        print(f"Error loading image {img_path}: {e}")
    
    X_train = np.array(X_train)
    y_train = np.array(y_train)
    
    # Load test data
    X_test = []
    y_test = None
    
    if test_labels_path and os.path.exists(test_labels_path):
        test_labels_df = pd.read_csv(test_labels_path)
        image_to_label = dict(zip(test_labels_df['image'], test_labels_df['label']))
    else:
        image_to_label = {}
    
    test_image_files = [f for f in os.listdir(test_path) if f.endswith('.jpg') or f.endswith('.png')]
    for img_file in test_image_files:
        img_path = os.path.join(test_path, img_file)
        try:
            img = Image.open(img_path)
            img = img.resize((28, 28))  # Resize to 28x28
            img_array = np.array(img) / 255.0  # Normalize to [0, 1]
            X_test.append(img_array.flatten())  # Flatten to 1D array
        except Exception as e:
            print(f"Error loading image {img_path}: {e}")
    
    X_test = np.array(X_test)
    
    if test_labels_path and os.path.exists(test_labels_path):
        y_test = np.array([image_to_label.get(img_file, -1) for img_file in test_image_files])
    
    return X_train, y_train, X_test, y_test


def calculate_metrics(y_true, y_pred, n_classes):
    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, labels=range(n_classes),zero_division=1)
    return precision, recall, f1


def save_predictions(y_pred, output_path):
    with open(output_path, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['prediction'])
        for pred in y_pred:
            writer.writerow([pred])

def plot_metrics(architectures, train_f1, test_f1, title, x_label, save_path=None):

    plt.figure(figsize=(10, 6))
    if isinstance(architectures[0], list):
        x_values = [len(arch) for arch in architectures]
        x_ticks = list(range(1, len(architectures) + 1))
        x_labels = [str(arch) for arch in architectures]
    else:
        x_values = architectures
        x_ticks = architectures
        x_labels = [str(x) for x in architectures]
    
    plt.plot(x_values, train_f1, 'b-o', label='Train F1')
    plt.plot(x_values, test_f1, 'r-o', label='Test F1')
    plt.xlabel(x_label)
    plt.ylabel('Average F1 Score')
    plt.title(title)
    plt.grid(True)
    plt.legend()
    
    plt.xticks(x_ticks, x_labels, rotation=45 if isinstance(architectures[0], list) else 0)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path)
    plt.show()



def part_b(train_path, test_path, output_folder_path,test_labels_path=None):
    X_train, y_train, X_test, y_test = load_traf_sign_data(train_path, test_path, test_labels_path)
    
    print(f"Training data shape: {X_train.shape}")
    print(f"Training labels shape: {y_train.shape}")
    print(f"Test data shape: {X_test.shape}")
    if y_test is not None:
        print(f"Test labels shape: {y_test.shape}")
    
    hidden_units_list = [1, 5, 10, 50, 100]
    train_avg_f1_scores = []
    test_avg_f1_scores = []
    
    for hidden_units in hidden_units_list:
        print(f"\nTraining neural network with {hidden_units} hidden units...")
        
        nn = NN(
            n_features=X_train.shape[1],
            hidden_layers=[hidden_units],
            n_classes=43,
            learning_rate=0.01,
            batch_size=32
        )
        
        indices = np.random.permutation(X_train.shape[0])
        split = int(0.9 * X_train.shape[0])
        train_indices, val_indices = indices[:split], indices[split:]
        
        X_train_split, X_val = X_train[train_indices], X_train[val_indices]
        y_train_split, y_val = y_train[train_indices], y_train[val_indices]
        
        history = nn.tr(
            X_train_split,
            y_train_split,
            X_val=X_val,
            y_val=y_val,
            epochs=100,
            verbose=True,
            early_stopping=True,
            patience=5
        )
        y_train_pred = nn.predicting(X_train)
        y_test_pred = nn.predicting(X_test)
        
        # train_precision, train_recall, train_f1 = calculate_metrics(y_train, y_train_pred, 43)
        # test_precision, test_recall, test_f1 = calculate_metrics(y_test, y_test_pred, 43)
        
        # metrics_df = pd.DataFrame({
        #     'Class': range(43),
        #     'Train_Precision': train_precision,
        #     'Train_Recall': train_recall,
        #     'Train_F1': train_f1,
        #     'Test_Precision': test_precision,
        #     'Test_Recall': test_recall,
        #     'Test_F1': test_f1
        # })
        
        # metrics_file = os.path.join(output_folder_path, f'metrics_hidden_{hidden_units}.csv')
        # metrics_df.to_csv(metrics_file, index=False)
        # print(f"Metrics saved to {metrics_file}")
        
        # train_avg_f1 = np.mean(train_f1)
        # test_avg_f1 = np.mean(test_f1)
        
        # train_avg_f1_scores.append(train_avg_f1)
        # test_avg_f1_scores.append(test_avg_f1)
        
        # print(f"Average Train F1 Score: {train_avg_f1:.4f}")
        # print(f"Average Test F1 Score: {test_avg_f1:.4f}")
        
        if(hidden_units)==100:
            save_predictions(y_test_pred, os.path.join(output_folder_path, f'prediction_b.csv'))
    
    # plot_metrics(
    #     hidden_units_list,
    #     train_avg_f1_scores,
    #     test_avg_f1_scores,
    #     'Average F1 Score vs Number of Hidden Layers',
    #     'Number of Hidden Layers',
    #     os.path.join(output_folder_path, 'f1_vs_hidden_units.png')
    # )
    
    # combined_metrics = pd.DataFrame({
    #     'Hidden_Units': hidden_units_list,
    #     'Train_Avg_F1': train_avg_f1_scores,
    #     'Test_Avg_F1': test_avg_f1_scores
    # })
    
    # combined_metrics.to_csv(os.path.join(output_folder_path, 'combined_metrics_b.csv'), index=False)
    # print(f"Combined metrics saved to {os.path.join(output_folder_path, 'combined_metrics_b.csv')}")


def part_c(train_path, test_path, output_folder_path,test_labels_path=None):
    X_train, y_train, X_test, y_test = load_traf_sign_data(train_path, test_path, test_labels_path)
    
    print(f"Training data shape: {X_train.shape}")
    print(f"Training labels shape: {y_train.shape}")
    print(f"Test data shape: {X_test.shape}")
    if y_test is not None:
        print(f"Test labels shape: {y_test.shape}")
    
    # List of hidden layer configurations to try
    hidden_layer_configs = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]
    
    train_avg_f1_scores = []
    test_avg_f1_scores = []
    
    for idx, hidden_layers in enumerate(hidden_layer_configs):
        print(f"\nTraining neural network with hidden layers: {hidden_layers}")
        
        nn = NN(
            n_features=X_train.shape[1],
            hidden_layers=hidden_layers,
            n_classes=43,
            learning_rate=0.01,
            batch_size=32,
            adaptive_lr=False  # No adaptive learning rate for part c
        )
        
        indices = np.random.permutation(X_train.shape[0])
        split = int(0.9 * X_train.shape[0])
        train_indices, val_indices = indices[:split], indices[split:]
        
        X_train_split, X_val = X_train[train_indices], X_train[val_indices]
        y_train_split, y_val = y_train[train_indices], y_train[val_indices]
        
        history = nn.tr(
            X_train_split,
            y_train_split,
            X_val=X_val,
            y_val=y_val,
            epochs=100,
            verbose=True,
            early_stopping=True,
            patience=5
        )
        
        y_train_pred = nn.predicting(X_train)
        y_test_pred = nn.predicting(X_test)
        
        # train_precision, train_recall, train_f1 = calculate_metrics(y_train, y_train_pred, 43)
        # test_precision, test_recall, test_f1 = calculate_metrics(y_test, y_test_pred, 43)
        
        # metrics_df = pd.DataFrame({
        #     'Class': range(43),
        #     'Train_Precision': train_precision,
        #     'Train_Recall': train_recall,
        #     'Train_F1': train_f1,
        #     'Test_Precision': test_precision,
        #     'Test_Recall': test_recall,
        #     'Test_F1': test_f1
        # })
        
        # # Create a descriptive name for the configuration
        # config_name = f"depth_{len(hidden_layers)}"
        
        # metrics_file = os.path.join(output_folder_path, f'metrics_c_{config_name}.csv')
        # metrics_df.to_csv(metrics_file, index=False)
        # print(f"Metrics saved to {metrics_file}")
        
        # # Calculate average F1 scores
        # train_avg_f1 = np.mean(train_f1)
        # test_avg_f1 = np.mean(test_f1)
        
        # train_avg_f1_scores.append(train_avg_f1)
        # test_avg_f1_scores.append(test_avg_f1)
        
        # # # Calculate average training time per epoch
        # # avg_train_time = np.mean(history['epoch_times'])
        # # avg_train_times.append(avg_train_time)
        
        # print(f"Average Train F1 Score: {train_avg_f1:.4f}")
        # print(f"Average Test F1 Score: {test_avg_f1:.4f}")
        # print(f"Average Training Time per Epoch: {avg_train_time:.2f}s")
        
        # Save predictions to CSV
        if idx==3:
            save_predictions(y_test_pred, os.path.join(output_folder_path, f'prediction_c.csv'))
    
    # Plot average F1 score vs network depth
    # plot_metrics(
    #     hidden_layer_configs,
    #     train_avg_f1_scores,
    #     test_avg_f1_scores,
    #     'Average F1 Score vs Network Depth (No Adaptive LR)',
    #     'Network Architecture',
    #     os.path.join(output_folder_path, 'f1_vs_depth_c.png')
    # )
    
    # # Save combined metrics
    # combined_metrics = pd.DataFrame({
    #     'Hidden_Layers': [str(layers) for layers in hidden_layer_configs],
    #     'Depth': [len(layers) for layers in hidden_layer_configs],
    #     'Train_Avg_F1': train_avg_f1_scores,
    #     'Test_Avg_F1': test_avg_f1_scores
    #     # 'Avg_Train_Time': avg_train_times
    # })
    
    # combined_metrics.to_csv(os.path.join(output_folder_path, 'combined_metrics_c.csv'), index=False)
    # print(f"Combined metrics saved to {os.path.join(output_folder_path, 'combined_metrics_c.csv')}")


def part_d(train_path, test_path, output_folder_path,test_labels_path=None):
    """
    Execute part d of the assignment: varying network depth with adaptive learning rate
    
    Parameters:
    -----------
    train_path: str
        Path to the training data directory
    test_path: str
        Path to the test data directory
    output_folder_path: str
        Path to the output folder
    """
    # Load data
    # test_labels_path = 'test_labels.csv'
    X_train, y_train, X_test, y_test = load_traf_sign_data(train_path, test_path, test_labels_path)
    
    print(f"Training data shape: {X_train.shape}")
    print(f"Training labels shape: {y_train.shape}")
    print(f"Test data shape: {X_test.shape}")
    if y_test is not None:
        print(f"Test labels shape: {y_test.shape}")
    
    # List of hidden layer configurations to try
    hidden_layer_configs = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]
    
    train_avg_f1_scores = []
    test_avg_f1_scores = []
    # avg_train_times = []
    
    for idx, hidden_layers in enumerate(hidden_layer_configs):
        print(f"\nTraining neural network with hidden layers: {hidden_layers} and adaptive learning rate")
        
        nn = NN(
            n_features=X_train.shape[1],
            hidden_layers=hidden_layers,
            n_classes=43,
            learning_rate=0.01,  # η0 = 0.01
            batch_size=32,
            adaptive_lr=True  # Use adaptive learning rate: ηe = η0/√e
        )
        
        indices = np.random.permutation(X_train.shape[0])
        split = int(0.9 * X_train.shape[0])
        train_indices, val_indices = indices[:split], indices[split:]
        
        X_train_split, X_val = X_train[train_indices], X_train[val_indices]
        y_train_split, y_val = y_train[train_indices], y_train[val_indices]
        
        history = nn.tr(
            X_train_split,
            y_train_split,
            X_val=X_val,
            y_val=y_val,
            epochs=100, 
            verbose=True,
            early_stopping=True,
            patience=10 
        )
        
        y_train_pred = nn.predicting(X_train)
        y_test_pred = nn.predicting(X_test)
        
        # Calculate metrics
        # train_precision, train_recall, train_f1 = calculate_metrics(y_train, y_train_pred, 43)
        # test_precision, test_recall, test_f1 = calculate_metrics(y_test, y_test_pred, 43)
        
        # metrics_df = pd.DataFrame({
        #     'Class': range(43),
        #     'Train_Precision': train_precision,
        #     'Train_Recall': train_recall,
        #     'Train_F1': train_f1,
        #     'Test_Precision': test_precision,
        #     'Test_Recall': test_recall,
        #     'Test_F1': test_f1
        # })
        
        # config_name = f"depth_{len(hidden_layers)}"
        
        # metrics_file = os.path.join(output_folder_path, f'metrics_d_{config_name}.csv')
        # metrics_df.to_csv(metrics_file, index=False)
        # print(f"Metrics saved to {metrics_file}")
        
        # # Calculate average F1 scores
        # train_avg_f1 = np.mean(train_f1)
        # test_avg_f1 = np.mean(test_f1)
        # train_avg_f1_scores.append(train_avg_f1)
        # test_avg_f1_scores.append(test_avg_f1)
        
        # # Calculate average training time per epoch
        # # avg_train_time = np.mean(history['epoch_times'])
        # # avg_train_times.append(avg_train_time)
        
        # print(f"Average Train F1 Score: {train_avg_f1:.4f}")
        # print(f"Average Test F1 Score: {test_avg_f1:.4f}")
        # # print(f"Average Training Time per Epoch: {avg_train_time:.2f}s")
        
        # Save predictions to CSV
        if idx==3:
            save_predictions(y_test_pred, os.path.join(output_folder_path, f'prediction_d.csv'))
    
    # Plot average F1 score vs network depth
    # plot_metrics(
    #     hidden_layer_configs,
    #     train_avg_f1_scores,
    #     test_avg_f1_scores,
    #     'Average F1 Score vs Network Depth (Adaptive LR)',
    #     'Network Architecture',
    #     os.path.join(output_folder_path, 'f1_vs_depth_d.png')
    # )
    
    # # Save combined metrics
    # combined_metrics = pd.DataFrame({
    #     'Hidden_Layers': [str(layers) for layers in hidden_layer_configs],
    #     'Depth': [len(layers) for layers in hidden_layer_configs],
    #     'Train_Avg_F1': train_avg_f1_scores,
    #     'Test_Avg_F1': test_avg_f1_scores
    #     # 'Avg_Train_Time': avg_train_times
    # })
    
    # combined_metrics.to_csv(os.path.join(output_folder_path, 'combined_metrics_d.csv'), index=False)
    # print(f"Combined metrics saved to {os.path.join(output_folder_path, 'combined_metrics_d.csv')}")


def part_e(train_path, test_path, output_folder_path,test_labels_path=None):
    # Load data
    # test_labels_path =  'test_labels.csv'
    X_train, y_train, X_test, y_test = load_traf_sign_data(train_path, test_path, test_labels_path)
    
    print(f"Training data shape: {X_train.shape}")
    print(f"Training labels shape: {y_train.shape}")
    print(f"Test data shape: {X_test.shape}")
    if y_test is not None:
        print(f"Test labels shape: {y_test.shape}")
    hidden_layer_configs = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]
    
    train_avg_f1_scores = []
    test_avg_f1_scores = []
    
    for idx, hidden_layers in enumerate(hidden_layer_configs):
        print(f"\nTraining neural network with hidden layers: {hidden_layers} and adaptive learning rate")
        
        nn = NN(
            n_features=X_train.shape[1],
            hidden_layers=hidden_layers,
            n_classes=43,
            learning_rate=0.01,  # η0 = 0.01
            batch_size=32,
            adaptive_lr=True,  # Use adaptive learning rate: ηe = η0/√e
            activation="relu"
        )
        
        # Split training data into train and validation sets
        indices = np.random.permutation(X_train.shape[0])
        split = int(0.9 * X_train.shape[0])
        train_indices, val_indices = indices[:split], indices[split:]
        
        X_train_split, X_val = X_train[train_indices], X_train[val_indices]
        y_train_split, y_val = y_train[train_indices], y_train[val_indices]
        
        history = nn.tr(
            X_train_split,
            y_train_split,
            X_val=X_val,
            y_val=y_val,
            epochs=100,  
            verbose=True,
            early_stopping=True,
            patience=10  
        )
        
        y_train_pred = nn.predicting(X_train)
        y_test_pred = nn.predicting(X_test)
        
        # train_precision, train_recall, train_f1 = calculate_metrics(y_train, y_train_pred, 43)
        # test_precision, test_recall, test_f1 = calculate_metrics(y_test, y_test_pred, 43)
        
        # metrics_df = pd.DataFrame({
        #     'Class': range(43),
        #     'Train_Precision': train_precision,
        #     'Train_Recall': train_recall,
        #     'Train_F1': train_f1,
        #     'Test_Precision': test_precision,
        #     'Test_Recall': test_recall,
        #     'Test_F1': test_f1
        # })
        
        # config_name = f"depth_{len(hidden_layers)}"
        
        # metrics_file = os.path.join(output_folder_path, f'metrics_e_{config_name}.csv')
        # metrics_df.to_csv(metrics_file, index=False)
        # print(f"Metrics saved to {metrics_file}")
        # train_avg_f1 = np.mean(train_f1)
        # test_avg_f1 = np.mean(test_f1)
        
        # train_avg_f1_scores.append(train_avg_f1)
        # test_avg_f1_scores.append(test_avg_f1)
        # print(f"Average Train F1 Score: {train_avg_f1:.4f}")
        # print(f"Average Test F1 Score: {test_avg_f1:.4f}")
        
        if idx==3:
            save_predictions(y_test_pred, os.path.join(output_folder_path, f'prediction_e.csv'))
    
    # plot_metrics(
    #     hidden_layer_configs,
    #     train_avg_f1_scores,
    #     test_avg_f1_scores,
    #     'Average F1 Score vs Network Depth (Adaptive LR, RELU Activation)',
    #     'Network Architecture',
    #     os.path.join(output_folder_path, 'f1_vs_depth_e.png')
    # )
    
    # combined_metrics = pd.DataFrame({
    #     'Hidden_Layers': [str(layers) for layers in hidden_layer_configs],
    #     'Depth': [len(layers) for layers in hidden_layer_configs],
    #     'Train_Avg_F1': train_avg_f1_scores,
    #     'Test_Avg_F1': test_avg_f1_scores
    # })
    
    # combined_metrics.to_csv(os.path.join(output_folder_path, 'combined_metrics_e.csv'), index=False)
    # print(f"Combined metrics saved to {os.path.join(output_folder_path, 'combined_metrics_e.csv')}")


def part_f(train_path, test_path, output_folder,test_labels_path=None):
    print("\nRunning Part F: MLPClassifier from scikit-learn")
    
    X_train, y_train, X_test, y_test = load_traf_sign_data(train_path, test_path,test_labels_path)
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
<A NAME="2"></A><FONT color = #0000FF><A HREF="match184-1.html#2" TARGET="1"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    hidden_layer_configs = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]
    
    depths = [len(config) for config in hidden_layer_configs]
</FONT>    train_f1_scores = []
    test_f1_scores = []
    
<A NAME="0"></A><FONT color = #FF0000><A HREF="match184-1.html#0" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    for i, hidden_layers in enumerate(hidden_layer_configs):
        print(f"\nTraining MLPClassifier with hidden layers: {hidden_layers}")
        
        model = MLPClassifier(
            hidden_layer_sizes=hidden_layers,
            activation='relu',
            solver='sgd',
            alpha=0,
            batch_size=32,
            learning_rate='invscaling',
            random_state=42,
</FONT>            verbose=True,
            early_stopping=True
        )
        
        start_time = time.time()
        model.fit(X_train_scaled, y_train)
        training_time = time.time() - start_time
        print(f"Training completed in {training_time:.2f} seconds")
        
        train_preds = model.predicting(X_train_scaled)
        test_preds = model.predicting(X_test_scaled)
        
        
        # print("\nTraining Set Metrics:")
        # train_precision, train_recall, train_f1 = calculate_metrics(y_train, train_preds,43)
        # print("\nTest Set Metrics:")
        # test_precision, test_recall, test_f1 = calculate_metrics(y_test, test_preds,43)
        # train_avg_f1 = np.mean(train_f1)
        # test_avg_f1 = np.mean(test_f1)

        # train_f1_scores.append(train_avg_f1)
        # test_f1_scores.append(test_avg_f1)
        # metrics_df = pd.DataFrame({
        #     'Class': range(43),
        #     'Train_Precision': train_precision,
        #     'Train_Recall': train_recall,
        #     'Train_F1': train_f1,
        #     'Test_Precision': test_precision,
        #     'Test_Recall': test_recall,
        #     'Test_F1': test_f1
        # })
        
        # config_name = f"depth_{len(hidden_layers)}"
        
        # metrics_file = os.path.join(output_folder_path, f'metrics_d_{config_name}.csv')
        # metrics_df.to_csv(metrics_file, index=False)
        # print(f"Metrics saved to {metrics_file}")
        
        # print(f"Average Train F1 Score: {train_avg_f1:.4f}")
        # print(f"Average Test F1 Score: {test_avg_f1:.4f}")
        if i==3:
            pd.DataFrame({'prediction': test_preds}).to_csv(os.path.join(output_folder, f"prediction_f.csv"), index=False)
    
    # plot_metrics(
    #     hidden_layer_configs,
    #     train_f1_scores,
    #     test_f1_scores,
    #     'Average F1 Score vs Network Depth (MLP Classifier)',
    #     'Network Architecture',
    #     os.path.join(output_folder_path, 'f1_vs_depth_f.png')
    # )
    # combined_metrics = pd.DataFrame({
    #     'Hidden_Layers': [str(layers) for layers in hidden_layer_configs],
    #     'Depth': [len(layers) for layers in hidden_layer_configs],
    #     'Train_Avg_F1': train_f1_scores,
    #     'Test_Avg_F1': test_f1_scores
    # })
    
    # combined_metrics.to_csv(os.path.join(output_folder_path, 'combined_metrics_c.csv'), index=False)
    # print(f"Combined metrics saved to {os.path.join(output_folder_path, 'combined_metrics_c.csv')}")
    return depths, test_f1_scores

if __name__ == "_main_":
    import sys
    
    if len(sys.argv) != 5:
        print("Usage: python neural_network.py &lt;train_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
        sys.exit(1)
    
    train_path = sys.argv[1]
    test_path = sys.argv[2]
    output_folder_path = sys.argv[3]
    question_part = sys.argv[4]
    # test_labels_path=sys.argv[5]
    # test_labels_path=None
    os.makedirs(output_folder_path, exist_ok=True)
    
    if question_part == 'b':
        part_b(train_path, test_path, output_folder_path)
    elif question_part == 'c':
        part_c(train_path, test_path, output_folder_path)
    elif question_part == 'd':
        part_d(train_path, test_path, output_folder_path)
    elif question_part =='e':
        part_e(train_path, test_path, output_folder_path)
    elif question_part == 'f':
        part_f(train_path, test_path, output_folder_path)

</PRE>
</PRE>
</BODY>
</HTML>
