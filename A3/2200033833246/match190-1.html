<HTML>
<HEAD>
<TITLE>./A3_processed_new_hash/combined_HQ61X.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A3_processed_new_hash/combined_Y26GA.py<p><PRE>


import pandas as pd
import numpy as np
from math import log2
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
import os
import sys

categorical = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']
numerical = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']

class Node:
<A NAME="5"></A><FONT color = #FF0000><A HREF="match190-0.html#5" TARGET="0"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    def __init__(self, feature=None, leaf=False, y=None, depth=0, split_value=None,parent = None):
        self.feature = feature      # Feature to split on
        self.is_leaf = leaf         # Whether this is a leaf node
        self.children = {}          # Child nodes
        self.y = y                  # Prediction value if leaf node
        self.depth = depth          # Depth of the node in the tree
        self.split_value = split_value  # Split value for numerical features
</FONT>        self.parent = parent
        self.y_num = 0                 # no of predictions == self.y
        self.actual_y_num = 0          # no of correct prediction of self.y
        self.not_y_num = 0             # no of predictions == ~self.y
        self.actual_not_y_num = 0      # no of correct prediction of ~self.y
        
class DecisionTree:
    def __init__(self):
        self.root = None
    
    def train(self, X, y, depth):
        self.root = self.grow_tree(X, y, depth)
    
    def grow_tree(self, X, y, depth , par=None):
        if len(np.unique(y)) == 1:
            return Node(leaf=True, y=y.iloc[0], depth=depth,parent=par)
            
        if depth == 0:
            majority_class = y.mode()[0]
            return Node(leaf=True, y=majority_class, depth=depth,parent = par)
            
        if X.empty:
            majority_class = y.mode()[0]
            return Node(leaf=True, y=majority_class, depth=depth,parent = par)
            
        best_feature, split_value = self.choose_best_feature(X, y)
        
        if len(np.unique(X[best_feature])) &lt;=1:
            majority_class = y.mode()[0]
            return Node(leaf=True, y=majority_class, depth=depth,parent=par)
        
        if best_feature is None:
            majority_class = y.mode()[0]
            return Node(leaf=True, y=majority_class, depth=depth,parent=par)
            
        majority_class = y.mode()[0]
        node = Node(feature=best_feature,y=majority_class,depth=depth, split_value=split_value,parent=par)
        
        if split_value is not None:
            left_mask = X[best_feature] &lt;= split_value
            right_mask = ~left_mask
            
            if (all(left_mask) or not any(left_mask)) or (all(right_mask) or not any(right_mask)):
                node.is_leaf = True
                return node
            node.children[0] = self.grow_tree(X[left_mask], y[left_mask], depth-1, par)
            node.children[1] = self.grow_tree(X[right_mask], y[right_mask], depth-1, par)
        else:
            partitions = self.partition(X, y, best_feature)
            for value, (X_part, y_part) in partitions.items():
                node.children[value] = self.grow_tree(X_part, y_part, depth-1 ,par)
                
        return node
    
    def choose_best_feature(self, X, y):
        best_feature = None
        best_value = -float('inf')
        split_value = None
        
        for feature in X.columns:
            if feature in numerical:
                median = X[feature].median()
                left_mask = X[feature] &lt;= median
                mi = self.mutual_information_numeric(X, y, feature, median)
                
                if mi &gt; best_value:
                    best_value = mi
                    best_feature = feature
                    split_value = median
            else:
                mi = self.mutual_information(X, y, feature)
                
                if mi &gt; best_value:
                    best_value = mi
                    best_feature = feature
                    split_value = None
                    
        return best_feature, split_value

    def mutual_information(self, X, y, feature):
        p_y = y.value_counts(normalize=True, sort=False)
        h_y = -np.sum(p_y * np.log2(p_y + 1e-10))
        
        len_y = len(y)

        def calculate_h_yx_j(g):
            len_g = len(g)
            p_g = g.value_counts(normalize=True, sort=False)
            h_yx_j = -np.sum(p_g * np.log2(p_g + 1e-10))
            return (len_g / len_y) * h_yx_j
        
        grouped = y.groupby(X[feature])
        h_yx = grouped.apply(calculate_h_yx_j)
        
        return h_y - h_yx.sum()

    def mutual_information_numeric(self, X, y, feature, split_value):
        p_y = y.value_counts(normalize=True, sort=False)
        h_y = -np.sum(p_y * np.log2(p_y + 1e-10))
        left_mask = X[feature] &lt;= split_value
        weights = np.array([left_mask.mean(), (~left_mask).mean()])
        h_yx = 0
        
        for m, w in zip([left_mask, ~left_mask], weights):
            if w &gt; 0:
                p = y[m].value_counts(normalize=True, sort=False)
                h_yx += w * (-np.sum(p * np.log2(p + 1e-10)))
        
        return h_y - h_yx
        
    def partition(self, X, y, feature):
        partitions = {}
        unique_values = X[feature].unique()
        
        for value in unique_values:
            mask = X[feature] == value
            partitions[value] = (X[mask].drop(columns=[feature]), y[mask])
            
        return partitions
    
    def predict(self, X):
        predictions = []
        for _, row in X.iterrows():
            node = self.root
            while not node.is_leaf:
                feature_value = row.get(node.feature, 0)
                
                if node.split_value is not None:
                    if feature_value &lt;= node.split_value:
                        node = node.children[0]
                    else:
                        node = node.children[1]
                else:
                    if feature_value in node.children:
                        node = node.children[feature_value]
                    else:
                        break
            
            predictions.append(node.y)
        
        return pd.Series(predictions, index=X.index)
    
    def predict2(self, X, Y):
        predictions = []
        for idx, row in X.iterrows():
            node = self.root
            node_lst = []
            while not node.is_leaf:
                feature_value = row.get(node.feature, 0)
                node_lst.append(node)
                
                if node.split_value is not None: 
                    if feature_value &lt;= node.split_value:
                        node = node.children[0]
                    else:
                        node = node.children[1]
                else:  
                    if feature_value in node.children:
                        node = node.children[feature_value]
                    else:
                        break

            actual_y = Y.loc[idx]
            predicted_y = node.y
            correct = (predicted_y == actual_y)
            
            for nod in node_lst:
                if nod.y == predicted_y:
                    nod.y_num += 1
                else:
                    nod.not_y_num += 1
                
                if nod.y == actual_y:
                    nod.actual_y_num += 1
                else:
                    nod.actual_not_y_num += 1
                
            node.y_num += 1
            if correct:
                node.actual_y_num += 1
            else:
                node.actual_not_y_num += 1
            
            predictions.append(predicted_y)
        
        return pd.Series(predictions, index=X.index)

    def test(self, X, y):
        predictions = self.predict(X)
        return (predictions == y).mean()
    
    def prune(self, X_val, y_val, X_train = None, y_train = None, X_test = None, y_test = None, analysis = False):
        all_nodes = 0
        
        
        nodes_lst = []
        accuracies_train = []
        accuracies_test = []
        accuracies_val = []
        
        initial_preds = self.predict2(X_val, y_val)
        total_samples = len(y_val)
        current_correct = (initial_preds == y_val).sum()
        best_val_acc = current_correct / total_samples
        
        
        # print(best_val_acc)
        improved = True
        best_acc = 0
        while improved:
            improved = False
            best_node = None
            best_delta = 0
            
            # Get all non-leaf nodes
            nodes , all_nodes = self.get_non_leaf_nodes()
            # if(done == 0):
            #     print(len(nodes),"le tree")
            
            for node in nodes:
                
                potential_gain =  (node.not_y_num - 2*node.actual_not_y_num)
                
                if potential_gain &gt; best_delta:
                    best_delta = potential_gain
                    best_node = node
                
                    if best_node and best_delta &gt; 0:
                        nc = current_correct+best_delta
                        new_acc = nc / total_samples
                        best_acc = new_acc
                        best_node = node
                    
                # if((done%500)==0):
                #     print(done,"be fast \n")
                # done+=1
                    
            if best_node and best_delta &gt; 0:
                # Permanently prune
                current_correct += best_delta
                best_node.is_leaf = True
                best_val_acc = best_acc
                self.update_ancestor_stats(best_node)
                improved = True
            
            if (analysis):
                nodes_count = all_nodes
                nodes_lst.append(nodes_count)
                accuracies_val.append(best_val_acc)
                self.update_accs(X_train,y_train,accuracies_train)
                self.update_accs(X_test,y_test,accuracies_test)
            
        # nodes_lst.append(all_nodes)
        # print(current_correct/total_samples)
        return nodes_lst, accuracies_train, accuracies_test, accuracies_val

    def update_accs(self,X,y,accuracies):
        prediction = self.predict(X)
        accuracy = np.mean(prediction == y)
        accuracies.append(accuracy)
        return

    def get_non_leaf_nodes(self):
        nodes = []
        stack = [self.root]
        val = 0
        while stack:
            node = stack.pop()
            val += 1
            if not node.is_leaf:
                nodes.append(node)
                stack.extend(node.children.values())
        return nodes,val
    
    def update_ancestor_stats(self, pruned_node:Node):
        current = pruned_node
        y_pru = pruned_node.y
        y_num_pru = pruned_node.y_num
        y_num_not = pruned_node.not_y_num
        y_actual_pru = pruned_node.actual_y_num
        y_not_actual_pru = pruned_node.actual_not_y_num
        
        y_incor = y_num_not - y_not_actual_pru
        
        while current:
            if(current.y==y_pru):
                current.y_num += (y_num_not)
                current.not_y_num -= y_num_not
                current.actual_y_num += y_incor
                current.actual_not_y_num -= y_not_actual_pru
            else:
                current.not_y_num += (y_num_not)
                current.y_num -= y_num_not
                current.actual_not_y_num += y_incor
                current.actual_y_num -= y_not_actual_pru
            
            current = current.parent

<A NAME="1"></A><FONT color = #00FF00><A HREF="match190-0.html#1" TARGET="0"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

def find_best_depth(X_train, y_train, X_test, y_test, X_val, y_val):
    depths = [25, 35, 45, 55]
    accuracies_train = []
    accuracies_val = []
    accuracies_test = []

    for depth in depths:
</FONT>        print(f"Training with max_depth = {depth}")
        tree = DecisionTreeClassifier(criterion='entropy',max_depth=depth)
        tree.fit(X_train, y_train, depth)

        prediction_train = tree.predict(X_train)
        prediction_val = tree.predict(X_val)
        prediction_test = tree.predict(X_test)

        accuracy_train = np.mean(prediction_train == y_train)
        accuracy_val = np.mean(prediction_val == y_val)
        accuracy_test = np.mean(prediction_test == y_test)

        accuracies_train.append(accuracy_train)
        accuracies_val.append(accuracy_val)
        accuracies_test.append(accuracy_test)

        print(f"Depth {depth}: Train Acc = {accuracy_train:.4f}, Val Acc = {accuracy_val:.4f}")
    
    plt.figure(figsize=(10, 6))
    plt.plot(depths, accuracies_train, marker='o', label='Train Accuracy')
    plt.plot(depths, accuracies_val, marker='s', label='Validation Accuracy')
    plt.plot(depths, accuracies_test, marker='+', label='Test Accuracy')
    plt.xlabel('Max Depth')
    plt.ylabel('Accuracy')
    plt.title('Scikit Learn Tree Accuracy vs Max Depth')
    plt.legend()
    plt.grid(True)
    plt.show()
    
    best_max_depth = 0
    best_acc = 0
    for i in range(4):
        if (accuracies_val[i] &gt; best_acc):
            best_acc = accuracies_val[i]
            best_max_depth = depths[i]
    
    print("Best Max Depth : ",best_max_depth)
    return best_max_depth
    
<A NAME="2"></A><FONT color = #0000FF><A HREF="match190-0.html#2" TARGET="0"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

def find_best_ccp_alpha(X_train, y_train, X_test, y_test, X_val, y_val):
    alphas = [0.001,0.01,0.1,0.2]
    accuracies_train = []
    accuracies_val = []
</FONT>    accuracies_test = []

    for alpha in alphas:
        print(f"Training with ccp-alpha = {alpha}")
        tree = DecisionTreeClassifier(criterion='entropy',ccp_alpha=alpha)
        tree.fit(X_train, y_train, alpha)

        prediction_train = tree.predict(X_train)
        prediction_val = tree.predict(X_val)
        prediction_test = tree.predict(X_test)

        accuracy_train = np.mean(prediction_train == y_train)
        accuracy_val = np.mean(prediction_val == y_val)
        accuracy_test = np.mean(prediction_test == y_test)

        accuracies_train.append(accuracy_train)
        accuracies_val.append(accuracy_val)
        accuracies_test.append(accuracy_test)

        print(f"CCP ALPHA {alpha}: Train Acc = {accuracy_train:.4f}, Val Acc = {accuracy_val:.4f}")
    
    plt.figure(figsize=(10, 6))
    plt.plot(alphas, accuracies_train, marker='o', label='Train Accuracy')
    plt.plot(alphas, accuracies_val, marker='s', label='Validation Accuracy')
    plt.plot(alphas, accuracies_test, marker='+', label='Test Accuracy')
    plt.xlabel('CCP-ALPHA')
    plt.ylabel('Accuracy')
    plt.title('Scikit Learn Tree Accuracy vs CCP-ALPHA')
    plt.legend()
    plt.grid(True)
    plt.show()
    
    best_ccp_alpha = 0
    best_acc = 0
    for i in range(4):
        if (accuracies_val[i] &gt; best_acc):
            best_acc = accuracies_val[i]
            best_ccp_alpha = alphas[i]
    
    print("Best CCP-ALPHA : ",best_ccp_alpha)
    return best_ccp_alpha

def prepare_datasets(path , flag=0):
    dataf = pd.read_csv(path)
    if(flag&gt;0):
        X = dataf.drop(columns=['income'])
        y = dataf['income']
        return X,y
    return dataf

def main():
    train_data_path = sys.argv[1]
    val_data_path = sys.argv[2]
    test_data_path = sys.argv[3]
    output_folder = sys.argv[4]
    question_part = sys.argv[5]

    X_train, y_train = prepare_datasets(train_data_path,1)
    X_test = prepare_datasets(test_data_path,0) 
    X_val, y_val = prepare_datasets(val_data_path,1)
    
    if "income" in X_test.columns:
        X_test = X_test.drop(columns=["income"])

    if question_part == 'a':
    #     depths = [5, 10, 15, 20]
    #     accuracies_train = []
    #     accuracies_val = []
    #     accuracies_test = []

    #     for depth in depths:
    #         print(f"Training with max_depth = {depth}")
    #         tree = DecisionTree()
    #         tree.train(X_train, y_train, depth)

    #         prediction_train = tree.predict(X_train)
    #         prediction_val = tree.predict(X_val)
    #         prediction_test = tree.predict(X_test)

    #         accuracy_train = np.mean(prediction_train == y_train)
    #         accuracy_val = np.mean(prediction_val == y_val)
    #         accuracy_test = np.mean(prediction_test == y_test)

    #         accuracies_train.append(accuracy_train)
    #         accuracies_val.append(accuracy_val)
    #         accuracies_test.append(accuracy_test)

    #         print(f"Depth {depth}: Train Acc = {accuracy_train}, Val Acc = {accuracy_val}, Test Acc = {accuracy_test}")
        
    #     plt.figure(figsize=(10, 6))
    #     plt.plot(depths, accuracies_train, marker='o', label='Train Accuracy')
    #     plt.plot(depths, accuracies_val, marker='s', label='Validation Accuracy')
    #     plt.plot(depths, accuracies_test, marker='+', label='Test Accuracy')
    #     plt.xlabel('Max Depth')
    #     plt.ylabel('Accuracy')
    #     plt.title('Tree Accuracy vs Max Depth')
    #     plt.legend()
    #     plt.grid(True)
    #     plt.show()

        
        
        tree = DecisionTree()
        tree.train(X_train, y_train, depth=20)
        prediction_test = tree.predict(X_test)
        output_csv_path = os.path.join(output_folder, f"prediction_{question_part}.csv")
        pd.DataFrame({'prediction': prediction_test}).to_csv(output_csv_path, index=False)

    if question_part == 'b':
        X_train = pd.get_dummies(X_train, columns=categorical)
        X_val = pd.get_dummies(X_val, columns=categorical)
        X_test = pd.get_dummies(X_test, columns=categorical)
        
        # depths = [25, 35, 45, 55]
        # accuracies_train = []
        # accuracies_val = []
        # accuracies_test = []

        # for depth in depths:
        #     print(f"Training with max_depth = {depth}")
        #     tree = DecisionTree()
        #     tree.train(X_train, y_train, depth)

        #     prediction_train = tree.predict(X_train)
        #     prediction_val = tree.predict(X_val)
        #     prediction_test = tree.predict(X_test)

        #     accuracy_train = np.mean(prediction_train == y_train)
        #     accuracy_val = np.mean(prediction_val == y_val)
        #     accuracy_test = np.mean(prediction_test == y_test)

        #     accuracies_train.append(accuracy_train)
        #     accuracies_val.append(accuracy_val)
        #     accuracies_test.append(accuracy_test)

        #     print(f"Depth {depth}: Train Acc = {accuracy_train}, Val Acc = {accuracy_val}, Test Acc = {accuracy_test}")
        
        # plt.figure(figsize=(10, 6))
        # plt.plot(depths, accuracies_train, marker='o', label='Train Accuracy')
        # plt.plot(depths, accuracies_val, marker='s', label='Validation Accuracy')
        # plt.plot(depths, accuracies_test, marker='+', label='Test Accuracy')
        # plt.xlabel('Max Depth')
        # plt.ylabel('Accuracy')
        # plt.title('Tree Accuracy vs Max Depth')
        # plt.legend()
        # plt.grid(True)
        # plt.show()
        
        tree = DecisionTree()
        tree.train(X_train, y_train, depth=55)
        prediction_test = tree.predict(X_test)
        output_csv_path = os.path.join(output_folder, f"prediction_{question_part}.csv")
        pd.DataFrame({'prediction': prediction_test}).to_csv(output_csv_path, index=False)

    if question_part == 'c':
        X_train = pd.get_dummies(X_train, columns=categorical)
        X_val = pd.get_dummies(X_val, columns=categorical)
        X_test = pd.get_dummies(X_test, columns=categorical)
        
        # depths = [25, 35, 45, 55]

        # for depth in depths:
        #     accuracies_train = []
        #     accuracies_val = []
        #     accuracies_test = []
        #     nodes_lst = []
        #     print(f"Training with max_depth = {depth}")
        #     tree = DecisionTree()
        #     tree.train(X_train, y_train, depth)
        #     nodes_lst, accuracies_train, accuracies_test, accuracies_val = tree.prune(X_val,y_val,X_train,y_train,X_test,y_test,True)
        #     plt.figure(figsize=(10, 6))
        #     plt.plot(nodes_lst, accuracies_train, marker='o', label='Train Accuracy')
        #     plt.plot(nodes_lst, accuracies_val, marker='s', label='Validation Accuracy')
        #     plt.plot(nodes_lst, accuracies_test, marker='s', label='Test Accuracy')
        #     plt.xlabel('Nodes count')
        #     plt.ylabel('Accuracy')
        #     plt.title('Decision Tree Accuracy vs Nodes Count')
        #     plt.legend()
        #     plt.grid(True)
        #     plt.show()
        
        tree = DecisionTree()
        tree.train(X_train,y_train,depth=5)
<A NAME="4"></A><FONT color = #FF00FF><A HREF="match190-0.html#4" TARGET="0"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        tree.prune(X_val,y_val)
        prediction_test = tree.predict(X_test)
        output_csv_path = os.path.join(output_folder, f"prediction_{question_part}.csv")
        pd.DataFrame({'prediction': prediction_test}).to_csv(output_csv_path, index=False)
</FONT>        
    if question_part == 'd':
        encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
        encoder.fit(X_train)
        X_train = encoder.transform(X_train)
        X_val = encoder.transform(X_val)
        X_test = encoder.transform(X_test)
        
        # # code for analysis
        # best_max_depth = find_best_depth(X_train,y_train,X_test,y_test,X_val,y_val)
        # best_ccp_alpha = find_best_ccp_alpha(X_train,y_train,X_test,y_test,X_val,y_val)
        
        # tree = DecisionTreeClassifier(criterion='entropy',max_depth=best_max_depth,ccp_alpha=best_ccp_alpha)
        # tree.fit(X_train,y_train)
        # prediction_train = tree.predict(X_train)
        # prediction_val = tree.predict(X_val)
        # prediction_test = tree.predict(X_test)

        # accuracy_train = np.mean(prediction_train == y_train)
        # accuracy_val = np.mean(prediction_val == y_val)
        # accuracy_test = np.mean(prediction_test == y_test)
        
        # print(f"Best Train Acc = {accuracy_train}, Val Acc = {accuracy_val}, Test Accc = {accuracy_test}")
        
        tree = DecisionTreeClassifier(criterion='entropy',max_depth=25,ccp_alpha=0.001)
        tree.fit(X_train,y_train)
        prediction_test = tree.predict(X_test)
        output_csv_path = os.path.join(output_folder, f"prediction_{question_part}.csv")
        pd.DataFrame({'prediction': prediction_test}).to_csv(output_csv_path, index=False)
        
    if question_part == 'e':
        encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
        encoder.fit(X_train)
        X_train = encoder.transform(X_train)
        X_val = encoder.transform(X_val)
        X_test = encoder.transform(X_test)
        
        # param_grid = {
        #     'n_estimators': [50, 150, 250, 350],
        #     'max_features': [0.1, 0.3, 0.5, 0.7, 1.0],
        #     'min_samples_split': [2, 4, 6, 8, 10],
        # }
        
        # def scoring(estimator,X,y):
        #     return estimator.oob_score_
    
        # Model = RandomForestClassifier(criterion='entropy',oob_score=True, bootstrap=True, random_state=42)
        # grid = GridSearchCV(estimator=Model, param_grid=param_grid, cv=2, scoring=scoring, verbose = 2)
        # grid.fit(X_val,y_val)
        # best_model = grid.best_estimator_
        # best_params = grid.best_params_
        # prediction_train = best_model.predict(X_train)
        # accuracy_train = np.mean(y_train == prediction_train)
        # prediction_val = best_model.predict(X_val)
        # accuracy_val = np.mean(y_val == prediction_val)
        # prediction_test = best_model.predict(X_test)
        # accuracy_test = np.mean(y_test == prediction_test)
        # accuracy_oob  = best_model.oob_score_
        # print("Best parameters:", best_params)
        # print(f"Train Accuracy: {accuracy_train:.4f}")
        # print(f"OOB Accuracy:   {accuracy_oob:.4f}")
        # print(f"Valid Accuracy: {accuracy_val:.4f}")
        # print(f"Test Accuracy:  {accuracy_test:.4f}")
        
        best_model = RandomForestClassifier(criterion='entropy',oob_score=True, bootstrap=True, random_state=42, n_jobs=-1, max_features=0.7, min_samples_split=10, n_estimators=350)
        best_model.fit(X_train,y_train)
        prediction_test = best_model.predict(X_test)
        output_csv_path = os.path.join(output_folder, f"prediction_{question_part}.csv")
        pd.DataFrame({'prediction': prediction_test}).to_csv(output_csv_path, index=False)
        
if __name__ == "__main__":
    main()



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import sys
from PIL import Image
import numpy as np
from sklearn.metrics import classification_report,precision_score, recall_score, f1_score
from sklearn.neural_network import MLPClassifier

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def softmax(z):
    z = z - np.max(z, axis=1, keepdims=True)
    exp_z = np.exp(z)
    return exp_z / np.sum(exp_z, axis=1, keepdims=True)

def relu(z):
    return np.maximum(0, z)

def relu_gradient(z):
    return (z &gt; 0).astype(float)

class NeuralNet:
    def __init__(self, M, n, hidden_layers, r, activation = 'sigmoid'):
        self.batch_size = M
        self.num_features = n
        self.hidden_layers = hidden_layers
        self.num_layers = len(hidden_layers) + 1  # +1 for output layer
        self.classes = r
        self.activation = activation
        # Initialize network parameters
        layer_dims = [n] + hidden_layers + [r]
        self.thetas = []
        for i in range(len(layer_dims)-1):
            dim_k = layer_dims[i] + 1  # +1 for bias
            dim_j = layer_dims[i+1]
            self.thetas.append(np.random.randn(dim_j, dim_k) * np.sqrt(2./dim_k))

        self.out_cur_x_next = []
        self.netj_lst = []

    def forward_pass(self, X):
        # Input with bias
        # X : (batch size , features = 28x28x3)
        if X.ndim == 4:
            X = X.reshape(X.shape[0], -1)
        
        a = np.hstack([X, np.ones((X.shape[0], 1))]) # (batch size, features + 1)
        self.out_cur_x_next = [a.T]  # Store as [(features+1, batch_size)]
        self.netj_lst = [] # [ (features , batch size) ] of netj

        # for hidden layers
        for i, theta in enumerate(self.thetas[:-1]):
            netj = theta @ self.out_cur_x_next[-1] # (features, batch size)  
            if self.activation == 'relu':
                o = relu(netj) # (features, batch size)
            else:
                o = sigmoid(netj) # (features, batch size)
            self.netj_lst.append(netj)
            biased_terms = np.ones((1, o.shape[1]))
            tmp = np.vstack([o, biased_terms])
            self.out_cur_x_next.append(tmp)  # Add bias

        # for output layer
        netj = self.thetas[-1] @ self.out_cur_x_next[-1]
        o = softmax(netj.T).T  # Transpose for correct softmax application
        self.netj_lst.append(netj)
        self.out_cur_x_next.append(o)
        
        return o.T  # (batch size, num_classes)

    def backpropagation(self, y_batch):
        # one hot encoding
        m = y_batch.shape[0]
        y_one_hot = np.zeros((m, self.classes))
        y_one_hot[np.arange(m), y_batch] = 1

        gradients = []
    
        # output layer del
        delta = (self.out_cur_x_next[-1].T - y_one_hot).T / m  # (classes, batch_size)
        gradients.insert(0, delta @ self.out_cur_x_next[-2].T)
        
        # Backpropagate
        for i in reversed(range(len(self.thetas)-1)):
            if self.activation == 'relu':
                netj = self.netj_lst[i]
                grad = relu_gradient(netj)
            else:
                a = self.out_cur_x_next[i+1]  
                grad = a * (1 - a)
                
            if self.activation == 'sigmoid':
                delta = (self.thetas[i+1].T @ delta) * grad
                delta = delta[:-1, :]  # removing bias error
                gradients.insert(0, delta @ self.out_cur_x_next[i].T)
            else:
                theta_without_bias = self.thetas[i + 1][:, 1:]  # Shape: (next_units, current_units)
                delta = (theta_without_bias.T @ delta) * grad  # Shape: (current_units, batch_size)
                gradients.insert(0, delta @ self.out_cur_x_next[i].T)
        
        return gradients

    def train(self, X_train, y_train,threshold=100,lr=0.01,bool=False):
        N = X_train.shape[0]
        J_prev = -10
        J_curr = -15
        epoch = 0
        
        permutation = np.random.permutation(N)
        X_s = X_train[permutation]
        y_s = y_train[permutation]
        
        batch_X = []
        batch_y = []
        i = 0
        while (i&lt;N):
            batch_X.append(X_s[i:i+self.batch_size])
            batch_y.append(y_s[i:i+self.batch_size])
            i = i + self.batch_size
            
        while(epoch&lt;=threshold):
            for i in range(0, N, self.batch_size):
                X_cur_batch = batch_X[(i//self.batch_size)]
                y_cur_batch = batch_y[(i//self.batch_size)]
                self.forward_pass(X_cur_batch)
                delJ_delp = self.backpropagation(y_cur_batch)

                for layer in range(len(self.thetas)):
                    lr_use = lr
                    if bool:
                        lr_use /= np.sqrt(epoch+1)
                    self.thetas[layer] -= lr_use * delJ_delp[layer]

            # Print training progress
            epoch+=1
            outputs = self.forward_pass(X_train)
            loss = -np.log(outputs[np.arange(N), y_train]).mean()
            J_prev = J_curr
            J_curr = loss
            predictions = np.argmax(outputs, axis=1)
            precision = precision_score(y_train, predictions, average='macro',zero_division=0)
            recall = recall_score(y_train, predictions, average='macro',zero_division=0)
            f1 = f1_score(y_train, predictions, average='macro',zero_division=0)
            print(f"Epoch {epoch:3d} | Loss: {loss:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1: {f1:.4f}")
            
        return f1

    def test(self, X_test, y_test):
        outputs = self.forward_pass(X_test)
        predictions = np.argmax(outputs, axis=1)
        accuracy = np.mean(predictions == y_test)
        precision = precision_score(y_test, predictions, average='macro', zero_division=0)
        recall = recall_score(y_test, predictions, average='macro', zero_division=0)
        f1 = f1_score(y_test, predictions, average='macro', zero_division=0)
        
        print(f"Test Accuracy: {accuracy*100:.2f}%")
        print("\nClassification Report:")
        print(classification_report(y_test, predictions, digits=4))
        print(f"Macro Precision: {precision:.4f}")
        print(f"Macro Recall: {recall:.4f}")
        print(f"Macro F1 Score: {f1:.4f}")
        return f1
                  
def load_image(path):
    img = Image.open(path).resize((28, 28)) 
    return np.array(img) / 255.0 


def main():
    train_dir = sys.argv[1]  
    test_dir = sys.argv[2]
    output_folder = sys.argv[3]
    question_part = sys.argv[4]    
    
    # comment before submission
    # test_labels_path = "data/q2/test_labels.csv"
    # test_labels_df = pd.read_csv(test_labels_path)
    # y_test = test_labels_df['label'].values  
    
    X_train, y_train = [], []
    for lstr in sorted(os.listdir(train_dir)):
<A NAME="0"></A><FONT color = #FF0000><A HREF="match190-0.html#0" TARGET="0"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        lpath = os.path.join(train_dir, lstr)
        if not os.path.isdir(lpath):
            continue
        label = int(lstr)
        for files in os.listdir(lpath):
            pathOfImages = os.path.join(lpath, files)
</FONT>            image = load_image(pathOfImages)
            X_train.append(image)
            y_train.append(label)
    X_train = np.array(X_train)
    y_train = np.array(y_train)
    
<A NAME="3"></A><FONT color = #00FFFF><A HREF="match190-0.html#3" TARGET="0"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    X_test = []
    files = sorted(os.listdir(test_dir), key=lambda x: int(x.split('.')[0]))
    for file in files:
</FONT>        path = os.path.join(test_dir, file)
        image = load_image(path)
        X_test.append(image)

    X_test = np.array(X_test)
    
    # print("Train set:", X_train.shape, y_train.shape)
    # print("Test set:", X_test.shape, y_test.shape)

    if question_part == 'b':
        # f1_scores = []
        # num_units = [1,5,10,50,100]
        # for i in range(len(num_units)):
        #     print("Running for num units : ",num_units[i])
        #     net = NeuralNet(32,2352,[num_units[i]], 43)
        #     net.train(X_train,y_train,0.0001,0.01)
        #     f1 = net.test(X_test,y_test)
        #     f1_scores.append(f1)
            
        # plt.figure(figsize=(8, 5))
        # plt.plot(num_units, f1_scores, marker='o')
        # plt.title("Average F1 Score vs Number of Hidden Layer Units")
        # plt.xlabel("Number of Hidden Layer Units")
        # plt.ylabel("Final Testing F1 Score")
        # plt.grid(True)
        # plt.show()
        
        net = NeuralNet(32,2352,[100],43)
        net.train(X_train,y_train)
        outputs = net.forward_pass(X_test)
        predictions = np.argmax(outputs, axis=1)
        output_csv_path = os.path.join(output_folder, f"prediction_{question_part}.csv")
        pd.DataFrame({'prediction': predictions}).to_csv(output_csv_path, index=False)
             
    if question_part == 'c':
        # f1_scores = []
        # hidden_layes = [[512],[512,256],[512,256,128],[512,256,128,64]]
        # for i in range(4):
        #     net = NeuralNet(32,2352,hidden_layes[i], 43)
        #     net.train(X_train,y_train,0.0001,0.01)
        #     f1 = net.test(X_test,y_test)
        #     f1_scores.append(f1)
        #     print("For training")
        #     net.test(X_train,y_train)
            
        # layer_depths = [len(layers) for layers in hidden_layes]
        # plt.figure(figsize=(8, 5))
        # plt.plot(layer_depths, f1_scores, marker='o')
        # plt.title("Average F1 Score vs Depth of Hidden Layers")
        # plt.xlabel("Number of Hidden Layers")
        # plt.ylabel("Final Training Macro F1 Score")
        # plt.grid(True)
        # plt.show()
        
        net = NeuralNet(32,2352,[512,256,128,64],43)
        net.train(X_train,y_train)
        outputs = net.forward_pass(X_test)
        predictions = np.argmax(outputs, axis=1)
        output_csv_path = os.path.join(output_folder, f"prediction_{question_part}.csv")
        pd.DataFrame({'prediction': predictions}).to_csv(output_csv_path, index=False)
            
    if question_part == 'd':
        # hidden_layes = [[512],[512,256],[512,256,128],[512,256,128,64]]
        # f1_scores = []
        # for i in range(4):
        #     net = NeuralNet(32,2352,hidden_layes[i], 43)
        #     net.train(X_train,y_train,0.0001,0.01,bool=True)
        #     f1 = net.test(X_test,y_test)
        #     f1_scores.append(f1)
        
        # layer_depths = [len(layers) for layers in hidden_layes]
        # plt.figure(figsize=(8, 5))
        # plt.plot(layer_depths, f1_scores, marker='o')
        # plt.title("Average F1 Score vs Depth of Hidden Layers")
        # plt.xlabel("Number of Hidden Layers")
        # plt.ylabel("Final Training Macro F1 Score")
        # plt.grid(True)
        # plt.show()
        
        net = NeuralNet(32,2352,[512,256,128,64],43)
        net.train(X_train,y_train,threshold=100,bool=True)
        outputs = net.forward_pass(X_test)
        predictions = np.argmax(outputs, axis=1)
        output_csv_path = os.path.join(output_folder, f"prediction_{question_part}.csv")
        pd.DataFrame({'prediction': predictions}).to_csv(output_csv_path, index=False)
            
    if question_part == 'e':
        # hidden_layes = [[512],[512,256],[512,256,128],[512,256,128,64]]
        # f1_scores = []
        # for i in range(4):
        #     net = NeuralNet(32,2352,hidden_layes[i], 43, activation='relu')
        #     net.train(X_train,y_train,100,0.01,bool=True)
        #     f1 = net.test(X_test,y_test)
        #     f1_scores.append(f1)
        #     net.test(X_train,y_train)
        
        # layer_depths = [len(layers) for layers in hidden_layes]
        # plt.figure(figsize=(8, 5))
        # plt.plot(layer_depths, f1_scores, marker='o')
        # plt.title("Average F1 Score vs Depth of Hidden Layers")
        # plt.xlabel("Number of Hidden Layers")
        # plt.ylabel("Final Training Macro F1 Score")
        # plt.grid(True)
        # plt.show()
        
        net = NeuralNet(32,2352,[512,256,128,64],43, activation = 'relu')
        net.train(X_train,y_train,threshold=100,bool=True)
        outputs = net.forward_pass(X_test)
        predictions = np.argmax(outputs, axis=1)
        output_csv_path = os.path.join(output_folder, f"prediction_{question_part}.csv")
        pd.DataFrame({'prediction': predictions}).to_csv(output_csv_path, index=False)

    if question_part == 'f':
        # hidden_layes = [[512],[512,256],[512,256,128],[512,256,128,64]]
        # f1_scores = []
        # for i in range(4):
        #     net = MLPClassifier(
        #         hidden_layer_sizes=hidden_layes[i],
        #         activation='relu',
        #         solver = 'sgd',
        #         alpha = 0,
        #         batch_size= 32,
        #         learning_rate= 'invscaling',
        #         max_iter= 100   
        #     )
        #     net.fit(X_train,y_train)
        #     predictions = net.predict(X_test)
            
        #     accuracy = np.mean(predictions == y_test)
        #     precision = precision_score(y_test, predictions, average='macro', zero_division=0)
        #     recall = recall_score(y_test, predictions, average='macro', zero_division=0)
        #     f1 = f1_score(y_test, predictions, average='macro', zero_division=0)
            
        #     print(f"Test Accuracy: {accuracy*100:.2f}%")
        #     print("\nClassification Report:")
        #     print(classification_report(y_test, predictions, digits=4))
        #     print(f"Macro Precision: {precision:.4f}")
        #     print(f"Macro Recall: {recall:.4f}")
        #     print(f"Macro F1 Score: {f1:.4f}")
        #     f1_scores.append(f1)
            
        # layer_depths = [len(layers) for layers in hidden_layes]
        # plt.figure(figsize=(8, 5))
        # plt.plot(layer_depths, f1_scores, marker='o')
        # plt.title("Average F1 Score vs Depth of Hidden Layers")
        # plt.xlabel("Number of Hidden Layers")
        # plt.ylabel("Final Training Macro F1 Score")
        # plt.grid(True)
        # plt.show()
        
        net = MLPClassifier(
                hidden_layer_sizes=[512,256,128,64],
                activation='relu',
                solver = 'sgd',
                alpha = 0,
                batch_size= 32,
                learning_rate= 'invscaling',
                max_iter= 100   
            )
        X_train = X_train.reshape(X_train.shape[0],-1)
        net.fit(X_train,y_train)
        X_test = X_test.reshape(X_test.shape[0],-1)
        predictions = net.predict(X_test)
        output_csv_path = os.path.join(output_folder, f"prediction_{question_part}.csv")
        pd.DataFrame({'prediction': predictions}).to_csv(output_csv_path, index=False)
        
if __name__ == "__main__":
    main()

</PRE>
</PRE>
</BODY>
</HTML>
