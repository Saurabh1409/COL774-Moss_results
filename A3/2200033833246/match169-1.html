<HTML>
<HEAD>
<TITLE>./A3_processed_new_hash/combined_EQGVX.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A3_processed_new_hash/combined_HWVIV.py<p><PRE>


import sys
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

# CODE FOR PART (A) ==================================================================================================================================================================

# This is used to get the training 
def get_training_dataframe(filepath, target_column):
    df = pd.read_csv(filepath)
    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)
    
    # (1) Rename the target column to 'y'
    df = df.rename(columns={target_column: 'y'})

    # (2) Get all attributes excluding the target column
    attributes = [col for col in df.columns if col != 'y']

    # (3) Determine if each attribute is numerical
    isNumAttribute = [pd.api.types.is_numeric_dtype(df[col]) for col in attributes]

    # (4) Create categorical mappings for non-numeric attributes
    categoricalMappings = {}
    for attr, is_num in zip(attributes, isNumAttribute):
        if not is_num:
            unique_vals = sorted(df[attr].unique())
            categoricalMappings[attr] = {val: idx for idx, val in enumerate(unique_vals)}

    # (5) Map 'y' to 0, 1, ..., k-1
    target_vals = sorted(df['y'].unique())
    targetMapping = {val: idx for idx, val in enumerate(target_vals)}
    df['y'] = df['y'].map(targetMapping)

    return df, attributes, isNumAttribute, categoricalMappings, targetMapping

def get_test_dataframe(filepath, target_column):
    df = pd.read_csv(filepath)
    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

    # Get the target column separately (if it exists)
    target = df[target_column] if target_column in df.columns else None

    # Drop the target column from the dataframe (if it exists)
    if target_column in df.columns:
        df = df.drop(columns=[target_column])

    return df, target

class Node:
    def __init__(self):
        self.numTrueSamples = 0
        self.numFalseSamples = 0
        self.isleaf = False

        self.splitAttribute = None
        self.splitValue = None # only useful in case of numerical attributes

        self.children = []
        self.depth = 0


class DecisionTree:
    def __init__(self, max_depth, attributes, isNumAttributes, categoricalMappings):
        self.root = Node() # Root node
        self.root.depth = 0

        # Catalogue 
        self.attributes = attributes
        self.isNumAttributes = isNumAttributes
        self.categoricalMappings = categoricalMappings

        self.max_depth = max_depth 

    def calculate_entropy(self, numTrue, numFalse):
        # This covers the case when either one of them is 0, both of them being 0 is not possible
        if(numTrue == 0 or numFalse == 0):
            return 0
        total = numTrue + numFalse
        probTrue = numTrue / total
        probFalse = numFalse / total
        entropy = - (probTrue * np.log2(probTrue) + probFalse * np.log2(probFalse))
        return entropy

    def calculate_information_gain(self, attribute, data):
        numTrue = np.sum(data['y'] == 1)
        numFalse = np.sum(data['y'] == 0)
        parentEntropy = self.calculate_entropy(numTrue, numFalse)

        total = len(data)

        attrIndex = self.attributes.index(attribute)
        attrValues = data[attribute].values

        childEntropy = 0
        if self.isNumAttributes[attrIndex]:
            # Numerical attribute
            median = np.median(attrValues)
            leftMask = attrValues &lt;= median
            rightMask = attrValues &gt; median

            yLeft = data['y'].values[leftMask]
            yRight = data['y'].values[rightMask]

            numTrueLeft = np.sum(yLeft == 1)
            numFalseLeft = np.sum(yLeft == 0)
            numTrueRight = np.sum(yRight == 1)
            numFalseRight = np.sum(yRight == 0)
            leftEntropy = self.calculate_entropy(numTrueLeft, numFalseLeft)
            rightEntropy = self.calculate_entropy(numTrueRight, numFalseRight)
            childEntropy = (len(yLeft) / total) * leftEntropy + (len(yRight) / total) * rightEntropy
        
        else:
            # Categorical attribute
            weighted_entropy = 0
            for category in self.categoricalMappings[attribute]:
                mask = attrValues == category
                ySubset = data['y'].values[mask]
                numTrue_cat = np.sum(ySubset == 1)
                numFalse_cat = len(ySubset) - numTrue_cat

                weight = len(ySubset) / total
                weighted_entropy += weight * self.calculate_entropy(numTrue_cat, numFalse_cat)
            
            childEntropy = weighted_entropy

        information_gain = parentEntropy - childEntropy
        return information_gain

    def best_attribute_to_split(self, data):
        bestGain = 0
        bestAttribute = None
        bestAttributeIndex = -1
        for i, attribute in enumerate(self.attributes):
            gain = self.calculate_information_gain(attribute, data)
            if gain &gt; bestGain:
                bestGain = gain
                bestAttribute = attribute
                bestAttributeIndex = i
        
        if bestAttributeIndex == -1:
            return None, None
        
        if self.isNumAttributes[bestAttributeIndex]:
            # Numerical attribute
            median = np.median(data[bestAttribute].values)
            return bestAttribute, median
        else:
            # Categorical attribute
            return bestAttribute, None

    def build_tree(self, node, data):
        node.numTrueSamples = np.sum(data['y'] == 1)
        node.numFalseSamples = np.sum(data['y'] == 0)

        # Base Cases
        # (1) If the max depth is reached
        if node.depth &gt;= self.max_depth:
            node.isleaf = True
            return

        # (2) If all samples are of the same class
        if node.numTrueSamples == 0 or node.numFalseSamples == 0:
            node.isleaf = True
            return

        # (3) If the best gain is 0 or less than that (i.e. best attribute to split is None)
        bestAttribute, medianValue = self.best_attribute_to_split(data)
        if bestAttribute is None:
            node.isleaf = True
            return

        node.splitAttribute = bestAttribute
        node.splitValue = medianValue
        node.isleaf = False

        attrIndex = self.attributes.index(bestAttribute)
        attrValues = data[bestAttribute].values

        if self.isNumAttributes[attrIndex]:
            # Numerical attribute =&gt; binary split
            leftMask = attrValues &lt;= medianValue
            rightMask = attrValues &gt; medianValue

            leftData = data[leftMask]
            rightData = data[rightMask]

            # This case would already be considered in Base Case (3), but let's keep it here
            if len(leftData) == 0 or len(rightData) == 0:
                node.isleaf = True
                return

            leftChild = Node()  
            rightChild = Node()

            leftChild.depth = node.depth + 1
            rightChild.depth = node.depth + 1

            node.children = [("&lt;= {:.3f}".format(medianValue), leftChild),("&gt; {:.3f}".format(medianValue), rightChild)]
            self.build_tree(leftChild, leftData)
            self.build_tree(rightChild, rightData)

        else:
            # Categorical attribute =&gt; multiple children
            node.children = []
            categories = list(self.categoricalMappings[bestAttribute].keys())
            for i in range(len(categories)):
                category = categories[i]
                mask = attrValues == category
                childData = data[mask]

                if len(childData) == 0:
                    continue

                childNode = Node()
                childNode.depth = node.depth + 1
                node.children.append((category,childNode))

                self.build_tree(childNode, childData)

    def predict_sample(self, row, node):
        if node.isleaf:
            return 1 if node.numTrueSamples &gt; node.numFalseSamples else 0

        attrValue = row[node.splitAttribute]
        if self.isNumAttributes[self.attributes.index(node.splitAttribute)]:
            if attrValue &lt;= node.splitValue:
                return self.predict_sample(row, node.children[0][1])
            else:
                return self.predict_sample(row, node.children[1][1])

        else:
            for category, childNode in node.children:
                if attrValue == category:
                    return self.predict_sample(row, childNode)

            return 1 if node.numTrueSamples &gt; node.numFalseSamples else 0

    def predict(self, df):
        # Make predictions for each example
        predictions = [self.predict_sample(row, self.root) for _, row in df.iterrows()]
        return np.array(predictions)

    # Useful for debugging - to see the structure of the built tree
    def print_tree(self, node, indent=""):
        """Recursively prints the tree with all important fields."""
        # Print the important details of the node
        print(f"{indent}Node (Depth: {node.depth}):")
        print(f"{indent}  Is leaf: {node.isleaf}")
        print(f"{indent}  Num True Samples: {node.numTrueSamples}")
        print(f"{indent}  Num False Samples: {node.numFalseSamples}")
        
        if node.isleaf:
            print(f"{indent}  Leaf Node - No split")
        else:
            print(f"{indent}  Split on Attribute: {node.splitAttribute}")
            if node.splitValue is not None:
                print(f"{indent}  Split Value: {node.splitValue}")
            else:
                print(f"{indent}  Split on Categories: {self.categoricalMappings[node.splitAttribute]}")
        
        # Recursively print children (if any)
        if not node.isleaf:
            for category, childNode in node.children:
                print(f"{indent}  -- Go to category: {category}")
                self.print_tree(childNode, indent + "    ")

# CODE FOR PART (B) AND PART (C) ===================================================================================================================================================================

def get_training_data_OHE(filepath, target_column):
    df = pd.read_csv(filepath)
    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

    # (1) Rename the target column to 'y'
    df = df.rename(columns={target_column: 'y'})

    # (2) Map 'y' to 0, 1, ..., k-1
    target_vals = sorted(df['y'].unique())
    targetMapping = {val: idx for idx, val in enumerate(target_vals)}
    df['y'] = df['y'].map(targetMapping)

    # (3) Separate features and apply One-Hot Encoding to categorical features
    feature_df = df.drop(columns=['y'])
    isNumAttribute_original = [pd.api.types.is_numeric_dtype(feature_df[col]) for col in feature_df.columns]

    num_cols = [col for col, is_num in zip(feature_df.columns, isNumAttribute_original) if is_num]
    cat_cols = [col for col, is_num in zip(feature_df.columns, isNumAttribute_original) if not is_num]

    # One-hot encode categorical columns
    df_encoded = pd.get_dummies(feature_df, columns=cat_cols, prefix=cat_cols).astype(int)

    # (4) Update the list of attributes and isNumAttribute
    attributes = list(df_encoded.columns)
    isNumAttribute = []
    for col in attributes:
        # If it was a numerical column before encoding, it's still numerical
        if col in num_cols:
            isNumAttribute.append(True)
        else:
            # All one-hot columns are from categorical columns
            isNumAttribute.append(False)

    # (5) Add the target column back
    df_encoded['y'] = df['y']

    return df_encoded, attributes, isNumAttribute, targetMapping

def get_test_data_OHE(filepath, target_column, attributes):
    df = pd.read_csv(filepath)
    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)

    # Extract and drop the target if it exists
    target = df[target_column] if target_column in df.columns else None
    if target_column in df.columns:
        df = df.drop(columns=[target_column])

    # Identify numeric and categorical columns in original test data
    isNumAttribute_original = [pd.api.types.is_numeric_dtype(df[col]) for col in df.columns]
    num_cols = [col for col, is_num in zip(df.columns, isNumAttribute_original) if is_num]
    cat_cols = [col for col, is_num in zip(df.columns, isNumAttribute_original) if not is_num]

    # One-hot encode test data
    df_encoded = pd.get_dummies(df, columns=cat_cols, prefix=cat_cols).astype(int)

    # Add missing columns (those present in training but missing in test)
    for col in attributes:
        if col not in df_encoded.columns:
            df_encoded[col] = 0

    # Reorder columns to match training attributes
    df_encoded = df_encoded[attributes]

    return df_encoded, target

class NodeOHE:
    def __init__(self):
        self.numTrueSamples = 0
        self.numFalseSamples = 0
        self.isleaf = False

        self.splitAttribute = None
        self.splitValue = None # only useful in case of numerical attributes

        self.leftChild = None
        self.rightChild = None
        self.depth = 0

        # New fields for pruning
        self.parent = None           # Pointer to parent node
        self.numValidSamples = 0     # Validation samples reaching this node
        self.numValidTrue = 0        # Validation samples with y=1
        self.numValidFalse = 0       # Validation samples with y=0
        self.numValidCorrect = 0     # Validation samples correctly classified

class DecisionTreeOHE:
    def __init__(self, max_depth, attributes, isNumAttributes):
        self.root = NodeOHE() # Root node
        self.root.depth = 0

        # Catalogue 
        self.attributes = attributes
        self.isNumAttributes = isNumAttributes

        self.max_depth = max_depth 

        # Prune Tracking
        self.num_nodes_list = []
        self.train_acc_list = []
        self.valid_acc_list = []
        self.test_acc_list = []

    def calculate_entropy(self, numTrue, numFalse):
        # This covers the case when either one of them is 0, both of them being 0 is not possible
        if(numTrue == 0 or numFalse == 0):
            return 0
        total = numTrue + numFalse
        probTrue = numTrue / total
        probFalse = numFalse / total
        entropy = - (probTrue * np.log2(probTrue) + probFalse * np.log2(probFalse))
        return entropy
    
    def calculate_information_gain(self, attribute, data):
        numTrue = np.sum(data['y'] == 1)
        numFalse = np.sum(data['y'] == 0)
        parentEntropy = self.calculate_entropy(numTrue, numFalse)

        total = len(data)

        attrIndex = self.attributes.index(attribute)
        attrValues = data[attribute].values

        if self.isNumAttributes[attrIndex]:
            # Numerical attribute
            median = np.median(attrValues)
            leftMask = attrValues &lt;= median

            yLeft = data['y'].values[leftMask]
            yRight = data['y'].values[~leftMask]

        else:
            leftMask = attrValues == 0
            yLeft = data['y'].values[leftMask]
            yRight = data['y'].values[~leftMask]

        numTrueLeft = np.sum(yLeft == 1)
        numFalseLeft = np.sum(yLeft == 0)
        numTrueRight = np.sum(yRight == 1)
        numFalseRight = np.sum(yRight == 0)
        leftEntropy = self.calculate_entropy(numTrueLeft, numFalseLeft)
        rightEntropy = self.calculate_entropy(numTrueRight, numFalseRight)
        childEntropy = (len(yLeft) / total) * leftEntropy + (len(yRight) / total) * rightEntropy
        informationGain = parentEntropy - childEntropy
        
        return informationGain

    def best_attribute_to_split(self, data):
        bestGain = 0
        bestAttribute = None
        bestAttributeIndex = -1
        for i, attribute in enumerate(self.attributes):
            gain = self.calculate_information_gain(attribute, data)
            if gain &gt; bestGain:
                bestGain = gain
                bestAttribute = attribute
                bestAttributeIndex = i
        
        if bestAttributeIndex == -1:
            return None, None
        
        if self.isNumAttributes[bestAttributeIndex]:
            # Numerical attribute
            median = np.median(data[bestAttribute].values)
            return bestAttribute, median
        else:
            # Categorical attribute
            return bestAttribute, None
        
    def build_tree(self, data, node):
        node.numTrueSamples = np.sum(data['y'] == 1)
        node.numFalseSamples = np.sum(data['y'] == 0)

        # Base Cases
        # (1) If the max depth is reached
        if node.depth &gt;= self.max_depth:
            node.isleaf = True
            return

        # (2) If all samples are of the same class
        if node.numTrueSamples == 0 or node.numFalseSamples == 0:
            node.isleaf = True
            return

        # (3) If the best gain is 0 or less than that (i.e. best attribute to split is None)
        bestAttribute, medianValue = self.best_attribute_to_split(data)
        if bestAttribute is None:
            node.isleaf = True
            return
        
        node.splitAttribute = bestAttribute
        node.splitValue = medianValue
        node.isleaf = False

        attrIndex = self.attributes.index(bestAttribute)
        attrValues = data[bestAttribute].values

        if self.isNumAttributes[attrIndex]:
            # Numerical attribute
            leftMask = attrValues &lt;= medianValue
            # Split data efficiently using boolean masks
            leftData = data[leftMask]
            rightData = data[~leftMask]
            node.splitValue = medianValue
        
        else:
            leftMask = attrValues == 0
            # Split data efficiently using boolean masks
            leftData = data[leftMask]
            rightData = data[~leftMask]

        if len(leftData) == 0 or len(rightData) == 0:
            node.isleaf = True
            return
        
        node.leftChild = NodeOHE()
        node.leftChild.depth = node.depth + 1
        node.leftChild.parent = node  # Set parent
        self.build_tree(leftData, node.leftChild)

        node.rightChild = NodeOHE()
        node.rightChild.depth = node.depth + 1
        node.rightChild.parent = node  # Set parent
        self.build_tree(rightData, node.rightChild)

    def predict_sample(self, row, node):
        if node.isleaf:
            return 1 if node.numTrueSamples &gt; node.numFalseSamples else 0

        attrIndex = self.attributes.index(node.splitAttribute)
        attrValue = row[node.splitAttribute]

        if self.isNumAttributes[attrIndex]:
            # Numerical attribute
            if attrValue &lt;= node.splitValue:
                return self.predict_sample(row, node.leftChild)
            else:
                return self.predict_sample(row, node.rightChild)
        else:
            # Categorical attribute
            if attrValue == 0:
                return self.predict_sample(row, node.leftChild)
            else:
                return self.predict_sample(row, node.rightChild)
            
    def predict(self, data):
        # Handle missing columns in test data
        missing_cols = set(self.attributes) - set(data.columns)
        for col in missing_cols:
            data[col] = 0  # Add missing column with 0s
        
        # Only use columns that were in training data
        relevant_cols = [col for col in data.columns if col in self.attributes or col == 'y']
        data_subset = data[relevant_cols]
        
        predictions = [self.predict_sample(row, self.root) for _, row in data_subset.iterrows()]
        return np.array(predictions)
    
    def update_validation_statistics(self, row, y, node):
        node.numValidSamples += 1
        if y == 1:
            node.numValidTrue += 1
        else:
            node.numValidFalse += 1
        if node.isleaf:
            prediction = 1 if node.numTrueSamples &gt; node.numFalseSamples else 0
            return prediction == y
        attrIndex = self.attributes.index(node.splitAttribute)
        attrValue = row[node.splitAttribute]
        if self.isNumAttributes[attrIndex]:
            if attrValue &lt;= node.splitValue:
                is_correct = self.update_validation_statistics(row, y, node.leftChild)
            else:
                is_correct = self.update_validation_statistics(row, y, node.rightChild)
        else:
            if attrValue == 0:
                is_correct = self.update_validation_statistics(row, y, node.leftChild)
            else:
                is_correct = self.update_validation_statistics(row, y, node.rightChild)
        if is_correct:
            node.numValidCorrect += 1
        return is_correct
    
    def _get_internal_nodes(self, node):
        if node is None or node.isleaf:
            return []
        return [node] + self._get_internal_nodes(node.leftChild) + self._get_internal_nodes(node.rightChild)
    
    def count_nodes(self, node=None):
        if node is None:
            node = self.root
        if node.isleaf:
            return 1
        return 1 + self.count_nodes(node.leftChild) + self.count_nodes(node.rightChild)
    
    def train_valid_acc(self, df):
        predictions = self.predict(df)
        true_labels = df['y'].values
        return np.mean(predictions == true_labels)
    
    def test_acc(self, test_df, test_target):
        predictions = self.predict(test_df)
        true_labels = test_target.values
        return np.mean(predictions == true_labels)
    
    def prune(self, valid_df, train_df, test_df, test_target):
        # Step 1: Compute initial validation statistics
        for _, row in valid_df.iterrows():
            self.update_validation_statistics(row, row['y'], self.root)
        
        # Step 2: Collect all internal nodes
        internal_nodes = self._get_internal_nodes(self.root)
        
        # Step 3: Iteratively prune nodes
        while internal_nodes:
            # Tracking step
            self.num_nodes_list.append(self.count_nodes())
            self.train_acc_list.append(self.train_valid_acc(train_df))
            self.valid_acc_list.append(self.train_valid_acc(valid_df))
            self.test_acc_list.append(self.test_acc(test_df, test_target))

            best_delta = -1
            best_node = None
            # Evaluate pruning each internal node
            for node in internal_nodes:
                # Majority class based on training data
                M_N = 1 if node.numTrueSamples &gt; node.numFalseSamples else 0
                # New correct predictions if pruned
                new_correct = node.numValidTrue if M_N == 1 else node.numValidFalse
                # Change in correct predictions
                delta = new_correct - node.numValidCorrect
                if delta &gt; best_delta:
                    best_delta = delta
                    best_node = node
            
            # If no improvement, stop pruning
            if best_delta &lt;= 0:
                break
            
            # Prune the best node
            nodes_to_remove = self._get_internal_nodes(best_node)
            best_node.isleaf = True
            best_node.leftChild = None
            best_node.rightChild = None

            # Remove the child nodes from the list of internal nodes
            for node in nodes_to_remove:
                if node in internal_nodes:
                    internal_nodes.remove(node)
            
            # Update ancestors' numValidCorrect
            current = best_node.parent
            while current is not None:
                current.numValidCorrect += best_delta
                current = current.parent

# CODE FOR PART (D) AND PART (E) ======================================================================================================================================================
# Function to load and preprocess data
def preprocess_data(file_path):
    # Load data
    df = pd.read_csv(file_path)
    
    # Strip whitespace from string columns
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col] = df[col].str.strip()
    
    # Separate features and target
    X = df.drop('income', axis=1)
    y = df['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
    
    # Identify numerical and categorical columns
    numerical_cols = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']
    categorical_cols = [col for col in X.columns if col not in numerical_cols]
    
    # Create a new dataframe with just numerical columns
    X_numerical = X[numerical_cols].reset_index(drop=True)
    
    # One-hot encode categorical columns using pandas get_dummies
    X_categorical = pd.get_dummies(X[categorical_cols], prefix_sep='_', dummy_na=False)
    
    # Combine numerical and categorical features
    X_processed = pd.concat([X_numerical, X_categorical], axis=1)
    
    # Store category values for consistent encoding of test/validation sets
    category_mappings = {}
    for col in categorical_cols:
        category_mappings[col] = list(X[col].unique())
    
    return X_processed, y, category_mappings, numerical_cols, categorical_cols

# Function to process test and validation data with consistent encoding
def process_test_valid_data(file_path, category_mappings, numerical_cols, categorical_cols):
    # Load data
    df = pd.read_csv(file_path)
    
    # Strip whitespace from string columns
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col] = df[col].str.strip()
    
    if 'income' in df.columns:
        y = df['income'].apply(lambda x: 1 if x == '&gt;50K' else 0)
        X = df.drop('income', axis=1)
    else:
        y = None
        X = df
    
    # Create a new dataframe with just numerical columns
    X_numerical = X[numerical_cols].reset_index(drop=True)
    
    # Initialize an empty DataFrame for categorical features
    X_categorical_encoded = pd.DataFrame()
    
    # Process each categorical column individually to ensure consistent encoding
    for col in categorical_cols:
        # Create a temporary series with categories from training set
        temp_series = pd.Series(X[col])
        
        # Create a DataFrame with one-hot encoding for this column
        dummies = pd.get_dummies(temp_series, prefix=col, prefix_sep='_')
        
        # Add dummy columns that are in training set but not in this dataset
        for category in category_mappings[col]:
            dummy_col = f"{col}_{category}"
            if dummy_col not in dummies.columns:
                dummies[dummy_col] = 0
        
        # Remove columns that weren't in the training set
        cols_to_keep = [f"{col}_{cat}" for cat in category_mappings[col] if f"{col}_{cat}" in dummies.columns]
        dummies = dummies[cols_to_keep]
        
        # Add to our encoded categorical dataframe
        X_categorical_encoded = pd.concat([X_categorical_encoded, dummies], axis=1)
    
    # Combine with numerical features
    X_processed = pd.concat([X_numerical, X_categorical_encoded], axis=1)
    
    # Ensure all columns from training are present in the same order
    return X_processed, y

# Custom scorer using OOB score (GridSearchCV doesnâ€™t natively support it)
def oob_scorer(estimator, X, y):
            return estimator.oob_score_

# Since we're diretly using libraries, most of the code for this part is in main()

# MAIN CODE ===========================================================================================================================================================================
def main():
    if len(sys.argv) != 6:
        sys.exit(1)

    train_path = sys.argv[1]
    valid_path = sys.argv[2]
    test_path = sys.argv[3]
    output_folder = sys.argv[4]
    question_part = sys.argv[5]

    target_column = 'income' 
    plots_output_folder = '../../output/Q1_plots'

    if(question_part == 'a'):
        train_df, train_attributes, train_isNumAttributes, train_categoricalMappings, train_TargetMapping = get_training_dataframe(train_path, target_column)
        test_df, test_target = get_test_dataframe(test_path, target_column)
        test_target = test_target.map(train_TargetMapping)

<A NAME="4"></A><FONT color = #FF00FF><A HREF="match169-0.html#4" TARGET="0"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        max_depths = [5, 10, 15, 20]
        train_accuracies = []
        test_accuracies = []

        for depth in max_depths:
            dt = DecisionTree(max_depth=depth, attributes=train_attributes, isNumAttributes=train_isNumAttributes, categoricalMappings=train_categoricalMappings)
</FONT>            dt.build_tree(dt.root, train_df)

            train_predictions = dt.predict(train_df)
            train_accuracy = np.mean(train_predictions == train_df['y'].values)

            test_predictions = dt.predict(test_df)
            test_accuracy = np.mean(test_predictions == test_target.values)

            train_accuracies.append(train_accuracy)
            test_accuracies.append(test_accuracy)

            print(f"Max Depth: {depth} | Train Accuracy: {train_accuracy:.4f} | Test Accuracy: {test_accuracy:.4f}")

            if depth == 20:
                inverse_target_mapping = {0 : '&lt;=50K', 1 : '&gt;50K'}
                mapped_predictions = [inverse_target_mapping[pred] for pred in test_predictions]

                prediction_df = pd.DataFrame({'predictions': mapped_predictions})
                os.makedirs(output_folder, exist_ok=True)
                prediction_df.to_csv(os.path.join(output_folder, f'prediction_{question_part}.csv'), index=False)

        # Plotting
        plt.figure(figsize=(10,6))
        plt.plot(max_depths, train_accuracies, marker='o', label='Train Accuracy')
        plt.plot(max_depths, test_accuracies, marker='s', label='Test Accuracy')
<A NAME="1"></A><FONT color = #00FF00><A HREF="match169-0.html#1" TARGET="0"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        plt.title('Train and Test Accuracy vs. Tree Depth')
        plt.xlabel('Maximum Depth')
        plt.ylabel('Accuracy')
        plt.legend()
        plt.grid(True)
        os.makedirs(plots_output_folder, exist_ok=True)
        plt.savefig(os.path.join(plots_output_folder, f'accuracy_vs_depth_{question_part}.png'))
</FONT>        plt.close()

    elif(question_part == 'b'):
        train_df, train_attributes, train_isNumAttributes, train_TargetMapping = get_training_data_OHE(train_path, target_column)
        test_df, test_target = get_test_data_OHE(test_path, target_column, train_attributes)
        test_target = test_target.map(train_TargetMapping)
        max_depths = [5, 10, 15, 20, 25, 35, 45, 55]
        train_accuracies = []
        test_accuracies = []

        for depth in max_depths:
            dt = DecisionTreeOHE(max_depth=depth, attributes=train_attributes, isNumAttributes=train_isNumAttributes)
            dt.build_tree(train_df, dt.root)

            train_predictions = dt.predict(train_df)
            train_accuracy = np.mean(train_predictions == train_df['y'].values)

            test_predictions = dt.predict(test_df)
            test_accuracy = np.mean(test_predictions == test_target.values)

            train_accuracies.append(train_accuracy)
            test_accuracies.append(test_accuracy)

            print(f"Max Depth: {depth} | Train Accuracy: {train_accuracy:.4f} | Test Accuracy: {test_accuracy:.4f}")

            if depth == 55:
                inverse_target_mapping = {0 : '&lt;=50K', 1 : '&gt;50K'}
                mapped_predictions = [inverse_target_mapping[pred] for pred in test_predictions]

                prediction_df = pd.DataFrame({'predictions': mapped_predictions})
                os.makedirs(output_folder, exist_ok=True)
                prediction_df.to_csv(os.path.join(output_folder, f'prediction_{question_part}.csv'), index=False)

        # Plotting
        plt.figure(figsize=(10,6))
        plt.plot(max_depths, train_accuracies, marker='o', label='Train Accuracy')
        plt.plot(max_depths, test_accuracies, marker='s', label='Test Accuracy')
        plt.title('Train and Test Accuracy vs. Tree Depth')
        plt.xlabel('Maximum Depth')
        plt.ylabel('Accuracy')
        plt.legend()
        plt.grid(True)
        os.makedirs(plots_output_folder, exist_ok=True)
        plt.savefig(os.path.join(plots_output_folder, f'accuracy_vs_depth_{question_part}.png'))
        plt.close()

    elif(question_part == 'c'):
        train_df, train_attributes, train_isNumAttributes, train_TargetMapping = get_training_data_OHE(train_path, target_column)
        valid_df, _, _, _ = get_training_data_OHE(valid_path, target_column)
        test_df, test_target = get_test_data_OHE(test_path, target_column, train_attributes)
        test_target = test_target.map(train_TargetMapping)

        max_depths = [25, 35, 45, 55]
        train_accuracies = []
        valid_accuracies = []
        test_accuracies = []

        for depth in max_depths:
            # Initialize and train the decision tree
            dt = DecisionTreeOHE(max_depth=depth, attributes=train_attributes, isNumAttributes=train_isNumAttributes)
            dt.build_tree(train_df, dt.root)

            # Prune the tree (corrected argument order)
            dt.prune(valid_df, train_df, test_df, test_target)

            # Compute accuracies after pruning
            train_predictions = dt.predict(train_df)
            train_accuracy = np.mean(train_predictions == train_df['y'].values)

            valid_predictions = dt.predict(valid_df)
            valid_accuracy = np.mean(valid_predictions == valid_df['y'].values)

            test_predictions = dt.predict(test_df)
            test_accuracy = np.mean(test_predictions == test_target.values)

            train_accuracies.append(train_accuracy)
            valid_accuracies.append(valid_accuracy)
            test_accuracies.append(test_accuracy)

            print(f"Max Depth: {depth} | Train Accuracy: {train_accuracy:.4f} | Valid Accuracy: {valid_accuracy:.4f} | Test Accuracy: {test_accuracy:.4f}")

            # Plot accuracies vs. number of nodes during pruning
            plt.figure(figsize=(10, 6))
            plt.plot(dt.num_nodes_list, dt.train_acc_list, marker='o', label='Train Accuracy')
            plt.plot(dt.num_nodes_list, dt.valid_acc_list, marker='^', label='Validation Accuracy')
            plt.plot(dt.num_nodes_list, dt.test_acc_list, marker='s', label='Test Accuracy')
            plt.title(f'Accuracy vs. Number of Nodes (Max Depth {depth})')
            plt.xlabel('Number of Nodes')
            plt.ylabel('Accuracy')
            plt.legend()
            plt.grid(True)
            os.makedirs(plots_output_folder, exist_ok=True)
            plt.savefig(os.path.join(plots_output_folder, f'accuracy_vs_num_nodes_{question_part}_{depth}.png'))
            plt.close()

            # Save predictions for max_depth=55
            if depth == 55:
                inverse_target_mapping = {0 : '&lt;=50K', 1 : '&gt;50K'}
                mapped_predictions = [inverse_target_mapping[pred] for pred in test_predictions]

                prediction_df = pd.DataFrame({'predictions': mapped_predictions})
                os.makedirs(output_folder, exist_ok=True)
                prediction_df.to_csv(os.path.join(output_folder, f'prediction_{question_part}.csv'), index=False)

        # Plot accuracies vs. max depth
        plt.figure(figsize=(10, 6))
        plt.plot(max_depths, train_accuracies, marker='o', label='Train Accuracy')
        plt.plot(max_depths, valid_accuracies, marker='^', label='Validation Accuracy')
        plt.plot(max_depths, test_accuracies, marker='s', label='Test Accuracy')
        plt.title('Accuracy vs. Tree Depth')
        plt.xlabel('Maximum Depth')
        plt.ylabel('Accuracy')
        plt.legend()
        plt.grid(True)
        os.makedirs(plots_output_folder, exist_ok=True)
        plt.savefig(os.path.join(plots_output_folder, f'accuracy_vs_depth_{question_part}.png'))
        plt.close()

    elif(question_part == 'd'):
        np.random.seed(42)
        # Load and preprocess training data
        X_train, y_train, category_mappings, numerical_cols, categorical_cols = preprocess_data('../../data/Q1/train.csv')

        # Load and preprocess validation and test data
        X_valid, y_valid = process_test_valid_data('../../data/Q1/valid.csv', category_mappings, numerical_cols, categorical_cols)
        X_test, y_test = process_test_valid_data('../../data/Q1/test.csv', category_mappings, numerical_cols, categorical_cols)

        # Verify all datasets have the same features
        print(f"Training set shape: {X_train.shape}")
        print(f"Validation set shape: {X_valid.shape}")
        print(f"Test set shape: {X_test.shape}")

        # Ensure validation and test dataframes have the same columns as training
        X_valid = X_valid.reindex(columns=X_train.columns, fill_value=0)
        X_test = X_test.reindex(columns=X_train.columns, fill_value=0)

        # Verify again after alignment
        print(f"After alignment - Training set shape: {X_train.shape}")
        print(f"After alignment - Validation set shape: {X_valid.shape}")
        print(f"After alignment - Test set shape: {X_test.shape}")

        # Part (i): Varying max_depth
        depth_values = [25, 35, 45, 55]
        train_acc_depth = []
        valid_acc_depth = []
        test_acc_depth = []

        plt.figure(figsize=(12, 6))

        for depth in depth_values:
            # Create and train the Decision Tree model
            dt_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42)
            dt_classifier.fit(X_train, y_train)
            
            # Make predictions
            y_train_pred = dt_classifier.predict(X_train)
            y_valid_pred = dt_classifier.predict(X_valid)
            y_test_pred = dt_classifier.predict(X_test)
            
            # Calculate accuracy
            train_accuracy = accuracy_score(y_train, y_train_pred)
            valid_accuracy = accuracy_score(y_valid, y_valid_pred)
            test_accuracy = accuracy_score(y_test, y_test_pred)
            
            # Store accuracies
            train_acc_depth.append(train_accuracy)
            valid_acc_depth.append(valid_accuracy)
            test_acc_depth.append(test_accuracy)
            
            print(f"max_depth={depth}, Train Accuracy: {train_accuracy:.4f}, Valid Accuracy: {valid_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")

        # Plot accuracies vs. max_depth
<A NAME="2"></A><FONT color = #0000FF><A HREF="match169-0.html#2" TARGET="0"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        plt.subplot(1, 2, 1)
        plt.plot(depth_values, train_acc_depth, 'o-', label='Train')
        plt.plot(depth_values, valid_acc_depth, 's-', label='Validation')
        plt.plot(depth_values, test_acc_depth, '^-', label='Test')
        plt.xlabel('Max Depth')
        plt.ylabel('Accuracy')
        plt.title('Accuracy vs. Max Depth')
</FONT>        plt.ylim(0.5, 1.1)  # Set y-axis limits from 0 to 1
        plt.grid(True)
        plt.legend()

        # Find best max_depth based on validation accuracy
        best_depth_idx = np.argmax(valid_acc_depth)
        best_depth = depth_values[best_depth_idx]
        print(f"\nBest max_depth value: {best_depth}")
        print(f"Best validation accuracy: {valid_acc_depth[best_depth_idx]:.4f}")
        print(f"Corresponding test accuracy: {test_acc_depth[best_depth_idx]:.4f}")

        # Part (ii): Varying ccp_alpha (pruning parameter)
        alpha_values = [0.001, 0.01, 0.1, 0.2]
        train_acc_alpha = []
        valid_acc_alpha = []
        test_acc_alpha = []

        for alpha in alpha_values:
            # Create and train the Decision Tree model
            dt_classifier = DecisionTreeClassifier(criterion='entropy', ccp_alpha=alpha, random_state=42, max_depth=55)
            dt_classifier.fit(X_train, y_train)
            
            # Make predictions
            y_train_pred = dt_classifier.predict(X_train)
            y_valid_pred = dt_classifier.predict(X_valid)
            y_test_pred = dt_classifier.predict(X_test)
            
            # Calculate accuracy
            train_accuracy = accuracy_score(y_train, y_train_pred)
            valid_accuracy = accuracy_score(y_valid, y_valid_pred)
            test_accuracy = accuracy_score(y_test, y_test_pred)
            
            # Store accuracies
            train_acc_alpha.append(train_accuracy)
            valid_acc_alpha.append(valid_accuracy)
            test_acc_alpha.append(test_accuracy)
            
            print(f"ccp_alpha={alpha}, Train Accuracy: {train_accuracy:.4f}, Valid Accuracy: {valid_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")

        # Plot accuracies vs. ccp_alpha
<A NAME="3"></A><FONT color = #00FFFF><A HREF="match169-0.html#3" TARGET="0"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        plt.subplot(1, 2, 2)
        plt.plot(alpha_values, train_acc_alpha, 'o-', label='Train')
        plt.plot(alpha_values, valid_acc_alpha, 's-', label='Validation')
        plt.plot(alpha_values, test_acc_alpha, '^-', label='Test')
        plt.xlabel('ccp_alpha')
        plt.ylabel('Accuracy')
        plt.title('Accuracy vs. ccp_alpha')
</FONT>        plt.ylim(0.5, 1.1)  # Set y-axis limits from 0 to 1
        plt.grid(True)
        plt.legend()

        plt.tight_layout()
        os.makedirs(plots_output_folder, exist_ok=True)
        plt.savefig(os.path.join(plots_output_folder, f'decision_tree_param_tuning_{question_part}.png'))
        # plt.show()

        # Find best ccp_alpha based on validation accuracy
        best_alpha_idx = np.argmax(valid_acc_alpha)
        best_alpha = alpha_values[best_alpha_idx]
        print(f"\nBest ccp_alpha value: {best_alpha}")
        print(f"Best validation accuracy: {valid_acc_alpha[best_alpha_idx]:.4f}")
        print(f"Corresponding test accuracy: {test_acc_alpha[best_alpha_idx]:.4f}")

        # Compare the best models from (i) and (ii)
        print("\nComparison of best models:")
        print(f"Best max_depth model: Validation Accuracy = {valid_acc_depth[best_depth_idx]:.4f}, Test Accuracy = {test_acc_depth[best_depth_idx]:.4f}")
        print(f"Best ccp_alpha model: Validation Accuracy = {valid_acc_alpha[best_alpha_idx]:.4f}, Test Accuracy = {test_acc_alpha[best_alpha_idx]:.4f}")

        # Train final model with best parameters
        if valid_acc_depth[best_depth_idx] &gt;= valid_acc_alpha[best_alpha_idx]:
            print(f"\nFinal model uses max_depth={best_depth}")
            final_model = DecisionTreeClassifier(criterion='entropy', max_depth=best_depth, random_state=42)
        else:
            print(f"\nFinal model uses ccp_alpha={best_alpha}")
            final_model = DecisionTreeClassifier(criterion='entropy', ccp_alpha=best_alpha, random_state=42)

        final_model.fit(X_train, y_train)
        final_train_acc = accuracy_score(y_train, final_model.predict(X_train))
        final_valid_acc = accuracy_score(y_valid, final_model.predict(X_valid))
        final_test_acc = accuracy_score(y_test, final_model.predict(X_test))

        inverse_target_mapping = {0 : '&lt;=50K', 1 : '&gt;50K'}
        mapped_predictions = [inverse_target_mapping[pred] for pred in final_model.predict(X_test)]
        prediction_df = pd.DataFrame({'predictions': mapped_predictions})

        print(f"Final model results:")
        print(f"Training accuracy: {final_train_acc:.4f}")
        print(f"Validation accuracy: {final_valid_acc:.4f}")
        print(f"Test accuracy: {final_test_acc:.4f}")
        os.makedirs(output_folder, exist_ok=True)
        prediction_df.to_csv(os.path.join(output_folder, f'prediction_{question_part}.csv'), index=False)

    elif(question_part == 'e'):
        np.random.seed(42)
        # Load and preprocess training data
        X_train, y_train, category_mappings, numerical_cols, categorical_cols = preprocess_data('../../data/Q1/train.csv')

        # Load and preprocess validation and test data
        X_valid, y_valid = process_test_valid_data('../../data/Q1/valid.csv', category_mappings, numerical_cols, categorical_cols)
        X_test, y_test = process_test_valid_data('../../data/Q1/test.csv', category_mappings, numerical_cols, categorical_cols)

        # Verify all datasets have the same features
        print(f"Training set shape: {X_train.shape}")
        print(f"Validation set shape: {X_valid.shape}")
        print(f"Test set shape: {X_test.shape}")

        # Ensure validation and test dataframes have the same columns as training
        X_valid = X_valid.reindex(columns=X_train.columns, fill_value=0)
        X_test = X_test.reindex(columns=X_train.columns, fill_value=0)

        # Verify again after alignment
        print(f"After alignment - Training set shape: {X_train.shape}")
        print(f"After alignment - Validation set shape: {X_valid.shape}")
        print(f"After alignment - Test set shape: {X_test.shape}")
        param_grid = {
            'n_estimators': [50, 150, 250, 350],
            'max_features': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0],
            'min_samples_split': [2, 4, 6, 8, 10],
        }

        # Create base estimator
        rf_base = RandomForestClassifier(
            criterion='entropy',
            oob_score=True,
            random_state=42,
            n_jobs=-1,
            bootstrap=True
        )

        # Use GridSearchCV with custom scorer
        grid_search = GridSearchCV(
            estimator=rf_base,
            param_grid=param_grid,
            cv=2, # Use all data for OOB - Cross-Validation is useless here since OOB does a similar job : using 5 for now - default(need to figure this out later)
            scoring=oob_scorer,
            verbose=3,
            n_jobs=-1  # Parallelizes across parameter combinations
        )

        # Fit grid search
        grid_search.fit(X_train, y_train)

        # Best model and parameters
        best_rf = grid_search.best_estimator_
        best_params = grid_search.best_params_
        best_oob_accuracy = grid_search.best_score_

        # Accuracy evaluations
        train_accuracy = accuracy_score(y_train, best_rf.predict(X_train))
        valid_accuracy = accuracy_score(y_valid, best_rf.predict(X_valid))
        test_accuracy = accuracy_score(y_test, best_rf.predict(X_test))

        inverse_target_mapping = {0 : '&lt;=50K', 1 : '&gt;50K'}
        mapped_predictions = [inverse_target_mapping[pred] for pred in best_rf.predict(X_test)]
        prediction_df = pd.DataFrame({'predictions': mapped_predictions})

        # Print results
        print(f"\nBest Parameters: {best_params}")
        print(f"Training Accuracy: {train_accuracy:.4f}")
        print(f"OOB Accuracy: {best_oob_accuracy:.4f}")
        print(f"Validation Accuracy: {valid_accuracy:.4f}")
        print(f"Test Accuracy: {test_accuracy:.4f}")
        os.makedirs(output_folder, exist_ok=True)
        prediction_df.to_csv(os.path.join(output_folder, f'prediction_{question_part}.csv'), index=False)

if __name__ == "__main__":
    main()



import os
import sys
import numpy as np
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_fscore_support

def getTrainingData(train_path):
    """
    Load and preprocess training images and labels from the train_path directory.
    """
    image_list = []
    label_list = []

    for folder_name in sorted(os.listdir(train_path)):
        folder_path = os.path.join(train_path, folder_name)
        if not os.path.isdir(folder_path):
            continue
        label = int(folder_name.lstrip('0') or '0')
        for filename in os.listdir(folder_path):
            if filename.endswith((".ppm", ".png", ".jpg", ".jpeg")):
                file_path = os.path.join(folder_path, filename)
                try:
                    img = Image.open(file_path).resize((28, 28))
<A NAME="5"></A><FONT color = #FF0000><A HREF="match169-0.html#5" TARGET="0"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

                    img_array = np.asarray(img).astype(np.float32) / 255.0
                    img_flat = img_array.flatten()
                    image_list.append(img_flat)
                    one_hot = np.zeros(43)
</FONT>                    one_hot[label] = 1
                    label_list.append(one_hot)
                except Exception as e:
                    print(f"Error loading image {file_path}: {e}")

    X = np.array(image_list)
    y = np.array(label_list)
    return X, y

def getTestData(test_path):
    """
    Load and preprocess test images from the test_path directory.
    """
    image_list = []
    
    for filename in sorted(os.listdir(test_path)):
        if filename.endswith((".ppm", ".png", ".jpg", ".jpeg")):
            file_path = os.path.join(test_path, filename)
            try:
                img = Image.open(file_path).resize((28, 28))
<A NAME="0"></A><FONT color = #FF0000><A HREF="match169-0.html#0" TARGET="0"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

                img_array = np.asarray(img).astype(np.float32) / 255.0
                img_flat = img_array.flatten()
                image_list.append(img_flat)
            except Exception as e:
                print(f"Error loading test image {file_path}: {e}")
    
    X_test = np.array(image_list)
</FONT>    return X_test

def getTestOutput(annotation_file):
    """
    Load true labels from the test_labels.csv file.
    """
    label_list = []
    
    annotations = pd.read_csv(annotation_file)
    
    for _, row in annotations.iterrows():
        label = row['label']
        one_hot = np.zeros(43)
        one_hot[label] = 1
        label_list.append(one_hot)
    
    y_test = np.array(label_list)
    return y_test

class NeuralNetwork:
    def __init__(self, batchSize, numFeatures, hiddenLayerArchitecture, numTargetClasses, learningRate):
        self.batchSize = batchSize
        self.numFeatures = numFeatures
        self.hiddenLayerArchitecture = hiddenLayerArchitecture
        self.numTargetClasses = numTargetClasses
        self.learningRate = learningRate

        layerSizes = [numFeatures] + hiddenLayerArchitecture + [numTargetClasses]   
        self.weights = []
        self.biases = []

        for i in range(len(layerSizes) - 1):
            weight = np.random.randn(layerSizes[i], layerSizes[i + 1]) * np.sqrt(2.0 / layerSizes[i])
            bias = np.zeros((1, layerSizes[i + 1]))
            self.weights.append(weight)
            self.biases.append(bias)

        self.activations = []
        self.z_values = []

    def sigmoidActivation(self, x):
        x = np.clip(x, -500, 500)
        return 1 / (1 + np.exp(-x))
    
    def sigmoidDerivative(self, x):
        sigVal = self.sigmoidActivation(x)
        return sigVal * (1 - sigVal)
    
    def softmaxActivation(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forwardPropagation(self, X):
        self.activations = [X]
        self.z_values = []
        
        for i in range(len(self.weights) - 1):
            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
            self.z_values.append(z)
            activation = self.sigmoidActivation(z)
            self.activations.append(activation)
        
        z = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
        self.z_values.append(z)
        output = self.softmaxActivation(z)
        self.activations.append(output)
        return output    
    
    def computeCrossEntropyLoss(self, yTrue, yHat):
        yHat = np.clip(yHat, 1e-15, 1 - 1e-15)
        loss = -np.sum(yTrue * np.log(yHat)) / yTrue.shape[0]
        return loss
    
    def backwardPropagation(self, X, yTrue, yHat):
        batchSize = X.shape[0]
        weightGradients = [np.zeros_like(w) for w in self.weights]
        biasGradients = [np.zeros_like(b) for b in self.biases]

        delta = yHat - yTrue
        for i in range(len(self.weights) - 1, -1, -1):
            weightGradients[i] = np.dot(self.activations[i].T, delta) / batchSize
            biasGradients[i] = np.sum(delta, axis=0, keepdims=True) / batchSize
            if i &gt; 0:
                delta = np.dot(delta, self.weights[i].T) * self.sigmoidDerivative(self.z_values[i - 1])
        return weightGradients, biasGradients
    
    def updateParameters(self, weightGradients, biasGradients, currentLearningRate=None):
        if(currentLearningRate is None):
            for i in range(len(self.weights)):
                self.weights[i] -= self.learningRate * weightGradients[i]
                self.biases[i] -= self.learningRate * biasGradients[i]
        else:
            for i in range(len(self.weights)):
                self.weights[i] -= currentLearningRate * weightGradients[i]
                self.biases[i] -= currentLearningRate * biasGradients[i]

    def save_best_weights(self):
        self.best_weights = [w.copy() for w in self.weights]
        self.best_biases = [b.copy() for b in self.biases]

    def load_best_weights(self):
        self.weights = [w.copy() for w in self.best_weights]
        self.biases = [b.copy() for b in self.best_biases]

    def train(self, X_train, y_train, X_val, y_val, max_epochs=200, patience=5):
        M = X_train.shape[0]
        best_val_loss = float('inf')
        epochs_no_improve = 0
        self.save_best_weights()

        for epoch in range(max_epochs):
            # shuffling on every epoch for now - dunno if it is really required or not !
            # implemented early stopping, but ig the num_epochs are so low, that it doesn't really help
            indices = np.random.permutation(M)
            X_train_shuffled = X_train[indices]
            y_train_shuffled = y_train[indices]

            for i in range(0, M, self.batchSize):
                X_batch = X_train_shuffled[i:i + self.batchSize]
                y_batch = y_train_shuffled[i:i + self.batchSize]
                yHat = self.forwardPropagation(X_batch)
                loss = self.computeCrossEntropyLoss(y_batch, yHat)
                weightGradients, biasGradients = self.backwardPropagation(X_batch, y_batch, yHat)
                self.updateParameters(weightGradients, biasGradients)

            y_val_pred = self.forwardPropagation(X_val)
            val_loss = self.computeCrossEntropyLoss(y_val, y_val_pred)
            
            print(f"Epoch {epoch+1}/{max_epochs}, Train Loss: {loss:.4f}, Val Loss: {val_loss:.4f}")

            if val_loss &lt; best_val_loss:
                best_val_loss = val_loss
                self.save_best_weights()
                epochs_no_improve = 0
            else:
                epochs_no_improve += 1

            if epochs_no_improve &gt;= patience:
                print(f"Early stopping at epoch {epoch+1}")
                self.load_best_weights()
                break

    def train_with_adaptive_lr(self, X_train, y_train, X_val, y_val, max_epochs=200, patience=5):
        M = X_train.shape[0]
        best_val_loss = float('inf')
        epochs_no_improve = 0
        self.save_best_weights()
        initial_lr = self.learningRate  # Î·0

        for epoch in range(max_epochs):
            # Calculate adaptive learning rate
            # Adding 1 to epoch to avoid division by zero in first epoch
            current_lr = initial_lr / np.sqrt(epoch + 1)
            
            indices = np.random.permutation(M)
            X_train_shuffled = X_train[indices]
            y_train_shuffled = y_train[indices]

            for i in range(0, M, self.batchSize):
                X_batch = X_train_shuffled[i:i + self.batchSize]
                y_batch = y_train_shuffled[i:i + self.batchSize]
                yHat = self.forwardPropagation(X_batch)
                loss = self.computeCrossEntropyLoss(y_batch, yHat)
                weightGradients, biasGradients = self.backwardPropagation(X_batch, y_batch, yHat)
                self.updateParameters(weightGradients, biasGradients, current_lr)

            y_val_pred = self.forwardPropagation(X_val)
            val_loss = self.computeCrossEntropyLoss(y_val, y_val_pred)
            
            print(f"Epoch {epoch+1}/{max_epochs}, LR: {current_lr:.6f}, Train Loss: {loss:.4f}, Val Loss: {val_loss:.4f}")

            if val_loss &lt; best_val_loss:
                best_val_loss = val_loss
                self.save_best_weights()
                epochs_no_improve = 0
            else:
                epochs_no_improve += 1

            if epochs_no_improve &gt;= patience:
                print(f"Early stopping at epoch {epoch+1}")
                self.load_best_weights()
                break

    def predict(self, X):
        return self.forwardPropagation(X)

def evaluate_model(nn, X, y, dataset_name):
    y_pred = nn.predict(X)
    y_true_classes = np.argmax(y, axis=1)
    y_pred_classes = np.argmax(y_pred, axis=1)
    
    accuracy = np.mean(y_true_classes == y_pred_classes) * 100
    
    precision, recall, f1, _ = precision_recall_fscore_support(
        y_true_classes, y_pred_classes, average=None, labels=np.arange(43), zero_division=0
    )
    
    # Calculate average metrics
    avg_precision = np.mean(precision)
    avg_recall = np.mean(recall)
    avg_f1 = np.mean(f1)
    
    print(f"\n{dataset_name} Metrics:")
    print(f"Accuracy: {accuracy:.2f}%")
    print(f"Average Precision: {avg_precision:.4f}")
    print(f"Average Recall: {avg_recall:.4f}")
    print(f"Average F1 Score: {avg_f1:.4f}")
    print("\nPer-Class Metrics:")
    print("Class | Precision | Recall | F1 Score")
    for i in range(43):
        print(f"{i:2d}    | {precision[i]:.4f}    | {recall[i]:.4f} | {f1[i]:.4f}")
    
    return precision, recall, f1, avg_f1, accuracy, y_pred_classes

def main():
    # Paths (adjust as needed)
    if len(sys.argv) != 5:
        print("Usage: python neural_network.py &lt;train_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
        sys.exit(1)
    
    train_path = sys.argv[1]
    test_path = sys.argv[2]
    output_folder = sys.argv[3]
    question_part = sys.argv[4]
    
    # Ensure output folder exists
    os.makedirs(output_folder, exist_ok=True)
    
    # Set random seed for reproducibility
    np.random.seed(42)

    annotation_file = "../../data/Q2/test_labels.csv"
    plots_output_folder = '../../output/Q2_plots'

    # Load training data
    print("Loading training data...")
    X, y = getTrainingData(train_path)
    print(f"Training data shape: {X.shape}, Labels shape: {y.shape}")

    # Manual shuffle and 80-20 split
    print("Shuffling and splitting training data...")
    N = X.shape[0]
    indices = np.random.permutation(N)
    X_shuffled = X[indices]
    y_shuffled = y[indices]
    split_idx = int(0.8 * N)
    X_train = X_shuffled[:split_idx]
    y_train = y_shuffled[:split_idx]
    X_val = X_shuffled[split_idx:]
    y_val = y_shuffled[split_idx:]
    print(f"Train split: {X_train.shape}, Val split: {X_val.shape}")

    # Load test data
    print("Loading test data...")
    X_test = getTestData(test_path)
    y_test = getTestOutput(annotation_file)
    print(f"Test data shape: {X_test.shape}, Labels shape: {y_test.shape}")

    if(question_part == 'b'):
        # Parameters
        batch_size = 32
        num_features = 2352
        num_classes = 43
        learning_rate = 0.01
        hidden_units = [1, 5, 10, 50, 100]
        avg_f1_scores_train = []
        avg_f1_scores_test = []
        accuracy_train_list = []
        accuracy_test_list = []

        # Store predictions for 100 hidden units
        predictions_100 = None

        for units in hidden_units:
            print(f"\nExperiment with {units} hidden units")
            nn = NeuralNetwork(
                batchSize=batch_size,
                numFeatures=num_features,
                hiddenLayerArchitecture=[units],
                numTargetClasses=num_classes,
                learningRate=learning_rate
            )
            
            nn.train(X_train, y_train, X_val, y_val, max_epochs=100, patience=10)
            
            _, _, _, avg_f1_train, accuracy_train, _ = evaluate_model(nn, X_train, y_train, "Training")
            _, _, _, avg_f1_test, accuracy_test, y_pred_classes = evaluate_model(nn, X_test, y_test, "Test")
            
            avg_f1_scores_train.append(avg_f1_train)
            avg_f1_scores_test.append(avg_f1_test)
            accuracy_train_list.append(accuracy_train)
            accuracy_test_list.append(accuracy_test)

            # Save predictions for 100 hidden units
            if units == 100:
                predictions_100 = y_pred_classes

        # Save predictions to CSV
        if predictions_100 is not None:
            predictions_df = pd.DataFrame(predictions_100, columns=["predictions"])
            predictions_df.to_csv(f"predictions_{question_part}.csv", index=False)
            print("\nSaved predictions for 100 hidden units to 'predictions_b.csv'")

        # Plot F1 scores
        plt.figure(figsize=(8, 6))
        plt.plot(hidden_units, avg_f1_scores_train, marker='o', label='Training F1')
        plt.plot(hidden_units, avg_f1_scores_test, marker='s', label='Test F1')
        plt.xlabel('Number of Hidden Units')
        plt.ylabel('Average F1 Score')
        plt.title('Average F1 Score vs Hidden Units')
        plt.legend()
        plt.grid(True)
        os.makedirs(plots_output_folder, exist_ok=True)
        plt.savefig(os.path.join(plots_output_folder, f'f1_vs_hidden_units_{question_part}.png'))
        plt.close()
        # plt.show()

        # Summary
        print("\nSummary of Results:")
        print("Hidden Units | Train F1 | Test F1 | Train Accuracy | Test Accuracy")
        for units, f1_train, f1_test, acc_train, acc_test in zip(hidden_units, avg_f1_scores_train, avg_f1_scores_test, accuracy_train_list, accuracy_test_list):
            print(f"{units:11d} | {f1_train:.4f} | {f1_test:.4f} | {acc_train:.2f}% | {acc_test:.2f}%")

    elif (question_part == 'c'):
        # Parameters
        batch_size = 32
        num_features = 2352
        num_classes = 43
        learning_rate = 0.01
        hidden_layer_configs = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]
        depths = [len(config) for config in hidden_layer_configs]  # [1, 2, 3, 4]
        avg_f1_scores_train = []
        avg_f1_scores_test = []
        accuracy_train_list = []
        accuracy_test_list = []

        # Store predictions for [512, 256, 128, 64]
        predictions_deepest = None

        for config in hidden_layer_configs:
            depth = len(config)
            print(f"\nExperiment with hidden layers: {config} (depth={depth})")
            nn = NeuralNetwork(
                batchSize=batch_size,
                numFeatures=num_features,
                hiddenLayerArchitecture=config,
                numTargetClasses=num_classes,
                learningRate=learning_rate
            )
            
            nn.train(X_train, y_train, X_val, y_val, max_epochs=150, patience=10)
            
            _, _, _, avg_f1_train, accuracy_train, _ = evaluate_model(nn, X_train, y_train, "Training")
            _, _, _, avg_f1_test, accuracy_test, y_pred_classes = evaluate_model(nn, X_test, y_test, "Test")
            
            avg_f1_scores_train.append(avg_f1_train)
            avg_f1_scores_test.append(avg_f1_test)
            accuracy_train_list.append(accuracy_train)
            accuracy_test_list.append(accuracy_test)

            # Save predictions for [512, 256, 128, 64]
            if config == [512, 256, 128, 64]:
                predictions_deepest = y_pred_classes

        # Save predictions to CSV
        if predictions_deepest is not None:
            predictions_df = pd.DataFrame(predictions_deepest, columns=["predictions"])
            predictions_df.to_csv(f"predictions_{question_part}.csv", index=False)
            print("\nSaved predictions for hidden layers [512, 256, 128, 64] to 'predictions_c.csv'")

        # Plot F1 scores vs network depth
        plt.figure(figsize=(8, 6))
        plt.plot(depths, avg_f1_scores_train, marker='o', label='Training F1')
        plt.plot(depths, avg_f1_scores_test, marker='s', label='Test F1')
        plt.xlabel('Network Depth (Number of Hidden Layers)')
        plt.ylabel('Average F1 Score')
        plt.title('Average F1 Score vs Network Depth')
        plt.xticks(depths)
        plt.legend()
        plt.grid(True)
        os.makedirs(plots_output_folder, exist_ok=True)
        plt.savefig(os.path.join(plots_output_folder, f'f1_vs_network_depth_{question_part}.png'))
        plt.close()
        # plt.show()

        # Summary
        print("\nSummary of Results:")
        print("Hidden Layers | Depth | Train F1 | Test F1 | Train Accuracy | Test Accuracy")
        for config, depth, f1_train, f1_test, acc_train, acc_test in zip(hidden_layer_configs, depths, avg_f1_scores_train, avg_f1_scores_test, accuracy_train_list, accuracy_test_list):
            print(f"{str(config):&lt;13} | {depth:&lt;5} | {f1_train:.4f} | {f1_test:.4f} | {acc_train:.2f}% | {acc_test:.2f}%")

    elif (question_part == 'd'):
        # Parameters
        batch_size = 32
        num_features = 2352
        num_classes = 43
        learning_rate = 0.01  # Initial learning rate (Î·0)
        hidden_layer_configs = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]
        depths = [len(config) for config in hidden_layer_configs]  # [1, 2, 3, 4]
        avg_f1_scores_train = []
        avg_f1_scores_test = []
        accuracy_train_list = []
        accuracy_test_list = []
        training_epochs = []

        # Store predictions for [512, 256, 128, 64]
        predictions_deepest = None

        for config in hidden_layer_configs:
            depth = len(config)
            print(f"\nExperiment with hidden layers: {config} (depth={depth}) using adaptive learning rate")
            nn = NeuralNetwork(
                batchSize=batch_size,
                numFeatures=num_features,
                hiddenLayerArchitecture=config,
                numTargetClasses=num_classes,
                learningRate=learning_rate
            )
            
            # Train with adaptive learning rate
            nn.train_with_adaptive_lr(X_train, y_train, X_val, y_val, max_epochs=200, patience=5)
            
            # Track number of training epochs
            if hasattr(nn, 'epochs_trained'):
                training_epochs.append(nn.epochs_trained)
            
            _, _, _, avg_f1_train, accuracy_train, _ = evaluate_model(nn, X_train, y_train, "Training")
            _, _, _, avg_f1_test, accuracy_test, y_pred_classes = evaluate_model(nn, X_test, y_test, "Test")
            
            avg_f1_scores_train.append(avg_f1_train)
            avg_f1_scores_test.append(avg_f1_test)
            accuracy_train_list.append(accuracy_train)
            accuracy_test_list.append(accuracy_test)

            # Save predictions for [512, 256, 128, 64]
            if config == [512, 256, 128, 64]:
                predictions_deepest = y_pred_classes

        # Save predictions to CSV
        if predictions_deepest is not None:
            predictions_df = pd.DataFrame(predictions_deepest, columns=["predictions"])
            predictions_df.to_csv(f"predictions_{question_part}.csv", index=False)
            print("\nSaved predictions for hidden layers [512, 256, 128, 64] to 'predictions_d.csv'")

        # Plot F1 scores vs network depth
        plt.figure(figsize=(8, 6))
        plt.plot(depths, avg_f1_scores_train, marker='o', label='Training F1')
        plt.plot(depths, avg_f1_scores_test, marker='s', label='Test F1')
        plt.xlabel('Network Depth (Number of Hidden Layers)')
        plt.ylabel('Average F1 Score')
        plt.title('Average F1 Score vs Network Depth (Adaptive Learning Rate)')
        plt.xticks(depths)
        plt.legend()
        plt.grid(True)
        os.makedirs(plots_output_folder, exist_ok=True)
        plt.savefig(os.path.join(plots_output_folder, f'f1_vs_network_depth__adaptive_lr_{question_part}.png'))
        plt.close()
        # plt.show()

        # Summary
        print("\nSummary of Results (Adaptive Learning Rate):")
        print("Hidden Layers | Depth | Train F1 | Test F1 | Train Accuracy | Test Accuracy")
        for config, depth, f1_train, f1_test, acc_train, acc_test in zip(hidden_layer_configs, depths, avg_f1_scores_train, avg_f1_scores_test, accuracy_train_list, accuracy_test_list):
            print(f"{str(config):&lt;13} | {depth:&lt;5} | {f1_train:.4f} | {f1_test:.4f} | {acc_train:.2f}% | {acc_test:.2f}%")

if __name__ == "__main__":
    main()

</PRE>
</PRE>
</BODY>
</HTML>
