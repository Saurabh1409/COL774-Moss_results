<HTML>
<HEAD>
<TITLE>./A3_processed_new_hash/combined_089GD.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A3_processed_new_hash/combined_089GD.py<p><PRE>


import pandas as pd
import numpy as np
import sys
import os
import time
import matplotlib.pyplot as plt
from collections import Counter
from math import log2
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

def train_random_forest_with_grid_search(X_train, y_train, X_valid, y_valid, X_test, y_test):    
    param_grid = {
        'max_features': [0.3, 0.1, 0.9, 0.5, 0.7, 1.0],
        'min_samples_split': [10, 2, 8, 4, 6],
        'n_estimators': [350, 250, 150, 50]
    }
    
    rf = RandomForestClassifier(
        criterion='entropy',
        oob_score=True,  # Use out-of-bag samples to estimate accuracy
        random_state=42
    )
    
    grid_search = GridSearchCV(
        estimator=rf,
        param_grid=param_grid,
        cv=5,  # 5-fold cross-validation
        scoring='accuracy',
        verbose=2
    )
    
    print("Starting grid search...")
    grid_search.fit(X_train, y_train)
    
    # Get the best parameters and best estimator
    best_rf = grid_search.best_estimator_
    print("Best CV score:", grid_search.best_score_)
    best_params = grid_search.best_params_
    
    print("\nBest parameters:", best_params)
    
    # Get the out-of-bag score
    oob_score = best_rf.oob_score_
    print(f"Out-of-bag score: {oob_score:.4f}")
    
    # Evaluate the best model
    # Training accuracy
    train_pred = best_rf.predict(X_train)
    train_accuracy = accuracy_score(y_train, train_pred)
    
    # Validation accuracy
    valid_pred = best_rf.predict(X_valid)
    valid_accuracy = accuracy_score(y_valid, valid_pred)
    
    # Test accuracy
    test_pred = best_rf.predict(X_test)
    test_accuracy = 0
    # test_accuracy = accuracy_score(y_test, test_pred)
    
    print(f"\nTraining accuracy: {train_accuracy:.4f}")
    print(f"Out-of-bag accuracy: {oob_score:.4f}")
    print(f"Validation accuracy: {valid_accuracy:.4f}")
    print(f"Test accuracy: {test_accuracy:.4f}")
    
    # Return the best model and various metrics
    results = {
        'oob_score': oob_score,
        'best_params': best_params,
        'valid_accuracy': valid_accuracy,
        'best_estimator': best_rf,
        'train_accuracy': train_accuracy,
        'test_accuracy': test_accuracy
    }
    
    return results, test_pred

def part_i_vary_max_depth(X_train, y_train, X_valid, y_valid, X_test, y_test, output_folder_path, question_part):    
    max_depths = [25, 35, 45, 55]    
    train_accuracies = []
    valid_accuracies = []
    test_accuracies = []
    all_test_preds = []
    
    for depth in max_depths:
        print(f"Training decision tree with max_depth = {depth}")
        
        # Create and train the decision tree with entropy criterion
<A NAME="1"></A><FONT color = #00FF00><A HREF="match220-1.html#1" TARGET="1"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        dt = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42)
        dt.fit(X_train, y_train)
        # Evaluate on training set
        train_pred = dt.predict(X_train)
        train_accuracy = accuracy_score(y_train, train_pred)
        train_accuracies.append(train_accuracy)
        # Evaluate on validation set
        valid_pred = dt.predict(X_valid)
        valid_accuracy = accuracy_score(y_valid, valid_pred)
</FONT>        valid_accuracies.append(valid_accuracy)
        # Evaluate on test set
        test_pred = dt.predict(X_test)
        test_accuracy = 0
        # test_accuracy = accuracy_score(y_test, test_pred)
<A NAME="2"></A><FONT color = #0000FF><A HREF="match220-1.html#2" TARGET="1"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        test_accuracies.append(test_accuracy)
        all_test_preds.append(test_pred)
        
        print(f"Train accuracy: {train_accuracy:.4f}")
        print(f"Validation accuracy: {valid_accuracy:.4f}")
        print(f"Test accuracy: {test_accuracy:.4f}")

    # curr_best_val_acc = 0
    # final_csv_preds = []
    # for i in range(len(valid_accuracies)):
    #     if valid_accuracies[i]&gt;curr_best_val_acc:
    #         curr_best_val_acc = valid_accuracies[i]
    #         final_csv_preds = all_test_preds[i]

    # test_pred = list(map(lambda x: "&gt;50K" if x == 1 else "&lt;=50K", final_csv_preds))
    # # Create a DataFrame with the predictions
    # prediction_df = pd.DataFrame({'prediction': test_pred})
    # # Save to CSV
    # output_file = os.path.join(output_folder_path, f"prediction_{question_part}.csv")
    # prediction_df.to_csv(output_file, index=False)
    # print(f"Predictions saved to {output_file}")
        
    
    # # Plot results
    # plt.figure(figsize=(10, 6))
    # plt.plot(max_depths, train_accuracies, 'o-', label='Training Accuracy')
    # plt.plot(max_depths, valid_accuracies, 's-', label='Validation Accuracy')
    # plt.plot(max_depths, test_accuracies, '^-', label='Test Accuracy')
    # plt.xlabel('Maximum Depth')
    # plt.ylabel('Accuracy')
    # plt.title('Decision Tree Performance vs. Maximum Depth (Entropy)')
    # plt.legend()
    # plt.grid(True)
    # plt.savefig('sklearn_dt_max_depth.png')
    # plt.show()
    
    # Find best depth based on validation accuracy
    best_depth_idx = np.argmax(valid_accuracies)
    best_depth = max_depths[best_depth_idx]
    print(f"\nBest max_depth based on validation accuracy: {best_depth}")
</FONT>    print(f"Best validation accuracy: {valid_accuracies[best_depth_idx]:.4f}")
    print(f"Corresponding test accuracy: {test_accuracies[best_depth_idx]:.4f}")
    
    return best_depth, train_accuracies, valid_accuracies, test_accuracies

<A NAME="0"></A><FONT color = #FF0000><A HREF="match220-1.html#0" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

def part_ii_vary_ccp_alpha(X_train, y_train, X_valid, y_valid, X_test, y_test, output_folder_path, question_part):    
    ccp_alphas = [0.001, 0.01, 0.1, 0.2]
    train_accuracies = []
    valid_accuracies = []
</FONT>    test_accuracies = []
    all_test_preds = []
    for alpha in ccp_alphas:
        print(f"Training decision tree with ccp_alpha = {alpha}")
        # Create and train the decision tree with entropy criterion and default max_depth
<A NAME="3"></A><FONT color = #00FFFF><A HREF="match220-1.html#3" TARGET="1"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        dt = DecisionTreeClassifier(criterion='entropy', ccp_alpha=alpha, random_state=42)
        dt.fit(X_train, y_train)
        
        train_pred = dt.predict(X_train)
        train_accuracy = accuracy_score(y_train, train_pred)
        train_accuracies.append(train_accuracy)
        
        valid_pred = dt.predict(X_valid)
        valid_accuracy = accuracy_score(y_valid, valid_pred)
</FONT>        valid_accuracies.append(valid_accuracy)
        
        test_pred = dt.predict(X_test)
        test_accuracy = 0
        # test_accuracy = accuracy_score(y_test, test_pred)
        test_accuracies.append(test_accuracy)
        all_test_preds.append(test_pred)
        
<A NAME="4"></A><FONT color = #FF00FF><A HREF="match220-1.html#4" TARGET="1"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        print(f"Train accuracy: {train_accuracy:.4f}")
        print(f"Validation accuracy: {valid_accuracy:.4f}")
        print(f"Test accuracy: {test_accuracy:.4f}")
        print(f"Tree depth: {dt.get_depth()}")
        print(f"Number of nodes: {dt.tree_.node_count}")

    # curr_best_val_acc = 0
    # final_csv_preds = []
    # for i in range(len(valid_accuracies)):
    #     if valid_accuracies[i]&gt;curr_best_val_acc:
    #         curr_best_val_acc = valid_accuracies[i]
    #         final_csv_preds = all_test_preds[i]

    # test_pred = list(map(lambda x: "&gt;50K" if x == 1 else "&lt;=50K", final_csv_preds))
    # # Create a DataFrame with the predictions
    # prediction_df = pd.DataFrame({'prediction': test_pred})
    # # Save to CSV
    # output_file = os.path.join(output_folder_path, f"prediction_{question_part}.csv")
    # prediction_df.to_csv(output_file, index=False)
    # print(f"Predictions saved to {output_file}")
    
    # # Plot results
    # plt.figure(figsize=(10, 6))
    # plt.plot(ccp_alphas, train_accuracies, 'o-', label='Training Accuracy')
    # plt.plot(ccp_alphas, valid_accuracies, 's-', label='Validation Accuracy')
    # plt.plot(ccp_alphas, test_accuracies, '^-', label='Test Accuracy')
    # plt.xscale('log')
    # plt.xlabel('Cost-Complexity Pruning Alpha')
    # plt.ylabel('Accuracy')
    # plt.title('Decision Tree Performance vs. CCP Alpha (Entropy)')
    # plt.legend()
    # plt.grid(True)
    # plt.savefig('sklearn_dt_ccp_alpha.png')
    # plt.show()
    
    # Find best ccp_alpha based on validation accuracy
    best_alpha_idx = np.argmax(valid_accuracies)
    best_alpha = ccp_alphas[best_alpha_idx]
    print(f"\nBest ccp_alpha based on validation accuracy: {best_alpha}")
</FONT>    print(f"Best validation accuracy: {valid_accuracies[best_alpha_idx]:.4f}")
    print(f"Corresponding test accuracy: {test_accuracies[best_alpha_idx]:.4f}")
    
    return best_alpha, train_accuracies, valid_accuracies, test_accuracies

# Function to count nodes in the tree
def count_nodes(node):
    if node is None:
        return 0
    
    if node.is_leaf:
        return 1
    
    if node.is_categorical:
        # Count this node plus all children
        summation = sum(count_nodes(child) for child in node.children.values())
        return summation + 1
    else:
        # Count this node plus left and right children
        left_right = count_nodes(node.left) + count_nodes(node.right)
        return left_right + 1

# Function to get all non-leaf nodes in the tree
def get_all_nodes(node, nodes_list=None):
    if nodes_list is None:
        nodes_list = []
    
    # Skip leaf nodes
    if node.is_leaf:
        return nodes_list
    
    # Add this node to the list
    add_node = node
    nodes_list.append(add_node)
    
    # Traverse children
    if node.is_categorical:
        children = node.children.values()
        for child in children:
            get_all_nodes(child, nodes_list)
    else:
        get_all_nodes(node.left, nodes_list)
        get_all_nodes(node.right, nodes_list)
    
    return nodes_list

# Function to convert a node to a leaf node
def convert_to_leaf(node, y):
    # Count class frequencies
    class_counts = Counter(y)
    
    # Get majority class
    if class_counts:
        majority_class = class_counts.most_common(1)[0][0]
    else:
        # If no classes (shouldn't happen), default to 0
        majority_class = 0
    
    # Convert to leaf node
    node.label = majority_class
    node.is_leaf = True
    # Remove child references
    node.left = None
    node.children = {}
    node.right = None
    node.attribute = None
    node.is_categorical = False
    node.threshold = None

# Function to collect instances that reach a specific node
def get_instances_at_node(X, y, node, parent_node=None, parent_value=None):
    if parent_node is None:
        # Root node, return all instances
        return X, y
    
    # Filter instances that reach this node
    if parent_node.is_categorical:
        # For categorical attributes, filter by the specific value
        indices = X[parent_node.attribute] == parent_value
    else:
        # For numerical attributes, filter by threshold
        if node == parent_node.left:
            indices = X[parent_node.attribute] &lt;= parent_node.threshold
        else:
            indices = X[parent_node.attribute] &gt; parent_node.threshold
    
    return X[indices], y[indices]

# Function to evaluate a node for pruning
def evaluate_pruning(tree, node, X_valid, y_valid, node_to_instances=None):
    # Create a copy of the tree
    import copy
    tree_copy = copy.deepcopy(tree)
    
    # Find the corresponding node in the copied tree
    if node == tree:
        node_to_prune = tree_copy
    else:
        raise NotImplementedError("Need a way to locate the corresponding node in the copied tree")
    
    # Store the original state
    attribute_orig = node_to_prune.attribute
    is_leaf_orig = node_to_prune.is_leaf
    label_orig = node_to_prune.label
    threshold_orig = node_to_prune.threshold
    is_categorical_orig = node_to_prune.is_categorical
    right_orig = node_to_prune.right
    children_orig = node_to_prune.children.copy() if hasattr(node_to_prune, 'children') else None
    left_orig = node_to_prune.left
    
    # Convert to leaf node based on majority class at this node
    X_node, y_node = get_instances_at_node(X_valid, y_valid, node)
    convert_to_leaf(node_to_prune, y_node)
    # Restore the node to its original state
    node_to_prune.attribute = attribute_orig
    node_to_prune.is_leaf = is_leaf_orig
    node_to_prune.right = right_orig
    node_to_prune.threshold = threshold_orig
    node_to_prune.label = label_orig
    node_to_prune.is_categorical = is_categorical_orig
    if children_orig is not None:
        node_to_prune.children = children_orig
    node_to_prune.left = left_orig
    # Measure accuracy after pruning
    pruned_accuracy = calculate_accuracy(y_valid, predict(tree_copy, X_valid))
    
    return pruned_accuracy

# Function to post-prune a decision tree
def post_prune_tree(tree, X_train, y_train, X_valid, y_valid):
    baseline_accuracy = calculate_accuracy(y_valid, predict(tree, X_valid))
    print(f"Baseline validation accuracy before pruning: {baseline_accuracy:.4f}")
    
    # Keep track of tree metrics during pruning
    pruning_history = []
    node_counts = []
    current_tree = tree
    train_accuracies = []
    valid_accuracies = []
    current_accuracy = baseline_accuracy
    test_accuracies = []
    # Collect initial metrics
    valid_acc = current_accuracy
    train_acc = calculate_accuracy(y_train, predict(current_tree, X_train))
    train_accuracies.append(train_acc)
    node_count = count_nodes(current_tree)
    node_counts.append(node_count)
    valid_accuracies.append(valid_acc)
    
    pruning_iteration = 0
    # Continue pruning until no improvement
    while True:
        pruning_iteration += 1
        best_accuracy = current_accuracy
        print(f"Pruning iteration {pruning_iteration}, current validation accuracy: {current_accuracy:.4f}")
        best_node = None
        
        # Get all non-leaf nodes
        all_non_leaf_nodes = get_all_nodes(current_tree)
        print(f"Evaluating {len(all_non_leaf_nodes)} candidate nodes for pruning")
        all_nodes = all_non_leaf_nodes
        # For each non-leaf node, evaluate the effect of pruning it
        for node in all_nodes:
            # Remember the original state
            is_leaf_orig = node.is_leaf
            children_orig = node.children.copy() if hasattr(node, 'children') and node.children else {}
            left_orig = node.left
            is_categorical_orig = node.is_categorical
            attribute_orig = node.attribute
            right_orig = node.right
            threshold_orig = node.threshold
            # Collect instances that reach this node for determining majority class
            if current_tree == node:  # Root node
                X_node, y_node = X_train, y_train
            else:
                X_node, y_node = X_train, y_train
            
            # Find majority class for this node
            majority_class = Counter(y_node).most_common(1)[0][0] if len(y_node) &gt; 0 else 0
            
            # Temporarily convert to leaf node
            node.label = majority_class
            node.left = None
            node.is_leaf = True
            node.children = {}
            node.right = None
            # Evaluate accuracy with this node pruned
            pruned_accuracy = calculate_accuracy(y_valid, predict(current_tree, X_valid))
            
            # If this pruning improves accuracy, keep track of this node
            if pruned_accuracy &gt; best_accuracy:
                best_node = node
                best_accuracy = pruned_accuracy
            # Restore the node to its original state
            node.is_leaf = is_leaf_orig
            node.left = left_orig
            node.is_categorical = is_categorical_orig
            node.right = right_orig
            node.attribute = attribute_orig
            node.children = children_orig
            node.threshold = threshold_orig
        # If no pruning improves accuracy, stop
        if best_node is None:
            print("No further pruning improves validation accuracy. Stopping.")
            break
        
        print(f"Pruning node with attribute {best_node.attribute} improves accuracy to {best_accuracy:.4f}")
        
        # Prune the best node (convert to leaf)
        y_node, X_node = y_train, X_train 
        majority_class = Counter(y_node).most_common(1)[0][0] if len(y_node) &gt; 0 else 0
        
        best_node.label = majority_class
        best_node.left = None
        best_node.is_leaf = True
        best_node.children = {}
        best_node.right = None
        # Update current accuracy
        current_accuracy = best_accuracy
        
        # Collect metrics after this pruning step
        valid_acc = current_accuracy
        valid_accuracies.append(valid_acc)
        train_acc = calculate_accuracy(y_train, predict(current_tree, X_train))
        node_count = count_nodes(current_tree)
        node_counts.append(node_count)
        train_accuracies.append(train_acc)        
        print(f"Tree now has {node_count} nodes, train acc: {train_acc:.4f}, valid acc: {valid_acc:.4f}")
    
    return current_tree, node_counts, train_accuracies, valid_accuracies

# Enhanced version of post_prune_tree with better node tracking
def post_prune_tree_enhanced(tree, X_train, y_train, X_valid, y_valid, X_test, y_test):
    # First, let's assign unique IDs to each node in the tree
    node_id_counter = [0]  # Use a list to allow modification inside nested function
    
    def assign_node_ids(node):
        var = node_id_counter[0]
        node_id_counter[0] += 1
        node.id = var
        
        if not node.is_leaf:
            if node.is_categorical:
                child_vals = node.children.values()
                for child in child_vals:
                    assign_node_ids(child)
            else:
                assign_node_ids(node.left)
                assign_node_ids(node.right)
    
    assign_node_ids(tree)
    
    # Create a function to collect instances that reach each node
    def collect_instances_at_nodes(node, X, y, parent_path=None):
        if parent_path is None:
            instances = {'X': X, 'y': y}
        else:
            # Filter based on parent path
            mask = np.ones(len(X), dtype=bool)
            for attr, op, value in parent_path:
                if op == '&lt;=':
                    mask &= (X[attr] &lt;= value)
                elif op == '&gt;':
                    mask &= (X[attr] &gt; value)
                elif op == '==':
                    mask &= (X[attr] == value)
            
            instances = {'X': X[mask], 'y': y[mask]}
        # Store instances at this node
        var_id = node.id
        node_instances[var_id] = instances
        
        # Recurse for children
        if not node.is_leaf:
            if node.is_categorical:
                for value, child in node.children.items():
                    new_path = parent_path.copy() if parent_path else []
                    new_path.append((node.attribute, '==', value))
                    collect_instances_at_nodes(child, X, y, new_path)
            else:
                # Left child (&lt;=)
                left_path = parent_path.copy() if parent_path else []
                left_path.append((node.attribute, '&lt;=', node.threshold))
                collect_instances_at_nodes(node.left, X, y, left_path)
                # Right child (&gt;)
                right_path = parent_path.copy() if parent_path else []
                right_path.append((node.attribute, '&gt;', node.threshold))
                collect_instances_at_nodes(node.right, X, y, right_path)
    
    # Collect instances that reach each node
    collect_instances_at_nodes(tree, X_train, y_train)
    node_instances = {}
    # Get baseline accuracy before pruning
    baseline_accuracy = calculate_accuracy(y_valid, predict(tree, X_valid))
    node_counts = []
    # Initialize with current tree metrics
    current_tree = tree
    valid_accuracies = []
    print(f"Baseline validation accuracy before pruning: {baseline_accuracy:.4f}")
    # Keep track of tree metrics during pruning
    train_accuracies = []
    current_accuracy = baseline_accuracy
    test_accuracies = []
    
    # Collect initial metrics
    test_acc = 0
    # test_acc = calculate_accuracy(y_test, predict(current_tree, X_test))
    test_accuracies.append(test_acc)
    valid_acc = current_accuracy
    valid_accuracies.append(valid_acc)
    node_count = count_nodes(current_tree)
    train_acc = calculate_accuracy(y_train, predict(current_tree, X_train))    
    node_counts.append(node_count)
    train_accuracies.append(train_acc)
    
    pruning_iteration = 0
    # Continue pruning until no improvement
    while True:
        best_accuracy = current_accuracy
        pruning_iteration += 1
        print(f"Pruning iteration {pruning_iteration}, current validation accuracy: {current_accuracy:.4f}")
        best_node = None
        # Get all non-leaf nodes
        all_nodes = get_all_nodes(current_tree)
        print(f"Evaluating {len(all_nodes)} candidate nodes for pruning")
        
        # For each non-leaf node, evaluate the effect of pruning it
        for node in all_nodes:
            # Remember the original state
            attribute_orig = node.attribute
            is_leaf_orig = node.is_leaf
            label_orig = node.label
            left_orig = node.left
            children_orig = node.children.copy() if hasattr(node, 'children') and node.children else {}
            right_orig = node.right
            threshold_orig = node.threshold
            is_categorical_orig = node.is_categorical            
            # Get instances at this node and determine majority class
            var_id = node.id
            instances = node_instances[var_id]
            X_node, y_node = instances['X'], instances['y']
            
            if len(y_node) &gt; 0:
                majority_class = Counter(y_node).most_common(1)[0][0]
            else:
                majority_class = 0  # Default
            
            # Temporarily convert to leaf node
            node.children = {}
            node.left = None
            node.label = majority_class
            node.right = None
            node.is_leaf = True
            
            # Evaluate accuracy with this node pruned
            pruned_accuracy = calculate_accuracy(y_valid, predict(current_tree, X_valid))
            # If this pruning improves accuracy, keep track of this node
            if pruned_accuracy &gt; best_accuracy:
                best_node = node
                best_accuracy = pruned_accuracy
            
            # Restore the node to its original state
            node.threshold = threshold_orig
            node.is_leaf = is_leaf_orig
            node.right = right_orig
            node.is_categorical = is_categorical_orig
            node.attribute = attribute_orig
            node.label = label_orig
            node.children = children_orig
            node.left = left_orig
        
        # If no pruning improves accuracy, stop
        if best_node is None:
            print("No further pruning improves validation accuracy. Stopping.")
            break
        
        print(f"Pruning node with attribute {best_node.attribute} improves accuracy to {best_accuracy:.4f}")
        # Prune the best node (convert to leaf)
        var_id = best_node.id
        instances = node_instances[var_id]
        y_node = instances['y']
        
        if len(y_node) &gt; 0:
            majority_class = Counter(y_node).most_common(1)[0][0]
        else:
            majority_class = 0  # Default
        
        best_node.children = {}
        best_node.left = None
        best_node.is_leaf = True
        best_node.label = majority_class
        best_node.right = None
        
        # Update current accuracy
        current_accuracy = best_accuracy
        # Collect metrics after this pruning step
        valid_acc = current_accuracy
        train_acc = calculate_accuracy(y_train, predict(current_tree, X_train))
        train_accuracies.append(train_acc)
        test_acc = 0
        # test_acc = calculate_accuracy(y_test, predict(current_tree, X_test))
        node_count = count_nodes(current_tree)
        node_counts.append(node_count)
        valid_accuracies.append(valid_acc)
        test_accuracies.append(test_acc)
        
        print(f"Tree now has {node_count} nodes, train acc: {train_acc:.4f}, valid acc: {valid_acc:.4f}, test acc: {test_acc:.4f}")
    
    return current_tree, node_counts, train_accuracies, valid_accuracies, test_accuracies

# # Plot pruning results
# def plot_pruning_results(node_counts, train_accuracies, valid_accuracies, test_accuracies, max_depth):
#     plt.figure(figsize=(10, 6))
#     plt.plot(node_counts, train_accuracies, 'o-', label='Training Accuracy')
#     plt.plot(node_counts, valid_accuracies, 's-', label='Validation Accuracy')
#     plt.plot(node_counts, test_accuracies, '^-', label='Test Accuracy')
#     plt.xlabel('Number of Nodes')
#     plt.ylabel('Accuracy')
#     plt.title(f'Decision Tree Performance vs. Number of Nodes (Initial Max Depth: {max_depth})')
#     plt.legend()
#     plt.grid(True)
#     plt.gca().invert_xaxis()  # Invert x-axis to show pruning progress left-to-right
#     plt.savefig(f'decision_tree_pruning_depth_{max_depth}.png')
#     plt.show()

# Calculate entropy for a dataset
def calculate_entropy(y):
    if len(y) == 0:
        return 0
    counts = Counter(y)
    c_vals = counts.values()
    probabilities = [count / len(y) for count in c_vals]
    return -sum(p * log2(p) for p in probabilities)

# Calculate mutual information (information gain)
def calculate_mutual_information(X, y, attribute, categorical_cols, numerical_cols):
    # Calculate the entropy of the original dataset
    total_entropy = calculate_entropy(y)
    # Calculate the weighted entropy after the split
    weighted_entropy = 0
    
    if attribute in numerical_cols:
        # For numerical attributes, split based on median
        median_value = np.median(X[attribute])
        # Split the data into two groups based on the median
        right_indices = X[attribute] &gt; median_value
        right_entropy = calculate_entropy(y[right_indices])
        left_indices = X[attribute] &lt;= median_value
        left_entropy = calculate_entropy(y[left_indices])

        l_ind_sum = sum(left_indices)
        r_ind_sum = sum(right_indices)
        len_y = len(y)
        l_d = l_ind_sum / len_y
        r_d = r_ind_sum / len_y
        
        weighted_entropy = (l_d) * left_entropy + (r_d) * right_entropy
        
    else:  # Categorical attribute
        # Get unique values of the attribute
        unique_values = X[attribute].unique()
        # Calculate entropy for each value
        for value in unique_values:
            indices = X[attribute] == value
            subset_entropy = calculate_entropy(y[indices])
            sum_ind = sum(indices)
            len_y = len(y)
            sum_len_div = sum_ind / len_y
            weighted_entropy += (sum_len_div) * subset_entropy
    
    # Calculate mutual information (information gain)
    mi = total_entropy - weighted_entropy
    mutual_info = mi
    return mutual_info

# Function to find the best attribute to split on
def find_best_attribute(X, y, attributes, categorical_cols, numerical_cols):
    mutual_info_values = {}
    for attribute in attributes:
        mutual_info = calculate_mutual_information(X, y, attribute, categorical_cols, numerical_cols)
        mi = mutual_info
        attr = attribute
        mutual_info_values[attr] = mi
    
    # Return the attribute with the highest mutual information
    return max(mutual_info_values, key=mutual_info_values.get)

# Node class for the decision tree
class Node:
    def __init__(self, is_leaf=False, label=None, attribute=None, threshold=None, is_categorical=False):
        self.label = label
        self.is_leaf = is_leaf
        self.left = None
        self.threshold = threshold
        self.is_categorical = is_categorical
        self.right = None  
        self.children = {}  
        self.attribute = attribute

# Build the decision tree
def build_decision_tree(X, y, attributes, max_depth, categorical_cols, numerical_cols, current_depth=0):
    # Base case 1: All instances have the same class
    uniq_len_y = len(set(y))
    if uniq_len_y == 1:
        return Node(is_leaf=True, label=y.iloc[0])
    
    # Base case 2: No attributes left or maximum depth reached
    attr_len = len(attributes)
    if attr_len == 0 or current_depth &gt;= max_depth:
        majority_class = Counter(y).most_common(1)[0][0]
        return Node(is_leaf=True, label=majority_class)
    
    # Find the best attribute to split on
    best_attribute = find_best_attribute(X, y, attributes, categorical_cols, numerical_cols)
    # Create a new node
    node = Node(attribute=best_attribute)
    
    # Check if the attribute is categorical or numerical
<A NAME="5"></A><FONT color = #FF0000><A HREF="match220-1.html#5" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    if best_attribute in numerical_cols:
        # Numerical attribute: split based on median
        median_value = np.median(X[best_attribute])
        node.threshold = median_value
        node.is_categorical = False
        # Split data
        right_indices = X[best_attribute] &gt; median_value
</FONT>        left_indices = X[best_attribute] &lt;= median_value
        # Check if split resulted in empty sets
        sum_l_ind = sum(left_indices)
        sum_r_ind = sum(right_indices)
        if sum_l_ind == 0 or sum_r_ind == 0:
            majority_class = Counter(y).most_common(1)[0][0]
            return Node(is_leaf=True, label=majority_class)
        # Recursively build left and right subtrees
        node.left = build_decision_tree(X[left_indices], y[left_indices], attributes, max_depth, 
                                        categorical_cols, numerical_cols, current_depth + 1)
        node.right = build_decision_tree(X[right_indices], y[right_indices], attributes, max_depth, 
                                         categorical_cols, numerical_cols, current_depth + 1)
        
    else:  # Categorical attribute
        # Get unique values of the attribute
        unique_values = X[best_attribute].unique()
        node.is_categorical = True
        
        # For each unique value, create a child node
        for value in unique_values:
            indices = X[best_attribute] == value
            # Skip if no instances match this value
            ind_sum = sum(indices)
            if ind_sum == 0:
                continue
            # Recursively build the subtree
            child_node = build_decision_tree(X[indices], y[indices], 
                                           [a for a in attributes if a != best_attribute], 
                                           max_depth, categorical_cols, numerical_cols, 1 + current_depth)
            
            node.children[value] = child_node
    
    return node

# Function to predict class for a single instance
def predict_instance(node, instance):
    # If it's a leaf node, return the label
    if node.is_leaf:
        lab = node.label
        return lab
    
    # If it's a categorical attribute
    if node.is_categorical:
        node_attr = node.attribute
        attribute_value = instance[node_attr]
        # If the attribute value is not in the tree, return the majority class
        n_ch = node.children
        if attribute_value not in n_ch:
            # For unseen categorical values, treat as a leaf and return the prediction
            return Counter([predict_instance(child, instance) for child in node.children.values()]).most_common(1)[0][0]
        
        # Otherwise, follow the path corresponding to the attribute value
        n_ch_attr = node.children[attribute_value]
        return predict_instance(n_ch_attr, instance)
    
    # If it's a numerical attribute
    else:
        # Follow the path based on the threshold
        th = node.threshold
        if instance[node.attribute] &lt;= th:
            n_l = node.left
            return predict_instance(n_l, instance)
        else:
            n_r = node.right
            return predict_instance(n_r, instance)

# Function to predict classes for a dataset
def predict(tree, X):
    predictions = []
    X_l = len(X)
    for i in range(X_l):
        instance = X.iloc[i]
        pred = predict_instance(tree, instance)
        predictions.append(pred)
    return predictions

# Function to calculate accuracy
def calculate_accuracy(y_true, y_pred):
    correct = sum(y_true == y_pred)
    l_y = len(y_true)
    res = correct / l_y
    return res

def apply_one_hot_encoding(train_df, valid_df, test_df, categorical_columns):
    # Create copies to avoid modifying the originals
    test_encoded = test_df.copy()
    valid_encoded = valid_df.copy()
    train_encoded = train_df.copy()
    
    # Iterate over each categorical column to apply one-hot encoding
    for col in categorical_columns:
        # Get dummies for the training data
        drop_f = True
        dummies_train = pd.get_dummies(train_df[col], prefix=col, drop_first=drop_f)
        
        # Concatenate the dummy variables to the encoded DataFrames
        ax = 1
        train_encoded = pd.concat([train_encoded, dummies_train], axis=ax)
        
        # For validation and test, get dummies as well, but ensure the same columns as train
        drop_v = True
        dummies_valid = pd.get_dummies(valid_df[col], prefix=col, drop_first=drop_v)
        drop_t = True
        dummies_test = pd.get_dummies(test_df[col], prefix=col, drop_first=drop_t)
        
        # Re-align the validation and test datasets to match the train columns
        fill_v = 0
        dummies_valid = dummies_valid.reindex(columns=dummies_train.columns, fill_value=fill_v)
        fill_t = 0
        dummies_test = dummies_test.reindex(columns=dummies_train.columns, fill_value=fill_t)
        
        # Concatenate the one-hot encoded columns for valid and test
        ax_v = 1
        valid_encoded = pd.concat([valid_encoded, dummies_valid], axis=ax_v)
        ax_t = 1
        test_encoded = pd.concat([test_encoded, dummies_test], axis=ax_t)
        
        # Drop the original categorical column from all datasets
        ax_train_encoded = 1
        train_encoded = train_encoded.drop(col, axis=ax_train_encoded)
        valid_encoded = valid_encoded.drop(col, axis=1)
        ax_test_encoded = 1
        test_encoded = test_encoded.drop(col, axis=ax_test_encoded)
    
    return train_encoded, valid_encoded, test_encoded

def data_loading(train_data_path, validation_data_path, test_data_path):
    # Load the datasets with the correct column names
    train_data = pd.read_csv(train_data_path)
    valid_data = pd.read_csv(validation_data_path)
    test_data = pd.read_csv(test_data_path)
    # train_data = pd.read_csv('./data/train.csv')
    # valid_data = pd.read_csv('./data/valid.csv')
    # test_data = pd.read_csv('./data/test.csv')
    return train_data, valid_data, test_data

def target_col_preprocess(df):
    df['income&gt;50K'] = df['income'].apply(lambda x: 1 if x == ' &gt;50K' else 0)

def cat_num_attr(df):
    # Identify categorical and numerical attributes
    numerical_cols = df.select_dtypes(include=['int']).columns.tolist()
    categorical_cols = [col for col in df.columns if col not in numerical_cols 
                      and col != 'income&gt;50K' and col != 'income']
    
    # print("\nCategorical columns:", categorical_cols)
    # print("Numerical columns:", numerical_cols)
    return categorical_cols, numerical_cols

def train_dt(max_depths, attributes, train_data, valid_data, test_data, categorical_cols, numerical_cols, question_part):
    train_accuracies = []
    valid_accuracies = []
    test_accuracies = []
    trees = []
    test_pred_ret = []
    for max_depth in max_depths:
        print(f"\nTraining decision tree with max_depth = {max_depth}")
        tree = build_decision_tree(train_data, train_data['income&gt;50K'], attributes, max_depth, categorical_cols, numerical_cols)
        trees.append(tree)

        train_pred = predict(tree, train_data)
        train_accuracy = calculate_accuracy(train_data['income&gt;50K'], train_pred)
        valid_pred = predict(tree, valid_data)
        train_accuracies.append(train_accuracy)
        valid_accuracy = calculate_accuracy(valid_data['income&gt;50K'], valid_pred)
        test_pred = predict(tree, test_data)
        valid_accuracies.append(valid_accuracy)
        test_accuracy = 0
        # test_accuracy = calculate_accuracy(test_data['income&gt;50K'], test_pred)
        test_accuracies.append(test_accuracy)
        if max_depth==20 and question_part=='a':
            test_pred_ret = list(map(lambda x: "&gt;50K" if x == 1 else "&lt;=50K", test_pred))
        elif max_depth==55 and question_part=='b':
            test_pred_ret = list(map(lambda x: "&gt;50K" if x == 1 else "&lt;=50K", test_pred))
        
        print(f"Train accuracy: {train_accuracy:.4f}")
        print(f"Validation accuracy: {valid_accuracy:.4f}")
        print(f"Test accuracy: {test_accuracy:.4f}")
        
    return train_accuracies, valid_accuracies, test_accuracies, trees, test_pred_ret

# def plot_results(max_depths, train_accuracies, valid_accuracies, test_accuracies):
#     # Plot the results
#     plt.figure(figsize=(10, 6))
#     plt.plot(max_depths, train_accuracies, 'o-', label='Training Accuracy')
#     plt.plot(max_depths, valid_accuracies, 's-', label='Validation Accuracy')
#     plt.plot(max_depths, test_accuracies, '^-', label='Test Accuracy')
#     plt.xlabel('Maximum Depth')
#     plt.ylabel('Accuracy')
#     plt.title('Decision Tree Performance vs. Maximum Depth')
#     plt.legend()
#     plt.grid(True)
#     plt.savefig('decision_tree_performance.png')  # Save the figure to a file
#     plt.show()
    
#     # Report the final results
#     print("\nFinal Results:")
#     print("Max Depths:", max_depths)
#     print("Train Accuracies:", [f"{acc:.4f}" for acc in train_accuracies])
#     print("Validation Accuracies:", [f"{acc:.4f}" for acc in valid_accuracies])
#     print("Test Accuracies:", [f"{acc:.4f}" for acc in test_accuracies])

def c(train_data_path, validation_data_path, test_data_path, output_folder_path, question_part):
    # Create output directory if it doesn't exist
    os.makedirs(output_folder_path, exist_ok=True)
    # Load the datasets with the correct column names
    train_data, valid_data, test_data = data_loading(train_data_path, validation_data_path, test_data_path)
    
    # Process target variable - convert to binary format
    target_col_preprocess(train_data)
    target_col_preprocess(valid_data)
    # target_col_preprocess(test_data)

    # Clean up the data - strip whitespace from string columns
    for df in [train_data, valid_data, test_data]:
        for col in df.select_dtypes(include=['object']).columns:
            df[col] = df[col].str.strip()
    

    # Identify categorical and numerical attributes
    categorical_cols, numerical_cols = cat_num_attr(train_data)
    # Apply one-hot encoding
    train_encoded, valid_encoded, test_encoded = apply_one_hot_encoding(train_data, valid_data, test_data, categorical_cols)
    # Identify categorical and numerical attributes
    categorical_cols, numerical_cols = cat_num_attr(train_encoded)
    numerical_cols.remove('income&gt;50K')
    
    # Define attributes (columns to use for training)
    attributes = list(train_encoded.columns)
    attributes.remove('income&gt;50K')  # Remove the target variable
    attributes.remove('income')      # Remove the original income column
    
    # Define max depths to evaluate
    max_depths_to_prune = [25, 35, 45, 55]  # We'll prune trees of these initial depths
    train_accuracies, valid_accuracies, test_accuracies, trees, test_pred = train_dt(max_depths_to_prune, attributes, 
                                                                   train_encoded, valid_encoded, test_encoded, categorical_cols, numerical_cols)
    for i in range(len(trees)):
        # Count initial nodes
        initial_nodes = count_nodes(trees[i])
        print(f"Initial tree has {initial_nodes} nodes")
        print(f"Initial tree (max_depth={max_depths_to_prune[i]}):")
        print(f"  Train accuracy: {train_accuracies[i]:.4f}")
        print(f"  Valid accuracy: {valid_accuracies[i]:.4f}")
        print(f"  Test accuracy: {test_accuracies[i]:.4f}")

        # Post-prune the tree
        pruned_tree, node_counts, train_accuracies, valid_accuracies, test_accuracies = post_prune_tree_enhanced(
            trees[i], train_encoded, train_encoded['income&gt;50K'], 
            valid_encoded, valid_encoded['income&gt;50K'],
            test_encoded, []
        )

        if max_depths_to_prune[i]==55:
            test_pred = predict(pruned_tree, test_encoded)
            # Create a DataFrame with the predictions
            prediction_df = pd.DataFrame({'prediction': test_pred})
            
            # Save to CSV
            output_file = os.path.join(output_folder_path, f"prediction_{question_part}.csv")
            prediction_df.to_csv(output_file, index=False)
            
            print(f"Predictions saved to {output_file}")
        
        # Plot pruning results
        # plot_pruning_results(node_counts, train_accuracies, valid_accuracies, test_accuracies, max_depths_to_prune[i])
        
        # Evaluate final pruned tree
        pred_t = predict(pruned_tree, train_encoded)
        final_train_acc = calculate_accuracy(train_encoded['income&gt;50K'], pred_t)
        pred_v = predict(pruned_tree, valid_encoded)
        final_valid_acc = calculate_accuracy(valid_encoded['income&gt;50K'], pred_v)
        pred_te = predict(pruned_tree, test_encoded)
        final_test_acc = 0
        # final_test_acc = calculate_accuracy(test_encoded['income&gt;50K'], pred_te)
        
        final_nodes = count_nodes(pruned_tree)
        
        print(f"\nFinal pruned tree (started with max_depth={max_depths_to_prune[i]}):")
        print(f"  Nodes reduced: {initial_nodes} -&gt; {final_nodes} ({initial_nodes - final_nodes} nodes removed)")
        print(f"  Train accuracy: {final_train_acc:.4f} (initial: {train_accuracies[i]:.4f}, change: {final_train_acc - train_accuracies[i]:.4f})")
        print(f"  Valid accuracy: {final_valid_acc:.4f} (initial: {valid_accuracies[i]:.4f}, change: {final_valid_acc - valid_accuracies[i]:.4f})")
        print(f"  Test accuracy: {final_test_acc:.4f} (initial: {test_accuracies[i]:.4f}, change: {final_test_acc - test_accuracies[i]:.4f})")




def a(train_data_path, validation_data_path, test_data_path, output_folder_path, question_part):
    # Create output directory if it doesn't exist
    os.makedirs(output_folder_path, exist_ok=True)
    # Load the datasets with the correct column names
    train_data, valid_data, test_data = data_loading(train_data_path, validation_data_path, test_data_path)
    
    # Process target variable - convert to binary format
    # If the datasets already have headers, we'll need to skip the first row
    # Standardize the target variable name and format
    target_col_preprocess(train_data)
    target_col_preprocess(valid_data)
    # target_col_preprocess(test_data)

    # Clean up the data - strip whitespace from string columns
    for df in [train_data, valid_data, test_data]:
        for col in df.select_dtypes(include=['object']).columns:
            df[col] = df[col].str.strip()
    
    # Identify categorical and numerical attributes
    categorical_cols, numerical_cols = cat_num_attr(train_data)
    

    # Train decision trees with different maximum depths and evaluate
    max_depths_without_one_hot = [5, 10, 15, 20]
    # Train the decision tree
    attributes = list(train_data.columns)
    attributes.remove('income&gt;50K')  # Remove the target variable
    attributes.remove('income')      # Remove the original income column
    train_accuracies, valid_accuracies, test_accuracies, trees, test_pred = train_dt(max_depths_without_one_hot, attributes, 
                                                                   train_data, valid_data, test_data, categorical_cols, numerical_cols
                                                                                    , question_part)
    # Create a DataFrame with the predictions
    prediction_df = pd.DataFrame({'prediction': test_pred})
    
    # Save to CSV
    output_file = os.path.join(output_folder_path, f"prediction_{question_part}.csv")
    prediction_df.to_csv(output_file, index=False)
    
    print(f"Predictions saved to {output_file}")
    # plot_results(max_depths_without_one_hot, train_accuracies, valid_accuracies, test_accuracies)

def b(train_data_path, validation_data_path, test_data_path, output_folder_path, question_part):
    # Create output directory if it doesn't exist
    os.makedirs(output_folder_path, exist_ok=True)
    # Load the datasets with the correct column names
    train_data, valid_data, test_data = data_loading(train_data_path, validation_data_path, test_data_path)
    
    # Process target variable - convert to binary format
    # If the datasets already have headers, we'll need to skip the first row
    # Standardize the target variable name and format
    target_col_preprocess(train_data)
    target_col_preprocess(valid_data)
    # target_col_preprocess(test_data)

    # Clean up the data - strip whitespace from string columns
    for df in [train_data, valid_data, test_data]:
        for col in df.select_dtypes(include=['object']).columns:
            df[col] = df[col].str.strip()
    
    # Identify categorical and numerical attributes
    categorical_cols, numerical_cols = cat_num_attr(train_data)

    # Update numerical columns list to include all columns except target
    # Apply one-hot encoding
    train_encoded, valid_encoded, test_encoded = apply_one_hot_encoding(train_data, valid_data, test_data, categorical_cols)
    categorical_cols, numerical_cols = cat_num_attr(train_encoded)
    numerical_cols.remove('income&gt;50K')
    # categorical_cols.remove('income')
    attributes = list(train_encoded.columns)
    attributes.remove('income&gt;50K')  # Remove the target variable
    attributes.remove('income')      # Remove the original income column
    max_depths_with_one_hot = [25, 35, 45, 55]
    train_accuracies, valid_accuracies, test_accuracies, trees, test_pred = train_dt(max_depths_with_one_hot, attributes, 
                                                                   train_encoded, valid_encoded, test_encoded, categorical_cols, numerical_cols
                                                                                    , question_part)
    # Create a DataFrame with the predictions
    prediction_df = pd.DataFrame({'prediction': test_pred})
    
    # Save to CSV
    output_file = os.path.join(output_folder_path, f"prediction_{question_part}.csv")
    ind = False
    prediction_df.to_csv(output_file, index=ind)
    
    print(f"Predictions saved to {output_file}")
    # plot_results(max_depths_with_one_hot, train_accuracies, valid_accuracies, test_accuracies)


def d(train_data_path, validation_data_path, test_data_path, output_folder_path, question_part):
    # Create output directory if it doesn't exist
    os.makedirs(output_folder_path, exist_ok=True)
    # Load the datasets with the correct column names
    train_data, valid_data, test_data = data_loading(train_data_path, validation_data_path, test_data_path)
    
    # Process target variable - convert to binary format
    # If the datasets already have headers, we'll need to skip the first row
    # Standardize the target variable name and format
    target_col_preprocess(train_data)
    target_col_preprocess(valid_data)
    # target_col_preprocess(test_data)

    # Clean up the data - strip whitespace from string columns
    for df in [train_data, valid_data, test_data]:
        for col in df.select_dtypes(include=['object']).columns:
            df[col] = df[col].str.strip()
    
    # Identify categorical and numerical attributes
    categorical_cols, numerical_cols = cat_num_attr(train_data)

    # Extract features and targets
    train_encoded, valid_encoded, test_encoded = apply_one_hot_encoding(train_data, valid_data, test_data, categorical_cols)
    ax_tr = 1
    X_train = train_encoded.drop(['income', 'income&gt;50K'], axis=ax_tr)
    y_train = train_encoded['income&gt;50K']
    X_valid = valid_encoded.drop(['income', 'income&gt;50K'], axis=1)
    # ax_te = 1
    y_valid = valid_encoded['income&gt;50K']
    X_test = test_encoded
    # X_test = test_encoded.drop(['income', 'income&gt;50K'], axis=ax_te)
    y_test = []
    # y_test = test_encoded['income&gt;50K']
    
    best_depth, train_accuracies, valid_accuracies, test_accuracies = part_i_vary_max_depth(X_train, y_train, X_valid, y_valid, X_test, y_test, output_folder_path, question_part)
    best_alpha, train_accuracies, valid_accuracies, test_accuracies = part_ii_vary_ccp_alpha(X_train, y_train, X_valid, y_valid, X_test, y_test, output_folder_path, question_part)

    dt = DecisionTreeClassifier(criterion='entropy', max_depth=best_depth, random_state=42, ccp_alpha=best_alpha)
    dt.fit(X_train, y_train)
    # Evaluate on test set
    test_pred = dt.predict(X_test)
    test_pred = list(map(lambda x: "&gt;50K" if x == 1 else "&lt;=50K", test_pred))
    # Create a DataFrame with the predictions
    prediction_df = pd.DataFrame({'prediction': test_pred})
    # Save to CSV
    output_file = os.path.join(output_folder_path, f"prediction_{question_part}.csv")
    prediction_df.to_csv(output_file, index=False)
    print(f"Predictions saved to {output_file}")

def e(train_data_path, validation_data_path, test_data_path, output_folder_path, question_part):
    # Create output directory if it doesn't exist
    os.makedirs(output_folder_path, exist_ok=True)
    # Load the datasets with the correct column names
    train_data, valid_data, test_data = data_loading(train_data_path, validation_data_path, test_data_path)
    
    # Process target variable - convert to binary format
    # If the datasets already have headers, we'll need to skip the first row
    # Standardize the target variable name and format
    target_col_preprocess(train_data)
    target_col_preprocess(valid_data)
    # target_col_preprocess(test_data)

    # Clean up the data - strip whitespace from string columns
    for df in [train_data, valid_data, test_data]:
        for col in df.select_dtypes(include=['object']).columns:
            df[col] = df[col].str.strip()
    
    # Identify categorical and numerical attributes
    categorical_cols, numerical_cols = cat_num_attr(train_data)

    # Extract features and targets
    train_encoded, valid_encoded, test_encoded = apply_one_hot_encoding(train_data, valid_data, test_data, categorical_cols)
    X_train = train_encoded.drop(['income', 'income&gt;50K'], axis=1)
    y_train = train_encoded['income&gt;50K']
    
    X_valid = valid_encoded.drop(['income', 'income&gt;50K'], axis=1)
    y_valid = valid_encoded['income&gt;50K']
    
    # X_test = test_encoded.drop(['income', 'income&gt;50K'], axis=1)
    X_test = test_encoded
    y_test = []
    # y_test = test_encoded['income&gt;50K']
    results, test_pred = train_random_forest_with_grid_search(X_train, y_train, X_valid, y_valid, X_test, y_test)
    # Create a DataFrame with the predictions
    test_pred = list(map(lambda x: "&gt;50K" if x == 1 else "&lt;=50K", test_pred))
    prediction_df = pd.DataFrame({'prediction': test_pred})
    
    # Save to CSV
    output_file = os.path.join(output_folder_path, f"prediction_{question_part}.csv")
    ind = False
    prediction_df.to_csv(output_file, index=ind)
    
    print(f"Predictions saved to {output_file}")
    # plot_results(max_depths_with_one_hot, train_accuracies, valid_accuracies, test_accuracies)
    
    
    

def main():
    # Check if correct number of arguments are provided
    if len(sys.argv) != 6:
        print("Usage: python decision_tree.py &lt;train_data_path&gt; &lt;validation_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
        sys.exit(1)
    
    # Parse command line arguments
    train_data_path = sys.argv[1]
    validation_data_path = sys.argv[2]
    test_data_path = sys.argv[3]
    output_folder_path = sys.argv[4]
    question_part = sys.argv[5]
    
    # Validate question part
    if question_part not in ['a', 'b', 'c', 'd', 'e']:
        print("Question part must be one of 'a', 'b', 'c', 'd', or 'e'")
        sys.exit(1)
    
    
    if question_part=='a':
        a(train_data_path, validation_data_path, test_data_path, output_folder_path, question_part)
    elif question_part=='b':
        b(train_data_path, validation_data_path, test_data_path, output_folder_path, question_part)
    elif question_part=='c':
        c(train_data_path, validation_data_path, test_data_path, output_folder_path, question_part)
    elif question_part=='d':
        d(train_data_path, validation_data_path, test_data_path, output_folder_path, question_part)
    elif question_part=='e':
        e(train_data_path, validation_data_path, test_data_path, output_folder_path, question_part)
        
    

if __name__ == "__main__":
    main()



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import cv2
import pickle
import math
import time
import sys
from tqdm import tqdm
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, precision_recall_fscore_support


def part_f(X_train, y_train, X_test, output_folder_path, question_part):
    """
    Implement neural networks using scikit-learn's MLPClassifier with the same architectures as in part (e).
    """
    # Define hidden layer configurations (same as parts c-e)
    layer_configs = [
        (512,),
        (512, 256),
        (512, 256, 128),
        (512, 256, 128, 64)
    ]
    
    # Results storage
    results = []
    network_depths = [len(config) for config in layer_configs]
    avg_f1_scores = []
    
    # Training parameters
    max_iter = 400  # Maximum iterations (epochs)
    batch_size = 32
    
    for i, hidden_layers in enumerate(layer_configs):
        print(f"\nTraining MLPClassifier with depth {len(hidden_layers)}: {hidden_layers}")
        start_time = time.time()
        
        # Create MLPClassifier with specified parameters
        mlp = MLPClassifier(
            hidden_layer_sizes=hidden_layers,
            activation='relu',           # Use ReLU activation
            solver='sgd',                # Stochastic Gradient Descent
            alpha=0,                     # No regularization
            batch_size=batch_size,       # Mini-batch size
            learning_rate='invscaling',  # Inverse scaling learning rate
            max_iter=max_iter,           # Maximum number of iterations
            learning_rate_init=0.01,     # Initial learning rate
            verbose=True,                # Print progress
            early_stopping=False,         # Use early stopping
            n_iter_no_change=17,         # Early stopping patience
            tol=1e-4                     # Tolerance for optimization
        )
        
        # Train the model
        mlp.fit(X_train, y_train)
        train_time = time.time() - start_time
        epochs_used = mlp.n_iter_
        # Make predictions
        y_train_pred = mlp.predict(X_train)
        y_test_pred = mlp.predict(X_test)
        test_pred = y_test_pred

        if i==3:
            # Create a DataFrame with the predictions
            prediction_df = pd.DataFrame({'prediction': test_pred})
            
            # Save to CSV
            output_file = os.path.join(output_folder_path, f"prediction_{question_part}.csv")
            prediction_df.to_csv(output_file, index=False)
            
            print(f"Predictions saved to {output_file}")
        
        # # Calculate metrics for each class on training data
        # train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(
        #     y_train, y_train_pred, average=None, zero_division=0
        # )
        
        # # Calculate metrics for each class on test data
        # test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(
        #     y_test, y_test_pred, average=None, zero_division=0
        # )

        # # Get class names (assuming y has categorical labels)
        # class_names = np.unique(np.concatenate([y_train, y_test]))
        
        # # Create a DataFrame for training metrics
        # train_metrics_df = pd.DataFrame({
        #     'Class': class_names,
        #     'Precision': train_precision,
        #     'Recall': train_recall,
        #     'F1 Score': train_f1
        # })
        
        # # Create a DataFrame for test metrics
        # test_metrics_df = pd.DataFrame({
        #     'Class': class_names,
        #     'Precision': test_precision,
        #     'Recall': test_recall,
        #     'F1 Score': test_f1
        # })
        
        # # Print tables
        # print("Training Metrics by Class:")
        # print(train_metrics_df.to_string(index=False))
        
        # print("\nTest Metrics by Class:")
        # print(test_metrics_df.to_string(index=False))
        
        # # Calculate average metrics
        # avg_train_precision = np.mean(train_precision)
        # avg_train_recall = np.mean(train_recall)
        # avg_train_f1 = np.mean(train_f1)
        
        # avg_test_precision = np.mean(test_precision)
        # avg_test_recall = np.mean(test_recall)
        # avg_test_f1 = np.mean(test_f1)
        
        # # Calculate test accuracy
        # test_accuracy = accuracy_score(y_test, y_test_pred)
        # train_accuracy = accuracy_score(y_train, y_train_pred)
        
        # # Store results
        # result = {
        #     'hidden_layers': hidden_layers,
        #     'network_depth': len(hidden_layers),
        #     'train_precision': train_precision,
        #     'train_recall': train_recall,
        #     'train_f1': train_f1,
        #     'test_precision': test_precision,
        #     'test_recall': test_recall,
        #     'test_f1': test_f1,
        #     'avg_train_precision': avg_train_precision,
        #     'avg_train_recall': avg_train_recall,
        #     'avg_train_f1': avg_train_f1,
        #     'avg_test_precision': avg_test_precision,
        #     'avg_test_recall': avg_test_recall,
        #     'avg_test_f1': avg_test_f1,
        #     'test_accuracy': test_accuracy,
        #     'train_accuracy': train_accuracy,
        #     'epochs_trained': epochs_used,
        #     'training_time': train_time,
        #     'loss_curve': mlp.loss_curve_ if hasattr(mlp, 'loss_curve_') else None
        # }
        
        # results.append(result)
        # avg_f1_scores.append(avg_test_f1)
        
        # # Print summary
        # print(f"Hidden Layers: {hidden_layers}")
        # print(f"Epochs trained: {epochs_used}")
        # print(f"Training time: {train_time:.2f} seconds")
        # print(f"Average Training - Precision: {avg_train_precision:.4f}, Recall: {avg_train_recall:.4f}, F1: {avg_train_f1:.4f}")
        # print(f"Average Test - Precision: {avg_test_precision:.4f}, Recall: {avg_test_recall:.4f}, F1: {avg_test_f1:.4f}")
        # print(f"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")

    
    # # Plot average F1 score vs. network depth
    # plt.figure(figsize=(10, 6))
    # plt.plot(network_depths, avg_f1_scores, marker='o', linestyle='-', linewidth=2, color='purple')
    # plt.title('Average F1 Score vs. Network Depth (scikit-learn MLPClassifier)')
    # plt.xlabel('Network Depth (Number of Hidden Layers)')
    # plt.ylabel('Average F1 Score')
    # plt.grid(True)
    # plt.xticks(network_depths)
    
    # # Add data labels to points
    # for i, txt in enumerate(avg_f1_scores):
    #     plt.annotate(f"{txt:.4f}", 
    #                 (network_depths[i], avg_f1_scores[i]),
    #                 textcoords="offset points", 
    #                 xytext=(0,10), 
    #                 ha='center')
    
    # plt.tight_layout()
    # plt.savefig('f1_vs_network_depth_sklearn.png')
    # plt.show()
    
    # # Plot loss curves if available
    # plt.figure(figsize=(12, 6))
    # for i, result in enumerate(results):
    #     if result['loss_curve'] is not None:
    #         plt.plot(result['loss_curve'], label=f"Depth {result['network_depth']}: {result['hidden_layers']}")
    
    # plt.title('Loss Curves for Different Network Depths')
    # plt.xlabel('Iterations')
    # plt.ylabel('Loss')
    # plt.grid(True)
    # plt.legend()
    # plt.tight_layout()
    # plt.savefig('sklearn_loss_curves.png')
    # plt.show()
    
    # return results

def part_e(X_train, y_train, X_test, output_folder_path, question_part):
    # Vary hidden layer configurations
    layer_configs = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]
    network_depths = [len(config) for config in layer_configs]
    mini_batch = 32
    initial_lr = 0.01  # η_0 seed value
    n = 2352  # (28 × 28 × 3)    
    # Results storage
    results = []
    r = 43    # number of traffic sign classes
    avg_f1_scores = []
    
    for i, hidden_layers in enumerate(layer_configs):
        print(f"\nTraining ReLU network with depth {len(hidden_layers)}: {hidden_layers}")
        
        # Create ReLU neural network
        nn = ReLUNeuralNetwork(
            input_size=n,
            hidden_layers=hidden_layers,
            output_size=r,
            mini_batch_size=mini_batch,
            initial_learning_rate=initial_lr
        )
        
        # Train the model with ReLU activation and adaptive learning rate
        history = nn.train(
            X_train=X_train,
            y_train=y_train,
            epochs=400,  # Same as part (d)
            patience=15,  # Same as part (d)
            min_delta=0.0005  # Same as part (d)
        )
        
        # Make predictions
        y_train_pred = nn.predict(X_train)
        y_test_pred = nn.predict(X_test)
        test_pred = y_test_pred

        if i==3:
            # Create a DataFrame with the predictions
            prediction_df = pd.DataFrame({'prediction': test_pred})
            
            # Save to CSV
            output_file = os.path.join(output_folder_path, f"prediction_{question_part}.csv")
            prediction_df.to_csv(output_file, index=False)
            
            print(f"Predictions saved to {output_file}")
        
        
        # # Calculate metrics for each class on training data
        # train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(
        #     y_train, y_train_pred, average=None, zero_division=0
        # )
        
        # # Calculate metrics for each class on test data
        # test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(
        #     y_test, y_test_pred, average=None, zero_division=0
        # )

        # # Get class names (assuming y has categorical labels)
        # class_names = np.unique(np.concatenate([y_train, y_test]))
        
        # # Create a DataFrame for training metrics
        # train_metrics_df = pd.DataFrame({
        #     'Class': class_names,
        #     'Precision': train_precision,
        #     'Recall': train_recall,
        #     'F1 Score': train_f1
        # })
        
        # # Create a DataFrame for test metrics
        # test_metrics_df = pd.DataFrame({
        #     'Class': class_names,
        #     'Precision': test_precision,
        #     'Recall': test_recall,
        #     'F1 Score': test_f1
        # })
        
        # # Print tables
        # print("Training Metrics by Class:")
        # print(train_metrics_df.to_string(index=False))
        
        # print("\nTest Metrics by Class:")
        # print(test_metrics_df.to_string(index=False))
        
        # # Calculate average metrics
        # avg_train_precision = np.mean(train_precision)
        # avg_train_recall = np.mean(train_recall)
        # avg_train_f1 = np.mean(train_f1)
        
        # avg_test_precision = np.mean(test_precision)
        # avg_test_recall = np.mean(test_recall)
        # avg_test_f1 = np.mean(test_f1)
        
        # # Calculate test accuracy
        # test_accuracy = accuracy_score(y_test, y_test_pred)
        
        # # Store results
        # result = {
        #     'hidden_layers': hidden_layers,
        #     'network_depth': len(hidden_layers),
        #     'train_precision': train_precision,
        #     'train_recall': train_recall,
        #     'train_f1': train_f1,
        #     'test_precision': test_precision,
        #     'test_recall': test_recall,
        #     'test_f1': test_f1,
        #     'avg_train_precision': avg_train_precision,
        #     'avg_train_recall': avg_train_recall,
        #     'avg_train_f1': avg_train_f1,
        #     'avg_test_precision': avg_test_precision,
        #     'avg_test_recall': avg_test_recall,
        #     'avg_test_f1': avg_test_f1,
        #     'test_accuracy': test_accuracy,
        #     'epochs_trained': len(history['train_loss']),
        #     'history': history
        # }
        
    #     results.append(result)
    #     avg_f1_scores.append(avg_test_f1)
        
    #     # Print summary
    #     print(f"Hidden Layers: {hidden_layers}")
    #     print(f"Epochs trained: {len(history['train_loss'])}")
    #     print(f"Average Training - Precision: {avg_train_precision:.4f}, Recall: {avg_train_recall:.4f}, F1: {avg_train_f1:.4f}")
    #     print(f"Average Test - Precision: {avg_test_precision:.4f}, Recall: {avg_test_recall:.4f}, F1: {avg_test_f1:.4f}")
    #     print(f"Test Accuracy: {test_accuracy:.4f}")

    
    # # Plot average F1 score vs. network depth
    # plt.figure(figsize=(10, 6))
    # plt.plot(network_depths, avg_f1_scores, marker='o', linestyle='-', linewidth=2, color='green')
    # plt.title('Average F1 Score vs. Network Depth (ReLU with Adaptive Learning Rate)')
    # plt.xlabel('Network Depth (Number of Hidden Layers)')
    # plt.ylabel('Average F1 Score')
    # plt.grid(True)
    # plt.xticks(network_depths)
    
    # # Add data labels to points
    # for i, txt in enumerate(avg_f1_scores):
    #     plt.annotate(f"{txt:.4f}", 
    #                 (network_depths[i], avg_f1_scores[i]),
    #                 textcoords="offset points", 
    #                 xytext=(0,10), 
    #                 ha='center')
    
    # plt.tight_layout()
    # plt.savefig('f1_vs_network_depth_relu.png')
    # plt.show()
    
    # return results

def part_d(X_train, y_train, X_test, output_folder_path, question_part):
    initial_lr = 0.01  # η_0 seed value
    # Vary hidden layer configurations
    layer_configs = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]
    results = []
    mini_batch = 32
    n = 2352  # (28 × 28 × 3)
    network_depths = [len(config) for config in layer_configs]
    r = 43    # number of traffic sign classes
    
    # Results storage
    avg_f1_scores = []
    
    for i, hidden_layers in enumerate(layer_configs):
        print(f"\nTraining network with depth {len(hidden_layers)}: {hidden_layers}")
        
        # Create neural network
        nn = AdaptiveLRNeuralNetwork(
            input_size=n,
            hidden_layers=hidden_layers,
            output_size=r,
            mini_batch_size=mini_batch,
            initial_learning_rate=initial_lr
        )
        
        # Train the model with adaptive learning rate
        history = nn.train(
            X_train=X_train,
            y_train=y_train,
            epochs=400,  # Increased max epochs due to slower convergence with adaptive LR
            patience=15,  # Increased patience for more stable stopping
            min_delta=0.0005  # Reduced min_delta for finer convergence detection
        )
        
        # Make predictions
        y_train_pred = nn.predict(X_train)
        y_test_pred = nn.predict(X_test)
        test_pred = y_test_pred

        if i==3:
            # Create a DataFrame with the predictions
            prediction_df = pd.DataFrame({'prediction': test_pred})
            
            # Save to CSV
            output_file = os.path.join(output_folder_path, f"prediction_{question_part}.csv")
            prediction_df.to_csv(output_file, index=False)
            
            print(f"Predictions saved to {output_file}")
        
    #     # Calculate metrics for each class on training data
    #     train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(
    #         y_train, y_train_pred, average=None, zero_division=0
    #     )
        
    #     # Calculate metrics for each class on test data
    #     test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(
    #         y_test, y_test_pred, average=None, zero_division=0
    #     )

    #     # Get class names (assuming y has categorical labels)
    #     class_names = np.unique(np.concatenate([y_train, y_test]))
        
    #     # Create a DataFrame for training metrics
    #     train_metrics_df = pd.DataFrame({
    #         'Class': class_names,
    #         'Precision': train_precision,
    #         'Recall': train_recall,
    #         'F1 Score': train_f1
    #     })
        
    #     # Create a DataFrame for test metrics
    #     test_metrics_df = pd.DataFrame({
    #         'Class': class_names,
    #         'Precision': test_precision,
    #         'Recall': test_recall,
    #         'F1 Score': test_f1
    #     })
        
    #     # Print tables
    #     print("Training Metrics by Class:")
    #     print(train_metrics_df.to_string(index=False))
        
    #     print("\nTest Metrics by Class:")
    #     print(test_metrics_df.to_string(index=False))
        
    #     # Calculate average metrics
    #     avg_train_precision = np.mean(train_precision)
    #     avg_train_recall = np.mean(train_recall)
    #     avg_train_f1 = np.mean(train_f1)
        
    #     avg_test_precision = np.mean(test_precision)
    #     avg_test_recall = np.mean(test_recall)
    #     avg_test_f1 = np.mean(test_f1)
        
    #     # Store results
    #     result = {
    #         'hidden_layers': hidden_layers,
    #         'network_depth': len(hidden_layers),
    #         'train_precision': train_precision,
    #         'train_recall': train_recall,
    #         'train_f1': train_f1,
    #         'test_precision': test_precision,
    #         'test_recall': test_recall,
    #         'test_f1': test_f1,
    #         'avg_train_precision': avg_train_precision,
    #         'avg_train_recall': avg_train_recall,
    #         'avg_train_f1': avg_train_f1,
    #         'avg_test_precision': avg_test_precision,
    #         'avg_test_recall': avg_test_recall,
    #         'avg_test_f1': avg_test_f1,
    #         'epochs_trained': len(history['train_loss']),
    #         'history': history
    #     }
        
    #     results.append(result)
    #     avg_f1_scores.append(avg_test_f1)
        
    #     # Print summary
    #     print(f"Hidden Layers: {hidden_layers}")
    #     print(f"Epochs trained: {len(history['train_loss'])}")
    #     print(f"Average Training - Precision: {avg_train_precision:.4f}, Recall: {avg_train_recall:.4f}, F1: {avg_train_f1:.4f}")
    #     print(f"Average Test - Precision: {avg_test_precision:.4f}, Recall: {avg_test_recall:.4f}, F1: {avg_test_f1:.4f}")

    
    # # Plot average F1 score vs. network depth
    # plt.figure(figsize=(10, 6))
    # plt.plot(network_depths, avg_f1_scores, marker='o', linestyle='-', linewidth=2, color='orange')
    # plt.title('Average F1 Score vs. Network Depth (Adaptive Learning Rate)')
    # plt.xlabel('Network Depth (Number of Hidden Layers)')
    # plt.ylabel('Average F1 Score')
    # plt.grid(True)
    # plt.xticks(network_depths)
    
    # # Add data labels to points
    # for i, txt in enumerate(avg_f1_scores):
    #     plt.annotate(f"{txt:.4f}", 
    #                 (network_depths[i], avg_f1_scores[i]),
    #                 textcoords="offset points", 
    #                 xytext=(0,10), 
    #                 ha='center')
    
    # plt.tight_layout()
    # plt.savefig('f1_vs_network_depth_adaptive_lr.png')
    # plt.show()
    
    # return results

def part_c(X_train, y_train, X_test, output_folder_path, question_part):
    r = 43    # number of traffic sign classes
    # Vary hidden layer configurations
    layer_configs = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]
    # Results storage
    avg_f1_scores = []
    mini_batch = 32
    results = []
    n = 2352  # (28 × 28 × 3)
    network_depths = [len(config) for config in layer_configs]
    lr = 0.01
    
    for i, hidden_layers in enumerate(layer_configs):
        print(f"\nTraining network with depth {len(hidden_layers)}: {hidden_layers}")
        
        # Create and train the neural network
        nn = NeuralNetwork(
            input_size=n,
            hidden_layers=hidden_layers,
            output_size=r,
            mini_batch_size=mini_batch,
            learning_rate=lr
        )
        
        # Train the model
        history = nn.train(
            X_train=X_train,
            y_train=y_train,
            epochs=400
        )
        
        # Make predictions on training and test data
        y_train_pred = nn.predict(X_train)
        y_test_pred = nn.predict(X_test)
        test_pred = y_test_pred

        if i==3:
            # Create a DataFrame with the predictions
            prediction_df = pd.DataFrame({'prediction': test_pred})
            
            # Save to CSV
            output_file = os.path.join(output_folder_path, f"prediction_{question_part}.csv")
            prediction_df.to_csv(output_file, index=False)
            
            print(f"Predictions saved to {output_file}")
        
    #     # Calculate metrics for each class on training data
    #     train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(
    #         y_train, y_train_pred, average=None, zero_division=0
    #     )
        
    #     # Calculate metrics for each class on test data
    #     test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(
    #         y_test, y_test_pred, average=None, zero_division=0
    #     )

    #     # Get class names (assuming y has categorical labels)
    #     class_names = np.unique(np.concatenate([y_train, y_test]))
        
    #     # Create a DataFrame for training metrics
    #     train_metrics_df = pd.DataFrame({
    #         'Class': class_names,
    #         'Precision': train_precision,
    #         'Recall': train_recall,
    #         'F1 Score': train_f1
    #     })
        
    #     # Create a DataFrame for test metrics
    #     test_metrics_df = pd.DataFrame({
    #         'Class': class_names,
    #         'Precision': test_precision,
    #         'Recall': test_recall,
    #         'F1 Score': test_f1
    #     })
        
    #     # Print tables
    #     print("Training Metrics by Class:")
    #     print(train_metrics_df.to_string(index=False))
        
    #     print("\nTest Metrics by Class:")
    #     print(test_metrics_df.to_string(index=False))
        
    #     # Calculate average metrics
    #     avg_train_precision = np.mean(train_precision)
    #     avg_train_recall = np.mean(train_recall)
    #     avg_train_f1 = np.mean(train_f1)
        
    #     avg_test_precision = np.mean(test_precision)
    #     avg_test_recall = np.mean(test_recall)
    #     avg_test_f1 = np.mean(test_f1)
        
    #     # Store results
    #     result = {
    #         'hidden_layers': hidden_layers,
    #         'network_depth': len(hidden_layers),
    #         'train_precision': train_precision,
    #         'train_recall': train_recall,
    #         'train_f1': train_f1,
    #         'test_precision': test_precision,
    #         'test_recall': test_recall,
    #         'test_f1': test_f1,
    #         'avg_train_precision': avg_train_precision,
    #         'avg_train_recall': avg_train_recall,
    #         'avg_train_f1': avg_train_f1,
    #         'avg_test_precision': avg_test_precision,
    #         'avg_test_recall': avg_test_recall,
    #         'avg_test_f1': avg_test_f1,
    #         'history': history
    #     }
        
    #     results.append(result)
    #     avg_f1_scores.append(avg_test_f1)
        
    #     # Print summary
    #     print(f"Hidden Layers: {hidden_layers}")
    #     print(f"Average Training - Precision: {avg_train_precision:.4f}, Recall: {avg_train_recall:.4f}, F1: {avg_train_f1:.4f}")
    #     print(f"Average Test - Precision: {avg_test_precision:.4f}, Recall: {avg_test_recall:.4f}, F1: {avg_test_f1:.4f}")

    # # Create a table of results
    # print("\nSummary of Results:")
    # print("-" * 80)
    # print(f"{'Network Depth':&lt;15} {'Hidden Layers':&lt;30} {'Train F1':&lt;10} {'Test F1':&lt;10}")
    # print("-" * 80)
    # for result in results:
    #     hidden_str = str(result['hidden_layers'])
    #     print(f"{result['network_depth']:&lt;15} {hidden_str:&lt;30} {result['avg_train_f1']:.4f}     {result['avg_test_f1']:.4f}")

    # # Plot average F1 score vs. network depth
    # plt.figure(figsize=(10, 6))
    # plt.plot(network_depths, avg_f1_scores, marker='o', linestyle='-', linewidth=2)
    # plt.title('Average F1 Score vs. Network Depth')
    # plt.xlabel('Network Depth (Number of Hidden Layers)')
    # plt.ylabel('Average F1 Score')
    # plt.grid(True)
    # plt.xticks(network_depths)
    
    # # Add data labels to points
    # for i, txt in enumerate(avg_f1_scores):
    #     plt.annotate(f"{txt:.4f}", 
    #                 (network_depths[i], avg_f1_scores[i]),
    #                 textcoords="offset points", 
    #                 xytext=(0,10), 
    #                 ha='center')
    
    # plt.tight_layout()
    # plt.savefig('f1_vs_network_depth.png')
    # plt.show()
    
    # return results

def part_b(X_train, y_train, X_test, output_folder_path, question_part):
    lr = 0.01
    n = 2352 #(28 × 28 × 3)
    r = 43
    mini_batch = 32

    # Results storage
    layers = [[1], [5], [10], [50], [100]]
    results = []
    avg_f1_scores = []
    
    for i in range(len(layers)):
        hidden_layer = layers[i]
        units = hidden_layer[0]
        # Create and train the neural network
        nn = NeuralNetwork(
            input_size=n,
            hidden_layers=hidden_layer,
            output_size=r,
            mini_batch_size=mini_batch,
            learning_rate=lr
        )
        
        # Train the model
        history = nn.train(
            X_train=X_train,
            y_train=y_train,
            epochs=400
        )
        # Make predictions on training and test data
        y_train_pred = nn.predict(X_train)
        y_test_pred = nn.predict(X_test)
        test_pred = y_test_pred

        if i==4:
            # Create a DataFrame with the predictions
            prediction_df = pd.DataFrame({'prediction': test_pred})
            
            # Save to CSV
            output_file = os.path.join(output_folder_path, f"prediction_{question_part}.csv")
            prediction_df.to_csv(output_file, index=False)
            
            print(f"Predictions saved to {output_file}")
        
    #     # Calculate metrics for each class on training data
    #     train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(
    #         y_train, y_train_pred, average=None, zero_division=0
    #     )
        
    #     # Calculate metrics for each class on test data
    #     test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(
    #         y_test, y_test_pred, average=None, zero_division=0
    #     )
        

    #     # Get class names (assuming y has categorical labels)
    #     class_names = np.unique(np.concatenate([y_train, y_test]))
        
    #     # Create a DataFrame for training metrics
    #     train_metrics_df = pd.DataFrame({
    #         'Class': class_names,
    #         'Precision': train_precision,
    #         'Recall': train_recall,
    #         'F1 Score': train_f1
    #     })
        
    #     # Create a DataFrame for test metrics
    #     test_metrics_df = pd.DataFrame({
    #         'Class': class_names,
    #         'Precision': test_precision,
    #         'Recall': test_recall,
    #         'F1 Score': test_f1
    #     })
        
    #     # Print tables
    #     print("Training Metrics by Class:")
    #     print(train_metrics_df.to_string(index=False))
        
    #     print("\nTest Metrics by Class:")
    #     print(test_metrics_df.to_string(index=False))
        
    #     # Calculate average metrics
    #     avg_train_precision = np.mean(train_precision)
    #     avg_train_recall = np.mean(train_recall)
    #     avg_train_f1 = np.mean(train_f1)
        
    #     avg_test_precision = np.mean(test_precision)
    #     avg_test_recall = np.mean(test_recall)
    #     avg_test_f1 = np.mean(test_f1)
        
    #     # Store results
    #     result = {
    #         'hidden_units': units,
    #         'train_precision': train_precision,
    #         'train_recall': train_recall,
    #         'train_f1': train_f1,
    #         'test_precision': test_precision,
    #         'test_recall': test_recall,
    #         'test_f1': test_f1,
    #         'avg_train_precision': avg_train_precision,
    #         'avg_train_recall': avg_train_recall,
    #         'avg_train_f1': avg_train_f1,
    #         'avg_test_precision': avg_test_precision,
    #         'avg_test_recall': avg_test_recall,
    #         'avg_test_f1': avg_test_f1,
    #         'history': history
    #     }
        
    #     results.append(result)
    #     avg_f1_scores.append(avg_test_f1)
    #     # # Print summary
    #     print(f"Hidden Units: {units}")
    #     print(f"Average Training - Precision: {avg_train_precision:.4f}, Recall: {avg_train_recall:.4f}, F1: {avg_train_f1:.4f}")
    #     print(f"Average Test - Precision: {avg_test_precision:.4f}, Recall: {avg_test_recall:.4f}, F1: {avg_test_f1:.4f}")

    # hidden_units_options = [1, 5, 10, 50, 100]
    # # Plot average F1 score vs. number of hidden units
    # plt.figure(figsize=(10, 6))
    # plt.plot(hidden_units_options, avg_f1_scores, marker='o', linestyle='-')
    # plt.title('Average F1 Score vs. Number of Hidden Units')
    # plt.xlabel('Number of Hidden Units')
    # plt.ylabel('Average F1 Score')
    # plt.grid(True)
    # plt.savefig('f1_vs_hidden_units.png')
    # plt.show()
    
    

class NeuralNetwork:

    def __init__(self, input_size, hidden_layers, output_size, mini_batch_size, learning_rate=0.01):
        # Store all parameters in a dictionary
        self.params = {
            'architecture': {
                'input_size': input_size,
                'hidden_layers': hidden_layers,
                'output_size': output_size
            },
            'training': {
                'mini_batch_size': mini_batch_size,
                'learning_rate': learning_rate
            },
            'weights': [],
            'biases': []
        }
        
        # Initialize weights and biases
        # Input layer to first hidden layer
        prev_layer_size = self.params['architecture']['input_size']
        for layer_size in self.params['architecture']['hidden_layers']:
            # Xavier/Glorot initialization for better convergence
            self.params['weights'].append(
                np.random.randn(prev_layer_size, layer_size) * 
                np.sqrt(2.0 / (prev_layer_size + layer_size))
            )
            self.params['biases'].append(np.zeros((1, layer_size)))
            prev_layer_size = layer_size
        
        # Last hidden layer to output layer
        output_size = self.params['architecture']['output_size']
        self.params['weights'].append(
            np.random.randn(prev_layer_size, self.params['architecture']['output_size']) * 
            np.sqrt(2.0 / (prev_layer_size + self.params['architecture']['output_size']))
        )
        self.params['biases'].append(np.zeros((1, output_size)))
    
    def sigmoid(self, x):
        n = 1.0
        n_e = np.exp(-np.clip(x, -500, 500))
        d = (1.0 + n_e)
        return n / d  # Clip to avoid overflow
    
    def sigmoid_derivative(self, x):
        sigmoid_x = self.sigmoid(x)
        sig_1 = (1 - sigmoid_x)
        return sigmoid_x * sig_1
    
    def softmax(self, x):
        # Shift x for numerical stability (to avoid overflow)
        shifted_x = x - np.max(x, axis=1, keepdims=True)
        exp_x = np.exp(shifted_x)
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def cross_entropy_loss(self, y_true, y_pred):
        # Add small epsilon to avoid log(0)
        epsilon = 1e-15
        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)
        return -np.sum(y_true * np.log(y_pred)) / y_true.shape[0]

    def forward(self, X):
        # Initialize new parameters in the dictionary for tracking state
        self.params['layer_inputs'] = []
        self.params['activations'] = [X]  # First activation is the input itself
        
        # Process through hidden layers with sigmoid activation
        curr_activation = X
        for i in range(len(self.params['architecture']['hidden_layers'])):
            z = np.dot(curr_activation, self.params['weights'][i]) + self.params['biases'][i]
            self.params['layer_inputs'].append(z)
            curr_activation = self.sigmoid(z)
            self.params['activations'].append(curr_activation)
        
        # Process through output layer with softmax activation
        z_out = np.dot(curr_activation, self.params['weights'][-1]) + self.params['biases'][-1]
        self.params['layer_inputs'].append(z_out)
        output = self.softmax(z_out)
        self.params['activations'].append(output)
        
        return output

    def backward(self, X, y):
        """Backward pass through the network (backpropagation)"""
        m = X.shape[0]
        num_layers = len(self.params['weights'])
        
        # Convert labels to one-hot encoding if they're not already
        if len(y.shape) == 1:
            y_one_hot = np.zeros((m, self.params['architecture']['output_size']))
            y_one_hot[np.arange(m), y] = 1
        else:
            y_one_hot = y
        
        # Initialize gradients
        weight_gradients = [np.zeros_like(w) for w in self.params['weights']]
        bias_gradients = [np.zeros_like(b) for b in self.params['biases']]
        
        # Output layer error: delta = (output - y_true)
        # This is the gradient of cross-entropy loss with respect to softmax input
        delta = self.params['activations'][-1] - y_one_hot
        
        # Output layer gradients
        weight_gradients[-1] = np.dot(self.params['activations'][-2].T, delta) / m
        bias_gradients[-1] = np.sum(delta, axis=0, keepdims=True) / m
        
        # Backpropagate through hidden layers
        for l in range(num_layers - 2, -1, -1):
            # Calculate error for current layer
            delta = np.dot(delta, self.params['weights'][l+1].T) * self.sigmoid_derivative(self.params['layer_inputs'][l])
            
            # Calculate gradients
            weight_gradients[l] = np.dot(self.params['activations'][l].T, delta) / m
            bias_gradients[l] = np.sum(delta, axis=0, keepdims=True) / m
        
        return weight_gradients, bias_gradients

    def update_parameters(self, weight_gradients, bias_gradients):
        learning_rate = self.params['training']['learning_rate']
        for i in range(len(self.params['weights'])):
            self.params['weights'][i] -= learning_rate * weight_gradients[i]
            self.params['biases'][i] -= learning_rate * bias_gradients[i]
    
    def predict(self, X):
        """Predict class labels for samples in X"""
        probabilities = self.forward(X)
        ax_np = 0+1
        return np.argmax(probabilities, axis=ax_np)

    def train(self, X_train, y_train, epochs=13, patience=3, min_delta=0.001, verbose=True):
        train_accuracies = []
        m = X_train.shape[0]
        mini_batch_size = self.params['training']['mini_batch_size']
        n_batches = m // mini_batch_size
        train_losses = []
        output_size = self.params['architecture']['output_size']
                
        # Convert labels to one-hot encoding if they're not already
        if len(y_train.shape) == 1:
            y_train_one_hot = np.zeros((m, self.params['architecture']['output_size']))
            y_train_one_hot[np.arange(m), y_train] = 1
        else:
            y_train_one_hot = y_train
        
        # Early stopping variables
        prev_loss = float('inf')
        best_train_loss = float('inf')
        patience_counter = 0
        for epoch in range(epochs):
            
            # Shuffle training data
            indices = np.random.permutation(m)
            X_shuffled = X_train[indices]
            y_shuffled = y_train[indices]
            y_one_hot_shuffled = y_train_one_hot[indices]
            
            # Mini-batch training
            for i in range(n_batches):
                start_idx = i * self.params['training']['mini_batch_size']
                end_idx = min((i + 1) * self.params['training']['mini_batch_size'], m)
                
                X_batch = X_shuffled[start_idx:end_idx]
                y_batch_one_hot = y_one_hot_shuffled[start_idx:end_idx]
                # Forward pass
                self.forward(X_batch)
                # Backward pass
                weight_gradients, bias_gradients = self.backward(X_batch, y_batch_one_hot)
                # Update parameters
                self.update_parameters(weight_gradients, bias_gradients)
            
            # Calculate training loss and accuracy at the end of each epoch
            train_preds = self.forward(X_train)
            train_loss = self.cross_entropy_loss(y_train_one_hot, train_preds)
            train_losses.append(train_loss)

            ax_t = 1
            train_accuracy = accuracy_score(y_train, np.argmax(train_preds, axis=ax_t))
            train_accuracies.append(train_accuracy)
            
            if verbose:
                print(f"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}")
            
            # Early stopping check
            if abs(train_loss-prev_loss) &lt;= min_delta:
                print(f"Early stopping triggered after {epoch+1} epochs")
                break
            prev_loss = train_loss
        
        history = {
            'train_loss': train_losses,
            'train_accuracy': train_accuracies
        }
        
        return history


class AdaptiveLRNeuralNetwork(NeuralNetwork):
    def __init__(self, input_size, hidden_layers, output_size, mini_batch_size, initial_learning_rate=0.01):
        super().__init__(input_size, hidden_layers, output_size, mini_batch_size, learning_rate=initial_learning_rate)
        self.lr_history = []  # Track learning rate changes
        self.params['training']['initial_learning_rate'] = initial_learning_rate
    
    def get_adaptive_learning_rate(self, epoch):
        # Add 1 to epoch since we're 0-indexed but formula assumes 1-indexed
        e_1 = epoch + 1
        epoch_for_calc = max(1, e_1)
        return self.params['training']['initial_learning_rate'] / np.sqrt(epoch_for_calc)
    
    def train(self, X_train, y_train, epochs=100, patience=3, min_delta=0.001, verbose=True):
        train_losses = []
        m = X_train.shape[0]
        mini_batch_size = self.params['training']['mini_batch_size']
        output_size = self.params['architecture']['output_size']
        train_accuracies = []
        n_batches = m // self.params['training']['mini_batch_size']
        
        self.lr_history = []
        
        # Convert labels to one-hot encoding if they're not already
        if len(y_train.shape) == 1:
            y_train_one_hot = np.zeros((m, self.params['architecture']['output_size']))
            y_train_one_hot[np.arange(m), y_train] = 1
        else:
            y_train_one_hot = y_train
        
        # Early stopping variables
        prev_loss = float('inf')
        best_train_loss = float('inf')
        patience_counter = 0
        
        for epoch in range(epochs):
            # Update learning rate based on epoch
            self.params['training']['learning_rate'] = self.get_adaptive_learning_rate(epoch)
            self.lr_history.append(self.params['training']['learning_rate'])
            
            # Shuffle training data
            indices = np.random.permutation(m)
            X_shuffled = X_train[indices]
            y_shuffled = y_train[indices]
            y_one_hot_shuffled = y_train_one_hot[indices]
            
            # Mini-batch training
            for i in range(n_batches):
                start_idx = i * self.params['training']['mini_batch_size']
                end_idx = min((i + 1) * self.params['training']['mini_batch_size'], m)
                
                X_batch = X_shuffled[start_idx:end_idx]                
                # Forward pass
                self.forward(X_batch)
                # Backward pass
                y_batch_one_hot = y_one_hot_shuffled[start_idx:end_idx]
                weight_gradients, bias_gradients = self.backward(X_batch, y_batch_one_hot)
                # Update parameters
                self.update_parameters(weight_gradients, bias_gradients)
            
            # Calculate training loss and accuracy at the end of each epoch
            train_preds = self.forward(X_train)
            train_loss = self.cross_entropy_loss(y_train_one_hot, train_preds)
            train_losses.append(train_loss)
            ax_t = 0+1
            np_amax = np.argmax(train_preds, axis=ax_t)
            train_accuracy = accuracy_score(y_train, np_amax)
            train_accuracies.append(train_accuracy)


            # # Early stopping check - modified for adaptive learning rate
            # if train_loss &lt; best_train_loss - min_delta:
            #     best_train_loss = train_loss
            #     patience_counter = 0
            # else:
            #     patience_counter += 1
            
            if verbose:
                print()
            
            # # If no improvement for 'patience' epochs, stop training
            # if patience_counter &gt;= patience:
            #     print(f"Early stopping triggered after {epoch+1} epochs")
            #     break
            
            # Extra check to avoid overshooting with too small learning rates
            # if self.learning_rate &lt; 1e-5:
            #     print(f"Learning rate too small ({self.learning_rate:.8f}). Stopping training.")
            #     break

            if abs(train_loss-prev_loss)&lt;=min_delta:
                print(f"Early stopping triggered after {epoch+1} epochs")
                break
            prev_loss = train_loss
        
        history = {
            'train_loss': train_losses,
            'train_accuracy': train_accuracies,
            'learning_rates': self.lr_history
        }
        
        return history

class ReLUNeuralNetwork(AdaptiveLRNeuralNetwork):
    def __init__(self, input_size, hidden_layers, output_size, mini_batch_size, initial_learning_rate=0.01):
        super().__init__(input_size, hidden_layers, output_size, mini_batch_size, initial_learning_rate)
        
    def relu(self, x):
        return np.maximum(0, x)
    
    def relu_derivative(self, x):
        derivative = np.zeros_like(x)
        derivative[x &gt; 0] = 1.0
        derivative[x == 0] = 0.5  # Subgradient at point of non-differentiability
        return derivative

    def forward(self, X):
        self.layer_inputs = []
        self.activations = [X]  # First activation is the input itself
        
        # Process through hidden layers with ReLU activation
        curr_activation = X
        for i in range(len(self.params['architecture']['hidden_layers'])):
            z = np.dot(curr_activation, self.params['weights'][i]) + self.params['biases'][i]
            self.layer_inputs.append(z)
            curr_activation = self.relu(z)  # ReLU activation for hidden layers
            self.activations.append(curr_activation)
        
        # Process through output layer with softmax activation
        z_out = np.dot(curr_activation, self.params['weights'][-1]) + self.params['biases'][-1]
        self.layer_inputs.append(z_out)
        output = self.softmax(z_out)  # Softmax for output layer
        self.activations.append(output)
        
        return output

    def backward(self, X, y):
        m = X.shape[0]
        num_layers = len(self.params['weights'])
        output_size = self.params['architecture']['output_size']
        
        # Convert labels to one-hot encoding if they're not already
        if len(y.shape) == 1:
            y_one_hot = np.zeros((m, self.params['architecture']['output_size']))
            y_one_hot[np.arange(m), y] = 1
        else:
            y_one_hot = y
        
        # Initialize gradients
        weight_gradients = [np.zeros_like(w) for w in self.params['weights']]
        bias_gradients = [np.zeros_like(b) for b in self.params['biases']]
        
        # Output layer error: delta = (output - y_true)
        # This is the gradient of cross-entropy loss with respect to softmax input
        delta = self.activations[-1] - y_one_hot
        
        # Output layer gradients
        np_dot = np.dot(self.activations[-2].T, delta)
        weight_gradients[-1] = np_dot / m
        k_d = True
        ax = 0
        np_sum = np.sum(delta, axis=ax, keepdims=k_d)
        bias_gradients[-1] = np_sum / m
        
        # Backpropagate through hidden layers (using ReLU derivative)
        for l in range(len(self.params['weights']) - 2, -1, -1):
            # Calculate error for current layer with ReLU derivative
            delta = np.dot(delta, self.params['weights'][l+1].T) * self.relu_derivative(self.layer_inputs[l])
            
            # Calculate gradients
            np_dot = np.dot(self.activations[l].T, delta)
            weight_gradients[l] = np_dot / m
            np_sum = np.sum(delta, axis=0, keepdims=True)
            bias_gradients[l] = np_sum / m
        
        return weight_gradients, bias_gradients
    

# Function to load and preprocess the GTSRB dataset
def load_data(train_data_path, test_data_path):
    """
    Load the GTSRB dataset where:
    - train directory contains folders '00000' to '00042'
    - test directory contains just images with a CSV mapping filenames to labels
    
    Parameters:
    -----------
    data_path : str
        Path to the root directory containing 'train' and 'test' folders
    test_csv_path : str
        Path to the CSV file mapping test image filenames to their labels
    
    Returns:
    --------
    X_train : array-like
        Training data
    y_train : array-like
        Training labels
    X_test : array-like
        Test data
    y_test : array-like
        Test labels
    """
    train_path = train_data_path
    test_path = test_data_path
    
    # Define the target size for resizing
    target_size = (28, 28)
    
    # Load training data
    X_train = []
    y_train = []
    
    print("Loading training data...")
    for class_id in tqdm(range(43)):  # 43 classes from 0 to 42
        class_dir = os.path.join(train_path, f"{class_id:05d}")
        if os.path.exists(class_dir):
            for filename in os.listdir(class_dir):
                if filename.endswith(('.png', '.jpg', '.jpeg', '.ppm')):
                    img_path = os.path.join(class_dir, filename)
                    try:
                        # Read and resize image
                        img = cv2.imread(img_path)
                        if img is not None:
                            img = cv2.resize(img, target_size)
                            # Convert BGR to RGB
                            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                            X_train.append(img)
                            y_train.append(class_id)
                    except Exception as e:
                        print(f"Error processing {img_path}: {e}")

    # Load test data using the CSV file
    X_test = []
    print("Loading test images...")
    test_files = os.listdir(test_path)
    for filename in tqdm(test_files, total=len(test_files)):
        img_path = os.path.join(test_path, filename)
        
        try:
            # Check if the file is an image
            if os.path.isfile(img_path) and filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                # Read and resize image
                img = cv2.imread(img_path)
                if img is not None:
                    img = cv2.resize(img, target_size)
                    # Convert BGR to RGB
                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    X_test.append(img)
                else:
                    print(f"Could not read image: {img_path}")
            else:
                print(f"Not an image file: {img_path}")
        except Exception as e:
            print(f"Error processing {img_path}: {e}")
    
    
    # Convert to numpy arrays
    X_train = np.array(X_train, dtype=np.float32)
    y_train = np.array(y_train, dtype=np.int64)
    X_test = np.array(X_test, dtype=np.float32)
    
    # Normalize pixel values to [0, 1]
    X_train = X_train / 255.0
    X_test = X_test / 255.0
    
    # Reshape images to flatten them (28x28x3 -&gt; 2352)
    X_train = X_train.reshape(X_train.shape[0], -1)
    X_test = X_test.reshape(X_test.shape[0], -1)
    
    return X_train, y_train, X_test


def main():

    # Check if correct number of arguments are provided
    if len(sys.argv) != 5:
        print("Usage: python neural_network.py &lt;train_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
        sys.exit(1)
    
    # Parse command line arguments
    train_data_path = sys.argv[1]
    test_data_path = sys.argv[2]
    output_folder_path = sys.argv[3]
    question_part = sys.argv[4]
    
    # Validate question part
    if question_part not in ['b', 'c', 'd', 'e', 'f']:
        print("Question part must be one of 'b', 'c', 'd', 'e', or 'f'")
        sys.exit(1)

    # Load the dataset
    X_train, y_train, X_test = load_data(train_data_path, test_data_path)
    

    if question_part=='b':
        part_b(X_train, y_train, X_test, output_folder_path, question_part)
    elif question_part=='c':
        part_c(X_train, y_train, X_test, output_folder_path, question_part)
    elif question_part=='d':
        part_d(X_train, y_train, X_test, output_folder_path, question_part)
    elif question_part=='e':
        part_e(X_train, y_train, X_test, output_folder_path, question_part)
    elif question_part=='f':
        part_f(X_train, y_train, X_test, output_folder_path, question_part)
    

if __name__ == "__main__":
    main()

</PRE>
</PRE>
</BODY>
</HTML>
