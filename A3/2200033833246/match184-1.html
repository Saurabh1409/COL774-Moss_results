<HTML>
<HEAD>
<TITLE>./A3_processed_new_hash/combined_AAPWP.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A3_processed_new_hash/combined_TORQY.py<p><PRE>


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV
from tqdm import tqdm
import os
import sys

# Define the types of attributes (categorical or continuous)
def identify_attribute_types(data):
    types = []
    for col in data.columns[:-1]:  # Exclude the target column
        if data[col].dtype == 'object':
            types.append("cat")
        else:
            types.append("cont")
    return types

# Calculate entropy
def entropy(y):
    if len(y) == 0:
        return 0
    p1 = np.sum(y == '&gt;50K') / len(y)
    p0 = 1 - p1
    if p1 == 0 or p0 == 0:
        return 0
    return -p1 * np.log2(p1) - p0 * np.log2(p0)

# Calculate overall entropy after splitting
def calc_overall_entropy(splits):
    total = 0
    size = 0
    for split in splits:
        if len(split) &gt; 0:
            total += entropy(split) * len(split)
            size += len(split)
    if size == 0:
        return 0
    return total / size

# Check if a node is pure (all examples have the same class)
def check_pure(y):
    return len(np.unique(y)) == 1

# Find the best attribute to split on
def find_best_split(X, y, types):
    best_gain = 0
    best_split = -1
    
    if check_pure(y):
        return -1
    
    for column in range(X.shape[1]):
        if types[column] == "cont":
            # Split on median for continuous attributes
            median = np.median(X[:, column])
            left_indices = X[:, column] &lt;= median
            right_indices = X[:, column] &gt; median
            
            splits = [y[left_indices], y[right_indices]]
            
            if len(splits[0]) == 0 or len(splits[1]) == 0:
                continue
                
            gain = entropy(y) - calc_overall_entropy(splits)
            
            if gain &gt; best_gain:
                best_gain = gain
                best_split = column
                best_threshold = median
        else:
            # Split on categories for categorical attributes
            unique_values = np.unique(X[:, column])
            splits = []
            
            for value in unique_values:
                splits.append(y[X[:, column] == value])
                
            gain = entropy(y) - calc_overall_entropy(splits)
            
            if gain &gt; best_gain:
                best_gain = gain
                best_split = column
    
    return best_split

# Decision Tree Node class
class DTNode:
    def __init__(self, depth, is_leaf=False, value=None, column=None):
        self.depth = depth
        self.children = []
        self.is_leaf = is_leaf
        self.value = value
        self.column = column
        self.threshold = None
        self.vals = None
        
    def get_children(self, X, types):  # Added types parameter
        if self.is_leaf:
            return None
            
        column = self.column
        
        if types[column] == "cont":
            # For continuous attributes
            if X[column] &lt;= self.threshold:
                return self.children[0]
            else:
                return self.children[1]
        else:
            # For categorical attributes
            if X[column] in self.vals:
                return self.children[self.vals.index(X[column])]
            else:
                # If value not seen during training, treat as leaf
                return None

# Decision Tree class
class DTTree:
    def __init__(self):
        self.root = None
        self.types = None  # Store types as instance variable
        
    def fit(self, X, y, types, max_depth=5):
        self.types = types  # Save types for prediction
        self.root = self._build_tree(X, y, types, max_depth)
        return self
        
    def _build_tree(self, X, y, types, max_depth, depth=0):
        root = DTNode(depth=depth)
        
        # If max depth reached or node is pure, make it a leaf
        if depth == max_depth or check_pure(y):
            root.is_leaf = True
            root.value = '&gt;50K' if np.sum(y == '&gt;50K') &gt; np.sum(y == '&lt;=50K') else '&lt;=50K'
            return root
            
        # Find the best attribute to split on
        split = find_best_split(X, y, types)
        
        if split == -1:
            # If no good split found, make it a leaf
            root.is_leaf = True
            root.value = '&gt;50K' if np.sum(y == '&gt;50K') &gt; np.sum(y == '&lt;=50K') else '&lt;=50K'
            return root
            
        root.column = split
        
        if types[split] == "cont":
            # For continuous attributes
            root.threshold = np.median(X[:, split])
            left_indices = X[:, split] &lt;= root.threshold
            right_indices = X[:, split] &gt; root.threshold
            
            # Create child nodes
            root.children = [
                self._build_tree(X[left_indices], y[left_indices], types, max_depth, depth+1),
                self._build_tree(X[right_indices], y[right_indices], types, max_depth, depth+1)
            ]
        else:
            # For categorical attributes
            root.vals = np.unique(X[:, split]).tolist()
            
            # Create a child for each unique value
            for val in root.vals:
                indices = X[:, split] == val
                root.children.append(self._build_tree(X[indices], y[indices], types, max_depth, depth+1))
                
        # Set majority class as value (used when a test example can't reach a leaf)
        root.value = '&gt;50K' if np.sum(y == '&gt;50K') &gt; np.sum(y == '&lt;=50K') else '&lt;=50K'
        
        return root
        
    def predict(self, X):
        y_pred = np.empty(X.shape[0], dtype=object)
        
        for i in range(X.shape[0]):
            node = self.root
            
            while not node.is_leaf:
                child = node.get_children(X[i], self.types)  # Pass types parameter
                if child is None:
                    break
                node = child
                
            y_pred[i] = node.value
            
        return y_pred
        
    def accuracy(self, X, y):
        y_pred = self.predict(X)
        return np.sum(y_pred == y) / len(y)
        
    def count_nodes(self):
        """Count the total number of nodes in the tree"""
        if self.root is None:
            return 0
            
        count = 0
        queue = [self.root]
        
        while queue:
            node = queue.pop(0)
            count += 1
            
            if not node.is_leaf:
                queue.extend(node.children)
                
        return count
        
    def prune(self, X_val, y_val, X_train, y_train, X_test, y_test):
        """Prune the tree to improve validation accuracy"""
        # Store the initial tree state
        nodes = [self.count_nodes()]
        training_acc = [self.accuracy(X_train, y_train)]
        test_acc = [self.accuracy(X_test, y_test)]
        val_acc = [self.accuracy(X_val, y_val)]
        
        best_tree = self
        current_tree = self
        
        # Continue pruning until no improvement is possible
        while True:
            current_tree, improved = current_tree._prune_one_node(X_val, y_val)
            
            if not improved:
                break
                
            nodes.append(current_tree.count_nodes())
            training_acc.append(current_tree.accuracy(X_train, y_train))
            test_acc.append(current_tree.accuracy(X_test, y_test))
            val_acc.append(current_tree.accuracy(X_val, y_val))
            
            best_tree = current_tree
        
        # Reverse the lists to show progression from fewer to more nodes
        nodes.reverse()
        training_acc.reverse()
        test_acc.reverse()
        val_acc.reverse()
        
        return best_tree, nodes, training_acc, test_acc, val_acc

        
    def _prune_one_node(self, X_val, y_val):
        """Prune one node that gives the maximum increase in validation accuracy"""
        best_accuracy = self.accuracy(X_val, y_val)
        best_node = None
        
        # Collect all non-leaf nodes
        nodes = []
        queue = [self.root]
        
        while queue:
            node = queue.pop(0)
            
            if not node.is_leaf:
                nodes.append(node)
                queue.extend(node.children)
                
        # Try pruning each non-leaf node
        for node in nodes:
            # Temporarily make it a leaf
            was_leaf = node.is_leaf
            children = node.children
            
            node.is_leaf = True
            node.children = []
            
            # Check if accuracy improves
            accuracy = self.accuracy(X_val, y_val)
            
            if accuracy &gt; best_accuracy:
                best_accuracy = accuracy
                best_node = node
            
            # Restore the node
            if not best_node == node:
                node.is_leaf = was_leaf
                node.children = children
                
        # If a node was found that improves accuracy, prune it
        if best_node:
            best_node.is_leaf = True
            best_node.children = []
            return self, True
        else:
            return self, False
        
# Load and preprocess data

def load_data(file_path):
    """Load data from CSV file and strip whitespaces from string values"""
    data = pd.read_csv(file_path)
    # Strip whitespace from string columns
    for col in data.select_dtypes(include=['object']).columns:
        data[col] = data[col].str.strip()
    return data

def preprocess_data(data):
    """Preprocess the data for decision tree learning"""
    X = data.iloc[:, :-1]
    y = data.iloc[:, -1]
    
    return X, y

def one_hot_encode(X_train, X_val, X_test):
    """Perform one-hot encoding for categorical features"""
    categorical_cols = X_train.select_dtypes(include=['object']).columns
    
    # Apply one-hot encoding
    X_train_encoded = pd.get_dummies(X_train, columns=categorical_cols)
    X_val_encoded = pd.get_dummies(X_val, columns=categorical_cols)
    X_test_encoded = pd.get_dummies(X_test, columns=categorical_cols)
    
    # Ensure all datasets have the same columns
    all_columns = set(X_train_encoded.columns).union(set(X_val_encoded.columns)).union(set(X_test_encoded.columns))
    
    for col in all_columns:
        if col not in X_train_encoded.columns:
            X_train_encoded[col] = 0
        if col not in X_val_encoded.columns:
            X_val_encoded[col] = 0
        if col not in X_test_encoded.columns:
            X_test_encoded[col] = 0
    
    # Ensure columns are in the same order
    X_train_encoded = X_train_encoded[sorted(X_train_encoded.columns)]
    X_val_encoded = X_val_encoded[sorted(X_val_encoded.columns)]
    X_test_encoded = X_test_encoded[sorted(X_test_encoded.columns)]
    
    return X_train_encoded, X_val_encoded, X_test_encoded

# Train and evaluate decision tree
def experiment_1(X_train, y_train, X_test, y_test, types, output_path):
    """Experiment with different maximum depths for decision tree"""
    max_depths = [5, 10, 15, 20]
    train_accuracies = []
    test_accuracies = []
    
    for max_depth in tqdm(max_depths, desc="Training trees with different depths"):
        # Train decision tree
        tree = DTTree()
        tree.fit(X_train.values, y_train.values, types, max_depth=max_depth)
        
        # Calculate accuracies
        train_acc = tree.accuracy(X_train.values, y_train.values)
        test_acc = tree.accuracy(X_test.values, y_test.values)
        
        train_accuracies.append(train_acc)
        test_accuracies.append(test_acc)
        
        print(f"Max Depth: {max_depth}, Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}")
        
        # Calculate class-specific accuracies
        y_pred_test = tree.predict(X_test.values)
        
        # Accuracy for &gt;50K predictions - with zero-division protection
        high_income_indices = y_test.values == '&gt;50K'
        high_income_count = np.sum(high_income_indices)
        if high_income_count &gt; 0:
            high_income_acc = np.sum(y_pred_test[high_income_indices] == '&gt;50K') / high_income_count
        else:
            high_income_acc = 0.0
        
        # Accuracy for &lt;=50K predictions - with zero-division protection
        low_income_indices = y_test.values == '&lt;=50K'
        low_income_count = np.sum(low_income_indices)
        if low_income_count &gt; 0:
            low_income_acc = np.sum(y_pred_test[low_income_indices] == '&lt;=50K') / low_income_count
        else:
            low_income_acc = 0.0
        
        print(f"Accuracy for &gt;50K: {high_income_acc:.4f}, Accuracy for &lt;=50K: {low_income_acc:.4f}")
    
    # Save predictions to CSV named 'prediction_a.csv' in output_path dir
    if not os.path.exists(output_path):
        os.makedirs(output_path)
    pd.DataFrame({'prediction': y_pred_test}).to_csv(os.path.join(output_path, 'prediction_a.csv'), index=False)
    # Plot accuracies
    plt.figure(figsize=(10, 6))
    plt.plot(max_depths, train_accuracies, marker='o', label='Training Accuracy')
    plt.plot(max_depths, test_accuracies, marker='x', label='Testing Accuracy')
    plt.xlabel('Maximum Depth')
    plt.ylabel('Accuracy')
    plt.title('Training and Testing Accuracy vs. Maximum Depth')
    plt.legend()
    plt.grid(True)
    plt.savefig('experiment_1_accuracies.png')
    plt.show()
    
    return train_accuracies, test_accuracies

def experiment_2(X_train_encoded, y_train, X_test_encoded, y_test, output_path):
    """Experiment with one-hot encoded data"""
    # Identify types for encoded data (all are continuous after one-hot encoding)
    types_encoded = ["cont"] * X_train_encoded.shape[1]
    
    max_depths = [25, 35, 45, 55]
    train_accuracies = []
    test_accuracies = []
    
    for max_depth in tqdm(max_depths, desc="Training trees with one-hot encoding"):
        # Train decision tree
        tree = DTTree()
        tree.fit(X_train_encoded.values, y_train.values, types_encoded, max_depth=max_depth)
        
        # Calculate accuracies
        train_acc = tree.accuracy(X_train_encoded.values, y_train.values)
        test_acc = tree.accuracy(X_test_encoded.values, y_test.values)
        
        train_accuracies.append(train_acc)
        test_accuracies.append(test_acc)
        
        print(f"Max Depth: {max_depth}, Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}")
    
    # save predictions
    if not os.path.exists(output_path):
        os.makedirs(output_path)
    pd.DataFrame({'prediction': tree.predict(X_test_encoded.values)}).to_csv(os.path.join(output_path, 'prediction_b.csv'), index=False)
    # Plot accuracies
    plt.figure(figsize=(10, 6))
    plt.plot(max_depths, train_accuracies, marker='o', label='Training Accuracy')
    plt.plot(max_depths, test_accuracies, marker='x', label='Testing Accuracy')
    plt.xlabel('Maximum Depth')
    plt.ylabel('Accuracy')
    plt.title('Training and Testing Accuracy vs. Maximum Depth (One-Hot Encoded)')
    plt.legend()
    plt.grid(True)
    plt.savefig('experiment_2_accuracies.png')
    plt.show()
    
    return train_accuracies, test_accuracies, max_depths

def experiment_3(X_train_encoded, y_train, X_val_encoded, y_val, X_test_encoded, y_test, max_depths, output_path):
    """Experiment with post-pruning"""
    types_encoded = ["cont"] * X_train_encoded.shape[1]
    
    for max_depth in tqdm(max_depths, desc="Post-pruning trees"):
        # Train decision tree
        tree = DTTree()
        tree.fit(X_train_encoded.values, y_train.values, types_encoded, max_depth=max_depth)
        # Calculate accuracies BEFORE pruning
        train_acc_before = tree.accuracy(X_train_encoded.values, y_train.values)
        test_acc_before = tree.accuracy(X_test_encoded.values, y_test.values)
        val_acc_before = tree.accuracy(X_val_encoded.values, y_val.values)
        
        # Prune the tree
        pruned_tree, nodes, train_acc, test_acc, val_acc = tree.prune(
            X_val_encoded.values, y_val.values, 
            X_train_encoded.values, y_train.values, 
            X_test_encoded.values, y_test.values
        )
        # save the predictions in csv named 'prediction_c.csv'
        if not os.path.exists(output_path):
            os.makedirs(output_path)
        pd.DataFrame({'prediction': pruned_tree.predict(X_test_encoded.values)}).to_csv(os.path.join(output_path, 'prediction_c.csv'), index=False)
        # Plot accuracies vs number of nodes
        plt.figure(figsize=(10, 6))
        plt.plot(nodes, train_acc, marker='o', label='Training Accuracy')
        plt.plot(nodes, test_acc, marker='x', label='Testing Accuracy')
        plt.plot(nodes, val_acc, marker='s', label='Validation Accuracy')
        plt.xlabel('Number of Nodes')
        plt.ylabel('Accuracy')
        plt.title(f'Accuracy vs. Number of Nodes (Max Depth: {max_depth})')
        plt.legend()
        plt.grid(True)
        plt.savefig(f'output/experiment_3_pruning_depth_{max_depth}.png')
        plt.show()
        
        print(f"Max Depth: {max_depth}")
        print(f"Before pruning - Train: {train_acc_before:.4f}, "
              f"Test: {test_acc_before:.4f}, "
              f"Val: {val_acc_before:.4f}")
        print(f"After pruning - Train: {train_acc[0]:.4f}, Test: {test_acc[0]:.4f}, Val: {val_acc[0]:.4f}")


def experiment_4(X_train_encoded, y_train, X_val_encoded, y_val, X_test_encoded, y_test, output_path):
    """Experiment with scikit-learn's decision tree"""
    # Part (i): Vary max_depth
    max_depths = [25, 35, 45, 55]
    train_accuracies = []
    test_accuracies = []
    val_accuracies = []
    
    for max_depth in max_depths:
        # Train decision tree
        clf = DecisionTreeClassifier(criterion='entropy', max_depth=max_depth, random_state=42)
        clf.fit(X_train_encoded, y_train)
        
        # Calculate accuracies
        train_acc = accuracy_score(y_train, clf.predict(X_train_encoded))
        test_acc = accuracy_score(y_test, clf.predict(X_test_encoded))
        val_acc = accuracy_score(y_val, clf.predict(X_val_encoded))
        
        train_accuracies.append(train_acc)
        test_accuracies.append(test_acc)
        val_accuracies.append(val_acc)
        
        print(f"Max Depth: {max_depth}, Train: {train_acc:.4f}, Test: {test_acc:.4f}, Val: {val_acc:.4f}")
    
    # Plot accuracies
    plt.figure(figsize=(10, 6))
    plt.plot(max_depths, train_accuracies, marker='o', label='Training Accuracy')
    plt.plot(max_depths, test_accuracies, marker='x', label='Testing Accuracy')
    plt.plot(max_depths, val_accuracies, marker='s', label='Validation Accuracy')
    plt.xlabel('Maximum Depth')
    plt.ylabel('Accuracy')
    plt.title('Accuracy vs. Maximum Depth (Scikit-learn)')
    plt.legend()
    plt.grid(True)
    plt.savefig('output/experiment_4i_accuracies.png')
    plt.show()
    
    # Find best max_depth based on validation accuracy
<A NAME="3"></A><FONT color = #00FFFF><A HREF="match184-0.html#3" TARGET="0"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    best_max_depth = max_depths[np.argmax(val_accuracies)]
    print(f"Best max_depth: {best_max_depth}")
    
    # Part (ii): Vary ccp_alpha
    ccp_alphas = [0.001, 0.01, 0.1, 0.2]
    train_accuracies_ccp = []
</FONT>    test_accuracies_ccp = []
    val_accuracies_ccp = []
    
    for ccp_alpha in ccp_alphas:
        # Train decision tree
        clf = DecisionTreeClassifier(criterion='entropy', ccp_alpha=ccp_alpha, random_state=42)
        clf.fit(X_train_encoded, y_train)
        
        # Calculate accuracies
        train_acc = accuracy_score(y_train, clf.predict(X_train_encoded))
        test_acc = accuracy_score(y_test, clf.predict(X_test_encoded))
        val_acc = accuracy_score(y_val, clf.predict(X_val_encoded))
        
        train_accuracies_ccp.append(train_acc)
        test_accuracies_ccp.append(test_acc)
        val_accuracies_ccp.append(val_acc)
        
        print(f"CCP Alpha: {ccp_alpha}, Train: {train_acc:.4f}, Test: {test_acc:.4f}, Val: {val_acc:.4f}")
    
    # Plot accuracies
    plt.figure(figsize=(10, 6))
    plt.plot(ccp_alphas, train_accuracies_ccp, marker='o', label='Training Accuracy')
    plt.plot(ccp_alphas, test_accuracies_ccp, marker='x', label='Testing Accuracy')
    plt.plot(ccp_alphas, val_accuracies_ccp, marker='s', label='Validation Accuracy')
    plt.xlabel('CCP Alpha')
    plt.ylabel('Accuracy')
    plt.title('Accuracy vs. CCP Alpha (Scikit-learn)')
    plt.legend()
    plt.grid(True)
    plt.savefig('output/experiment_4ii_accuracies.png')
    plt.show()
    
    # Find best ccp_alpha based on validation accuracy
    best_ccp_alpha = ccp_alphas[np.argmax(val_accuracies_ccp)]
    print(f"Best ccp_alpha: {best_ccp_alpha}")
    
    # Train final model with best parameters
    best_model_depth = DecisionTreeClassifier(criterion='entropy', max_depth=best_max_depth, random_state=42)
    best_model_depth.fit(X_train_encoded, y_train)
    
    best_model_ccp = DecisionTreeClassifier(criterion='entropy', ccp_alpha=best_ccp_alpha, random_state=42)
    best_model_ccp.fit(X_train_encoded, y_train)
    
    # Calculate final accuracies
    depth_test_acc = accuracy_score(y_test, best_model_depth.predict(X_test_encoded))
    ccp_test_acc = accuracy_score(y_test, best_model_ccp.predict(X_test_encoded))
    
    print(f"Final Test Accuracy (best max_depth={best_max_depth}): {depth_test_acc:.4f}")
    print(f"Final Test Accuracy (best ccp_alpha={best_ccp_alpha}): {ccp_test_acc:.4f}")
    
    
    if not os.path.exists(output_path):
        os.makedirs(output_path)
    if depth_test_acc &gt; ccp_test_acc:
        pd.DataFrame({'prediction': best_model_depth.predict(X_test_encoded)}).to_csv(os.path.join(output_path, 'prediction_d.csv'), index=False)
    else:
        pd.DataFrame({'prediction': best_model_ccp.predict(X_test_encoded)}).to_csv(os.path.join(output_path, 'prediction_d.csv'), index=False)
    return best_max_depth, best_ccp_alpha, depth_test_acc, ccp_test_acc

def experiment_5(X_train_encoded, y_train, X_val_encoded, y_val, X_test_encoded, y_test, output_path):
    """Experiment with Random Forests"""
    print("Starting Random Forest experiment...")
    
    # Define parameter grid for grid search
    param_grid = {
        'n_estimators': range(50, 350, 100),  # [50, 150, 250]
        'max_features': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0],
        'min_samples_split': range(2, 10, 2)  # [2, 4, 6, 8]
    }
    
    print("Performing grid search for Random Forest parameters...")
    # Create Random Forest classifier with out-of-bag score
    rf = RandomForestClassifier(criterion='entropy', oob_score=True, random_state=42)
    
    # Perform grid search
    grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')
    grid_search.fit(X_train_encoded, y_train)
    
    # Get best parameters
    best_params = grid_search.best_params_
    print(f"Best parameters: {best_params}")
    
    # Train Random Forest with best parameters
<A NAME="1"></A><FONT color = #00FF00><A HREF="match184-0.html#1" TARGET="0"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    best_rf = RandomForestClassifier(criterion='entropy', oob_score=True, random_state=42, **best_params)
    best_rf.fit(X_train_encoded, y_train)
    
    # Calculate accuracies
    train_acc = accuracy_score(y_train, best_rf.predict(X_train_encoded))
    val_acc = accuracy_score(y_val, best_rf.predict(X_val_encoded))
    test_acc = accuracy_score(y_test, best_rf.predict(X_test_encoded))
</FONT>    oob_acc = best_rf.oob_score_
    
    print(f"Training Accuracy: {train_acc:.4f}")
    print(f"Validation Accuracy: {val_acc:.4f}")
    print(f"Test Accuracy: {test_acc:.4f}")
    print(f"Out-of-Bag Accuracy: {oob_acc:.4f}")
    
    # Calculate class-specific accuracies for test set
    y_pred_test = best_rf.predict(X_test_encoded)
    
    # Accuracy for &gt;50K predictions
    high_income_indices = y_test == '&gt;50K'
    high_income_acc = np.sum(y_pred_test[high_income_indices] == '&gt;50K') / np.sum(high_income_indices)
    
    # Accuracy for &lt;=50K predictions
    low_income_indices = y_test == '&lt;=50K'
    low_income_acc = np.sum(y_pred_test[low_income_indices] == '&lt;=50K') / np.sum(low_income_indices)
    
    print(f"Accuracy for &gt;50K: {high_income_acc:.4f}, Accuracy for &lt;=50K: {low_income_acc:.4f}")
    
    # Save predictions to CSV
    if not os.path.exists(output_path):
        os.makedirs(output_path)
    pd.DataFrame({'prediction': y_pred_test}).to_csv(os.path.join(output_path, 'prediction_e.csv'), index=False)
    
    return {
        'best_params': best_params,
        'train_acc': train_acc,
        'val_acc': val_acc,
        'test_acc': test_acc,
        'oob_acc': oob_acc,
        'high_income_acc': high_income_acc,
        'low_income_acc': low_income_acc
    }



if __name__ == "__main__":
    # Parse command line arguments
    if len(sys.argv) &gt; 1:
        train_path = sys.argv[1]
        val_path = sys.argv[2]
        test_path = sys.argv[3]
        output_path = sys.argv[4]
        question_part = sys.argv[5]
        
        if question_part == 'a':
            # Experiment 1
            train_data = load_data(train_path)
            test_data = load_data(test_path)
            X_train, y_train = preprocess_data(train_data)
            X_test, y_test = preprocess_data(test_data)
            types = identify_attribute_types(train_data)
            experiment_1(X_train, y_train, X_test, y_test, types, output_path)
        elif question_part == 'b':
            # Experiment 2
            train_data = load_data(train_path)
            test_data = load_data(test_path)
            X_train, y_train = preprocess_data(train_data)
            X_test, y_test = preprocess_data(test_data)
            X_train_encoded, _, X_test_encoded = one_hot_encode(X_train, X_train, X_test)  # Using train as val placeholder
            experiment_2(X_train_encoded, y_train, X_test_encoded, y_test, output_path)
        elif question_part == 'c':
            # Experiment 3
            train_data = load_data(train_path)
            val_data = load_data(val_path)
            test_data = load_data(test_path)
            X_train, y_train = preprocess_data(train_data)
            X_val, y_val = preprocess_data(val_data)
            X_test, y_test = preprocess_data(test_data)
            X_train_encoded, X_val_encoded, X_test_encoded = one_hot_encode(X_train, X_val, X_test)
            max_depths = [25, 35, 45, 55]
            experiment_3(X_train_encoded, y_train, X_val_encoded, y_val, X_test_encoded, y_test, max_depths, output_path)
        elif question_part == 'd':
            # Experiment 4
            train_data = load_data(train_path)
            val_data = load_data(val_path)
            test_data = load_data(test_path)
            X_train, y_train = preprocess_data(train_data)
            X_val, y_val = preprocess_data(val_data)
            X_test, y_test = preprocess_data(test_data)
            X_train_encoded, X_val_encoded, X_test_encoded = one_hot_encode(X_train, X_val, X_test)
            experiment_4(X_train_encoded, y_train, X_val_encoded, y_val, X_test_encoded, y_test, output_path)
        elif question_part == 'e':
            # Experiment 5
            train_data = load_data(train_path)
            val_data = load_data(val_path)
            test_data = load_data(test_path)
            X_train, y_train = preprocess_data(train_data)
            X_val, y_val = preprocess_data(val_data)
            X_test, y_test = preprocess_data(test_data)
            X_train_encoded, X_val_encoded, X_test_encoded = one_hot_encode(X_train, X_val, X_test)
            experiment_5(X_train_encoded, y_train, X_val_encoded, y_val, X_test_encoded, y_test, output_path)
    # else:
    #     # Run all experiments
    #     main()

# def main():
#     """Main function to run all experiments"""
#     # Create output directory if it doesn't exist
#     if not os.path.exists('output'):
#         os.makedirs('output')
    
#     print("Loading data...")
#     # Load the data
#     script_dir = os.path.dirname(os.path.abspath(__file__))
#     train_data = load_data(os.path.join(script_dir, "data/train.csv"))
#     val_data = load_data(os.path.join(script_dir, "data/valid.csv"))
#     test_data = load_data(os.path.join(script_dir, "data/test.csv"))
    
#     # Preprocess the data
#     X_train, y_train = preprocess_data(train_data)
#     X_val, y_val = preprocess_data(val_data)
#     X_test, y_test = preprocess_data(test_data)
    
#     # Identify attribute types
#     types = identify_attribute_types(train_data)
#     print(f"Identified {types.count('cat')} categorical and {types.count('cont')} continuous features")
    
#     # Experiment 1: Decision Tree with different max depths
#     print("\n=== Experiment 1: Decision Tree with Different Max Depths ===")
#     exp1_results = experiment_1(X_train, y_train, X_test, y_test, types)
    
#     # Experiment 2: Decision Tree with One-Hot Encoding
#     print("\n=== Experiment 2: Decision Tree with One-Hot Encoding ===")
#     # Perform one-hot encoding
#     X_train_encoded, X_val_encoded, X_test_encoded = one_hot_encode(X_train, X_val, X_test)
#     exp2_results = experiment_2(X_train_encoded, y_train, X_test_encoded, y_test)
    
#     # Experiment 3: Post-Pruning
#     print("\n=== Experiment 3: Post-Pruning ===")
#     experiment_3(X_train_encoded, y_train, X_val_encoded, y_val, X_test_encoded, y_test, exp2_results[2])
    
#     # Experiment 4: Scikit-learn Decision Tree
#     print("\n=== Experiment 4: Scikit-learn Decision Tree ===")
#     exp4_results = experiment_4(X_train_encoded, y_train, X_val_encoded, y_val, X_test_encoded, y_test)
    
#     # Experiment 5: Random Forests
#     print("\n=== Experiment 5: Random Forests ===")
#     exp5_results = experiment_5(X_train_encoded, y_train, X_val_encoded, y_val, X_test_encoded, y_test)
    
#     # Compare results from all experiments
#     print("\n=== Comparison of Results ===")
#     print("Experiment 1 (Custom DT): Test Accuracy = {:.4f}".format(exp1_results[1][-1]))
#     print("Experiment 2 (Custom DT with One-Hot): Test Accuracy = {:.4f}".format(exp2_results[1][-1]))
#     print("Experiment 4 (Scikit-learn DT): Test Accuracy = {:.4f}".format(max(exp4_results[2], exp4_results[3])))
#     print("Experiment 5 (Random Forest): Test Accuracy = {:.4f}".format(exp5_results['test_acc']))
    
#     print("\nAll experiments completed successfully!")




import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
from PIL import Image
import time
from sklearn.metrics import precision_score, recall_score, f1_score, classification_report
from sklearn.neural_network import MLPClassifier
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import warnings
warnings.filterwarnings("ignore")

# Define paths
TRAIN_DIR = './data2/train'
TEST_DIR = './data2/test'
TEST_LABELS_PATH = './data2/test_labels.csv'

def avg(arr):
    return sum(arr) / len(arr)

def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def sigmoid_derivative(a):
    return a * (1 - a)

def relu(z):
    return np.maximum(0, z)

def relu_derivative(a):
    return (a &gt; 0).astype(float)

def softmax(z):
    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))
    return exp_z / np.sum(exp_z, axis=1, keepdims=True)

class NeuralNetwork:
    def __init__(self, n_features, hidden_layers, n_classes, activation='sigmoid'):
<A NAME="5"></A><FONT color = #FF0000><A HREF="match184-0.html#5" TARGET="0"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        self.n_features = n_features
        self.hidden_layers = hidden_layers
        self.n_classes = n_classes
        self.activation_type = activation
        self.weights = {}
        self.biases = {}
</FONT>        self.initialize_parameters()
        
    def initialize_parameters(self):
        # Initialize weights and biases
        layer_sizes = [self.n_features] + self.hidden_layers + [self.n_classes]
        
        for i in range(1, len(layer_sizes)):
            # He initialization for ReLU, Xavier for sigmoid
            if self.activation_type == 'relu':
                scale = np.sqrt(2.0 / layer_sizes[i-1])
            else:  # sigmoid
                scale = np.sqrt(1.0 / layer_sizes[i-1])
                
            self.weights[i] = np.random.randn(layer_sizes[i-1], layer_sizes[i]) * scale
            self.biases[i] = np.zeros((1, layer_sizes[i]))
    
    def activation(self, z):
        if self.activation_type == 'relu':
            return relu(z)
        else:  # sigmoid
            return sigmoid(z)
    
    def activation_derivative(self, a):
        if self.activation_type == 'relu':
            return relu_derivative(a)
        else:  # sigmoid
            return sigmoid_derivative(a)
    
    def forward_propagation(self, X):
        self.layer_inputs = {}
        self.layer_outputs = {}
        
        # Input layer
        self.layer_outputs[0] = X
        
        # Hidden layers
        for i in range(1, len(self.hidden_layers) + 1):
            self.layer_inputs[i] = np.dot(self.layer_outputs[i-1], self.weights[i]) + self.biases[i]
            self.layer_outputs[i] = self.activation(self.layer_inputs[i])
        
        # Output layer
        i = len(self.hidden_layers) + 1
        self.layer_inputs[i] = np.dot(self.layer_outputs[i-1], self.weights[i]) + self.biases[i]
        self.layer_outputs[i] = softmax(self.layer_inputs[i])
        
        return self.layer_outputs[i]
    
    def compute_cost(self, y_pred, y_true):
        # Cross-entropy loss
        m = y_true.shape[0]
        cost = -np.sum(y_true * np.log(y_pred + 1e-15)) / m
        return cost
    
    def backward_propagation(self, X, y):
        m = X.shape[0]
        n_layers = len(self.hidden_layers) + 1
        
        # Initialize gradients
        dW = {}
        db = {}
        
        # Output layer error
        dZ = self.layer_outputs[n_layers] - y
        
        # Compute gradients for output layer
        dW[n_layers] = np.dot(self.layer_outputs[n_layers-1].T, dZ) / m
        db[n_layers] = np.sum(dZ, axis=0, keepdims=True) / m
        
        # Backpropagate through hidden layers
        for i in range(n_layers-1, 0, -1):
            dA = np.dot(dZ, self.weights[i+1].T)
            dZ = dA * self.activation_derivative(self.layer_outputs[i])
            dW[i] = np.dot(self.layer_outputs[i-1].T, dZ) / m
            db[i] = np.sum(dZ, axis=0, keepdims=True) / m
        
        return dW, db
    
    def update_parameters(self, dW, db, learning_rate):
        for i in range(1, len(self.hidden_layers) + 2):
            self.weights[i] -= learning_rate * dW[i]
            self.biases[i] -= learning_rate * db[i]
    
    def train(self, X, y, X_val, y_val, batch_size=32, learning_rate=0.01, epochs=100, 
              adaptive_lr=False, verbose=True):
        m = X.shape[0]
        n_batches = m // batch_size
        
        # For tracking metrics
        train_costs = []
        val_costs = []
        train_accuracies = []
        val_accuracies = []
        
        for epoch in range(epochs):
            # Shuffle data
            indices = np.random.permutation(m)
            X_shuffled = X[indices]
            y_shuffled = y[indices]
            
            # Adjust learning rate if adaptive
            if adaptive_lr:
                current_lr = learning_rate / np.sqrt(epoch + 1)
            else:
                current_lr = learning_rate
            
            # Mini-batch training
            for i in range(n_batches):
                start_idx = i * batch_size
                end_idx = min((i + 1) * batch_size, m)
                
                X_batch = X_shuffled[start_idx:end_idx]
                y_batch = y_shuffled[start_idx:end_idx]
                
                # Forward and backward pass
                y_pred = self.forward_propagation(X_batch)
                dW, db = self.backward_propagation(X_batch, y_batch)
                self.update_parameters(dW, db, current_lr)
            
            # Compute metrics at the end of each epoch
            y_pred_train = self.forward_propagation(X)
            train_cost = self.compute_cost(y_pred_train, y)
            train_costs.append(train_cost)
            
            y_pred_val = self.forward_propagation(X_val)
            val_cost = self.compute_cost(y_pred_val, y_val)
            val_costs.append(val_cost)
            
            train_accuracy = self.accuracy(X, y)
            val_accuracy = self.accuracy(X_val, y_val)
            train_accuracies.append(train_accuracy)
            val_accuracies.append(val_accuracy)
            
            if verbose and (epoch % 10 == 0 or epoch == epochs - 1):
                print(f"Epoch {epoch+1}/{epochs}, LR: {current_lr:.6f}, Train Cost: {train_cost:.6f}, "
                      f"Val Cost: {val_cost:.6f}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}")
        
        return {
            'train_costs': train_costs,
            'val_costs': val_costs,
            'train_accuracies': train_accuracies,
            'val_accuracies': val_accuracies
        }
    
<A NAME="4"></A><FONT color = #FF00FF><A HREF="match184-0.html#4" TARGET="0"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    def predict(self, X):
        y_pred = self.forward_propagation(X)
        return np.argmax(y_pred, axis=1)
    
    def accuracy(self, X, y):
        y_pred = self.predict(X)
</FONT>        y_true = np.argmax(y, axis=1)
        return np.mean(y_pred == y_true)
    
    def evaluate(self, X, y):
        y_pred = self.predict(X)
        y_true = np.argmax(y, axis=1)
        
        precision = precision_score(y_true, y_pred, average='macro')
        recall = recall_score(y_true, y_pred, average='macro')
        f1 = f1_score(y_true, y_pred, average='macro')
        accuracy = np.mean(y_pred == y_true)
        
        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1
        }

# Data loading and preprocessing
class GTSRBDataset(Dataset):
    def __init__(self, image_paths, labels=None, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
    
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        if self.labels is not None:
            label = self.labels[idx]
            return image, label
        else:
            return image

def load_data(train_data_path, test_data_path):
    # Load training data
    train_images = []
    train_labels = []
    
    for class_dir in os.listdir(train_data_path):
        # if class_dir.startswith('000'):
        class_id = int(class_dir)
        class_dir_path = os.path.join(train_data_path, class_dir)
        
        for img_name in os.listdir(class_dir_path):
            if img_name.endswith('.jpg'):
                img_path = os.path.join(class_dir_path, img_name)
                train_images.append(img_path)
                train_labels.append(class_id)
    
    # Load test data
    test_dir = os.path.dirname(test_data_path)
    test_labels_path = os.path.join(test_dir, '../test_labels.csv')
    test_labels_df = pd.read_csv(test_labels_path)
    test_images = []
    test_labels = []
    
    for idx, row in test_labels_df.iterrows():
        img_name = row['image']
        label = row['label']
        img_path = os.path.join(test_data_path, img_name)
        
        if os.path.exists(img_path):
            test_images.append(img_path)
            test_labels.append(label)
    
    # Create transformations
    transform = transforms.Compose([
        transforms.Resize((32, 32)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # Create datasets
    train_dataset = GTSRBDataset(train_images, train_labels, transform)
    test_dataset = GTSRBDataset(test_images, test_labels, transform)
    
    # Create data loaders
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    # Extract data for our custom NN implementation
    X_train = []
    y_train = []
    
    for images, labels in train_loader:
        batch_images = images.numpy()
        batch_images = batch_images.reshape(batch_images.shape[0], -1)  # Flatten
        X_train.append(batch_images)
        y_train.append(labels.numpy())
    
    X_train = np.vstack(X_train)
    y_train = np.concatenate(y_train)
    
    X_test = []
    y_test = []
    
    for images, labels in test_loader:
        batch_images = images.numpy()
        batch_images = batch_images.reshape(batch_images.shape[0], -1)  # Flatten
        X_test.append(batch_images)
        y_test.append(labels.numpy())
    
    X_test = np.vstack(X_test)
    y_test = np.concatenate(y_test)
    
    # Split training data into train and validation
    indices = np.random.permutation(len(X_train))
    split = int(0.8 * len(X_train))
    train_idx, val_idx = indices[:split], indices[split:]
    
    X_train_final = X_train[train_idx]
    y_train_final = y_train[train_idx]
    X_val = X_train[val_idx]
    y_val = y_train[val_idx]
    
    # One-hot encode labels
    num_classes = 43  # GTSRB has 43 classes
    y_train_onehot = np.zeros((len(y_train_final), num_classes))
    y_train_onehot[np.arange(len(y_train_final)), y_train_final] = 1
    
    y_val_onehot = np.zeros((len(y_val), num_classes))
    y_val_onehot[np.arange(len(y_val)), y_val] = 1
    
    y_test_onehot = np.zeros((len(y_test), num_classes))
    y_test_onehot[np.arange(len(y_test)), y_test] = 1
    
    return X_train_final, y_train_final, X_val, y_val, X_test, y_test, y_train_onehot, y_val_onehot, y_test_onehot

def plot_metrics(results, title, xlabel, ylabel, save_path=None):
    plt.figure(figsize=(10, 6))
    
    for label, values in results.items():
        plt.plot(values['x'], values['y'], marker='o', linestyle='-', label=label)
    
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.grid(True)
    plt.legend()
    
    if save_path:
        plt.savefig(save_path)
    
    plt.show()

def generate_classification_report(y_true, y_pred, target_names=None):
    report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)
    
    # Extract precision, recall, and F1 score for each class
    classes_report = {}
    
    for class_name, metrics in report.items():
        if class_name not in ['accuracy', 'macro avg', 'weighted avg']:
            classes_report[class_name] = {
                'precision': metrics['precision'],
                'recall': metrics['recall'],
                'f1-score': metrics['f1-score']
            }
    
    return classes_report, report['macro avg']['f1-score']

def save_predictions(y_pred, output_path, filename):
    output_folder = os.path.join(output_path, filename)
    pd.DataFrame({"prediction": y_pred}).to_csv(output_folder, index=False)

# Experiment functions
def experiment_b(X_train, y_train, X_val, y_val, X_test, y_test, y_train_onehot, y_val_onehot, y_test_onehot, output_path):
    """
    Experiment (b): Varying number of hidden layer units in a single hidden layer
    """
    print("\n=== Experiment (b): Effect of Hidden Layer Size ===")
    
    n_features = X_train.shape[1]
    n_classes = y_train_onehot.shape[1]
    
    # Hidden layer sizes to test
    hidden_sizes = [1, 5, 10, 50, 100]
    
    results = {
        'train_accuracy': {'x': hidden_sizes, 'y': []},
        'test_accuracy': {'x': hidden_sizes, 'y': []},
        'train_f1': {'x': hidden_sizes, 'y': []},
        'test_f1': {'x': hidden_sizes, 'y': []}
    }
    y_test_pred_final = None
    for size in hidden_sizes:
        print(f"\nTraining with hidden layer size: {size}")
        
        # Create and train model
        model = NeuralNetwork(n_features, [size], n_classes, activation='sigmoid')
        history = model.train(X_train, y_train_onehot, X_val, y_val_onehot, 
                             batch_size=32, learning_rate=0.01, epochs=50)
        
        # Evaluate on train set
        y_train_pred = model.predict(X_train)
        _, train_f1 = generate_classification_report(y_train, y_train_pred)
        train_accuracy = model.accuracy(X_train, y_train_onehot)
        
        # Evaluate on test set
        y_test_pred = model.predict(X_test)
        _, test_f1 = generate_classification_report(y_test, y_test_pred)
        test_accuracy = model.accuracy(X_test, y_test_onehot)
        
        # Store results
        y_test_pred_final = y_test_pred
        results['train_accuracy']['y'].append(train_accuracy)
        results['test_accuracy']['y'].append(test_accuracy)
        results['train_f1']['y'].append(train_f1)
        results['test_f1']['y'].append(test_f1)
        
        print(f"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")
        print(f"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}")
    # Save predictions
    save_predictions(y_test_pred_final, output_path, f"prediction_b.csv")
    
    # Plot results
    plot_metrics(
        {'Train Accuracy': results['train_accuracy'], 'Test Accuracy': results['test_accuracy']},
        'Accuracy vs Hidden Layer Size',
        'Number of Hidden Units',
        'Accuracy',
        'experiment_b_accuracy.png'
    )
    
    plot_metrics(
        {'Train F1 Score': results['train_f1'], 'Test F1 Score': results['test_f1']},
        'F1 Score vs Hidden Layer Size',
        'Number of Hidden Units',
        'F1 Score',
        'experiment_b_f1.png'
    )
    
    return results

def experiment_c(X_train, y_train, X_val, y_val, X_test, y_test, y_train_onehot, y_val_onehot, y_test_onehot, output_path):
    """
    Experiment (c): Varying network depth (number of hidden layers)
    """
    print("\n=== Experiment (c): Effect of Network Depth ===")
    
    n_features = X_train.shape[1]
    n_classes = y_train_onehot.shape[1]
    
    # Network architectures to test
<A NAME="2"></A><FONT color = #0000FF><A HREF="match184-0.html#2" TARGET="0"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    architectures = [
        [512],                  # 1 hidden layer
        [512, 256],             # 2 hidden layers
        [512, 256, 128],        # 3 hidden layers
        [512, 256, 128, 64]     # 4 hidden layers
    ]
    
    depths = [len(arch) for arch in architectures]
</FONT>    
    results = {
        'train_accuracy': {'x': depths, 'y': []},
        'test_accuracy': {'x': depths, 'y': []},
        'train_f1': {'x': depths, 'y': []},
        'test_f1': {'x': depths, 'y': []}
    }
    y_test_pred_final = None
    for i, arch in enumerate(architectures):
        print(f"\nTraining with architecture: {arch}")
        
        # Create and train model
        model = NeuralNetwork(n_features, arch, n_classes, activation='sigmoid')
        history = model.train(X_train, y_train_onehot, X_val, y_val_onehot, 
                             batch_size=32, learning_rate=0.01, epochs=50)
        
        # Evaluate on train set
        y_train_pred = model.predict(X_train)
        _, train_f1 = generate_classification_report(y_train, y_train_pred)
        train_accuracy = model.accuracy(X_train, y_train_onehot)
        
        # Evaluate on test set
        y_test_pred = model.predict(X_test)
        _, test_f1 = generate_classification_report(y_test, y_test_pred)
        test_accuracy = model.accuracy(X_test, y_test_onehot)
        
        # Store results
        y_test_pred_final = y_test_pred
        results['train_accuracy']['y'].append(train_accuracy)
        results['test_accuracy']['y'].append(test_accuracy)
        results['train_f1']['y'].append(train_f1)
        results['test_f1']['y'].append(test_f1)
        
        print(f"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")
        print(f"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}")

    save_predictions(y_test_pred_final, output_path, f"prediction_c.csv")
    # Plot results
    plot_metrics(
        {'Train Accuracy': results['train_accuracy'], 'Test Accuracy': results['test_accuracy']},
        'Accuracy vs Network Depth',
        'Network Depth (Number of Hidden Layers)',
        'Accuracy',
        'experiment_c_accuracy.png'
    )
    
    plot_metrics(
        {'Train F1 Score': results['train_f1'], 'Test F1 Score': results['test_f1']},
        'F1 Score vs Network Depth',
        'Network Depth (Number of Hidden Layers)',
        'F1 Score',
        'experiment_c_f1.png'
    )
    
    return results

def experiment_d(X_train, y_train, X_val, y_val, X_test, y_test, y_train_onehot, y_val_onehot, y_test_onehot, output_path):
    """
    Experiment (d): Adaptive learning rate with varying network depth
    """
    print("\n=== Experiment (d): Adaptive Learning Rate with Varying Network Depth ===")
    
    n_features = X_train.shape[1]
    n_classes = y_train_onehot.shape[1]
    
    # Network architectures to test
    architectures = [
        [512],                  # 1 hidden layer
        [512, 256],             # 2 hidden layers
        [512, 256, 128],        # 3 hidden layers
        [512, 256, 128, 64]     # 4 hidden layers
    ]
    
    depths = [len(arch) for arch in architectures]
    
    results = {
        'train_accuracy': {'x': depths, 'y': []},
        'test_accuracy': {'x': depths, 'y': []},
        'train_f1': {'x': depths, 'y': []},
        'test_f1': {'x': depths, 'y': []}
    }
    y_test_pred_final = None
    for i, arch in enumerate(architectures):
        print(f"\nTraining with architecture: {arch}")
        
        # Create and train model with adaptive learning rate
        model = NeuralNetwork(n_features, arch, n_classes, activation='sigmoid')
        history = model.train(X_train, y_train_onehot, X_val, y_val_onehot, 
                             batch_size=32, learning_rate=0.01, epochs=50, 
                             adaptive_lr=True)  # Use adaptive learning rate
        
        # Evaluate on train set
        y_train_pred = model.predict(X_train)
        _, train_f1 = generate_classification_report(y_train, y_train_pred)
        train_accuracy = model.accuracy(X_train, y_train_onehot)
        
        # Evaluate on test set
        y_test_pred = model.predict(X_test)
        _, test_f1 = generate_classification_report(y_test, y_test_pred)
        test_accuracy = model.accuracy(X_test, y_test_onehot)
        
        # Store results
        y_test_pred_final = y_test_pred
        results['train_accuracy']['y'].append(train_accuracy)
        results['test_accuracy']['y'].append(test_accuracy)
        results['train_f1']['y'].append(train_f1)
        results['test_f1']['y'].append(test_f1)
        
        print(f"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")
        print(f"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}")

    save_predictions(y_test_pred_final, output_path, f"prediction_d.csv")
    
    # Plot results
    plot_metrics(
        {'Train Accuracy': results['train_accuracy'], 'Test Accuracy': results['test_accuracy']},
        'Accuracy vs Network Depth (Adaptive LR)',
        'Network Depth (Number of Hidden Layers)',
        'Accuracy',
        'experiment_d_accuracy.png'
    )
    
    plot_metrics(
        {'Train F1 Score': results['train_f1'], 'Test F1 Score': results['test_f1']},
        'F1 Score vs Network Depth (Adaptive LR)',
        'Network Depth (Number of Hidden Layers)',
        'F1 Score',
        'experiment_d_f1.png'
    )
    
    return results

def experiment_e(X_train, y_train, X_val, y_val, X_test, y_test, y_train_onehot, y_val_onehot, y_test_onehot, output_path):
    """
    Experiment (e): ReLU activation with adaptive learning rate
    """
    print("\n=== Experiment (e): ReLU Activation with Adaptive Learning Rate ===")
    
    n_features = X_train.shape[1]
    n_classes = y_train_onehot.shape[1]
    
    # Network architectures to test
    architectures = [
        [512],                  # 1 hidden layer
        [512, 256],             # 2 hidden layers
        [512, 256, 128],        # 3 hidden layers
        [512, 256, 128, 64]     # 4 hidden layers
    ]
    
    depths = [len(arch) for arch in architectures]
    
    results = {
        'train_accuracy': {'x': depths, 'y': []},
        'test_accuracy': {'x': depths, 'y': []},
        'train_f1': {'x': depths, 'y': []},
        'test_f1': {'x': depths, 'y': []}
    }
    y_test_pred_final = None
    for i, arch in enumerate(architectures):
        print(f"\nTraining with architecture: {arch}")
        
        # Create and train model with ReLU activation and adaptive learning rate
        model = NeuralNetwork(n_features, arch, n_classes, activation='relu')
        history = model.train(X_train, y_train_onehot, X_val, y_val_onehot, 
                             batch_size=32, learning_rate=0.01, epochs=50, 
                             adaptive_lr=True)
        
        # Evaluate on train set
        y_train_pred = model.predict(X_train)
        _, train_f1 = generate_classification_report(y_train, y_train_pred)
        train_accuracy = model.accuracy(X_train, y_train_onehot)
        
        # Evaluate on test set
        y_test_pred = model.predict(X_test)
        _, test_f1 = generate_classification_report(y_test, y_test_pred)
        test_accuracy = model.accuracy(X_test, y_test_onehot)
        
        # Store results
        y_test_pred_final = y_test_pred
        results['train_accuracy']['y'].append(train_accuracy)
        results['test_accuracy']['y'].append(test_accuracy)
        results['train_f1']['y'].append(train_f1)
        results['test_f1']['y'].append(test_f1)
        
        print(f"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")
        print(f"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}")

    save_predictions(y_test_pred_final, output_path, f"prediction_e.csv")
    # Plot results
    plot_metrics(
        {'Train Accuracy': results['train_accuracy'], 'Test Accuracy': results['test_accuracy']},
        'Accuracy vs Network Depth (ReLU + Adaptive LR)',
        'Network Depth (Number of Hidden Layers)',
        'Accuracy',
        'experiment_e_accuracy.png'
    )
    
    plot_metrics(
        {'Train F1 Score': results['train_f1'], 'Test F1 Score': results['test_f1']},
        'F1 Score vs Network Depth (ReLU + Adaptive LR)',
        'Network Depth (Number of Hidden Layers)',
        'F1 Score',
        'experiment_e_f1.png'
    )
    
    return results

def experiment_f(X_train, y_train, X_val, y_val, X_test, y_test, output_path):
    """
    Experiment (f): scikit-learn MLPClassifier implementation
    """
    print("\n=== Experiment (f): scikit-learn MLPClassifier ===")
    
    # Network architectures to test
    architectures = [
        (512,),                     # 1 hidden layer
        (512, 256),                 # 2 hidden layers
        (512, 256, 128),            # 3 hidden layers
        (512, 256, 128, 64)         # 4 hidden layers
    ]
    
    depths = [len(arch) for arch in architectures]
    
    results = {
        'train_accuracy': {'x': depths, 'y': []},
        'test_accuracy': {'x': depths, 'y': []},
        'train_f1': {'x': depths, 'y': []},
        'test_f1': {'x': depths, 'y': []}
    }
    y_test_pred_final = None
<A NAME="0"></A><FONT color = #FF0000><A HREF="match184-0.html#0" TARGET="0"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    for i, arch in enumerate(architectures):
        print(f"\nTraining with architecture: {arch}")
        
        # Create and train scikit-learn MLPClassifier
        mlp = MLPClassifier(
            hidden_layer_sizes=arch,
            activation='relu',
            solver='sgd',
            alpha=0,
            batch_size=32,
            learning_rate='invscaling',
            learning_rate_init=0.01,
</FONT>            max_iter=50,
            random_state=42
        )
        
        # Train the model
        mlp.fit(X_train, y_train)
        
        # Evaluate on train set
        y_train_pred = mlp.predict(X_train)
        _, train_f1 = generate_classification_report(y_train, y_train_pred)
        train_accuracy = mlp.score(X_train, y_train)
        
        # Evaluate on test set
        y_test_pred = mlp.predict(X_test)
        _, test_f1 = generate_classification_report(y_test, y_test_pred)
        test_accuracy = mlp.score(X_test, y_test)
        
        # Store results
        y_test_pred_final = y_test_pred
        results['train_accuracy']['y'].append(train_accuracy)
        results['test_accuracy']['y'].append(test_accuracy)
        results['train_f1']['y'].append(train_f1)
        results['test_f1']['y'].append(test_f1)
        
        print(f"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}")
        print(f"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}")

    save_predictions(y_test_pred_final, output_path, f"prediction_f.csv")
    # Plot results
    plot_metrics(
        {'Train Accuracy': results['train_accuracy'], 'Test Accuracy': results['test_accuracy']},
        'Accuracy vs Network Depth (scikit-learn MLPClassifier)',
        'Network Depth (Number of Hidden Layers)',
        'Accuracy',
        'experiment_f_accuracy.png'
    )
    
    plot_metrics(
        {'Train F1 Score': results['train_f1'], 'Test F1 Score': results['test_f1']},
        'F1 Score vs Network Depth (scikit-learn MLPClassifier)',
        'Network Depth (Number of Hidden Layers)',
        'F1 Score',
        'experiment_f_f1.png'
    )
    
    return results

def compare_experiments(exp_c_results, exp_d_results, exp_e_results, exp_f_results):
    """
    Compare results from different experiments
    """
    print("\n=== Comparison of Experiments ===")
    
    # Network depths
    depths = [1, 2, 3, 4]
    
    # Compare test accuracies
    plt.figure(figsize=(12, 6))
    plt.plot(depths, exp_c_results['test_accuracy']['y'], 'o-', label='Sigmoid (Fixed LR)')
    plt.plot(depths, exp_d_results['test_accuracy']['y'], 's-', label='Sigmoid (Adaptive LR)')
    plt.plot(depths, exp_e_results['test_accuracy']['y'], '^-', label='ReLU (Adaptive LR)')
    plt.plot(depths, exp_f_results['test_accuracy']['y'], 'D-', label='scikit-learn MLPClassifier')
    plt.xlabel('Network Depth (Number of Hidden Layers)')
    plt.ylabel('Test Accuracy')
    plt.title('Comparison of Test Accuracies Across Experiments')
    plt.legend()
    plt.grid(True)
    plt.xticks(depths)
    plt.savefig('comparison_test_accuracy.png')
    plt.show()
    
    # Compare test F1 scores
    plt.figure(figsize=(12, 6))
    plt.plot(depths, exp_c_results['test_f1']['y'], 'o-', label='Sigmoid (Fixed LR)')
    plt.plot(depths, exp_d_results['test_f1']['y'], 's-', label='Sigmoid (Adaptive LR)')
    plt.plot(depths, exp_e_results['test_f1']['y'], '^-', label='ReLU (Adaptive LR)')
    plt.plot(depths, exp_f_results['test_f1']['y'], 'D-', label='scikit-learn MLPClassifier')
    plt.xlabel('Network Depth (Number of Hidden Layers)')
    plt.ylabel('Test F1 Score')
    plt.title('Comparison of Test F1 Scores Across Experiments')
    plt.legend()
    plt.grid(True)
    plt.xticks(depths)
    plt.savefig('comparison_test_f1.png')
    plt.show()

def main():
    # Parse command line arguments
    if len(sys.argv) != 5:
        print("Usage: python neural_network.py &lt;train_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
        sys.exit(1)
    train_data_path = sys.argv[1]
    test_data_path = sys.argv[2]
    output_path = sys.argv[3]
    question_part = sys.argv[4].lower()
    # make output_path if it does not exist
    if not os.path.exists(output_path):
        os.makedirs(output_path)
    print("Loading and preprocessing data...")
    X_train, y_train, X_val, y_val, X_test, y_test, y_train_onehot, y_val_onehot, y_test_onehot = load_data(train_data_path, test_data_path)    
    
    # Run experiments
    if question_part == 'a':
        print("\n=== Experiment (a): Data Loading and Preprocessing ===")
        print("Data loaded successfully!")
    elif question_part == 'b':
        exp_b_results = experiment_b(X_train, y_train, X_val, y_val, X_test, y_test, 
                                y_train_onehot, y_val_onehot, y_test_onehot, output_path)
    
    elif question_part == 'c':
        exp_c_results = experiment_c(X_train, y_train, X_val, y_val, X_test, y_test, 
                                y_train_onehot, y_val_onehot, y_test_onehot, output_path)
    elif question_part == 'd':
        exp_d_results = experiment_d(X_train, y_train, X_val, y_val, X_test, y_test, 
                                y_train_onehot, y_val_onehot, y_test_onehot, output_path)
    
    elif question_part == 'e':
        exp_e_results = experiment_e(X_train, y_train, X_val, y_val, X_test, y_test, 
                                y_train_onehot, y_val_onehot, y_test_onehot, output_path)
    elif question_part == 'f':
        exp_f_results = experiment_f(X_train, y_train, X_val, y_val, X_test, y_test, output_path)
    else:
        print("Invalid question part. Please specify 'a', 'b', 'c', 'd', 'e', or 'f'.")
    return
    
if __name__ == "__main__":
    import sys
    main()


</PRE>
</PRE>
</BODY>
</HTML>
