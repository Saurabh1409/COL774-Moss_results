<HTML>
<HEAD>
<TITLE>./A3_processed_new_hash/combined_0Y80D.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A3_processed_new_hash/combined_0Y80D.py<p><PRE>


#-----------------1.a-------------------


import numpy as np
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from collections import defaultdict
from tqdm import tqdm
import sys
import os
from sklearn.tree import DecisionTreeClassifier as DecisionTreeClassifier_sk
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import OneHotEncoder
<A NAME="1"></A><FONT color = #00FF00><A HREF="match78-1.html#1" TARGET="1"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

class DecisionTreeClassifier:
    def __init__(self, max_depth=5):
        self.max_depth = max_depth
        self.continuous_attrs = ['age', 'fnlwgt', 'education.num', 
</FONT>                                'capital.gain', 'capital.loss', 'hours.per.week']
        self.root = None

    class Node:
        def __init__(self, is_leaf=False, class_label=None, split_attribute=None,
                     split_type=None, split_value=None, children=None, default_class=None):
            self.is_leaf = is_leaf
            self.class_label = class_label
            self.split_attribute = split_attribute
            self.split_type = split_type
            self.split_value = split_value
            self.children = children if children else {}
            self.default_class = default_class

    @staticmethod
    def _entropy(S):
        p = (S['income'] == ' &gt;50K').mean()
        if p == 0 or p == 1:
            return 0
        return -p * np.log2(p) - (1-p) * np.log2(1-p)

<A NAME="2"></A><FONT color = #0000FF><A HREF="match78-1.html#2" TARGET="1"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    def _conditional_entropy_continuous(self, S, A, m):
        S_left = S[S[A] &lt;= m]
        S_right = S[S[A] &gt; m]
        if len(S_left) == 0 or len(S_right) == 0:
</FONT>            return self._entropy(S)
        weight_left = len(S_left) / len(S)
        weight_right = len(S_right) / len(S)
        return weight_left * self._entropy(S_left) + weight_right * self._entropy(S_right)

    def _conditional_entropy_categorical(self, S, A):
        values = S[A].unique()
        weighted_entropy = 0
        for v in values:
            S_v = S[S[A] == v]
            weight = len(S_v) / len(S)
            weighted_entropy += weight * self._entropy(S_v)
        return weighted_entropy

    def _select_best_attribute(self, S, attributes):
        best_IG = -1
        best_A = None
        best_m = None
        H_Y = self._entropy(S)
        m = None
        H_Y_given_A = None
        
        for A in attributes:
            if A not in self.continuous_attrs:
                H_Y_given_A = self._conditional_entropy_categorical(S, A)
            elif A in self.continuous_attrs and S[A].nunique() &gt; 1:
                m = S[A].median()
                H_Y_given_A = self._conditional_entropy_continuous(S, A, m)
            else:
                H_Y_given_A = H_Y  # No split possible
                
            IG = H_Y - H_Y_given_A
            if IG &gt; best_IG:
                best_IG = IG
                best_A = A
                best_m = m if A in self.continuous_attrs else None
                
        return best_A, best_m, best_IG

    def _majority_class(self, S):
        return S['income'].value_counts().idxmax()

    def _build_tree(self, S, attributes, current_depth):
        if (current_depth &gt;= self.max_depth or 
            S['income'].nunique() &lt;= 1 or 
            len(S) == 0):
            return self.Node(is_leaf=True, class_label=self._majority_class(S))
            
        best_A, best_m, best_IG = self._select_best_attribute(S, attributes)
        
        if best_IG &lt;= 0:
            return self.Node(is_leaf=True, class_label=self._majority_class(S))
            
        node = self.Node(
            split_attribute=best_A,
            default_class=self._majority_class(S)
        )
        
        if best_A not in self.continuous_attrs:
            node.split_type = 'categorical'
            for v in S[best_A].unique():
                S_v = S[S[best_A] == v]
                remaining_attrs = [a for a in attributes if a != best_A]
                child = self._build_tree(S_v, remaining_attrs, current_depth + 1)
                node.children[v] = child
        else:
            node.split_type = 'continuous'
            node.split_value = best_m
<A NAME="3"></A><FONT color = #00FFFF><A HREF="match78-1.html#3" TARGET="1"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

            S_left = S[S[best_A] &lt;= best_m]
            S_right = S[S[best_A] &gt; best_m]
            node.children['left'] = self._build_tree(S_left, attributes, current_depth + 1)
</FONT>            node.children['right'] = self._build_tree(S_right, attributes, current_depth + 1)
            
        return node

    def fit(self, train_data):
        attributes = train_data.columns[:-1].tolist()
        self.root = self._build_tree(train_data, attributes, current_depth=0)

    def _predict_single(self, node, instance):
        if node.is_leaf:
            return node.class_label
            
        A = node.split_attribute
        
        if node.split_type == 'categorical':
            value = instance[A]
            if value in node.children:
                return self._predict_single(node.children[value], instance)
            return node.default_class
        else:
            if instance[A] &lt;= node.split_value:
                return self._predict_single(node.children['left'], instance)
            return self._predict_single(node.children['right'], instance)

    def predict(self, data):
        return [self._predict_single(self.root, row) for _, row in data.iterrows()]

    def accuracy(self, data):
        predictions = self.predict(data)
        correct = sum(1 for i, row in data.iterrows() if predictions[i] == row['income'])
        return correct / len(data)

    def _calculate_max_depth(self):
        def _depth(node):
            if node.is_leaf:
                return 0
            depths = [_depth(child) for child in node.children.values()]
            return 1 + max(depths) if depths else 0
            
        return _depth(self.root)
    def count_nodes(self, node=None):
        """Count the total number of nodes in the tree."""
        if node is None:
            node = self.root
        if node.is_leaf:
            return 1
        return 1 + sum(self.count_nodes(child) for child in node.children.values())
    
    def post_prune(self, train_data, valid_data,test_data):
        """Optimized post-pruning with progress tracking and efficient accuracy updates."""
        # Precompute validation predictions and paths
        valid_predictions, valid_paths = self.predict_with_paths(valid_data)
        original_correct = sum(1 for i, row in valid_data.iterrows() 
                              if valid_predictions[i] == row['income'])
        current_correct = original_correct
        total = len(valid_data)
        
        # Build node-to-instances mapping
        node_to_instances = defaultdict(list)
        for idx, path in enumerate(valid_paths):
            for node in path:
                node_to_instances[node].append(idx)
        
        # Initialize metrics
        train_accuracies = [self.accuracy(train_data)]
        valid_accuracies = [current_correct / total]
        test_accuracies = [self.accuracy(test_data)]
        node_counts = [self.count_nodes()]
        
        improved = True
        with tqdm(desc="Pruning Progress") as pbar:
            while improved:
                improved = False
                best_node = None
                best_improvement = 0
                best_affected = []
                best_new_pred = None
                
                # Collect all candidate nodes
                candidate_nodes = []
                self._collect_nodes(self.root, candidate_nodes)
                
                # Evaluate nodes with progress bar
                for node in tqdm(candidate_nodes, desc="Evaluating Nodes", leave=False):
                    if node.is_leaf:
                        continue
                        
                    affected_indices = node_to_instances.get(node, [])
                    if not affected_indices:
                        continue
                    
                    # Calculate potential improvement
                    current_right = sum(valid_predictions[i] == valid_data.iloc[i]['income']
                                    for i in affected_indices)
                    new_right = sum(node.default_class == valid_data.iloc[i]['income']
                                  for i in affected_indices)
                    improvement = new_right - current_right
                    
                    if improvement &gt; best_improvement:
                        best_improvement = improvement
                        best_node = node
                        best_affected = affected_indices
                        best_new_pred = node.default_class
                
                # Apply best prune if improvement found
                if best_node and best_improvement &gt; 0:
                    # Prune the node
                    best_node.is_leaf = True
                    best_node.class_label = best_new_pred
                    best_node.children = {}
                    
                    # Update predictions
                    for i in best_affected:
                        valid_predictions[i] = best_new_pred
                    
                    # Update metrics
                    current_correct += best_improvement
                    train_accuracies.append(self.accuracy(train_data))
                    valid_accuracies.append(current_correct / total)
                    test_accuracies.append(self.accuracy(test_data))
                    node_counts.append(self.count_nodes())
                    
                    improved = True
                    pbar.update(1)
                    pbar.set_postfix({
                        'Val Acc': f"{valid_accuracies[-1]:.4f}",
                        'Nodes': node_counts[-1]
                    })
                else:
                    break  # No more improvements

        return train_accuracies, valid_accuracies, node_counts, test_accuracies

    # Helper methods
    def _collect_nodes(self, node, nodes_list):
        """Recursively collect all nodes in the tree."""
        nodes_list.append(node)
        if not node.is_leaf:
            for child in node.children.values():
                self._collect_nodes(child, nodes_list)

    def predict_with_paths(self, data):
        """Return predictions and node paths for each instance."""
        predictions = []
        paths = []
        for _, row in data.iterrows():
            path = []
            pred = self._predict_single_with_path(self.root, row, path)
            predictions.append(pred)
            paths.append(path)
        return predictions, paths

    def _predict_single_with_path(self, node, instance, path):
        """Recursive prediction with path tracking."""
        path.append(node)
        if node.is_leaf:
            return node.class_label
        
        A = node.split_attribute
        if node.split_type == 'categorical':
            value = instance[A]
            if value in node.children:
                return self._predict_single_with_path(node.children[value], instance, path)
            return node.default_class
        else:
            if instance[A] &lt;= node.split_value:
                return self._predict_single_with_path(node.children['left'], instance, path)
            return self._predict_single_with_path(node.children['right'], instance, path)





def hot_encode(X_train,X_test,X_valid):
    categorical_cols = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']

    cols_to_encode = [col for col in categorical_cols if X_train[col].nunique() &gt; 2]
    
    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(sparse_output=False, drop=None), cols_to_encode)
        ],
        remainder='passthrough'  
    )
    
    X_train_transformed = preprocessor.fit_transform(X_train)
    X_test_transformed = preprocessor.transform(X_test)
    X_valid_transformed = preprocessor.transform(X_valid)
    
    feature_names = (preprocessor.named_transformers_['cat'].get_feature_names_out(cols_to_encode)
                     .tolist() + [col for col in X_train.columns if col not in cols_to_encode])
    X_train_transformed = pd.DataFrame(X_train_transformed, columns=feature_names)
    X_test_transformed = pd.DataFrame(X_test_transformed, columns=feature_names)
    X_valid_transformed = pd.DataFrame(X_valid_transformed, columns=feature_names)
    
    return X_train_transformed ,X_test_transformed, X_valid_transformed




#-------------------------------------------------------------------------------------------------------
#-------------------------------------------------------------------------------------------------------
#-------------------------------------------------------------------------------------------------------
#-------------------------------------------------------------------------------------------------------


def run_part_a(train, validation_data, test, output_folder_path):

    max_depths = [20]
    train_accuracies = []
    test_accuracies = []

    for depth in max_depths:
        dt = DecisionTreeClassifier(max_depth=depth)
        dt.fit(train)
        predictions = dt.predict(test)
        accuracy = dt.accuracy(test)
        print(f"Max Depth: {depth}, Test Accuracy: {accuracy:.4f}")
        predictions = [pred.replace(" &gt;50K", "&gt;50K").replace(" &lt;=50K", "&lt;=50K") for pred in predictions]
        output_file = os.path.join(output_folder_path, f"prediction_a.csv")
        pd.DataFrame(predictions, columns=["prediction"]).to_csv(output_file, index=False)
        print(f"Predictions saved to {output_file}")

def run_part_b(train, valid, test, output_folder_path):
    #-----------------1.b-------------------
    train_encoded, test_encoded, valid_encoded = hot_encode(train, test, valid)
    max_depths = [55]

    train_accuracies = []
    test_accuracies = []

    for depth in max_depths:
        dt = DecisionTreeClassifier(max_depth=depth)
        dt.fit(train_encoded)
        predictions = dt.predict(test_encoded)
        accuracy = dt.accuracy(test_encoded)
        print(f"Max Depth: {depth}, Test Accuracy: {accuracy:.4f}")
        predictions = [pred.replace(" &gt;50K", "&gt;50K").replace(" &lt;=50K", "&lt;=50K") for pred in predictions]
        output_file = os.path.join(output_folder_path, f"prediction_b.csv")
        pd.DataFrame(predictions, columns=["prediction"]).to_csv(output_file, index=False)
        print(f"Predictions saved to {output_file}")

def run_part_c(train, valid, test, output_folder_path):
    #------------------1.c-------------------

    train_encoded, test_encoded, valid_encoded = hot_encode(train, test, valid)
    max_depths = [55]



    for depth in max_depths:
        dt = DecisionTreeClassifier(max_depth=depth)
        dt.fit(train_encoded)
        dt.post_prune(train_encoded, valid_encoded,test_encoded)
        predictions = dt.predict(test_encoded)
        accuracy = dt.accuracy(test_encoded)
        print(f"Max Depth: {depth}, Test Accuracy: {accuracy:.4f}")
        predictions = [pred.replace(" &gt;50K", "&gt;50K").replace(" &lt;=50K", "&lt;=50K") for pred in predictions]
        output_file = os.path.join(output_folder_path, f"prediction_c.csv")
        pd.DataFrame(predictions, columns=["prediction"]).to_csv(output_file, index=False)
        print(f"Predictions saved to {output_file}")

        
def run_part_d(train, valid, test, output_folder_path):
    #------------------1.d-------------------
    categorical_cols = ['workclass', 'education', 'marital.status', 'occupation', 
                    'relationship', 'race', 'sex', 'native.country']
    numerical_cols = ['age', 'fnlwgt', 'education.num', 'capital.gain', 
                    'capital.loss', 'hours.per.week']

    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),
            ('num', 'passthrough', numerical_cols)
        ]
    )

    X_train = train.drop('income', axis=1)
    y_train = train['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

    X_valid = valid.drop('income', axis=1)
    y_valid = valid['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

    X_test = test.drop('income', axis=1)
    y_test = test['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

    print(y_train.value_counts())
    best_max_depth = 25
    best_ccp_alpha = 0.001
    def create_best_pipeline():
        return Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('classifier', DecisionTreeClassifier_sk(criterion="entropy", max_depth=best_max_depth, ccp_alpha=best_ccp_alpha))
        ])
    pipeline = create_best_pipeline()
    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Test Accuracy: {accuracy:.4f}")
    predictions = ["&gt;50K" if pred == 1 else "&lt;=50K" for pred in y_pred]
    output_file = os.path.join(output_folder_path, f"prediction_d.csv")
    pd.DataFrame(predictions, columns=["prediction"]).to_csv(output_file, index=False)
    print(f"Predictions saved to {output_file}")



def run_part_e(train, valid, test, output_folder_path):
    #-----------------1.e-------------------


    X_train = train.drop('income', axis=1)
    y_train = train['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)
    X_valid = valid.drop('income', axis=1)
    y_valid = valid['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)
    X_test = test.drop('income', axis=1)
    y_test = test['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

    categorical_cols = ['workclass', 'education', 'marital.status', 'occupation', 
                        'relationship', 'race', 'sex', 'native.country']
    numerical_cols = ['age', 'fnlwgt', 'education.num', 'capital.gain', 
                    'capital.loss', 'hours.per.week']

    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),
            ('num', 'passthrough', numerical_cols)
        ]
    )

    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(criterion='entropy', oob_score=True, random_state=42))
    ])

    param_grid = {
        'classifier__n_estimators': [250],
        'classifier__max_features': [0.5],
        'classifier__min_samples_split': [10]
    }

    best_oob_score = -1
    best_params = None
    best_model = None
    oob_scores = []

    for n_estimators in param_grid['classifier__n_estimators']:
        for max_features in param_grid['classifier__max_features']:
            for min_samples_split in param_grid['classifier__min_samples_split']:
                pipeline.set_params(
                    classifier__n_estimators=n_estimators,
                    classifier__max_features=max_features,
                    classifier__min_samples_split=min_samples_split
                )
                pipeline.fit(X_train, y_train)
                oob_score = pipeline.named_steps['classifier'].oob_score_
                oob_scores.append(oob_score)
                print(f"n_estimators: {n_estimators}, max_features: {max_features}, "
                    f"min_samples_split: {min_samples_split}, OOB Score: {oob_score:.4f}")
                
                if oob_score &gt; best_oob_score:
                    best_oob_score = oob_score
                    best_params = {
                        'n_estimators': n_estimators,
                        'max_features': max_features,
                        'min_samples_split': min_samples_split
                    }
                    best_model = pipeline

    train_pred = best_model.predict(X_train)
    train_acc = accuracy_score(y_train, train_pred)
    valid_pred = best_model.predict(X_valid)
    valid_acc = accuracy_score(y_valid, valid_pred)
    test_pred = best_model.predict(X_test)
    test_acc = accuracy_score(y_test, test_pred)

    predictions = ["&gt;50K" if pred == 1 else "&lt;=50K" for pred in test_pred]
    output_file = os.path.join(output_folder_path, f"prediction_e.csv")
    pd.DataFrame(predictions, columns=["prediction"]).to_csv(output_file, index=False)
    print(f"Predictions saved to {output_file}")


    print("\nBest Parameters:", best_params)
    print(f"Training Accuracy: {train_acc:.4f}")
    print(f"OOB Accuracy: {best_oob_score:.4f}")
    print(f"Validation Accuracy: {valid_acc:.4f}")
    print(f"Test Accuracy: {test_acc:.4f}")
    print(f"  Train Accuracy: {train_acc:.4f}, Validation Accuracy: {valid_acc:.4f}, Test Accuracy: {test_acc:.4f}")



#-------------------------------------------------------------------------------------------------------
#-------------------------------------------------------------------------------------------------------
#-------------------------------------------------------------------------------------------------------
#-------------------------------------------------------------------------------------------------------



if __name__ == "__main__":
    
    train_data_path = sys.argv[1]
<A NAME="0"></A><FONT color = #FF0000><A HREF="match78-1.html#0" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    validation_data_path = sys.argv[2]
    test_data_path = sys.argv[3]
    output_folder_path = sys.argv[4]

    train_data = pd.read_csv(train_data_path)
    validation_data = pd.read_csv(validation_data_path)
    test_data = pd.read_csv(test_data_path)
</FONT>
    question_part = sys.argv[5]

    if question_part == 'a':
        run_part_a(train_data, validation_data, test_data, output_folder_path)
    elif question_part == 'b':
        run_part_b(train_data, validation_data, test_data, output_folder_path)
    elif question_part == 'c':
        run_part_c(train_data, validation_data, test_data, output_folder_path)
    elif question_part == 'd':
        run_part_d(train_data, validation_data, test_data, output_folder_path)
    elif question_part == 'e':
        run_part_e(train_data, validation_data, test_data, output_folder_path)
    else:
        print("Invalid question part. Please specify 'a', 'b', 'c', 'd', or 'e'.")
        sys.exit(1)
    
        

    
    



import os
import cv2
import sys
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPClassifier
from tqdm import trange

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def relu(x):
    return np.maximum(0, x)

def softmax(x, axis=0):
    max_x = np.max(x, axis=axis, keepdims=True)
    exp_x = np.exp(x - max_x)
    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)

def load_data(train_folder, test_folder):
    X_train = []
    y_train = []
    for label in range(43):
        label1 = str(label).zfill(5) + '/'
        folder_path = os.path.join(train_folder, label1)
        for filename in os.listdir(folder_path):
            if filename.endswith('.jpg'):
                img_path = os.path.join(folder_path, filename)
                img = cv2.imread(img_path)
                img = cv2.resize(img, (28, 28))
                X_train.append(img)
                y_train.append(label)
    X_train = np.array(X_train).astype(np.float32) / 255.0
    y_train = np.array(y_train)
    
    
    X_test = []
    for filename in os.listdir(test_folder):
        if filename.endswith('.jpg'):
            img_path = os.path.join(test_folder, filename)
            img = cv2.imread(img_path)
            img = cv2.resize(img, (28, 28))

            X_test.append(img)
    X_test = np.array(X_test).astype(np.float32) / 255.0
    
    X_train = X_train.reshape(X_train.shape[0], -1)  # (N, 2352)
    X_test = X_test.reshape(X_test.shape[0], -1)    # (M, 2352)
    X_val = X_train.copy()
    y_val = y_train.copy()
    
    
    return X_train, y_train, X_test,X_val,y_val



from tqdm import trange


class NeuralNetwork:
    def __init__(self, layer_sizes, activation='sigmoid', dtype=np.float32):
        self.layer_sizes = layer_sizes
        self.num_layers = len(layer_sizes) - 1
        self.activation = activation
        self.dtype = dtype
        
        self.weights = []
        self.biases = []
        for i in range(self.num_layers):
            self.weights.append(
                np.random.randn(layer_sizes[i+1], layer_sizes[i]).astype(dtype) * 0.01)
            self.biases.append(
                np.zeros((layer_sizes[i+1], 1), dtype=dtype))

    def forward(self, X):
        activations = [X.astype(self.dtype)]
        for i in range(self.num_layers):
            z = self.weights[i] @ activations[-1] + self.biases[i]
            if i &lt; self.num_layers - 1:
                if self.activation == 'sigmoid':
                    a = sigmoid(z)
                elif self.activation == 'relu':
                    a = relu(z)
            else:
                a = softmax(z, axis=0)
            activations.append(a)
        return activations[-1], activations

    def backward(self, Y, activations):
        M = Y.shape[1]
        delta = activations[-1] - Y  
        grads = []
        
        for i in reversed(range(self.num_layers)):
            grad_W = (delta @ activations[i].T) / M
            grad_b = np.sum(delta, axis=1, keepdims=True) / M
            grads.append({'weights': grad_W, 'biases': grad_b})
            
            if i &gt; 0:
                if self.activation == 'sigmoid':
                    g_prime = activations[i] * (1 - activations[i])
                elif self.activation == 'relu':
                    g_prime = (activations[i] &gt; 0).astype(self.dtype)
                delta = (self.weights[i].T @ delta) * g_prime
        
        return reversed(grads)

    def train_step(self, X, Y, learning_rate):
        a_L, activations = self.forward(X)
        loss = -np.mean(np.sum(Y * np.log(a_L + 1e-8), axis=0))
        grads = self.backward(Y, activations)
        
        for i, grad in enumerate(grads):
            self.weights[i] -= learning_rate * grad['weights']
            self.biases[i] -= learning_rate * grad['biases']
        
        return loss

    def predict(self, X):
        a_L, _ = self.forward(X)
        return np.argmax(a_L, axis=0)

    def train(self, X_train, y_train, X_val, y_val,
             batch_size=32, eta0=0.01, num_epochs=100,
             patience=10, adaptive=False):
        
        X_train = X_train.astype(self.dtype)
        y_train = y_train.astype(self.dtype)
        X_val = X_val.astype(self.dtype)
        
        best_weights = [w.copy() for w in self.weights]
        best_biases = [b.copy() for b in self.biases]
        best_metric = -np.inf if adaptive else np.inf
        counter = 0
        
        with trange(num_epochs, desc="Training") as progress_bar:
            for epoch in progress_bar:
                lr = eta0 / np.sqrt(epoch + 1) if adaptive else eta0
                indices = np.random.permutation(X_train.shape[1])
                X_shuffled = X_train[:, indices]
                y_shuffled = y_train[:, indices]
                epoch_loss = 0
                
                for i in range(0, X_train.shape[1], batch_size):
                    X_batch = X_shuffled[:, i:i+batch_size]
                    y_batch = y_shuffled[:, i:i+batch_size]
                    batch_loss = self.train_step(X_batch, y_batch, lr)
                    epoch_loss += batch_loss * X_batch.shape[1]
                
                avg_loss = epoch_loss / X_train.shape[1]
                val_pred = self.predict(X_val)
                val_acc = np.mean(val_pred == y_val)
                
                postfix = {'loss': avg_loss, 'val_acc': val_acc}
                if adaptive:
                    postfix['lr'] = lr
                progress_bar.set_postfix(postfix)
                
                current_metric = val_acc if adaptive else avg_loss
                condition = (current_metric &gt; best_metric) if adaptive else (current_metric &lt; best_metric)
                
                if condition:
                    best_metric = current_metric
                    best_weights = [w.copy() for w in self.weights]
                    best_biases = [b.copy() for b in self.biases]
                    counter = 0
                else:
                    counter += 1
                
                if counter &gt;= patience:
                    print(f"\nEarly stopping at epoch {epoch}")
                    break
        
        self.weights = best_weights
        self.biases = best_biases




#-----------------------------------------------------------------------------------------------
#-----------------------------------------------------------------------------------------------
#-----------------------------------------------------------------------------------------------
#-----------------------------------------------------------------------------------------------
#-----------------------------------------------------------------------------------------------


def run_part_b(X_train_T, y_train, X_val_T, y_val, X_test_T, output_folder_path,y_train_onehot):
    hidden_units = [100]
    f1_scores_train = []

    for h in hidden_units:
        print(f"\nPart (b): Training with {h} hidden units")
        layer_sizes = [2352, h, 43]
        nn = NeuralNetwork(layer_sizes, activation='sigmoid')
        nn.train(X_train_T, y_train_onehot, X_val_T, y_val, batch_size=32, eta0=0.01, num_epochs=200, patience=10)
        
        train_pred = nn.predict(X_train_T)
        test_pred = nn.predict(X_test_T)
        print("test_pred shape:", test_pred.shape)
        print("train_pred shape:", train_pred.shape)
        print("y_train shape:", y_train.shape)
        p_train, r_train, f1_train, _ = precision_recall_fscore_support(y_train, train_pred, average=None)
        
        f1_scores_train.append(np.mean(f1_train))
        
        print(f"F1 Score (Train): {np.mean(f1_train)}")
        # Save predictions
        output_file = os.path.join(output_folder_path, f'prediction_b.csv')
        df = pd.DataFrame({'prediction': test_pred})
        df.to_csv(output_file, index=False)
        print(f"Predictions saved to {output_file}")

def run_part_c(X_train_T, y_train, X_val_T, y_val, X_test_T, output_folder_path,y_train_onehot):
    #---------------------1.c------------------------------

    hidden_layers_list = [[512, 256, 128, 64]]
    f1_scores_train = []
    f1_scores_test = []

    for hidden_layers in hidden_layers_list:
        print(f"\nPart (c): Training with hidden layers {hidden_layers}")
        layer_sizes = [2352] + hidden_layers + [43]
        nn = NeuralNetwork(layer_sizes, activation='sigmoid')
        nn.train(X_train_T, y_train_onehot, X_val_T, y_val, batch_size=32, eta0=0.01, num_epochs=200, patience=50)
        
        train_pred = nn.predict(X_train_T)
        test_pred = nn.predict(X_test_T)
        p_train, r_train, f1_train, _ = precision_recall_fscore_support(y_train, train_pred, average=None)
        f1_scores_train.append(np.mean(f1_train))
        print(f"F1 Score (Train): {np.mean(f1_train)}")

        # Save predictions
        output_file = os.path.join(output_folder_path, f'prediction_c.csv')
        df = pd.DataFrame({'prediction': test_pred})
        df.to_csv(output_file, index=False)
        print(f"Predictions saved to {output_file}")


def run_part_d(X_train_T, y_train, X_val_T, y_val, X_test_T, output_folder_path,y_train_onehot):
    hidden_layers_list = [[512, 256, 128, 64]]
    f1_scores_train = []
    f1_scores_test = []

    for hidden_layers in hidden_layers_list:
        print(f"\nPart (d): Training with hidden layers {hidden_layers}")
        layer_sizes = [2352] + hidden_layers + [43]
        nn = NeuralNetwork(layer_sizes, activation='sigmoid')
        nn.train(X_train_T, y_train_onehot, X_val_T, y_val, batch_size=32, eta0=0.01, num_epochs=200, patience=50,adaptive=True)
        
        train_pred = nn.predict(X_train_T)
        test_pred = nn.predict(X_test_T)
        p_train, r_train, f1_train, _ = precision_recall_fscore_support(y_train, train_pred, average=None)
        f1_scores_train.append(np.mean(f1_train))
        print(f"F1 Score (Train): {np.mean(f1_train)}")

        # Save predictions
        output_file = os.path.join(output_folder_path, f'prediction_d.csv')
        df = pd.DataFrame({'prediction': test_pred})
        df.to_csv(output_file, index=False)
        print(f"Predictions saved to {output_file}")

def run_part_e(X_train_T, y_train, X_val_T, y_val, X_test_T, output_folder_path,y_train_onehot):
    hidden_layers_list = [[512, 256, 128, 64]]
    f1_scores_train = []
    f1_scores_test = []

    for hidden_layers in hidden_layers_list:
        print(f"\nPart (e): Training with hidden layers {hidden_layers}")
        layer_sizes = [2352] + hidden_layers + [43]
        nn = NeuralNetwork(layer_sizes, activation='relu')
        nn.train(X_train_T, y_train_onehot, X_val_T, y_val, batch_size=32, eta0=0.01, num_epochs=200, patience=50,adaptive=True)
        
        train_pred = nn.predict(X_train_T)
        test_pred = nn.predict(X_test_T)
        p_train, r_train, f1_train, _ = precision_recall_fscore_support(y_train, train_pred, average=None)
        f1_scores_train.append(np.mean(f1_train))
        print(f"F1 Score (Train): {np.mean(f1_train)}")

        # Save predictions
        output_file = os.path.join(output_folder_path, f'prediction_e.csv')
        df = pd.DataFrame({'prediction': test_pred})
        df.to_csv(output_file, index=False)
        print(f"Predictions saved to {output_file}")

def run_part_f(X_train, y_train, X_val, y_val, X_test, output_folder_path):
    #---------------------1.f------------------------------

    f1_scores_test = []
    f1_scores_train = []
    hidden_layers_list = [[512, 256, 128, 64]]
    depths = [len(hl) for hl in hidden_layers_list]

    for hidden_layers in hidden_layers_list:
        print(f"\nPart (f): Training with hidden layers {hidden_layers} using MLPClassifier")
        mlp = MLPClassifier(
            hidden_layer_sizes=hidden_layers,
            activation='relu',
            solver='sgd',          
            batch_size=32,         
            max_iter=100,
            early_stopping=True,    
            validation_fraction=0.1,
            n_iter_no_change=5,
            random_state=49,
            verbose=1         
        )
        mlp.fit(X_train, y_train)
        
        train_pred = mlp.predict(X_train)
        test_pred = mlp.predict(X_test)



        p_train, r_train, f1_train, _ = precision_recall_fscore_support(y_train, train_pred, average=None)

        f1_scores_train.append(np.mean(f1_train))
        print(f"F1 Score (Train): {np.mean(f1_train)}")
        # Save predictions
        output_file = os.path.join(output_folder_path, f'prediction_f.csv')
        df = pd.DataFrame({'prediction': test_pred})
        df.to_csv(output_file, index=False)
        print(f"Predictions saved to {output_file}")
        # Save the model

        















    



# command:
# python neural_network.py &lt;train_data_path&gt;  &lt;test_data_path&gt;
# &lt;output_folder_path&gt; &lt;question_part&gt;
# train data path : the absolute path of train data. 
# test data path : the absolute path of test data. 
# output folder path : the absolute path of the output folder. you will save your predictions of the test dataset named as prediction {question number}.csv. Eg. prediction b.csv.
# it will have one column named ”prediction”. Make sure to preserve the sequence of examples. question part: one of ‘b’ to ‘e’ denoting the part of the question.



if __name__ == "__main__":
    
    
    train_data_path = sys.argv[1]
    test_data_path = sys.argv[2]
    output_folder_path = sys.argv[3]
    question_part = sys.argv[4]
    X_train, y_train, X_test,X_val,y_val = load_data(train_data_path, test_data_path)
    X_train_T = X_train.T  # (2352, 21312)
    X_val_T = X_val.T      # (2352, 5328)
    X_test_T = X_test.T    # (2352, 12630)
    y_train_onehot = np.eye(43)[y_train].T  # (43, 21312)
    y_val_onehot = y_val

    run_part_b(X_train_T, y_train, X_val_T, y_val_onehot, X_test_T, output_folder_path,y_train_onehot)
    run_part_c(X_train_T, y_train, X_val_T, y_val_onehot, X_test_T, output_folder_path,y_train_onehot)
    run_part_d(X_train_T, y_train, X_val_T, y_val_onehot, X_test_T, output_folder_path,y_train_onehot)
    run_part_e(X_train_T, y_train, X_val_T, y_val_onehot, X_test_T, output_folder_path,y_train_onehot)
    run_part_f(X_train, y_train, X_val, y_val, X_test, output_folder_path)





    

    



#!/usr/bin/env python
# coding: utf-8

# In[11]:


#-----------------1.a-------------------


import numpy as np
import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from collections import defaultdict
from tqdm import tqdm

class DecisionTreeClassifier:
    def __init__(self, max_depth=5):
        self.max_depth = max_depth
        self.continuous_attrs = ['age', 'fnlwgt', 'education.num', 
                                'capital.gain', 'capital.loss', 'hours.per.week']
        self.root = None

    class Node:
        def __init__(self, is_leaf=False, class_label=None, split_attribute=None,
                     split_type=None, split_value=None, children=None, default_class=None):
            self.is_leaf = is_leaf
            self.class_label = class_label
            self.split_attribute = split_attribute
            self.split_type = split_type
            self.split_value = split_value
            self.children = children if children else {}
            self.default_class = default_class

    @staticmethod
    def _entropy(S):
        p = (S['income'] == ' &gt;50K').mean()
        if p == 0 or p == 1:
            return 0
        return -p * np.log2(p) - (1-p) * np.log2(1-p)

<A NAME="4"></A><FONT color = #FF00FF><A HREF="match78-1.html#4" TARGET="1"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    def _conditional_entropy_continuous(self, S, A, m):
        S_left = S[S[A] &lt;= m]
        S_right = S[S[A] &gt; m]
        if len(S_left) == 0 or len(S_right) == 0:
</FONT>            return self._entropy(S)
        weight_left = len(S_left) / len(S)
        weight_right = len(S_right) / len(S)
        return weight_left * self._entropy(S_left) + weight_right * self._entropy(S_right)

    def _conditional_entropy_categorical(self, S, A):
        values = S[A].unique()
        weighted_entropy = 0
        for v in values:
            S_v = S[S[A] == v]
            weight = len(S_v) / len(S)
            weighted_entropy += weight * self._entropy(S_v)
        return weighted_entropy

    def _select_best_attribute(self, S, attributes):
        best_IG = -1
        best_A = None
        best_m = None
        H_Y = self._entropy(S)
        m = None
        H_Y_given_A = None
        
        for A in attributes:
            if A not in self.continuous_attrs:
                H_Y_given_A = self._conditional_entropy_categorical(S, A)
            elif A in self.continuous_attrs and S[A].nunique() &gt; 1:
                m = S[A].median()
                H_Y_given_A = self._conditional_entropy_continuous(S, A, m)
            else:
                H_Y_given_A = H_Y  # No split possible
                
            IG = H_Y - H_Y_given_A
            if IG &gt; best_IG:
                best_IG = IG
                best_A = A
                best_m = m if A in self.continuous_attrs else None
                
        return best_A, best_m, best_IG

    def _majority_class(self, S):
        return S['income'].value_counts().idxmax()

    def _build_tree(self, S, attributes, current_depth):
        if (current_depth &gt;= self.max_depth or 
            S['income'].nunique() &lt;= 1 or 
            len(S) == 0):
            return self.Node(is_leaf=True, class_label=self._majority_class(S))
            
        best_A, best_m, best_IG = self._select_best_attribute(S, attributes)
        
        if best_IG &lt;= 0:
            return self.Node(is_leaf=True, class_label=self._majority_class(S))
            
        node = self.Node(
            split_attribute=best_A,
            default_class=self._majority_class(S)
        )
        
        if best_A not in self.continuous_attrs:
            node.split_type = 'categorical'
            for v in S[best_A].unique():
                S_v = S[S[best_A] == v]
                remaining_attrs = [a for a in attributes if a != best_A]
                child = self._build_tree(S_v, remaining_attrs, current_depth + 1)
                node.children[v] = child
        else:
            node.split_type = 'continuous'
            node.split_value = best_m
<A NAME="5"></A><FONT color = #FF0000><A HREF="match78-1.html#5" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

            S_left = S[S[best_A] &lt;= best_m]
            S_right = S[S[best_A] &gt; best_m]
            node.children['left'] = self._build_tree(S_left, attributes, current_depth + 1)
</FONT>            node.children['right'] = self._build_tree(S_right, attributes, current_depth + 1)
            
        return node

    def fit(self, train_data):
        attributes = train_data.columns[:-1].tolist()
        self.root = self._build_tree(train_data, attributes, current_depth=0)

    def _predict_single(self, node, instance):
        if node.is_leaf:
            return node.class_label
            
        A = node.split_attribute
        
        if node.split_type == 'categorical':
            value = instance[A]
            if value in node.children:
                return self._predict_single(node.children[value], instance)
            return node.default_class
        else:
            if instance[A] &lt;= node.split_value:
                return self._predict_single(node.children['left'], instance)
            return self._predict_single(node.children['right'], instance)

    def predict(self, data):
        return [self._predict_single(self.root, row) for _, row in data.iterrows()]

    def accuracy(self, data):
        predictions = self.predict(data)
        correct = sum(1 for i, row in data.iterrows() if predictions[i] == row['income'])
        return correct / len(data)

    def _calculate_max_depth(self):
        def _depth(node):
            if node.is_leaf:
                return 0
            depths = [_depth(child) for child in node.children.values()]
            return 1 + max(depths) if depths else 0
            
        return _depth(self.root)
    def count_nodes(self, node=None):
        """Count the total number of nodes in the tree."""
        if node is None:
            node = self.root
        if node.is_leaf:
            return 1
        return 1 + sum(self.count_nodes(child) for child in node.children.values())
    
    def post_prune(self, train_data, valid_data,test_data):
        """Optimized post-pruning with progress tracking and efficient accuracy updates."""
        # Precompute validation predictions and paths
        valid_predictions, valid_paths = self.predict_with_paths(valid_data)
        original_correct = sum(1 for i, row in valid_data.iterrows() 
                              if valid_predictions[i] == row['income'])
        current_correct = original_correct
        total = len(valid_data)
        
        # Build node-to-instances mapping
        node_to_instances = defaultdict(list)
        for idx, path in enumerate(valid_paths):
            for node in path:
                node_to_instances[node].append(idx)
        
        # Initialize metrics
        train_accuracies = [self.accuracy(train_data)]
        valid_accuracies = [current_correct / total]
        test_accuracies = [self.accuracy(test_data)]
        node_counts = [self.count_nodes()]
        
        improved = True
        with tqdm(desc="Pruning Progress") as pbar:
            while improved:
                improved = False
                best_node = None
                best_improvement = 0
                best_affected = []
                best_new_pred = None
                
                # Collect all candidate nodes
                candidate_nodes = []
                self._collect_nodes(self.root, candidate_nodes)
                
                # Evaluate nodes with progress bar
                for node in tqdm(candidate_nodes, desc="Evaluating Nodes", leave=False):
                    if node.is_leaf:
                        continue
                        
                    affected_indices = node_to_instances.get(node, [])
                    if not affected_indices:
                        continue
                    
                    # Calculate potential improvement
                    current_right = sum(valid_predictions[i] == valid_data.iloc[i]['income']
                                    for i in affected_indices)
                    new_right = sum(node.default_class == valid_data.iloc[i]['income']
                                  for i in affected_indices)
                    improvement = new_right - current_right
                    
                    if improvement &gt; best_improvement:
                        best_improvement = improvement
                        best_node = node
                        best_affected = affected_indices
                        best_new_pred = node.default_class
                
                # Apply best prune if improvement found
                if best_node and best_improvement &gt; 0:
                    # Prune the node
                    best_node.is_leaf = True
                    best_node.class_label = best_new_pred
                    best_node.children = {}
                    
                    # Update predictions
                    for i in best_affected:
                        valid_predictions[i] = best_new_pred
                    
                    # Update metrics
                    current_correct += best_improvement
                    train_accuracies.append(self.accuracy(train_data))
                    valid_accuracies.append(current_correct / total)
                    test_accuracies.append(self.accuracy(test_data))
                    node_counts.append(self.count_nodes())
                    
                    improved = True
                    pbar.update(1)
                    pbar.set_postfix({
                        'Val Acc': f"{valid_accuracies[-1]:.4f}",
                        'Nodes': node_counts[-1]
                    })
                else:
                    break  # No more improvements

        return train_accuracies, valid_accuracies, node_counts, test_accuracies

    # Helper methods
    def _collect_nodes(self, node, nodes_list):
        """Recursively collect all nodes in the tree."""
        nodes_list.append(node)
        if not node.is_leaf:
            for child in node.children.values():
                self._collect_nodes(child, nodes_list)

    def predict_with_paths(self, data):
        """Return predictions and node paths for each instance."""
        predictions = []
        paths = []
        for _, row in data.iterrows():
            path = []
            pred = self._predict_single_with_path(self.root, row, path)
            predictions.append(pred)
            paths.append(path)
        return predictions, paths

    def _predict_single_with_path(self, node, instance, path):
        """Recursive prediction with path tracking."""
        path.append(node)
        if node.is_leaf:
            return node.class_label
        
        A = node.split_attribute
        if node.split_type == 'categorical':
            value = instance[A]
            if value in node.children:
                return self._predict_single_with_path(node.children[value], instance, path)
            return node.default_class
        else:
            if instance[A] &lt;= node.split_value:
                return self._predict_single_with_path(node.children['left'], instance, path)
            return self._predict_single_with_path(node.children['right'], instance, path)



    


            
    

train = pd.read_csv('/Users/akshadmhaske/Desktop/mlass/Q1/data/train.csv')
test = pd.read_csv('/Users/akshadmhaske/Desktop/mlass/Q1/data/test.csv')
valid = pd.read_csv('/Users/akshadmhaske/Desktop/mlass/Q1/data/valid.csv')

def hot_encode(X_train,X_test,X_valid):
    categorical_cols = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']

    cols_to_encode = [col for col in categorical_cols if X_train[col].nunique() &gt; 2]
    
    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(sparse_output=False, drop=None), cols_to_encode)
        ],
        remainder='passthrough'  # Keep other columns unchanged
    )
    
    X_train_transformed = preprocessor.fit_transform(X_train)
    X_test_transformed = preprocessor.transform(X_test)
    X_valid_transformed = preprocessor.transform(X_valid)
    
    feature_names = (preprocessor.named_transformers_['cat'].get_feature_names_out(cols_to_encode)
                     .tolist() + [col for col in X_train.columns if col not in cols_to_encode])
    X_train_transformed = pd.DataFrame(X_train_transformed, columns=feature_names)
    X_test_transformed = pd.DataFrame(X_test_transformed, columns=feature_names)
    X_valid_transformed = pd.DataFrame(X_valid_transformed, columns=feature_names)
    
    return X_train_transformed ,X_test_transformed, X_valid_transformed





    
    
    


# In[3]:


import pandas as pd
train = pd.read_csv('/Users/akshadmhaske/Desktop/mlass/Q1/data/train.csv')
test = pd.read_csv('/Users/akshadmhaske/Desktop/mlass/Q1/data/test.csv')
valid = pd.read_csv('/Users/akshadmhaske/Desktop/mlass/Q1/data/valid.csv')


# In[4]:



max_depths = [1,2,3,4,5,6,7,8,10,12,14,16,18,20]
train_accuracies = []
test_accuracies = []

for depth in max_depths:
    dt = DecisionTreeClassifier(max_depth=depth)
    dt.fit(train)
    train_accuracy = dt.accuracy(train)
    test_accuracy = dt.accuracy(test)
    train_accuracies.append(train_accuracy)
    test_accuracies.append(test_accuracy)
    md = dt._calculate_max_depth()
    print(f"Max Depth: {depth}, Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}, Tree Depth: {md}")


# In[5]:



import matplotlib.pyplot as plt
plt.plot(max_depths, train_accuracies, label='Train Accuracy')
plt.plot(max_depths, test_accuracies, label='Test Accuracy')
plt.xlabel('Max Depth')
plt.ylabel('Accuracy')
plt.title('Decision Tree Accuracy vs Max Depth')
plt.legend()
plt.grid()
plt.savefig('decision_tree_accuracy.png')
plt.show()


# In[6]:


#-----------------1.b-------------------

train_encoded, test_encoded, valid_encoded = hot_encode(train, test, valid)
max_depths = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,17,19,21,23,25, 35, 45, 55]

train_accuracies = []
test_accuracies = []

for depth in max_depths:
    dt = DecisionTreeClassifier(max_depth=depth)
    dt.fit(train_encoded)
    train_accuracy = dt.accuracy(train_encoded)
    test_accuracy = dt.accuracy(test_encoded)
    train_accuracies.append(train_accuracy)
    test_accuracies.append(test_accuracy)
    md = dt._calculate_max_depth()
    print(f"Max Depth: {depth}, Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}, Tree Depth: {md}")


# In[7]:


plt.figure(figsize=(10, 6))
plt.plot(max_depths, train_accuracies, label='Train Accuracy', marker='o')
plt.plot(max_depths, test_accuracies, label='Test Accuracy', marker='o')
plt.xlabel('Maximum Depth')
plt.ylabel('Accuracy')
plt.title('Decision Tree Performance with One-Hot Encoding')
plt.legend()
plt.grid(True)
plt.show()


# In[14]:


#------------------1.c-------------------

train_encoded, test_encoded, valid_encoded = hot_encode(train, test, valid)
max_depths = [25,35,45,55]



for depth in max_depths:
    dt = DecisionTreeClassifier(max_depth=depth)
    dt.fit(train_encoded)
    train_accuracies, valid_accuracies, node_counts, test_accuracies = dt.post_prune(train_encoded, valid_encoded,test_encoded)
    print(f"Max Depth: {depth}, Train Accuracy: {train_accuracies[-1]:.4f}, Validation Accuracy: {valid_accuracies[-1]:.4f}, Test Accuracy: {test_accuracies[-1]:.4f}, Nodes: {node_counts[-1]}")
    plt.plot(node_counts, train_accuracies, label='Train Accuracy')
    plt.plot(node_counts, valid_accuracies, label='Validation Accuracy')
    plt.plot(node_counts, test_accuracies, label='Test Accuracy')
    plt.xlabel('Number of Nodes')
    plt.ylabel('Accuracy')
    plt.title(f'Decision Tree Accuracy vs Number of Nodes (Max Depth: {depth})')
    plt.legend()
    plt.grid()
    plt.savefig(f'decision_tree_accuracy_nodes_{depth}.png')
    plt.show()



    


    






# In[23]:


#-----------------1.d-------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

categorical_cols = ['workclass', 'education', 'marital.status', 'occupation', 
                    'relationship', 'race', 'sex', 'native.country']
numerical_cols = ['age', 'fnlwgt', 'education.num', 'capital.gain', 
                  'capital.loss', 'hours.per.week']

preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),
        ('num', 'passthrough', numerical_cols)
    ]
)

X_train = train.drop('income', axis=1)
y_train = train['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

X_valid = valid.drop('income', axis=1)
y_valid = valid['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

X_test = test.drop('income', axis=1)
y_test = test['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

print(y_train.value_counts())


# In[25]:


def create_pipeline(max_depth):
    return Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', DecisionTreeClassifier(criterion='entropy', max_depth=max_depth))
    ])

max_depths = [25, 35, 45, 55]
train_accuracies = []
valid_accuracies = []
test_accuracies = []

for depth in max_depths:
    pipeline = create_pipeline(depth)
    pipeline.fit(X_train, y_train)
    
    # Training accuracy
    y_train_pred = pipeline.predict(X_train)
    train_acc = accuracy_score(y_train, y_train_pred)
    train_accuracies.append(train_acc)
    
    # Validation accuracy
    y_valid_pred = pipeline.predict(X_valid)
    valid_acc = accuracy_score(y_valid, y_valid_pred)
    valid_accuracies.append(valid_acc)
    
    # Test accuracy
    y_test_pred = pipeline.predict(X_test)
    test_acc = accuracy_score(y_test, y_test_pred)
    test_accuracies.append(test_acc)
    
    print(f"Max Depth: {depth}, Train Accuracy: {train_acc:.4f}, "
          f"Validation Accuracy: {valid_acc:.4f}, Test Accuracy: {test_acc:.4f}")

plt.figure(figsize=(10, 6))
plt.plot(max_depths, train_accuracies, label='Train Accuracy', marker='o')
plt.plot(max_depths, valid_accuracies, label='Validation Accuracy', marker='o')
plt.plot(max_depths, test_accuracies, label='Test Accuracy', marker='o')
plt.xlabel('Maximum Depth')
plt.ylabel('Accuracy')
plt.title('Decision Tree Performance with Varying Maximum Depths')
plt.legend()
plt.grid(True)
<A NAME="6"></A><FONT color = #00FF00><A HREF="match78-1.html#6" TARGET="1"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

plt.show()


# In[26]:


ccp_alphas = [0.001, 0.01, 0.1, 0.2]
train_accuracies = []
valid_accuracies = []
test_accuracies = []
</FONT>
def create_pipeline_with_ccp(ccp_alpha):
    return Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', DecisionTreeClassifier(criterion='entropy', ccp_alpha=ccp_alpha))
    ])

for ccp_alpha in ccp_alphas:
    pipeline = create_pipeline_with_ccp(ccp_alpha)
    pipeline.fit(X_train, y_train)
    
    y_train_pred = pipeline.predict(X_train)
    train_acc = accuracy_score(y_train, y_train_pred)
    train_accuracies.append(train_acc)
    
    y_valid_pred = pipeline.predict(X_valid)
    valid_acc = accuracy_score(y_valid, y_valid_pred)
    valid_accuracies.append(valid_acc)
    
    
    y_test_pred = pipeline.predict(X_test)
    test_acc = accuracy_score(y_test, y_test_pred)
    test_accuracies.append(test_acc)
    
    print(f"CCP Alpha: {ccp_alpha}, Train Accuracy: {train_acc:.4f}, "
          f"Validation Accuracy: {valid_acc:.4f}, Test Accuracy: {test_acc:.4f}")
    
plt.figure(figsize=(10, 6))
plt.plot(ccp_alphas, train_accuracies, label='Train Accuracy', marker='o')
plt.plot(ccp_alphas, valid_accuracies, label='Validation Accuracy', marker='o')
plt.plot(ccp_alphas, test_accuracies, label='Test Accuracy', marker='o')
plt.xlabel('CCP Alpha')
plt.ylabel('Accuracy')
plt.title('Decision Tree Performance with Varying CCP Alpha')
plt.legend()
plt.grid(True)
plt.show()

    
    


# In[27]:


best_max_depth = 25
best_ccp_alpha = 0.001
def create_best_pipeline():
    return Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', DecisionTreeClassifier(criterion='entropy', max_depth=best_max_depth, ccp_alpha=best_ccp_alpha))
    ])
pipeline = create_best_pipeline()
pipeline.fit(X_train, y_train)
y_train_pred = pipeline.predict(X_train)
train_acc = accuracy_score(y_train, y_train_pred)
y_valid_pred = pipeline.predict(X_valid)
valid_acc = accuracy_score(y_valid, y_valid_pred)
y_test_pred = pipeline.predict(X_test)
test_acc = accuracy_score(y_test, y_test_pred)
print(f"Best Model - Train Accuracy: {train_acc:.4f}, "
      f"Validation Accuracy: {valid_acc:.4f}, Test Accuracy: {test_acc:.4f}")




# In[29]:


#-----------------1.e-------------------

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
<A NAME="7"></A><FONT color = #0000FF><A HREF="match78-1.html#7" TARGET="1"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

train = pd.read_csv('data/train.csv')
valid = pd.read_csv('data/valid.csv')
test = pd.read_csv('data/test.csv')

X_train = train.drop('income', axis=1)
</FONT>y_train = train['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)
X_valid = valid.drop('income', axis=1)
y_valid = valid['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)
X_test = test.drop('income', axis=1)
y_test = test['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

categorical_cols = ['workclass', 'education', 'marital.status', 'occupation', 
                    'relationship', 'race', 'sex', 'native.country']
numerical_cols = ['age', 'fnlwgt', 'education.num', 'capital.gain', 
                  'capital.loss', 'hours.per.week']

preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),
        ('num', 'passthrough', numerical_cols)
    ]
)

pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(criterion='entropy', oob_score=True, random_state=42))
])

param_grid = {
    'classifier__n_estimators': [50, 150, 250, 350],
    'classifier__max_features': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0],
    'classifier__min_samples_split': [2, 4, 6, 8, 10]
}

best_oob_score = -1
best_params = None
best_model = None
oob_scores = []

for n_estimators in param_grid['classifier__n_estimators']:
    for max_features in param_grid['classifier__max_features']:
        for min_samples_split in param_grid['classifier__min_samples_split']:
            pipeline.set_params(
                classifier__n_estimators=n_estimators,
                classifier__max_features=max_features,
                classifier__min_samples_split=min_samples_split
            )
            pipeline.fit(X_train, y_train)
            oob_score = pipeline.named_steps['classifier'].oob_score_
            oob_scores.append(oob_score)
            print(f"n_estimators: {n_estimators}, max_features: {max_features}, "
                  f"min_samples_split: {min_samples_split}, OOB Score: {oob_score:.4f}")
            
            if oob_score &gt; best_oob_score:
                best_oob_score = oob_score
                best_params = {
                    'n_estimators': n_estimators,
                    'max_features': max_features,
                    'min_samples_split': min_samples_split
                }
                best_model = pipeline

train_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, train_pred)
valid_pred = best_model.predict(X_valid)
valid_acc = accuracy_score(y_valid, valid_pred)
test_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, test_pred)

print("\nBest Parameters:", best_params)
print(f"Training Accuracy: {train_acc:.4f}")
print(f"OOB Accuracy: {best_oob_score:.4f}")
print(f"Validation Accuracy: {valid_acc:.4f}")
print(f"Test Accuracy: {test_acc:.4f}")


print(f"  Train Accuracy: {train_acc:.4f}, Validation Accuracy: {valid_acc:.4f}, Test Accuracy: {test_acc:.4f}")


# In[2]:


import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

train = pd.read_csv('data/train.csv')
valid = pd.read_csv('data/valid.csv')
test = pd.read_csv('data/test.csv')

X_train = train.drop('income', axis=1)
y_train = train['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)
X_valid = valid.drop('income', axis=1)
y_valid = valid['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)
X_test = test.drop('income', axis=1)
y_test = test['income'].apply(lambda x: 1 if x.strip() == '&gt;50K' else 0)

categorical_cols = ['workclass', 'education', 'marital.status', 'occupation', 
                        'relationship', 'race', 'sex', 'native.country']
numerical_cols = ['age', 'fnlwgt', 'education.num', 'capital.gain', 
                    'capital.loss', 'hours.per.week']

preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),
        ('num', 'passthrough', numerical_cols)
    ]
)

pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(criterion='entropy', oob_score=True, random_state=42))
])

param_grid = {
    'classifier__n_estimators': [250],
    'classifier__max_features': [0.5],
    'classifier__min_samples_split': [10]
}

best_oob_score = -1
best_params = None
best_model = None
oob_scores = []

for n_estimators in param_grid['classifier__n_estimators']:
    for max_features in param_grid['classifier__max_features']:
        for min_samples_split in param_grid['classifier__min_samples_split']:
            pipeline.set_params(
                classifier__n_estimators=n_estimators,
                classifier__max_features=max_features,
                classifier__min_samples_split=min_samples_split
            )
            pipeline.fit(X_train, y_train)
            oob_score = pipeline.named_steps['classifier'].oob_score_
            oob_scores.append(oob_score)
            print(f"n_estimators: {n_estimators}, max_features: {max_features}, "
                f"min_samples_split: {min_samples_split}, OOB Score: {oob_score:.4f}")
        
            if oob_score &gt; best_oob_score:
                best_oob_score = oob_score
                best_params = {
                    'n_estimators': n_estimators,
                    'max_features': max_features,
                    'min_samples_split': min_samples_split
                }
                best_model = pipeline

train_pred = best_model.predict(X_train)
train_acc = accuracy_score(y_train, train_pred)
valid_pred = best_model.predict(X_valid)
valid_acc = accuracy_score(y_valid, valid_pred)
test_pred = best_model.predict(X_test)
test_acc = accuracy_score(y_test, test_pred)




print("\nBest Parameters:", best_params)
print(f"Training Accuracy: {train_acc:.4f}")
print(f"OOB Accuracy: {best_oob_score:.4f}")
print(f"Validation Accuracy: {valid_acc:.4f}")
print(f"Test Accuracy: {test_acc:.4f}")
print(f"  Train Accuracy: {train_acc:.4f}, Validation Accuracy: {valid_acc:.4f}, Test Accuracy: {test_acc:.4f}")





import re
import pandas as pd
import dataframe_image as dfi
from tabulate import tabulate  

input_text = r"""
Metrics for 1 hidden layers:
Training Precision per class: [0.96103896 0.98165138 0.97150611 0.94123711 0.94091904 0.94001643
 0.996633   0.94002068 0.89078822 0.98756477 0.969163   0.96939891
 0.98807854 0.98273481 0.99814126 0.97607656 1.         0.98926174
 0.9527745  0.98230088 0.88235294 1.         0.98897059 0.99415205
 0.99425287 0.96360153 0.98254364 0.99418605 0.98071625 0.99421965
 0.98310811 0.94565217 0.96721311 0.995842   0.99658703 1.
 0.98888889 0.99319728 0.9821556  1.         0.99170124 0.99435028
 1.        ]
Training Recall per class: [0.98666667 0.92733333 0.95466667 0.95104167 0.97727273 0.90793651
 0.98666667 0.946875   0.97708333 0.96262626 0.97777778 0.98555556
 0.99929078 0.98819444 0.99444444 0.97142857 0.99       0.98266667
 0.9962963  0.74       0.875      0.99166667 0.9962963  0.94444444
 0.96111111 0.98627451 0.93809524 0.95       0.98888889 0.95555556
 0.97       0.96666667 0.98333333 0.99791667 0.97333333 0.99135802
 0.98888889 0.97333333 0.99710145 0.99047619 0.99583333 0.97777778
 0.98333333]
Training F1 per class: [0.97368421 0.95371957 0.96301278 0.94611399 0.95875139 0.92369802
 0.99162479 0.94343539 0.93194237 0.97493606 0.97345133 0.97741047
 0.99365303 0.98545706 0.99628942 0.97374702 0.99497487 0.98595318
 0.97404949 0.84410646 0.87866109 0.9958159  0.99261993 0.96866097
 0.97740113 0.9748062  0.95980512 0.97159091 0.98478562 0.97450425
 0.97651007 0.95604396 0.97520661 0.99687825 0.98482293 0.99566026
 0.98888889 0.98316498 0.9895721  0.99521531 0.99376299 0.9859944
 0.99159664]
Test Precision per class: [0.67391304 0.85442177 0.86472819 0.80340265 0.81690141 0.8796748
 0.85321101 0.84761905 0.78830645 0.94553377 0.91788856 0.84009009
 0.97443609 0.95115332 0.984      0.95544554 0.95918367 0.94476744
 0.72894737 0.81818182 0.4702381  0.95652174 0.88596491 0.82692308
 0.7173913  0.86864407 0.72192513 0.90322581 0.97345133 0.90425532
 0.7202381  0.67559524 0.75324675 0.96244131 0.98290598 0.96605744
 0.8828125  1.         0.97205882 0.96774194 0.85576923 0.70491803
 0.96153846]
Test Recall per class: [0.51666667 0.87222222 0.912      0.94444444 0.87878788 0.85873016
 0.62       0.79111111 0.86888889 0.90416667 0.94848485 0.88809524
 0.93913043 0.97361111 0.91111111 0.91904762 0.94       0.90277778
 0.71025641 0.45       0.87777778 0.48888889 0.84166667 0.57333333
 0.36666667 0.85416667 0.75       0.46666667 0.73333333 0.94444444
 0.80666667 0.84074074 0.96666667 0.97619048 0.95833333 0.94871795
 0.94166667 0.9        0.95797101 0.66666667 0.98888889 0.71666667
 0.83333333]
Test F1 per class: [0.58490566 0.86323024 0.88773524 0.86823289 0.84671533 0.86907631
 0.71814672 0.8183908  0.82663848 0.92438765 0.93293592 0.86342593
 0.95645756 0.9622512  0.94615385 0.9368932  0.94949495 0.92329545
 0.71948052 0.58064516 0.6124031  0.64705882 0.86324786 0.67716535
 0.48529412 0.86134454 0.73569482 0.61538462 0.8365019  0.92391304
 0.76100629 0.74917492 0.84671533 0.96926714 0.97046414 0.95730918
 0.91129032 0.94736842 0.9649635  0.78947368 0.91752577 0.7107438
 0.89285714]

Metrics for 2 hidden layers:
Training Precision per class: [0.98648649 0.97447952 0.96335079 0.96331237 0.96931138 0.96414018
 1.         0.96447231 0.96257796 0.98577236 0.97655678 0.95614973
 0.99715909 0.99374566 0.99628942 0.98550725 1.         0.98801598
 0.96287425 0.96774194 0.8671875  1.         1.         0.98309859
 1.         0.98133595 0.97820823 0.97701149 0.9943662  0.97740113
 0.98305085 0.95795247 0.97647059 0.99173554 0.98986486 0.99875931
 0.99622642 0.99328859 0.98922414 1.         0.9916318  0.94086022
 0.99444444]
Training Recall per class: [0.97333333 0.96733333 0.98133333 0.95729167 0.98106061 0.93888889
 0.99       0.96145833 0.96458333 0.97979798 0.98740741 0.99333333
 0.99574468 0.99305556 0.99444444 0.97142857 0.99333333 0.98933333
 0.99259259 0.8        0.925      0.99583333 0.99259259 0.96944444
 0.98333333 0.97941176 0.96190476 0.94444444 0.98055556 0.96111111
 0.96666667 0.97037037 0.92222222 1.         0.97666667 0.99382716
 0.97777778 0.98666667 0.99782609 0.9952381  0.9875     0.97222222
 0.99444444]
Training F1 per class: [0.97986577 0.97089328 0.97225892 0.96029258 0.9751506  0.951347
 0.99497487 0.96296296 0.9635796  0.98277609 0.98195212 0.97438692
 0.99645138 0.99340049 0.99536608 0.97841727 0.99665552 0.98867422
 0.9775076  0.87591241 0.89516129 0.99791232 0.99628253 0.97622378
 0.99159664 0.98037291 0.969988   0.96045198 0.98741259 0.96918768
 0.97478992 0.96412144 0.94857143 0.99585062 0.98322148 0.99628713
 0.98691589 0.98996656 0.99350649 0.99761337 0.98956159 0.95628415
 0.99444444]
Test Precision per class: [0.77142857 0.78333333 0.79271071 0.80076628 0.84871407 0.87603306
 0.96039604 0.88361045 0.85680751 0.94503171 0.94126285 0.79361702
 0.98273155 0.95994475 0.97131148 0.97777778 0.96621622 0.89196676
 0.76502732 0.69565217 0.45180723 0.97826087 0.92079208 0.64238411
 0.48192771 0.93333333 0.76966292 0.8        0.96521739 0.92307692
 0.67549669 0.73442623 0.68965517 0.85062241 0.98305085 0.96192893
 0.896      0.83870968 0.98318043 0.96721311 0.92307692 0.8627451
 0.95555556]
Test Recall per class: [0.45       0.91388889 0.928      0.92888889 0.85       0.84126984
 0.64666667 0.82666667 0.81111111 0.93125    0.97121212 0.88809524
 0.90724638 0.96527778 0.87777778 0.83809524 0.95333333 0.89444444
 0.71794872 0.53333333 0.83333333 0.5        0.775      0.64666667
 0.44444444 0.81666667 0.76111111 0.4        0.74       0.93333333
 0.68       0.82962963 1.         0.97619048 0.96666667 0.97179487
 0.93333333 0.86666667 0.93188406 0.65555556 0.93333333 0.73333333
 0.95555556]
Test F1 per class: [0.56842105 0.84358974 0.85503686 0.8600823  0.84935655 0.8582996
 0.77290837 0.85419059 0.83333333 0.93809024 0.95600298 0.83820225
 0.94348154 0.96260388 0.92217899 0.9025641  0.95973154 0.89320388
 0.74074074 0.60377358 0.5859375  0.66176471 0.84162896 0.64451827
 0.46242775 0.87111111 0.76536313 0.53333333 0.83773585 0.9281768
 0.67774086 0.77913043 0.81632653 0.90909091 0.97478992 0.96683673
 0.91428571 0.85245902 0.95684524 0.78145695 0.9281768  0.79279279
 0.95555556]


Metrics for 3 hidden layers:
Training Precision per class: [1.         0.97827518 0.98278146 0.98006296 0.98134328 0.98087649
 0.99667774 0.98336798 0.98958333 0.99590583 0.99850746 0.99664054
 1.         0.99514563 0.99815157 1.         1.         0.99466667
 0.99381188 0.96688742 0.97033898 1.         0.98897059 0.98618785
 0.98305085 0.99021526 0.99036145 0.98888889 0.99719888 0.98901099
 0.99662162 0.95714286 0.96774194 1.         0.99666667 0.99630086
 1.         1.         0.99854757 0.99526066 0.99170124 1.
 1.        ]
Training Recall per class: [0.98       0.99066667 0.98933333 0.97291667 0.99621212 0.97698413
 1.         0.98541667 0.98958333 0.98282828 0.99111111 0.98888889
 0.99716312 0.99652778 1.         0.98809524 1.         0.99466667
 0.99135802 0.97333333 0.95416667 0.99166667 0.9962963  0.99166667
 0.96666667 0.99215686 0.97857143 0.98888889 0.98888889 1.
 0.98333333 0.99259259 1.         1.         0.99666667 0.99753086
 0.99259259 0.98666667 0.99637681 1.         0.99583333 0.95555556
 0.99444444]
Training F1 per class: [0.98989899 0.98443193 0.98604651 0.97647674 0.9887218  0.97892644
 0.99833611 0.98439126 0.98958333 0.98932384 0.99479554 0.99274958
 0.99857955 0.99583622 0.99907493 0.99401198 1.         0.99466667
 0.99258344 0.97009967 0.96218487 0.9958159  0.99261993 0.98891967
 0.97478992 0.99118511 0.98443114 0.98888889 0.9930265  0.99447514
 0.98993289 0.97454545 0.98360656 1.         0.99666667 0.99691548
 0.99628253 0.99328859 0.99746101 0.9976247  0.99376299 0.97727273
 0.99721448]
Test Precision per class: [0.52272727 0.7436182  0.79425287 0.83632735 0.84730539 0.84094488
 0.83333333 0.89351852 0.87412587 0.96222222 0.95338346 0.88190955
 0.99001664 0.96849315 1.         0.91794872 0.95973154 0.96129032
 0.8538961  0.48623853 0.64       0.90196078 0.84615385 0.66878981
 0.5        0.90519187 0.79069767 0.77777778 0.96581197 0.84946237
 0.72222222 0.59512195 0.65934066 0.89823009 0.95833333 0.97074468
 0.8671875  0.875      0.98159509 0.97530864 0.85576923 0.82926829
 0.85365854]
Test Recall per class: [0.38333333 0.93055556 0.92133333 0.93111111 0.85757576 0.84761905
 0.66666667 0.85777778 0.83333333 0.90208333 0.96060606 0.83571429
 0.86231884 0.98194444 0.91851852 0.85238095 0.95333333 0.82777778
 0.67435897 0.88333333 0.88888889 0.51111111 0.73333333 0.7
 0.37777778 0.83541667 0.75555556 0.46666667 0.75333333 0.87777778
 0.60666667 0.9037037  1.         0.96666667 0.95833333 0.93589744
 0.925      0.93333333 0.92753623 0.87777778 0.98888889 0.56666667
 0.77777778]
Test F1 per class: [0.44230769 0.82665022 0.85308642 0.88117771 0.85240964 0.84426877
 0.74074074 0.87528345 0.85324232 0.9311828  0.95698113 0.85819071
 0.92176607 0.97517241 0.95752896 0.88395062 0.95652174 0.88955224
 0.75358166 0.62721893 0.74418605 0.65248227 0.78571429 0.68403909
 0.43037975 0.86890574 0.77272727 0.58333333 0.84644195 0.86338798
 0.65942029 0.71764706 0.79470199 0.93119266 0.95833333 0.95300261
 0.89516129 0.90322581 0.9538003  0.92397661 0.91752577 0.67326733
 0.81395349]



Metrics for 4 hidden layers:
Training Precision per class: [1.         0.99395973 0.98805574 0.97927461 0.99016641 0.98457792
 1.         0.96435845 0.97938144 0.99595142 0.99629904 0.99336283
 0.99858156 0.9910283  0.99814815 0.98122066 1.         0.99865952
 0.99384236 0.96710526 0.97510373 0.99173554 1.         0.98611111
 0.98857143 0.99509323 0.99049881 0.99435028 0.9972067  0.98333333
 0.99665552 0.98342541 0.99447514 0.99585062 0.99326599 0.99876238
 0.99625468 1.         0.99854545 0.99526066 0.99170124 1.
 1.        ]
Training Recall per class: [0.99333333 0.98733333 0.99266667 0.984375   0.99166667 0.96269841
 0.99333333 0.98645833 0.98958333 0.99393939 0.99703704 0.99777778
 0.99858156 0.99722222 0.99814815 0.9952381  0.98333333 0.99333333
 0.9962963  0.98       0.97916667 1.         0.9962963  0.98611111
 0.96111111 0.99411765 0.99285714 0.97777778 0.99166667 0.98333333
 0.99333333 0.98888889 1.         1.         0.98333333 0.9962963
 0.98518519 0.98666667 0.99492754 1.         0.99583333 0.98888889
 1.        ]
Training F1 per class: [0.99665552 0.99063545 0.99035584 0.98181818 0.99091597 0.97351525
 0.99665552 0.97528321 0.98445596 0.99494439 0.9966679  0.99556541
 0.99858156 0.99411561 0.99814815 0.98817967 0.99159664 0.9959893
 0.99506782 0.97350993 0.97713098 0.99585062 0.99814471 0.98611111
 0.97464789 0.9946052  0.99167658 0.9859944  0.99442897 0.98333333
 0.99499165 0.98614958 0.99722992 0.997921   0.98827471 0.99752781
 0.99068901 0.99328859 0.99673321 0.9976247  0.99376299 0.99441341
 1.        ]
Test Precision per class: [0.69565217 0.81875    0.82678984 0.88841202 0.85928144 0.88391376
 0.98165138 0.83191489 0.85227273 0.93816631 0.9455081  0.905
 0.98389694 0.94437086 1.         0.85585586 0.92258065 0.92507205
 0.84590164 0.40740741 0.74528302 0.89795918 0.85849057 0.5212766
 0.71052632 0.92671395 0.63513514 0.78787879 0.90243902 0.80582524
 0.66906475 0.63943662 0.76923077 0.78846154 0.95121951 0.95384615
 0.72049689 0.91525424 0.99671593 0.58695652 0.88059701 0.80952381
 0.89583333]
Test Recall per class: [0.26666667 0.90972222 0.95466667 0.92       0.86969697 0.84603175
 0.71333333 0.86888889 0.83333333 0.91666667 0.97272727 0.86190476
 0.88550725 0.99027778 0.87037037 0.9047619  0.95333333 0.89166667
 0.66153846 0.91666667 0.87777778 0.48888889 0.75833333 0.65333333
 0.3        0.81666667 0.78333333 0.43333333 0.74       0.92222222
 0.62       0.84074074 1.         0.97619048 0.975      0.95384615
 0.96666667 0.9        0.87971014 0.6        0.65555556 0.56666667
 0.95555556]
Test F1 per class: [0.38554217 0.86184211 0.88613861 0.90393013 0.86445783 0.86455799
 0.82625483 0.85       0.84269663 0.92729189 0.95892457 0.88292683
 0.93211289 0.96677966 0.93069307 0.87962963 0.93770492 0.90806223
 0.74244604 0.56410256 0.80612245 0.63309353 0.80530973 0.57988166
 0.421875   0.86821705 0.70149254 0.55913978 0.81318681 0.86010363
 0.64359862 0.7264     0.86956522 0.87234043 0.96296296 0.95384615
 0.82562278 0.90756303 0.93456505 0.59340659 0.75159236 0.66666667
 0.92473118]




"""

hidden_units = [1, 2, 3, 4]
metrics_map = {
    "Training Precision per class": "Tr_Prec",
    "Training Recall per class": "Tr_Rec",
    "Training F1 per class": "Tr_F1",
    "Test Precision per class": "Tst_Prec",
    "Test Recall per class": "Tst_Rec",
    "Test F1 per class": "Tst_F1",
}

data = {}
for hu in hidden_units:
    data[hu] = {}
    block_pattern = rf"Metrics for {hu} hidden layers:(.*?)(?=Metrics for \d+ hidden layers:|\Z)"

    block_match = re.search(block_pattern, input_text, re.DOTALL)
    if not block_match:
        print(f"Warning: Block for {hu} hidden units not found.")
        continue
    block_text = block_match.group(1)
    for long_metric, short_metric in metrics_map.items():
        pattern = rf"{re.escape(long_metric)}:\s*\[(.*?)\]"
        m = re.search(pattern, block_text, re.DOTALL)
        if not m:
            print(f"Warning: Metric '{long_metric}' for {hu} hidden units not found.")
            data[hu][short_metric] = [0.0] * 43
        else:
            numbers_str = m.group(1).replace("\n", " ").strip()
            number_list = numbers_str.split()
            numbers = [float(num) for num in number_list]
            if len(numbers) &lt; 43:
                numbers.extend([0.0] * (43 - len(numbers)))
            data[hu][short_metric] = numbers


cols = []
for hu in hidden_units:
    subcols = [f"{hu}_{m}" for m in ["Tr_Prec", "Tr_Rec", "Tr_F1", "Tst_Prec", "Tst_Rec", "Tst_F1"]]
    cols.append(subcols)
flat_cols = [col for group in cols for col in group]

table_data = []
for i in range(43):
    row = {}
    for hu in hidden_units:
        row[f"{hu}_Tr_Prec"] = f"{data[hu]['Tr_Prec'][i]:.4f}"
        row[f"{hu}_Tr_Rec"]  = f"{data[hu]['Tr_Rec'][i]:.4f}"
        row[f"{hu}_Tr_F1"]   = f"{data[hu]['Tr_F1'][i]:.4f}"
        row[f"{hu}_Tst_Prec"] = f"{data[hu]['Tst_Prec'][i]:.4f}"
        row[f"{hu}_Tst_Rec"]  = f"{data[hu]['Tst_Rec'][i]:.4f}"
        row[f"{hu}_Tst_F1"]   = f"{data[hu]['Tst_F1'][i]:.4f}"
    table_data.append(row)

df = pd.DataFrame(table_data, columns=flat_cols)
df.index.name = "Class"

new_cols = []
for col in flat_cols:
    parts = col.split("_")
    hu = parts[0]
    metric = "_".join(parts[1:])
    new_cols.append((hu, metric))
df.columns = pd.MultiIndex.from_tuples(new_cols, names=["Hidden Units", "Metrics"])

styled_df = df.style.set_caption("Performance Metrics for Different Hidden Unit Sizes").set_properties(**{'text-align': 'center'})
dfi.export(styled_df, "metrics_table.png")
 
print("Image file 'metrics_table.png' has been created.")
 



#!/usr/bin/env python
# coding: utf-8

# In[1]:


import os
import cv2
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
import matplotlib.pyplot as plt

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def relu(x):
    return np.maximum(0, x)

def softmax(x, axis=0):
    max_x = np.max(x, axis=axis, keepdims=True)
    exp_x = np.exp(x - max_x)
    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)

def load_data(train_folder, test_folder, test_labels_csv):
    X_train = []
    y_train = []
    for label in range(43):
        label1 = str(label).zfill(5) + '/'
        folder_path = os.path.join(train_folder, label1)
        for filename in os.listdir(folder_path):
            if filename.endswith('.jpg'):
                img_path = os.path.join(folder_path, filename)
                img = cv2.imread(img_path)
                img = cv2.resize(img, (28, 28))
                X_train.append(img)
                y_train.append(label)
    X_train = np.array(X_train).astype(np.float32) / 255.0
    y_train = np.array(y_train)
    
    test_labels_df = pd.read_csv(test_labels_csv)
    X_test = []
    y_test = []
    for _, row in test_labels_df.iterrows():
        filename = row[0]
        label = row[1]
        img_path = os.path.join(test_folder, filename)
        img = cv2.imread(img_path)
        img = cv2.resize(img, (28, 28))
        X_test.append(img)
        y_test.append(label)
    X_test = np.array(X_test).astype(np.float32) / 255.0
    y_test = np.array(y_test)
    
    X_train = X_train.reshape(X_train.shape[0], -1)  # (N, 2352)
    X_test = X_test.reshape(X_test.shape[0], -1)    # (M, 2352)
    
    return X_train, y_train, X_test, y_test

train_folder = '/Users/akshadmhaske/Desktop/mlass/Q2/Traffic sign board/train'
test_folder = '/Users/akshadmhaske/Desktop/mlass/Q2/Traffic sign board/test'
test_labels_csv = '/Users/akshadmhaske/Desktop/mlass/Q2/Traffic sign board/test_labels.csv'

X_train_full, y_train_full, X_test, y_test = load_data(train_folder, test_folder, test_labels_csv)
X_train = X_train_full
y_train = y_train_full
X_val = X_train.copy()
y_val = y_train.copy()

print("Training data shape:", X_train.shape)
print("Training labels shape:", y_train.shape)
print("Validation data shape:", X_val.shape)
print("Validation labels shape:", y_val.shape)
print("Testing data shape:", X_test.shape)
print("Testing labels shape:", y_test.shape)


# In[2]:



from tqdm import trange


class NeuralNetwork:
    def __init__(self, layer_sizes, activation='sigmoid', dtype=np.float32):
        self.layer_sizes = layer_sizes
        self.num_layers = len(layer_sizes) - 1
        self.activation = activation
        self.dtype = dtype
        
        self.weights = []
        self.biases = []
        for i in range(self.num_layers):
            self.weights.append(
                np.random.randn(layer_sizes[i+1], layer_sizes[i]).astype(dtype) * 0.01)
            self.biases.append(
                np.zeros((layer_sizes[i+1], 1), dtype=dtype))

    def forward(self, X):
        activations = [X.astype(self.dtype)]
        for i in range(self.num_layers):
            z = self.weights[i] @ activations[-1] + self.biases[i]
            if i &lt; self.num_layers - 1:
                if self.activation == 'sigmoid':
                    a = sigmoid(z)
                elif self.activation == 'relu':
                    a = relu(z)
            else:
                a = softmax(z, axis=0)
            activations.append(a)
        return activations[-1], activations

    def backward(self, Y, activations):
        M = Y.shape[1]
        delta = activations[-1] - Y  
        grads = []
        
        for i in reversed(range(self.num_layers)):
            grad_W = (delta @ activations[i].T) / M
            grad_b = np.sum(delta, axis=1, keepdims=True) / M
            grads.append({'weights': grad_W, 'biases': grad_b})
            
            if i &gt; 0:
                if self.activation == 'sigmoid':
                    g_prime = activations[i] * (1 - activations[i])
                elif self.activation == 'relu':
                    g_prime = (activations[i] &gt; 0).astype(self.dtype)
                delta = (self.weights[i].T @ delta) * g_prime
        
        return reversed(grads)

    def train_step(self, X, Y, learning_rate):
        a_L, activations = self.forward(X)
        loss = -np.mean(np.sum(Y * np.log(a_L + 1e-8), axis=0))
        grads = self.backward(Y, activations)
        
        for i, grad in enumerate(grads):
            self.weights[i] -= learning_rate * grad['weights']
            self.biases[i] -= learning_rate * grad['biases']
        
        return loss

    def predict(self, X):
        a_L, _ = self.forward(X)
        return np.argmax(a_L, axis=0)

    def train(self, X_train, y_train, X_val, y_val,
             batch_size=32, eta0=0.01, num_epochs=100,
             patience=10, adaptive=False):
        
        X_train = X_train.astype(self.dtype)
        y_train = y_train.astype(self.dtype)
        X_val = X_val.astype(self.dtype)
        
        best_weights = [w.copy() for w in self.weights]
        best_biases = [b.copy() for b in self.biases]
        best_metric = -np.inf if adaptive else np.inf
        counter = 0
        
        with trange(num_epochs, desc="Training") as progress_bar:
            for epoch in progress_bar:
                lr = eta0 / np.sqrt(epoch + 1) if adaptive else eta0
                indices = np.random.permutation(X_train.shape[1])
                X_shuffled = X_train[:, indices]
                y_shuffled = y_train[:, indices]
                epoch_loss = 0
                
                for i in range(0, X_train.shape[1], batch_size):
                    X_batch = X_shuffled[:, i:i+batch_size]
                    y_batch = y_shuffled[:, i:i+batch_size]
                    batch_loss = self.train_step(X_batch, y_batch, lr)
                    epoch_loss += batch_loss * X_batch.shape[1]
                
                avg_loss = epoch_loss / X_train.shape[1]
                val_pred = self.predict(X_val)
                val_acc = np.mean(val_pred == y_val)
                
                postfix = {'loss': avg_loss, 'val_acc': val_acc}
                if adaptive:
                    postfix['lr'] = lr
                progress_bar.set_postfix(postfix)
                
                current_metric = val_acc if adaptive else avg_loss
                condition = (current_metric &gt; best_metric) if adaptive else (current_metric &lt; best_metric)
                
                if condition:
                    best_metric = current_metric
                    best_weights = [w.copy() for w in self.weights]
                    best_biases = [b.copy() for b in self.biases]
                    counter = 0
                else:
                    counter += 1
                
                if counter &gt;= patience:
                    print(f"\nEarly stopping at epoch {epoch}")
                    break
        
        self.weights = best_weights
        self.biases = best_biases


# In[3]:


X_train_T = X_train.T  # (2352, 21312)
X_val_T = X_val.T      # (2352, 5328)
X_test_T = X_test.T    # (2352, 12630)
y_train_onehot = np.eye(43)[y_train].T  # (43, 21312)


# In[4]:


#---------------------1.b------------------------------

hidden_units = [1, 5, 10, 50, 100]
f1_scores_train = []
f1_scores_test = []

for h in hidden_units:
    print(f"\nPart (b): Training with {h} hidden units")
    layer_sizes = [2352, h, 43]
    nn = NeuralNetwork(layer_sizes, activation='sigmoid')
    nn.train(X_train_T, y_train_onehot, X_val_T, y_val, batch_size=32, eta0=0.01, num_epochs=200, patience=10)
    
    train_pred = nn.predict(X_train_T)
    test_pred = nn.predict(X_test_T)
    p_train, r_train, f1_train, _ = precision_recall_fscore_support(y_train, train_pred, average=None)
    p_test, r_test, f1_test, _ = precision_recall_fscore_support(y_test, test_pred, average=None)
    
    f1_scores_train.append(np.mean(f1_train))
    f1_scores_test.append(np.mean(f1_test))
    
    print(f"\nMetrics for {h} hidden units:")
    print("Training Precision per class:", p_train)
    print("Training Recall per class:", r_train)
    print("Training F1 per class:", f1_train)
    print("Test Precision per class:", p_test)
    print("Test Recall per class:", r_test)
    print("Test F1 per class:", f1_test)


plt.plot(hidden_units, f1_scores_test, marker='o', label='Test')
plt.xlabel('Number of Hidden Units')
plt.ylabel('Macro Average F1 Score')
plt.title('Part (b): F1 Score vs Hidden Units')
plt.legend()
plt.savefig('f1_vs_hidden_units_b.png')
plt.show()


# In[ ]:


#print f1_scores_train
print("\nTraining F1 Scores:", f1_scores_train)
print("Test F1 Scores:", f1_scores_test)




# In[9]:


#---------------------1.c------------------------------

hidden_layers_list = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]
f1_scores_train = []
f1_scores_test = []

for hidden_layers in hidden_layers_list:
    print(f"\nPart (c): Training with hidden layers {hidden_layers}")
    layer_sizes = [2352] + hidden_layers + [43]
    nn = NeuralNetwork(layer_sizes, activation='sigmoid')
    nn.train(X_train_T, y_train_onehot, X_val_T, y_val, batch_size=32, eta0=0.01, num_epochs=200, patience=50)
    
    train_pred = nn.predict(X_train_T)
    test_pred = nn.predict(X_test_T)
    p_train, r_train, f1_train, _ = precision_recall_fscore_support(y_train, train_pred, average=None)
    p_test, r_test, f1_test, _ = precision_recall_fscore_support(y_test, test_pred, average=None)
    
    f1_scores_train.append(np.mean(f1_train))
    f1_scores_test.append(np.mean(f1_test))

    train_acc = np.mean(train_pred == y_train)
    test_acc = np.mean(test_pred == y_test)
    print(f"Training Accuracy: {train_acc:.4f}")
    print(f"Test Accuracy: {test_acc:.4f}")
    
    print(f"\nMetrics for hidden layers {hidden_layers}:")
    print("Training Precision per class:", p_train)
    print("Training Recall per class:", r_train)
    print("Training F1 per class:", f1_train)
    print("Test Precision per class:", p_test)
    print("Test Recall per class:", r_test)
    print("Test F1 per class:", f1_test)

depths = [len(hl) for hl in hidden_layers_list]
plt.plot(depths, f1_scores_test, marker='o', label='Test')
plt.plot(depths, f1_scores_train, marker='o', label='Train')
plt.xlabel('Network Depth')
plt.ylabel('Macro Average F1 Score')
plt.title('Part (c): F1 Score vs Network Depth')
plt.legend()
plt.savefig('f1_vs_network_depth_c.png')
plt.show()


# In[10]:


#---------------------1.d------------------------------
f1_scores_train = []
f1_scores_test = []
hidden_layers_list = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]
depths = [len(hl) for hl in hidden_layers_list]

for hidden_layers in hidden_layers_list:
    print(f"\nPart (d): Training with hidden layers {hidden_layers} and adaptive learning rate")
    layer_sizes = [2352] + hidden_layers + [43]
    nn = NeuralNetwork(layer_sizes, activation='sigmoid')
    nn.train(X_train_T, y_train_onehot, X_val_T, y_val, batch_size=32, eta0=0.01, num_epochs=200, patience=50, adaptive=True)
    
    train_pred = nn.predict(X_train_T)
    test_pred = nn.predict(X_test_T)
    p_train, r_train, f1_train, _ = precision_recall_fscore_support(y_train, train_pred, average=None)
    p_test, r_test, f1_test, _ = precision_recall_fscore_support(y_test, test_pred, average=None)
    
    f1_scores_train.append(np.mean(f1_train))
    f1_scores_test.append(np.mean(f1_test))

    train_acc = np.mean(train_pred == y_train)
    test_acc = np.mean(test_pred == y_test)
    print(f"Training Accuracy: {train_acc:.4f}")
    print(f"Test Accuracy: {test_acc:.4f}")
    
    print(f"\nMetrics for hidden layers {hidden_layers}:")
    print("Training Precision per class:", p_train)
    print("Training Recall per class:", r_train)
    print("Training F1 per class:", f1_train)
    print("Test Precision per class:", p_test)
    print("Test Recall per class:", r_test)
    print("Test F1 per class:", f1_test)

print("\nTraining F1 Scores:", f1_scores_train)
print("Test F1 Scores:", f1_scores_test)

plt.plot(depths, f1_scores_test, marker='o', label='Test')
plt.plot(depths, f1_scores_train, marker='o', label='Train')
plt.xlabel('Network Depth')
plt.ylabel('Macro Average F1 Score')
plt.title('Part (d): F1 Score vs Depth with Adaptive LR')
plt.legend()
plt.savefig('f1_vs_network_depth_d.png')
plt.show()


# In[11]:


#---------------------1.e------------------------------
f1_scores_train = []
f1_scores_test = []
hidden_layers_list = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]
depths = [len(hl) for hl in hidden_layers_list]


for hidden_layers in hidden_layers_list:
    print(f"\nPart (e): Training with hidden layers {hidden_layers}, ReLU, and adaptive LR")
    layer_sizes = [2352] + hidden_layers + [43]
    nn = NeuralNetwork(layer_sizes, activation='relu')
    nn.train(X_train_T, y_train_onehot, X_val_T, y_val, batch_size=32, eta0=0.01, num_epochs=200, patience=10, adaptive=True)
    
    # Evaluate
    train_pred = nn.predict(X_train_T)
    test_pred = nn.predict(X_test_T)
    p_train, r_train, f1_train, _ = precision_recall_fscore_support(y_train, train_pred, average=None)
    p_test, r_test, f1_test, _ = precision_recall_fscore_support(y_test, test_pred, average=None)
    
    # Store average F1 scores
    f1_scores_train.append(np.mean(f1_train))
    f1_scores_test.append(np.mean(f1_test))
    
    # Report metrics
    print(f"\nMetrics for hidden layers {hidden_layers}:")
    print("Training Precision per class:", p_train)
    print("Training Recall per class:", r_train)
    print("Training F1 per class:", f1_train)
    print("Test Precision per class:", p_test)
    print("Test Recall per class:", r_test)
    print("Test F1 per class:", f1_test)

# Plot
plt.plot(depths, f1_scores_test, marker='o', label='Test')
plt.plot(depths, f1_scores_train, marker='o', label='Train')
plt.xlabel('Network Depth')
plt.ylabel('Macro Average F1 Score')
plt.title('Part (e): F1 Score vs Depth with ReLU')
plt.legend()
plt.savefig('f1_vs_network_depth_e.png')
plt.show()


# In[15]:


#---------------------1.f------------------------------
from sklearn.neural_network import MLPClassifier

f1_scores_test = []
f1_scores_train = []
hidden_layers_list = [[512], [512, 256], [512, 256, 128], [512, 256, 128, 64]]
depths = [len(hl) for hl in hidden_layers_list]

for hidden_layers in hidden_layers_list:
    print(f"\nPart (f): Training with hidden layers {hidden_layers} using MLPClassifier")
    mlp = MLPClassifier(
        hidden_layer_sizes=hidden_layers,
        activation='relu',
        solver='sgd',          
        batch_size=32,         
        max_iter=100,
        early_stopping=True,    
        validation_fraction=0.1,
        n_iter_no_change=5,
        random_state=49,
        verbose=1         
    )
    mlp.fit(X_train, y_train)
    
    train_pred = mlp.predict(X_train)
    test_pred = mlp.predict(X_test)



    p_train, r_train, f1_train, _ = precision_recall_fscore_support(y_train, train_pred, average=None)
    p_test, r_test, f1_test, _ = precision_recall_fscore_support(y_test, test_pred, average=None)

    f1_scores_train.append(np.mean(f1_train))
    f1_scores_test.append(np.mean(f1_test))
    
    
    print(f"\nMetrics for hidden layers {hidden_layers}:")
    print("Training Precision per class:", p_train)
    print("Training Recall per class:", r_train)
    print("Training F1 per class:", f1_train)
    print("Test Precision per class:", p_test)
    print("Test Recall per class:", r_test)
    print("Test F1 per class:", f1_test)

print("\nTraining F1 Scores:", f1_scores_train)
print("Test F1 Scores:", f1_scores_test)
plt.plot(depths, f1_scores_test, marker='o', label='Test')
plt.plot(depths, f1_scores_train, marker='o', label='Train')
plt.xlabel('Network Depth')
plt.ylabel('Macro Average F1 Score')
plt.title('Part (f): F1 Score vs Depth with MLPClassifier')
plt.legend()
plt.savefig('f1_vs_network_depth_f.png')
plt.show()



</PRE>
</PRE>
</BODY>
</HTML>
