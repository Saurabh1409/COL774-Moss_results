<HTML>
<HEAD>
<TITLE>./A3_processed_new_hash/combined_0A0UU.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A3_processed_new_hash/combined_0A0UU.py<p><PRE>


from first_1 import DecisionTree1
from second_1 import DecisionTree2
from third_1 import DecisionTree3
from fourth_1 import *
from fifth_1 import part_e_random_forest
import pandas as pd
import numpy as np
import sys



if __name__ == "__main__":
    # Check for correct number of command-line arguments
<A NAME="0"></A><FONT color = #FF0000><A HREF="match203-1.html#0" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    if len(sys.argv) != 6:
        print("Usage: python decision_tree.py &lt;train_data_path&gt; &lt;validation_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
        print("Example: python decision_tree.py data/train.csv data/valid.csv data/test.csv output/ d")
        sys.exit(1)

    # Parse command-line arguments
    train_path = sys.argv[1]
    valid_path = sys.argv[2]
    test_path = sys.argv[3]
</FONT>    output_folder = sys.argv[4]
    question_part = sys.argv[5].lower() # Convert to lower case


    if question_part == 'a':
        # Load data
<A NAME="3"></A><FONT color = #00FFFF><A HREF="match203-1.html#3" TARGET="1"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        train = pd.read_csv(train_path)
        valid = pd.read_csv(valid_path)
        test = pd.read_csv(test_path)

        # Separate features and target
        X_train = train.drop(columns=['income'])
</FONT>        y_train = train['income']
        X_valid = valid.drop(columns=['income'])
        y_valid = valid['income']
        X_test = test

        depths = [20]

        for depth in depths:
            print(f"Training tree with max_depth={depth}")
            tree = DecisionTree1(max_depth=depth)
            tree.fit(X_train, y_train)
            

            # Save predictions
            tree.save_pred_for_depth20(X_test, output_folder)
    elif question_part == 'b':
        # Load data
<A NAME="4"></A><FONT color = #FF00FF><A HREF="match203-1.html#4" TARGET="1"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        train = pd.read_csv(train_path)
        valid = pd.read_csv(valid_path)
        test = pd.read_csv(test_path)
        # Identify categorical columns with more than 2 categories
        categorical_cols = train.select_dtypes(include=['object']).columns
</FONT>        multi_cat_cols = [col for col in categorical_cols if len(train[col].unique()) &gt;= 2]

        # Apply one-hot encoding to these columns
        def one_hot_encode(df, cols):
            for col in cols:
                dummies = pd.get_dummies(df[col], prefix=col)
                df = pd.concat([df.drop(col, axis=1), dummies], axis=1)
            return df

        # Apply to all datasets
        train_encoded = one_hot_encode(train.copy(), multi_cat_cols)
        valid_encoded = one_hot_encode(valid.copy(), multi_cat_cols)
        test_encoded = one_hot_encode(test.copy(), multi_cat_cols)

        # Get column headers for train_encoded
        train_encoded_columns = train_encoded.columns.tolist()
        train_encoded_columns = set(train_encoded_columns)

        # Get column headers for valid_encoded
        valid_encoded_columns = valid_encoded.columns.tolist()
        valid_encoded_columns = set(valid_encoded_columns)

        # Get column headers for test_encoded
        test_encoded_columns = test_encoded.columns.tolist()
        test_encoded_columns = set(test_encoded_columns)

        #Union of all columns
        all_columns = train_encoded_columns.union(valid_encoded_columns).union(test_encoded_columns)

        # Add missing columns to each DataFrame with default value 0
        for col in all_columns:
            if col not in train_encoded.columns:
                train_encoded[col] = False
            if col not in valid_encoded.columns:
                valid_encoded[col] = False
            if col not in test_encoded.columns:
                test_encoded[col] = False


        # Separate features and target
        X_train = train_encoded.drop(columns=['income_ &lt;=50K','income_ &gt;50K'])
        y_train = train['income']
        X_valid = valid_encoded.drop(columns=['income_ &lt;=50K','income_ &gt;50K'])
        y_valid = valid['income']
        X_test = test_encoded

        depths = [55]
        for depth in depths:
            print(f"Training tree with max_depth={depth}")
            tree = DecisionTree2(max_depth=depth)
            tree.fit(X_train, y_train)

            # Save predictions
            tree.save_pred_for_depth55(X_test, output_folder)
    elif question_part == 'c':
        #Load data
        train = pd.read_csv(train_path)
        valid = pd.read_csv(valid_path)
        test = pd.read_csv(test_path)

        # --- Preprocessing for One-Hot Encoding (Part 1b setup) ---
        print("Preprocessing data with One-Hot Encoding...")

        # Target variable name might differ, ensure it's correct
        target_col_name = 'income' # Assuming this is the column name before OHE
        target_value_high = '&gt;50K' # Assuming this is one of the values

        # Check if target column exists
        if target_col_name not in train.columns:
            print(f"Error: Target column '{target_col_name}' not found in train data.")
            # Attempt to find income columns if they were already OHE'd in CSV
            if 'income_ &gt;50K' in train.columns:
                print("Found 'income_ &gt;50K'. Reconstructing target variable.")
                train[target_col_name] = np.where(train['income_ &gt;50K'] == True, '&gt;50K', '&lt;=50K')
                valid[target_col_name] = np.where(valid['income_ &gt;50K'] == True, '&gt;50K', '&lt;=50K')
            else:
                exit()


        # Identify categorical columns with more than 1 category (binary can be kept as is sometimes, but OHE handles all)
        categorical_cols = train.select_dtypes(include=['object']).columns.tolist()
        # Exclude the target column if it's object type
        if target_col_name in categorical_cols:
            categorical_cols.remove(target_col_name)

        # Apply one-hot encoding
        def one_hot_encode(df, cols_to_encode, train_cols=None):
            df_encoded = df.copy()
            # Encode specified columns
            df_encoded = pd.get_dummies(df_encoded, columns=cols_to_encode, dummy_na=False)

            if train_cols is not None:
                # Add missing columns (present in train, not in current df)
                missing_cols = set(train_cols) - set(df_encoded.columns)
                for c in missing_cols:
                    # Avoid adding back the original target column if it was numeric/boolean
                    if c != target_col_name and not c.startswith(target_col_name + '_'):
                        df_encoded[c] = 0 # Or False, depending on expected type
                # Ensure order and presence of all training columns, except target
                df_encoded = df_encoded.reindex(columns=train_cols, fill_value=0) # Or False
            return df_encoded

        # Encode Train and get column names
        train_encoded = pd.get_dummies(train.copy(), columns=categorical_cols, dummy_na=False)
        train_encoded_columns = train_encoded.columns.tolist()

        # Encode Valid and Test using Train columns for consistency
        valid_encoded = one_hot_encode(valid.copy(), categorical_cols, train_encoded_columns)
        test_encoded = one_hot_encode(test.copy(), categorical_cols, train_encoded_columns)


        # --- Align columns after potential inconsistencies ---
        # This step is crucial if OHE creates different columns in train/valid/test
        # (e.g., a category exists in valid but not train)

        # Get all unique columns across all sets (excluding target)
        all_cols = set(train_encoded.columns) | set(valid_encoded.columns) | set(test_encoded.columns)
        if target_col_name in all_cols:
            all_cols.remove(target_col_name)
        # If OHE target columns exist, remove them too
        ohe_target_cols = [c for c in all_cols if c.startswith(target_col_name + '_')]
        for c in ohe_target_cols:
            all_cols.remove(c)

        feature_columns = sorted(list(all_cols)) # Use sorted list for consistent order

        # Reindex all dataframes to have the same feature columns
        X_train = train_encoded.reindex(columns=feature_columns, fill_value=0)
        y_train = train[target_col_name] # Original target column

        X_valid = valid_encoded.reindex(columns=feature_columns, fill_value=0)
        y_valid = valid[target_col_name]

        X_test = test_encoded.reindex(columns=feature_columns, fill_value=0)
        # y_test = test[target_col_name]

        print("Data preprocessing finished.")
        print(f"X_train shape: {X_train.shape}, X_valid shape: {X_valid.shape}, X_test shape: {X_test.shape}")

        depths = [55]

        for depth in depths:
            print(f"Training tree with max_depth={depth}")
            tree = DecisionTree3(max_depth=depth)
            tree.fit(X_train, y_train) # Fit on training data

            nodes_before = tree._count_nodes(tree.original_tree)
            print(f"BEFORE Pruning (Depth {depth}): Nodes={nodes_before}")


            print(f"\nPruning tree initially grown to depth={depth}...")
            # Prune using the VALIDATION set
            history = tree.prune(X_valid, y_valid)

            nodes_after = tree._count_nodes(tree.tree) # Nodes in the final pruned tree

            print(f"AFTER Pruning (Initial Depth {depth}): Nodes={nodes_after}")

            # Save predictions
            preds = tree.predict(X_test)
            output_df = pd.DataFrame({'prediction': preds})
            output_df.to_csv(f"{output_folder}/predictions_c.csv", index=False)

            print(f"Predictions saved to {output_folder}/predictions_c.csv")

    elif question_part == 'd':
        print("Loading and preprocessing data...")
        X_train, y_train, X_valid, y_valid, X_test = load_and_preprocess_data(train_path, valid_path, test_path)

        # print(X_test)

        # Run Part 1(d) analyses
        best_model_depth, val_acc_depth = part_d_max_depth(X_train, y_train, X_valid, y_valid, X_test)
        best_model_alpha, val_acc_alpha = part_d_ccp_alpha(X_train, y_train, X_valid, y_valid, X_test)

        #Save predictions
        output_folder=output_folder+"/predictions_d.csv"
        save_predictions(best_model_alpha, X_test, output_folder)


    elif question_part == 'e':
        X_train, y_train, X_valid, y_valid, X_test = load_and_preprocess_data(train_path, valid_path, test_path)

        final_model = part_e_random_forest(X_train, y_train, X_valid, y_valid, X_test)

        output_folder=output_folder+"/predictions_e.csv"
        save_predictions(final_model, X_test, output_folder)





















import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier # Added for Part 1(e)
from sklearn.model_selection import GridSearchCV # Added for Part 1(e)
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import sys
import os
import time # Added to time GridSearchCV

# --- load_and_preprocess_data function remains the same ---
def load_and_preprocess_data(train_path, valid_path, test_path):
    """Loads train, validation, and test data and performs one-hot encoding."""
    try:
        train_df = pd.read_csv(train_path)
        valid_df = pd.read_csv(valid_path)
        test_df = pd.read_csv(test_path)
    except FileNotFoundError as e:
        print(f"Error loading data file: {e}. Please check file paths.")
        sys.exit(1)
    except Exception as e:
        print(f"An error occurred while reading the CSV files: {e}")
        sys.exit(1)

    # Separate target variable
    y_train = train_df['income']
    y_valid = valid_df['income']
    y_test = test_df['income']

    # Drop target variable from features
    X_train = train_df.drop('income', axis=1)
    X_valid = valid_df.drop('income', axis=1)
    X_test = test_df.drop('income', axis=1)

    # Identify categorical features (assuming object type)
    categorical_cols = X_train.select_dtypes(include=['object']).columns

    # Apply one-hot encoding
    # Combine train, valid, test to ensure consistent encoding
    combined_X = pd.concat([X_train, X_valid, X_test], keys=['train', 'valid', 'test'])
    # Use pd.get_dummies with drop_first=False as RF might handle multicollinearity differently,
    # and it aligns better with Sci-kit learn's internal handling mentioned in part 1(d) notes.
    # Let's stick to drop_first=True for consistency with part d unless results are poor.
    combined_X_encoded = pd.get_dummies(combined_X, columns=categorical_cols, drop_first=True)

    # Separate back into train, valid, test sets
    X_train_encoded = combined_X_encoded.loc['train']
    X_valid_encoded = combined_X_encoded.loc['valid']
    X_test_encoded = combined_X_encoded.loc['test']

    # Ensure all datasets have the same columns after encoding
    X_valid_encoded = X_valid_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)
    X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)

    # Ensure column order consistency (important for some models)
    X_valid_encoded = X_valid_encoded[X_train_encoded.columns]
    X_test_encoded = X_test_encoded[X_train_encoded.columns]

    return X_train_encoded, y_train, X_valid_encoded, y_valid, X_test_encoded, y_test


# --- NEW FUNCTION for Part 1(e) ---
def part_e_random_forest(X_train, y_train, X_valid, y_valid, X_test):
    """Performs analysis for Part 1(e) using RandomForestClassifier and GridSearchCV."""
    print("\n--- Part 1(e): Random Forest with GridSearchCV ---")

    # Define the parameter grid
    param_grid = {
        'n_estimators': [50, 150, 250, 350],          # 50 to 350 in steps of 100
        'max_features': np.round(np.arange(0.1, 1.01, 0.2), 2).tolist(), # 0.1 to 1.0 in steps of 0.2 -&gt; [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]
        'min_samples_split': list(range(2, 11, 2)) # 2 to 10 in steps of 2 -&gt; [2, 4, 6, 8, 10]
    }
    
    
    # Note: Using np.round for max_features to handle potential floating point inaccuracies with arange.
    # Making sure 1.0 is included if the range implies it. np.arange(0.1, 1.1, 0.2) achieves this.
    print("Parameter Grid for GridSearchCV:")
    print(param_grid)

    # Initialize the base RandomForestClassifier
    # criterion='entropy' as specified
    # oob_score=True is crucial for reporting OOB accuracy later
    # random_state for reproducibility
    # n_jobs=-1 to use all available CPU cores (speeds up training significantly)
    rf = RandomForestClassifier(criterion='entropy', oob_score=True, random_state=42, n_jobs=-1)

    # Initialize GridSearchCV
    # estimator: the model to tune (rf)
    # param_grid: the hyperparameters to search
    # scoring='accuracy': The metric to evaluate parameter combinations.
    # cv=5: Use 5-fold cross-validation within the grid search on the training data.
    #       The prompt mentions using OOB accuracy for *tuning*. While GridSearchCV primarily uses CV score for ranking,
    #       setting oob_score=True in the RF ensures the OOB score is *calculated* for the best model after refitting.
    #       Using CV is standard practice with GridSearchCV for robust parameter selection.
    # verbose=2: Show progress messages during grid search.
    # refit=True: (Default) Automatically retrain the best model found on the entire training dataset.
    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,
                               scoring='accuracy', cv=5, verbose=2, n_jobs=-1, refit=True)

    # Perform the grid search on the training data
    print("\nStarting GridSearchCV for Random Forest (this may take some time)...")
    start_time = time.time()
    grid_search.fit(X_train, y_train)
    end_time = time.time()
    print(f"GridSearchCV finished in {end_time - start_time:.2f} seconds.")

    # Get the best model and parameters
    best_params = grid_search.best_params_
    best_rf_model = grid_search.best_estimator_ # This model is already refitted on the full X_train

    print(f"\nBest Parameters found by GridSearchCV: {best_params}")

    # Report Accuracies for the *best* model found
    # 1. Out-of-Bag (OOB) Accuracy
    # This score is calculated on the data points *not* included in the bootstrap sample for each tree,
    # providing an unbiased estimate of performance on unseen data, computed during the training of the final best model.
    try:
        oob_accuracy = best_rf_model.oob_score_
        print(f"Out-of-Bag (OOB) Accuracy of Best Model: {oob_accuracy:.4f}")
    except AttributeError:
        print("OOB score not available (perhaps oob_score=False was used in the base estimator?).")
        oob_accuracy = None # Handle case where it might not be available

    # 2. Training Accuracy
    y_train_pred = best_rf_model.predict(X_train)
    train_accuracy = accuracy_score(y_train, y_train_pred)
    print(f"Training Accuracy of Best Model: {train_accuracy:.4f}")

    # 3. Validation Accuracy
    y_valid_pred = best_rf_model.predict(X_valid)
    valid_accuracy = accuracy_score(y_valid, y_valid_pred)
    print(f"Validation Accuracy of Best Model: {valid_accuracy:.4f}")

    # 4. Test Accuracy
    # y_test_pred = best_rf_model.predict(X_test)
    # test_accuracy = accuracy_score(y_test, y_test_pred)
    # print(f"Test Accuracy of Best Model: {test_accuracy:.4f}")

    return best_rf_model

# --- save_predictions function remains the same ---
def save_predictions(model, X_test, output_path):
    """Saves model predictions on the test set to a CSV file."""
    try:
        predictions = model.predict(X_test)
        pred_df = pd.DataFrame({'prediction': predictions})
        # Ensure output directory exists
        # os.makedirs(os.path.dirname(output_path), exist_ok=True)
        pred_df.to_csv(output_path, index=False)
        print(f"\nPredictions saved to {output_path}")
    except Exception as e:
        print(f"Error saving predictions: {e}")


# if __name__ == "__main__":
#     # Check for correct number of command-line arguments
#     if len(sys.argv) != 6:
#         print("Usage: python decision_tree.py &lt;train_data_path&gt; &lt;validation_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
#         print("Example: python decision_tree.py data/train.csv data/valid.csv data/test.csv output/ e") # Updated example
#         sys.exit(1)

#     # Parse command-line arguments
#     train_path = sys.argv[1]
#     valid_path = sys.argv[2]
#     test_path = sys.argv[3]
#     output_folder = sys.argv[4]
#     question_part = sys.argv[5].lower() # Convert to lower case

#     # Validate question_part argument
#     valid_parts = ['d', 'e'] # Add 'a', 'b', 'c' if/when implemented
#     if question_part not in valid_parts:
#         print(f"Error: question_part must be one of {valid_parts}. You provided '{question_part}'.")
#         sys.exit(1)

#     # Load and preprocess data
#     print("Loading and preprocessing data...")
#     X_train, y_train, X_valid, y_valid, X_test, y_test = load_and_preprocess_data(train_path, valid_path, test_path)
#     print("Data loaded and preprocessed successfully.")
#     print(f"Shape after preprocessing - Train X: {X_train.shape}, Valid X: {X_valid.shape}, Test X: {X_test.shape}")


#     final_model = None # Initialize variable to hold the model for prediction saving

#     if question_part == 'd':
#         # Run Part 1(d) analyses
#         best_model_depth, val_acc_depth = part_d_max_depth(X_train, y_train, X_valid, y_valid, X_test, y_test)
#         best_model_alpha, val_acc_alpha = part_d_ccp_alpha(X_train, y_train, X_valid, y_valid, X_test, y_test)

#         # --- Comparison Comments (Part 1(d) vs Parts 1(b)/1(c)) ---
#         print("\n--- Comparison Comments (Part 1(d) vs Parts 1(b)/1(c)) ---")
#         print("Note: These comments assume hypothetical results from Parts 1(b) and 1(c).")

#         print("\nComparison with Part 1(b) (One-Hot Encoding, Varying Depth):")
#         # (Comments remain the same as before)
#         print(f"- The scikit-learn implementation in Part 1(d)(i) uses entropy criterion and varies max_depth ({[25, 35, 45, 55]}).")
#         print("- This is directly comparable to Part 1(b) which also used one-hot encoding and varied depth (though potentially different ranges).")
#         print("- We would expect similar trends: training accuracy generally increases or plateaus with depth, while test/validation accuracy might peak and then decrease due to overfitting.")
#         print(f"- The best scikit-learn model from varying depth achieved validation accuracy {val_acc_depth:.4f}. This should be compared to the best validation accuracy obtained in Part 1(b).")
#         print("- Differences in accuracy could arise from slight implementation variations (e.g., handling of continuous features if different, specific split logic) between the custom implementation and scikit-learn.")

#         print("\nComparison with Part 1(c) (Post-Pruning):")
#         # (Comments remain the same as before)
#         print("- Part 1(d)(ii) uses scikit-learn's cost-complexity pruning (ccp_alpha) which is a form of pre-pruning (applied during growth) or post-pruning depending on how it's used, but conceptually related to controlling model complexity like post-pruning in 1(c).")
#         print("- Part 1(c) involved growing a tree (likely deep, based on 1(b)) and then *post-pruning* nodes based on validation accuracy.")
#         print(f"- The best scikit-learn model using ccp_alpha achieved validation accuracy {val_acc_alpha:.4f}. This should be compared to the best validation accuracy obtained after post-pruning in Part 1(c).")
#         print("- Both methods aim to combat overfitting. Cost-complexity pruning (ccp_alpha) finds a sequence of subtrees optimized for complexity vs. error, while the greedy post-pruning in 1(c) removes nodes iteratively based purely on validation gain.")
#         print("- The results might differ. Scikit-learn's pruning is often effective, but the best approach (depth limit, ccp_alpha, or custom post-pruning) can be dataset-dependent.")
#         print("- Scikit-learn's optimized implementation might also lead to performance differences compared to a from-scratch implementation.")

#         # Determine the overall best model based on validation accuracy *within part d*
#         # Note: The problem asks to use validation set to determine best depth/alpha *for that subpart*,
#         # not necessarily choose between depth/alpha for the final model of part d. Let's pick the better one for saving predictions.
#         if best_model_depth is None and best_model_alpha is None:
#              print("\nWarning: No best model found in Part 1(d). Cannot save predictions.")
#         elif best_model_depth is None:
#              print("\nChoosing best model from ccp_alpha variation (Part d) for final predictions.")
#              final_model = best_model_alpha
#         elif best_model_alpha is None:
#              print("\nChoosing best model from max_depth variation (Part d) for final predictions.")
#              final_model = best_model_depth
#         elif val_acc_depth &gt;= val_acc_alpha:
#             print("\nChoosing best model from max_depth variation (Part d) for final predictions.")
#             final_model = best_model_depth
#         else:
#             print("\nChoosing best model from ccp_alpha variation (Part d) for final predictions.")
#             final_model = best_model_alpha

#     elif question_part == 'e':
#         # Run Part 1(e) analysis
#         final_model = part_e_random_forest(X_train, y_train, X_valid, y_valid, X_test, y_test)
#         # Comparison comments are printed inside part_e_random_forest function

#     # Define the output file path based on the executed part
#     output_file_path = os.path.join(output_folder, f"prediction_{question_part}.csv")

#     # Save predictions of the chosen best model (if one was selected)
#     if final_model is not None:
#         save_predictions(final_model, X_test, output_file_path)
#     else:
#         print(f"\nNo final model selected or trained for Part 1({question_part}). Predictions not saved.")

#     print(f"\nPart 1({question_part}) execution completed.")

    if __name__ =="__main__":
        train_path = "../Adata/train.csv"
        valid_path = "../Adata/valid.csv"
        test_path = "../Adata/test.csv"

        print("Loading and preprocessing data...")
        X_train, y_train, X_valid, y_valid, X_test = load_and_preprocess_data(train_path, valid_path, test_path)
        print("Data loaded and preprocessed successfully.")

        # Run Part 1(e) analyses
        final_model = part_e_random_forest(X_train, y_train, X_valid, y_valid, X_test)


        #Save predictions of the chosen best model

        output_folder = "output.csv"

        save_predictions(final_model, X_test, output_folder)



import os
import numpy as np
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict
import math

class NeuralNetwork:
    def __init__(self, input_size, hidden_layers, output_size):
        self.input_size = input_size
        self.hidden_layers = hidden_layers
        self.output_size = output_size
        
        # Initialize weights and biases
        self.weights = []
        self.biases = []
        
        # Input to first hidden layer
        prev_size = input_size
        for size in hidden_layers:
            self.weights.append(np.random.randn(prev_size, size) * np.sqrt(2./prev_size))
            self.biases.append(np.zeros(size))
            prev_size = size
        
        # Last hidden to output layer
        self.weights.append(np.random.randn(prev_size, output_size) * np.sqrt(2./prev_size))
<A NAME="5"></A><FONT color = #FF0000><A HREF="match203-1.html#5" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        self.biases.append(np.zeros(output_size))
    
    def relu(self, x):
        return np.maximum(0, x)
    
    def relu_derivative(self, x):
        # Subgradient at 0 is 1 (common choice)
        return (x &gt; 0).astype(float)
</FONT>    
    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forward(self, X):
        self.activations = [X]
        self.z_values = []
        
        # Hidden layers with ReLU activation
        for i in range(len(self.hidden_layers)):
            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
            a = self.relu(z)
            self.z_values.append(z)
            self.activations.append(a)
        
        # Output layer with softmax activation
        z = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
        a = self.softmax(z)
        self.z_values.append(z)
        self.activations.append(a)
        
        return a
    
    def backward(self, X, y, learning_rate):
        m = X.shape[0]
        deltas = []
        
        # Output layer error
        error = self.activations[-1] - y
        delta = error  # For softmax with cross-entropy
        deltas.insert(0, delta)
        
        # Backpropagate through hidden layers
        for i in range(len(self.hidden_layers), 0, -1):
            error = np.dot(deltas[0], self.weights[i].T)
            delta = error * self.relu_derivative(self.z_values[i-1])  # Using z_values for ReLU derivative
            deltas.insert(0, delta)
        
        # Update weights and biases
        for i in range(len(self.weights)):
            dw = np.dot(self.activations[i].T, deltas[i]) / m
            db = np.sum(deltas[i], axis=0) / m
            self.weights[i] -= learning_rate * dw
            self.biases[i] -= learning_rate * db
    
    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size, initial_learning_rate):
        n_samples = X_train.shape[0]
        n_batches = n_samples // batch_size
        
        train_loss_history = []
        val_loss_history = []
        train_acc_history = []
        val_acc_history = []
        
        for epoch in range(epochs):
            # Adaptive learning rate
            current_lr = initial_learning_rate / math.sqrt(epoch + 1)
            
            # Shuffle data
            permutation = np.random.permutation(n_samples)
            X_shuffled = X_train[permutation]
            y_shuffled = y_train[permutation]
            
            epoch_loss = 0
            
            for i in range(n_batches):
                # Get mini-batch
                start = i * batch_size
                end = start + batch_size
                X_batch = X_shuffled[start:end]
                y_batch = y_shuffled[start:end]
                
                # Forward pass
                output = self.forward(X_batch)
                
                # Compute loss
                loss = -np.mean(np.sum(y_batch * np.log(output + 1e-15), axis=1))
                epoch_loss += loss
                
                # Backward pass
                self.backward(X_batch, y_batch, current_lr)
            
            # Calculate average epoch loss
            epoch_loss /= n_batches
            train_loss_history.append(epoch_loss)
            
            # Calculate validation loss
            val_output = self.forward(X_val)
            val_loss = -np.mean(np.sum(y_val * np.log(val_output + 1e-15), axis=1))
            val_loss_history.append(val_loss)
            
            # Calculate accuracies
            train_pred = np.argmax(self.forward(X_train), axis=1)
            train_true = np.argmax(y_train, axis=1)
            train_acc = np.mean(train_true == train_pred)
            train_acc_history.append(train_acc)
            
            val_pred = np.argmax(val_output, axis=1)
            val_true = np.argmax(y_val, axis=1)
            val_acc = np.mean(val_true == val_pred)
            val_acc_history.append(val_acc)
            
            print(f"Epoch {epoch+1}/{epochs}, LR: {current_lr:.5f}, Train Loss: {epoch_loss:.4f}, "
                  f"Val Loss: {val_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}")
            if epoch &gt; 1 and abs(val_loss_history[-1] - val_loss_history[-2]) &lt; 1e-4:
                print(f"Early stopping at epoch {epoch+1} due to minimal change in validation loss.")
                break
        
        return train_loss_history, val_loss_history, train_acc_history, val_acc_history
    
    def predict(self, X):
        return np.argmax(self.forward(X), axis=1)

def one_hot_encode(y, num_classes):
    """Manual one-hot encoding implementation"""
    y_onehot = np.zeros((len(y), num_classes))
    y_onehot[np.arange(len(y)), y.flatten()] = 1
    return y_onehot

def calculate_metrics(true_labels, pred_labels, num_classes):
    """Calculate precision, recall, and F1 score for each class"""
    metrics = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})
    
    for true, pred in zip(true_labels, pred_labels):
        if true == pred:
            metrics[true]['tp'] += 1
        else:
            metrics[true]['fn'] += 1
            metrics[pred]['fp'] += 1
    
    results = {}
    for class_id in range(num_classes):
        tp = metrics[class_id]['tp']
        fp = metrics[class_id]['fp']
        fn = metrics[class_id]['fn']
        
        precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0
        recall = tp / (tp + fn) if (tp + fn) &gt; 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) &gt; 0 else 0
        
        results[class_id] = {
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    
    return results

def load_data(train_path, test_path):
    # Load training data
    X_train = []
    y_train = []
    
    for label in range(43):
        folder = os.path.join(train_path, f"{label:05d}")
        for file in os.listdir(folder):
            if file.endswith('.jpg'):
                img = Image.open(os.path.join(folder, file))
                img = img.resize((28, 28))
                img_array = np.array(img).flatten() / 255.0
                X_train.append(img_array)
                y_train.append(label)
    
    X_train = np.array(X_train)
    y_train = np.array(y_train).reshape(-1, 1)
    
    # Manual one-hot encoding
    y_train = one_hot_encode(y_train, 43)
    
    # Load test data
    # test_df = pd.read_csv(test_labels_path)
    X_test = []
    # y_test = []
    
    # for _, row in test_df.iterrows():
    #     img = Image.open(os.path.join(test_path, row['image']))
    #     img = img.resize((28, 28))
    #     img_array = np.array(img).flatten() / 255.0
    #     X_test.append(img_array)
        # y_test.append(row['label'])
    
    for img_file in sorted(os.listdir(test_path)):  # Sorted for consistency
        img_path = os.path.join(test_path, img_file)
        img = img.resize((28, 28))
        img_array = np.array(img).flatten() / 255.0
        X_test.append(img_array)
    
    X_test = np.array(X_test)
    # y_test = np.array(y_test).reshape(-1, 1)
    # y_test = one_hot_encode(y_test, 43)
    
    return X_train, y_train, X_test

def run_experiment(hidden_layers, train_data_path, test_data_path, output_folder_path):
    # Load data
    X_train, y_train, X_test= load_data(train_data_path, test_data_path)
    
    # Split training data into train and validation (80-20 split)
    n_samples = X_train.shape[0]
    indices = np.random.permutation(n_samples)
    split = int(0.8 * n_samples)
    
    X_train_split = X_train[indices[:split]]
    y_train_split = y_train[indices[:split]]
    X_val = X_train[indices[split:]]
    y_val = y_train[indices[split:]]
    
    # Initialize neural network
    input_size = 28 * 28 * 3  # 2352
    output_size = 43
    
    nn = NeuralNetwork(input_size, hidden_layers, output_size)
    
    # Train the network
    epochs = 150
    batch_size = 32
    initial_learning_rate = 0.01
    
    print(f"\nTraining network with architecture: {hidden_layers}")
    train_loss, val_loss, train_acc, val_acc = nn.train(
        X_train_split, y_train_split, X_val, y_val, 
        epochs, batch_size, initial_learning_rate
    )
    
    # Evaluate on test set
    test_pred = nn.predict(X_test)
    # test_true = np.argmax(y_test, axis=1)
    
    # test_acc = np.mean(test_true == test_pred)
    # print(f"Test Accuracy with architecture {hidden_layers}: {test_acc:.4f}")
    
    # # Calculate metrics
    # train_pred = nn.predict(X_train)
    # train_true = np.argmax(y_train, axis=1)
    
    # train_metrics = calculate_metrics(train_true, train_pred, 43)
    # test_metrics = calculate_metrics(test_true, test_pred, 43)
    
    # # Calculate average F1 scores
    # avg_train_f1 = np.mean([metrics['f1'] for metrics in train_metrics.values()])
    # avg_test_f1 = np.mean([metrics['f1'] for metrics in test_metrics.values()])
    
    # print(f"Average Train F1 Score: {avg_train_f1:.4f}")
    # print(f"Average Test F1 Score: {avg_test_f1:.4f}")
    
    # Save predictions
    # arch_name = '_'.join(map(str, hidden_layers))
    predictions = pd.DataFrame({'prediction': test_pred})
    predictions.to_csv(os.path.join(output_folder_path, f'prediction_e.csv'), index=False)
    
    return 

def main4(train_data_path, test_data_path, output_folder_path):
    architectures = [
        [512, 256, 128, 64]
    ]
    
    # train_f1_scores = []
    # test_f1_scores = []
    # depths = []
    
    for arch in architectures:
        run_experiment(
            arch, train_data_path, test_data_path, 
            output_folder_path
        )
        # train_f1_scores.append(avg_train_f1)
        # test_f1_scores.append(avg_test_f1)
        # depths.append(depth)
    
    # # Plot F1 scores vs network depth
    # plt.figure(figsize=(10, 6))
    # plt.plot(depths, train_f1_scores, 'o-', label='Train F1 Score')
    # plt.plot(depths, test_f1_scores, 'o-', label='Test F1 Score')
    # plt.xlabel('Network Depth (Number of Hidden Layers)')
    # plt.ylabel('Average F1 Score')
    # plt.title('Average F1 Score vs Network Depth (ReLU Activation)')
    # plt.xticks(depths)
    # plt.legend()
    # plt.grid(True)
    # plt.savefig(os.path.join(output_folder_path, 'f1_vs_network_depth_relu.png'))
    # plt.close()

if __name__ == "__main__":
    # import argparse
    
    # parser = argparse.ArgumentParser()
    # parser.add_argument('train_data_path', type=str)
    # parser.add_argument('test_data_path', type=str)
    # parser.add_argument('output_folder_path', type=str)
    # parser.add_argument('question_part', type=str)
    
    # args = parser.parse_args()
    
    # # Assuming test_labels.csv is in the test_data_path folder
    # test_labels_path = os.path.join(args.test_data_path, 'test_labels.csv')
    
    # if args.question_part == 'e':
    #     main(args.train_data_path, args.test_data_path, args.output_folder_path, test_labels_path)
    train_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/train"
    test_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test"
    output_folder_path=""
    
    # Assuming test_labels.csv is in the test_data_path folder
    test_labels_path = "/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test_labels.csv"
    
    main(train_data_path, test_data_path, output_folder_path, test_labels_path)



import pandas as pd
import numpy as np
from math import log2
import matplotlib.pyplot as plt

class DecisionTree1:
    def __init__(self, max_depth=None):
        self.max_depth = max_depth
        self.tree = None
        
    def _entropy(self, y):
        """Calculate entropy of a target variable"""
        counts = y.value_counts()
        probabilities = counts / len(y)
        return -sum(probabilities * np.log2(probabilities))
    
    def _mutual_information(self, X_col, y):
        """Calculate mutual information between a feature and target"""
        if X_col.dtype == 'object':  # Categorical
            # For categorical, do k-way split
            unique_values = X_col.unique()
            weighted_entropy = 0
            for value in unique_values:
                subset = y[X_col == value]
                weight = len(subset) / len(y)
                weighted_entropy += weight * self._entropy(subset)
            return self._entropy(y) - weighted_entropy
        else:  # Numerical
            # For numerical, split at median
            median = X_col.median()
            left = y[X_col &lt;= median]
            right = y[X_col &gt; median]
            weight_left = len(left) / len(y)
            weight_right = len(right) / len(y)
            weighted_entropy = weight_left * self._entropy(left) + weight_right * self._entropy(right)
            return self._entropy(y) - weighted_entropy
    
    def _find_best_split(self, X, y):
        """Find the best feature to split on"""
        best_feature = None
        best_gain = -1
        
        for feature in X.columns:
            gain = self._mutual_information(X[feature], y)
            if gain &gt; best_gain:
                best_gain = gain
                best_feature = feature
                
        return best_feature, best_gain
    
    def _build_tree(self, X, y, depth=0):
        """Recursively build the decision tree"""
        # Stopping conditions
        if depth == self.max_depth or len(y.unique()) == 1:
            return y.mode()[0]  # Return most common class
        
        # Find best split
        best_feature, best_gain = self._find_best_split(X, y)
        
        if best_gain == 0:  # No information gain
            return y.mode()[0]
        
        node = {'feature': best_feature, 'gain': best_gain, 'depth': depth}
        
        if X[best_feature].dtype == 'object':  # Categorical
            unique_values = X[best_feature].unique()
            node['type'] = 'categorical'
            node['children'] = {}
            
            for value in unique_values:
                subset_X = X[X[best_feature] == value].drop(columns=[best_feature])
                subset_y = y[X[best_feature] == value]
                
                if len(subset_y) == 0:
                    node['children'][value] = y.mode()[0]
                else:
                    node['children'][value] = self._build_tree(subset_X, subset_y, depth+1)
        else:  # Numerical
            median = X[best_feature].median()
            node['type'] = 'numerical'
            node['split_value'] = median
            node['children'] = {'left': None, 'right': None}
            
            # Left child (&lt;= median)
            left_X = X[X[best_feature] &lt;= median]
            left_y = y[X[best_feature] &lt;= median]
            if len(left_y) &gt; 0:
                node['children']['left'] = self._build_tree(left_X, left_y, depth+1)
            else:
                node['children']['left'] = y.mode()[0]
            
            # Right child (&gt; median)
            right_X = X[X[best_feature] &gt; median]
            right_y = y[X[best_feature] &gt; median]
            if len(right_y) &gt; 0:
                node['children']['right'] = self._build_tree(right_X, right_y, depth+1)
            else:
                node['children']['right'] = y.mode()[0]
        
        return node
    
    def fit(self, X, y):
        """Fit the decision tree to the data"""
        self.tree = self._build_tree(X, y)
        return self
    
    def _predict_instance(self, x, node):
        """Predict a single instance"""
        if isinstance(node, str):  # Leaf node
            return node
        
        feature = node['feature']
        
        if node['type'] == 'categorical':
            if x[feature] in node['children']:
                return self._predict_instance(x, node['children'][x[feature]])
            else:  # Unseen category
                return list(node['children'].values())[0]  # Return first child's prediction
        else:  # Numerical
            if x[feature] &lt;= node['split_value']:
                return self._predict_instance(x, node['children']['left'])
            else:
                return self._predict_instance(x, node['children']['right'])
    
    def predict(self, X):
        """Predict for multiple instances"""
        return X.apply(lambda x: self._predict_instance(x, self.tree), axis=1)

    
    def accuracy(self, X, y):
        """Calculate accuracy"""
        preds = self.predict(X)
        return (preds == y).mean()
    
    def save_pred_for_depth20(self, X, output_folder):
        """Save predictions for depth 20"""
        preds = self.predict(X)
        output_df = pd.DataFrame({'prediction': preds})
        output_df.to_csv(f"{output_folder}/predictions_a.csv", index=False)
        print(f"Predictions saved to {output_folder}/predictions_a.csv")

if __name__ == "__main__":
    
    # Load data
    train = pd.read_csv('../Adata/train.csv')
    valid = pd.read_csv('../Adata/valid.csv')
    test = pd.read_csv('../Adata/test.csv')

    # Separate features and target
    X_train = train.drop(columns=['income'])
    y_train = train['income']
    X_valid = valid.drop(columns=['income'])
    y_valid = valid['income']
    X_test = test.drop(columns=['income'])
    y_test = test['income']

    # Experiment with different depths
    depths = [5, 10, 15, 20]
    train_accuracies = []
    test_accuracies = []

    for depth in depths:
        print(f"Training tree with max_depth={depth}")
        tree = DecisionTree1(max_depth=depth)
        tree.fit(X_train, y_train)
        
        train_acc = tree.accuracy(X_train, y_train)
        test_acc = tree.accuracy(X_test, y_test)
        
        train_accuracies.append(train_acc)
        test_accuracies.append(test_acc)
        
        print(f"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}")

    # Plot results
    plt.figure(figsize=(10, 6))
    plt.plot(depths, train_accuracies, label='Train Accuracy', marker='o')
    plt.plot(depths, test_accuracies, label='Test Accuracy', marker='o')
    plt.xlabel('Maximum Depth')
    plt.ylabel('Accuracy')
    plt.title('Decision Tree Performance vs. Maximum Depth')
    plt.legend()
    plt.grid()
    plt.show()

    # Evaluate on test set with best depth
    best_depth = depths[np.argmax(test_accuracies)]
    print(f"\nBest depth based on validation: {best_depth}")





import os
import numpy as np
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt

class NeuralNetwork1:
    def __init__(self, input_size, hidden_layers, output_size):
        self.input_size = input_size
        self.hidden_layers = hidden_layers
        self.output_size = output_size
        
        # Initialize weights and biases
        self.weights = []
        self.biases = []
        
        # Input to first hidden layer
        prev_size = input_size
        for size in hidden_layers:
            self.weights.append(np.random.randn(prev_size, size) * np.sqrt(2./prev_size))
            self.biases.append(np.zeros(size))
            prev_size = size
        
        # Last hidden to output layer
        self.weights.append(np.random.randn(prev_size, output_size) * np.sqrt(2./prev_size))
        self.biases.append(np.zeros(output_size))
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))
    
    def sigmoid_derivative(self, x):
        return x * (1 - x)
    
    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forward(self, X):
        self.activations = [X]
        self.z_values = []
        
        # Hidden layers with sigmoid activation
        for i in range(len(self.hidden_layers)):
            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
            a = self.sigmoid(z)
            self.z_values.append(z)
            self.activations.append(a)
        
        # Output layer with softmax activation
        z = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
        a = self.softmax(z)
        self.z_values.append(z)
        self.activations.append(a)
        
        return a
    
    def backward(self, X, y, learning_rate):
        m = X.shape[0]
        deltas = []
        
        # Output layer error
        error = self.activations[-1] - y
        delta = error  # For softmax with cross-entropy
        deltas.insert(0, delta)
        
        # Backpropagate through hidden layers
        for i in range(len(self.hidden_layers), 0, -1):
            error = np.dot(deltas[0], self.weights[i].T)
            delta = error * self.sigmoid_derivative(self.activations[i])
            deltas.insert(0, delta)
        
        # Update weights and biases
        for i in range(len(self.weights)):
            dw = np.dot(self.activations[i].T, deltas[i]) / m
            db = np.sum(deltas[i], axis=0) / m
            self.weights[i] -= learning_rate * dw
            self.biases[i] -= learning_rate * db
    
    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size, learning_rate):
        n_samples = X_train.shape[0]
        n_batches = n_samples // batch_size
        
        train_loss_history = []
        val_loss_history = []
        train_acc_history = []
        val_acc_history = []
        
        for epoch in range(epochs):
            # Shuffle data
            permutation = np.random.permutation(n_samples)
            X_shuffled = X_train[permutation]
            y_shuffled = y_train[permutation]
            
            epoch_loss = 0
            
            for i in range(n_batches):
                # Get mini-batch
                start = i * batch_size
                end = start + batch_size
                X_batch = X_shuffled[start:end]
                y_batch = y_shuffled[start:end]
                
                # Forward pass
                output = self.forward(X_batch)
                
                # Compute loss
                loss = -np.mean(np.sum(y_batch * np.log(output + 1e-15), axis=1))
                epoch_loss += loss
                
                # Backward pass
                self.backward(X_batch, y_batch, learning_rate)
            
            # Calculate average epoch loss
            epoch_loss /= n_batches
            train_loss_history.append(epoch_loss)
            
            # Calculate validation loss
            val_output = self.forward(X_val)
            val_loss = -np.mean(np.sum(y_val * np.log(val_output + 1e-15), axis=1))
            val_loss_history.append(val_loss)
            
            # Calculate accuracies
            train_pred = np.argmax(self.forward(X_train), axis=1)
            train_true = np.argmax(y_train, axis=1)
            train_acc = np.mean(train_true == train_pred)
            train_acc_history.append(train_acc)
            
            val_pred = np.argmax(val_output, axis=1)
            val_true = np.argmax(y_val, axis=1)
            val_acc = np.mean(val_true == val_pred)
            val_acc_history.append(val_acc)
            
            print(f"Epoch {epoch+1}/{epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, "
                  f"Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}")
            
            # Early stopping based on validation loss
            if epoch &gt; 1 and abs(val_loss_history[-1] - val_loss_history[-2]) &lt; 1e-4:
                print(f"Early stopping at epoch {epoch+1} due to minimal change in validation loss.")
                break
        
        return train_loss_history, val_loss_history, train_acc_history, val_acc_history
    
    def predict(self, X):
        return np.argmax(self.forward(X), axis=1)

def one_hot_encode1(y, num_classes):
    """Manual one-hot encoding implementation"""
    y_onehot = np.zeros((len(y), num_classes))
    y_onehot[np.arange(len(y)), y.flatten()] = 1
    return y_onehot

def load_data1(train_path, test_path):
    # Load training data
    X_train = []
    y_train = []
    
    for label in range(43):
        folder = os.path.join(train_path, f"{label:05d}")
        for file in os.listdir(folder):
            if file.endswith('.jpg'):
                img = Image.open(os.path.join(folder, file))
                img = img.resize((28, 28))
                img_array = np.array(img).flatten() / 255.0
                X_train.append(img_array)
                y_train.append(label)
    
    X_train = np.array(X_train)
    y_train = np.array(y_train).reshape(-1, 1)
    
    # Manual one-hot encoding
    y_train = one_hot_encode1(y_train, 43)
    
    # Load test data
    # test_df = pd.read_csv(test_labels_path)
    X_test = []
    # y_test = []
    
    # for _, row in test_df.iterrows():
    #     img = Image.open(os.path.join(test_path, row['image']))
    #     img = img.resize((28, 28))
    #     img_array = np.array(img).flatten() / 255.0
    #     X_test.append(img_array)
        # y_test.append(row['label'])
    
    for img_file in sorted(os.listdir(test_path)):  # Sorted for consistency
        img_path = os.path.join(test_path, img_file)
        img = img.resize((28, 28))
        img_array = np.array(img).flatten() / 255.0
        X_test.append(img_array)
    
    X_test = np.array(X_test)
    # y_test = np.array(y_test).reshape(-1, 1)
    # y_test = one_hot_encode(y_test, 43)
    
    return X_train, y_train, X_test

def main1(train_data_path, test_data_path, output_folder_path):
    # Load data
    X_train, y_train, X_test = load_data1(train_data_path, test_data_path)

    print(f"X_test ahape :{X_test.shape}")
    
    # Split training data into train and validation (80-20 split)
    n_samples = X_train.shape[0]
    indices = np.random.permutation(n_samples)
    split = int(0.8 * n_samples)
    
    X_train_split = X_train[indices[:split]]
    y_train_split = y_train[indices[:split]]
    X_val = X_train[indices[split:]]
    y_val = y_train[indices[split:]]
    
    # Initialize neural network
    input_size = 28 * 28 * 3  # 2352
    hidden_layers = [100]  # Single hidden layer with 100 units (will be varied in part b)
    output_size = 43
    
    nn = NeuralNetwork1(input_size, hidden_layers, output_size)
    
    # Train the network
    epochs = 150
    batch_size = 32
    learning_rate = 0.01
    
    train_loss, val_loss, train_acc, val_acc = nn.train(
        X_train_split, y_train_split, X_val, y_val, 
        epochs, batch_size, learning_rate
    )
    
    # Plot training and validation loss
    # plt.figure(figsize=(12, 5))
    # plt.subplot(1, 2, 1)
    # plt.plot(train_loss, label='Train Loss')
    # plt.plot(val_loss, label='Validation Loss')
    # plt.xlabel('Epoch')
    # plt.ylabel('Loss')
    # plt.title('Training and Validation Loss')
    # plt.legend()
    
    # # Plot training and validation accuracy
    # plt.subplot(1, 2, 2)
    # plt.plot(train_acc, label='Train Accuracy')
    # plt.plot(val_acc, label='Validation Accuracy')
    # plt.xlabel('Epoch')
    # plt.ylabel('Accuracy')
    # plt.title('Training and Validation Accuracy')
    # plt.legend()
    
    # plt.tight_layout()
    # plt.savefig(os.path.join(output_folder_path, 'training_plots.png'))
    # plt.close()
    
    # Evaluate on test set
    test_pred = nn.predict(X_test)
    # test_true = np.argmax(y_test, axis=1)
    test_pred = np.array(test_pred)

    # test_acc = np.mean(test_true == test_pred)
    # print(f"Test Accuracy: {test_acc:.4f}")
    
    # Save predictions
    predictions = pd.DataFrame({'prediction': test_pred})
    predictions.to_csv(os.path.join(output_folder_path, 'prediction_b.csv'), index=False)

if __name__ == "__main__":
    # import argparse
    
    # parser = argparse.ArgumentParser()
    # parser.add_argument('train_data_path', type=str)
    # parser.add_argument('test_data_path', type=str)
    # parser.add_argument('output_folder_path', type=str)
    # parser.add_argument('question_part', type=str)
    
    # args = parser.parse_args()
    train_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/train"
    test_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test"
    output_folder_path=""
    
    # Assuming test_labels.csv is in the test_data_path folder
    test_labels_path = "/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test_labels.csv"
    
    # if args.question_part == 'a':
    main(train_data_path, test_data_path, output_folder_path, test_labels_path)



import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import sys
import os

def load_and_preprocess_data(train_path, valid_path, test_path):
    """Loads train, validation, and test data and performs one-hot encoding."""
    try:
        train_df = pd.read_csv(train_path)
        valid_df = pd.read_csv(valid_path)
        test_df = pd.read_csv(test_path)
        if 'income' in test_df.columns:
            test_df = test_df.drop('income', axis=1)
    except FileNotFoundError as e:
        print(f"Error loading data file: {e}. Please check file paths.")
        sys.exit(1)
    except Exception as e:
        print(f"An error occurred while reading the CSV files: {e}")
        sys.exit(1)

    # Separate target variable
    y_train = train_df['income']
    y_valid = valid_df['income']



    # Drop target variable from features
    X_train = train_df.drop('income', axis=1)
    X_valid = valid_df.drop('income', axis=1)
    X_test = test_df



    # Identify categorical features (assuming object type)
    categorical_cols = X_train.select_dtypes(include=['object']).columns

    # Apply one-hot encoding
    # Combine train, valid, test to ensure consistent encoding
    combined_X = pd.concat([X_train, X_valid, X_test], keys=['train', 'valid', 'test'])
    combined_X_encoded = pd.get_dummies(combined_X, columns=categorical_cols, drop_first=True) # drop_first=True helps reduce multicollinearity

    # Separate back into train, valid, test sets
    X_train_encoded = combined_X_encoded.loc['train']
    X_valid_encoded = combined_X_encoded.loc['valid']
    X_test_encoded = combined_X_encoded.loc['test']

    # Ensure all datasets have the same columns after encoding
    X_valid_encoded = X_valid_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)
    X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)


    return X_train_encoded, y_train, X_valid_encoded, y_valid, X_test_encoded

def part_d_max_depth(X_train, y_train, X_valid, y_valid, X_test):
    """Performs analysis for Part 1(d) varying max_depth."""
    print("\n--- Part 1(d) (i): Varying max_depth ---")
    max_depths = [25, 35, 45, 55]
    train_accuracies = []
    valid_accuracies = []
    # test_accuracies = []

    best_val_acc = -1
    best_depth = -1
    best_model_depth = None

    print("Max Depth | Train Acc | Valid Acc | Test Acc")
    print("------------------------------------------")
    for depth in max_depths:
        # Initialize and train the model
        model = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42)
        model.fit(X_train, y_train)

        # Predict and calculate accuracies
        y_train_pred = model.predict(X_train)
        y_valid_pred = model.predict(X_valid)
        # y_test_pred = model.predict(X_test)

        train_acc = accuracy_score(y_train, y_train_pred)
        valid_acc = accuracy_score(y_valid, y_valid_pred)
        # test_acc = accuracy_score(y_test, y_test_pred)

        train_accuracies.append(train_acc)
        valid_accuracies.append(valid_acc)
        # test_accuracies.append(test_acc)

        # print(f"{depth:&lt;9} | {train_acc:.4f}    | {valid_acc:.4f}   | {test_acc:.4f}")

        # Track best model based on validation accuracy
        if valid_acc &gt; best_val_acc:
            best_val_acc = valid_acc
            best_depth = depth
            best_model_depth = model


    # Plotting
    # plt.figure(figsize=(10, 6))
    # plt.plot(max_depths, train_accuracies, marker='o', label='Train Accuracy')
    # plt.plot(max_depths, test_accuracies, marker='s', label='Test Accuracy')
    # plt.plot(max_depths, valid_accuracies, marker='^', label='Validation Accuracy')
    # plt.xlabel('Maximum Depth')
    # plt.ylabel('Accuracy')
    # plt.title('Decision Tree Accuracy vs. Maximum Depth (Criterion=Entropy)')
    # plt.xticks(max_depths)
    # plt.legend()
    # plt.grid(True)
    # plt.show()


    # print(f"\nBest max_depth based on validation accuracy: {best_depth} (Validation Acc: {best_val_acc:.4f})")
    # Test accuracy for the best model chosen by validation set
    # best_depth_test_acc = accuracy_score(y_test, best_model_depth.predict(X_test))
    # print(f"Test accuracy for best max_depth ({best_depth}): {best_depth_test_acc:.4f}")

    return best_model_depth, best_val_acc

def part_d_ccp_alpha(X_train, y_train, X_valid, y_valid, X_test, ):
    """Performs analysis for Part 1(d) varying ccp_alpha."""
    print("\n--- Part 1(d) (ii): Varying ccp_alpha ---")
    ccp_alphas = [0.001, 0.01, 0.1, 0.2]
    train_accuracies = []
    valid_accuracies = []
    test_accuracies = []

    best_val_acc = -1
    best_alpha = -1
    best_model_alpha = None

    print("ccp_alpha | Train Acc | Valid Acc | Test Acc")
    print("-------------------------------------------")
    for alpha in ccp_alphas:
        # Initialize and train the model (default max_depth=None)
        model = DecisionTreeClassifier(criterion='entropy', ccp_alpha=alpha, random_state=42)
        model.fit(X_train, y_train)

        # Predict and calculate accuracies
        y_train_pred = model.predict(X_train)
        y_valid_pred = model.predict(X_valid)
        # y_test_pred = model.predict(X_test)

        train_acc = accuracy_score(y_train, y_train_pred)
        valid_acc = accuracy_score(y_valid, y_valid_pred)
        # test_acc = accuracy_score(y_test, y_test_pred)

        train_accuracies.append(train_acc)
        valid_accuracies.append(valid_acc)
        # test_accuracies.append(test_acc)

        # print(f"{alpha:&lt;9} | {train_acc:.4f}    | {valid_acc:.4f}   | {test_acc:.4f}")

        # Track best model based on validation accuracy
        if valid_acc &gt; best_val_acc:
            best_val_acc = valid_acc
            best_alpha = alpha
            best_model_alpha = model

    # Plotting
    # plt.figure(figsize=(10, 6))
    # plt.plot(ccp_alphas, train_accuracies, marker='o', label='Train Accuracy')
    # plt.plot(ccp_alphas, test_accuracies, marker='s', label='Test Accuracy')
    # plt.plot(ccp_alphas, valid_accuracies, marker='^', label='Validation Accuracy')
    # plt.xlabel('ccp_alpha (Pruning Parameter)')
    # plt.ylabel('Accuracy')
    # plt.xscale('log') # Use log scale for better visualization if needed
    # plt.title('Decision Tree Accuracy vs. ccp_alpha (Criterion=Entropy)')
    # plt.xticks(ccp_alphas, labels=[str(a) for a in ccp_alphas])
    # plt.legend()
    # plt.grid(True)
    # plt.show()

    # print(f"\nBest ccp_alpha based on validation accuracy: {best_alpha} (Validation Acc: {best_val_acc:.4f})")
     # Test accuracy for the best model chosen by validation set
    # best_alpha_test_acc = accuracy_score(y_test, best_model_alpha.predict(X_test))
    # print(f"Test accuracy for best ccp_alpha ({best_alpha}): {best_alpha_test_acc:.4f}")

    return best_model_alpha, best_val_acc

def save_predictions(model, X_test, output_path):
    """Saves model predictions on the test set to a CSV file."""
    predictions = model.predict(X_test)
    print(f"Predictions: {predictions}")
    pred_df = pd.DataFrame({'prediction': predictions})
    # Ensure output directory exists
    # os.makedirs(os.path.dirname(output_path), exist_ok=True)
    pred_df.to_csv(output_path, index=False)
    print(f"\nPredictions saved to {output_path}")


# if __name__ == "__main__":
#     # Check for correct number of command-line arguments
#     if len(sys.argv) != 6:
#         print("Usage: python decision_tree.py &lt;train_data_path&gt; &lt;validation_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
#         print("Example: python decision_tree.py data/train.csv data/valid.csv data/test.csv output/ d")
#         sys.exit(1)

#     # Parse command-line arguments
#     train_path = sys.argv[1]
#     valid_path = sys.argv[2]
#     test_path = sys.argv[3]
#     output_folder = sys.argv[4]
#     question_part = sys.argv[5].lower() # Convert to lower case

#     if question_part != 'd':
#         print(f"This script only implements Part 1(d). You provided '{question_part}'.")
#         sys.exit(1)

#     # Load and preprocess data
#     print("Loading and preprocessing data...")
#     X_train, y_train, X_valid, y_valid, X_test, y_test = load_and_preprocess_data(train_path, valid_path, test_path)
#     print("Data loaded and preprocessed successfully.")

#     # Run Part 1(d) analyses
#     best_model_depth, val_acc_depth = part_d_max_depth(X_train, y_train, X_valid, y_valid, X_test, y_test)
#     best_model_alpha, val_acc_alpha = part_d_ccp_alpha(X_train, y_train, X_valid, y_valid, X_test, y_test)

#     # --- Comparison Comments (as requested in Part 1(d)) ---
#     print("\n--- Comparison Comments (Part 1(d) vs Parts 1(b)/1(c)) ---")
#     print("Note: These comments assume hypothetical results from Parts 1(b) and 1(c).")

#     print("\nComparison with Part 1(b) (One-Hot Encoding, Varying Depth):")
#     print(f"- The scikit-learn implementation in Part 1(d)(i) uses entropy criterion and varies max_depth ({[25, 35, 45, 55]}).")
#     print("- This is directly comparable to Part 1(b) which also used one-hot encoding and varied depth (though potentially different ranges).")
#     print("- We would expect similar trends: training accuracy generally increases or plateaus with depth, while test/validation accuracy might peak and then decrease due to overfitting.")
#     print(f"- The best scikit-learn model from varying depth achieved validation accuracy {val_acc_depth:.4f}. This should be compared to the best validation accuracy obtained in Part 1(b).")
#     print("- Differences in accuracy could arise from slight implementation variations (e.g., handling of continuous features if different, specific split logic) between the custom implementation and scikit-learn.")

#     print("\nComparison with Part 1(c) (Post-Pruning):")
#     print("- Part 1(d)(ii) uses scikit-learn's cost-complexity pruning (ccp_alpha) which is a form of pre-pruning (applied during growth) or post-pruning depending on how it's used, but conceptually related to controlling model complexity like post-pruning in 1(c).")
#     print("- Part 1(c) involved growing a tree (likely deep, based on 1(b)) and then *post-pruning* nodes based on validation accuracy.")
#     print(f"- The best scikit-learn model using ccp_alpha achieved validation accuracy {val_acc_alpha:.4f}. This should be compared to the best validation accuracy obtained after post-pruning in Part 1(c).")
#     print("- Both methods aim to combat overfitting. Cost-complexity pruning (ccp_alpha) finds a sequence of subtrees optimized for complexity vs. error, while the greedy post-pruning in 1(c) removes nodes iteratively based purely on validation gain.")
#     print("- The results might differ. Scikit-learn's pruning is often effective, but the best approach (depth limit, ccp_alpha, or custom post-pruning) can be dataset-dependent.")
#     print("- Scikit-learn's optimized implementation might also lead to performance differences compared to a from-scratch implementation.")

#     # Determine the overall best model based on validation accuracy
#     if val_acc_depth &gt;= val_acc_alpha:
#         print("\nChoosing best model from max_depth variation for final predictions.")
#         final_model = best_model_depth
#     else:
#         print("\nChoosing best model from ccp_alpha variation for final predictions.")
#         final_model = best_model_alpha

#     # Define the output file path
#     output_file_path = os.path.join(output_folder, f"prediction_{question_part}.csv")

#     # Save predictions of the chosen best model
#     save_predictions(final_model, X_test, output_file_path)

#     print("\nPart 1(d) execution completed.")

# Load and preprocess data
if __name__ == "__main__":
    train_path = "../Adata/train.csv"
    valid_path = "../Adata/valid.csv"
    test_path = "../Adata/test.csv"

    print("Loading and preprocessing data...")
    X_train, y_train, X_valid, y_valid, X_test, y_test = load_and_preprocess_data(train_path, valid_path, test_path)
    print("Data loaded and preprocessed successfully.")

    # Run Part 1(d) analyses
    best_model_depth, val_acc_depth = part_d_max_depth(X_train, y_train, X_valid, y_valid, X_test, y_test)
    best_model_alpha, val_acc_alpha = part_d_ccp_alpha(X_train, y_train, X_valid, y_valid, X_test, y_test)

    #Save predictions of the chosen best model

    output_folder = "output.csv"

    save_predictions(best_model_alpha, X_test, output_folder)






import os
import numpy as np
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict
import math

class NeuralNetwork:
    def __init__(self, input_size, hidden_layers, output_size):
        self.input_size = input_size
        self.hidden_layers = hidden_layers
        self.output_size = output_size
        
        # Initialize weights and biases
        self.weights = []
        self.biases = []
        
        # Input to first hidden layer
        prev_size = input_size
        for size in hidden_layers:
            self.weights.append(np.random.randn(prev_size, size) * np.sqrt(2./prev_size))
            self.biases.append(np.zeros(size))
            prev_size = size
        
        # Last hidden to output layer
        self.weights.append(np.random.randn(prev_size, output_size) * np.sqrt(2./prev_size))
        self.biases.append(np.zeros(output_size))
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))
    
    def sigmoid_derivative(self, x):
        return x * (1 - x)
    
    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forward(self, X):
        self.activations = [X]
        self.z_values = []
        
        # Hidden layers with sigmoid activation
        for i in range(len(self.hidden_layers)):
            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
            a = self.sigmoid(z)
            self.z_values.append(z)
            self.activations.append(a)
        
        # Output layer with softmax activation
        z = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
        a = self.softmax(z)
        self.z_values.append(z)
        self.activations.append(a)
        
        return a
    
    def backward(self, X, y, learning_rate):
        m = X.shape[0]
        deltas = []
        
        # Output layer error
        error = self.activations[-1] - y
        delta = error  # For softmax with cross-entropy
        deltas.insert(0, delta)
        
        # Backpropagate through hidden layers
        for i in range(len(self.hidden_layers), 0, -1):
            error = np.dot(deltas[0], self.weights[i].T)
            delta = error * self.sigmoid_derivative(self.activations[i])
            deltas.insert(0, delta)
        
        # Update weights and biases
        for i in range(len(self.weights)):
            dw = np.dot(self.activations[i].T, deltas[i]) / m
            db = np.sum(deltas[i], axis=0) / m
            self.weights[i] -= learning_rate * dw
            self.biases[i] -= learning_rate * db
    
    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size, initial_learning_rate):
        n_samples = X_train.shape[0]
        n_batches = n_samples // batch_size
        
        train_loss_history = []
        val_loss_history = []
        train_acc_history = []
        val_acc_history = []
        
        for epoch in range(epochs):
            # Adaptive learning rate
            current_lr = initial_learning_rate / math.sqrt(epoch + 1)
            
            # Shuffle data
            permutation = np.random.permutation(n_samples)
            X_shuffled = X_train[permutation]
            y_shuffled = y_train[permutation]
            
            epoch_loss = 0
            
            for i in range(n_batches):
                # Get mini-batch
                start = i * batch_size
                end = start + batch_size
                X_batch = X_shuffled[start:end]
                y_batch = y_shuffled[start:end]
                
                # Forward pass
                output = self.forward(X_batch)
                
                # Compute loss
                loss = -np.mean(np.sum(y_batch * np.log(output + 1e-15), axis=1))
                epoch_loss += loss
                
                # Backward pass
                self.backward(X_batch, y_batch, current_lr)
            
            # Calculate average epoch loss
            epoch_loss /= n_batches
            train_loss_history.append(epoch_loss)
            
            # Calculate validation loss
            val_output = self.forward(X_val)
            val_loss = -np.mean(np.sum(y_val * np.log(val_output + 1e-15), axis=1))
            val_loss_history.append(val_loss)
            
            # Calculate accuracies
            train_pred = np.argmax(self.forward(X_train), axis=1)
            train_true = np.argmax(y_train, axis=1)
            train_acc = np.mean(train_true == train_pred)
            train_acc_history.append(train_acc)
            
            val_pred = np.argmax(val_output, axis=1)
            val_true = np.argmax(y_val, axis=1)
            val_acc = np.mean(val_true == val_pred)
            val_acc_history.append(val_acc)
            
            print(f"Epoch {epoch+1}/{epochs}, LR: {current_lr:.5f}, Train Loss: {epoch_loss:.4f}, "
                  f"Val Loss: {val_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}")

            #stopping criterion
            if epoch &gt; 1 and abs(val_loss_history[-1] - val_loss_history[-2]) &lt; 1e-4:
                print(f"Early stopping at epoch {epoch+1} due to minimal change in validation loss.")
                break
        
        return train_loss_history, val_loss_history, train_acc_history, val_acc_history
    
    def predict(self, X):
        return np.argmax(self.forward(X), axis=1)

def one_hot_encode(y, num_classes):
    """Manual one-hot encoding implementation"""
    y_onehot = np.zeros((len(y), num_classes))
    y_onehot[np.arange(len(y)), y.flatten()] = 1
    return y_onehot

def calculate_metrics(true_labels, pred_labels, num_classes):
    """Calculate precision, recall, and F1 score for each class"""
    metrics = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})
    
    for true, pred in zip(true_labels, pred_labels):
        if true == pred:
            metrics[true]['tp'] += 1
        else:
            metrics[true]['fn'] += 1
            metrics[pred]['fp'] += 1
    
    results = {}
    for class_id in range(num_classes):
        tp = metrics[class_id]['tp']
        fp = metrics[class_id]['fp']
        fn = metrics[class_id]['fn']
        
        precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0
        recall = tp / (tp + fn) if (tp + fn) &gt; 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) &gt; 0 else 0
        
        results[class_id] = {
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    
    return results

def load_data3(train_path, test_path):
    # Load training data
    X_train = []
    y_train = []
    
    for label in range(43):
        folder = os.path.join(train_path, f"{label:05d}")
        for file in os.listdir(folder):
            if file.endswith('.jpg'):
                img = Image.open(os.path.join(folder, file))
                img = img.resize((28, 28))
                img_array = np.array(img).flatten() / 255.0
                X_train.append(img_array)
                y_train.append(label)
    
    X_train = np.array(X_train)
    y_train = np.array(y_train).reshape(-1, 1)
    
    # Manual one-hot encoding
    y_train = one_hot_encode(y_train, 43)
    
    # Load test data
    # test_df = pd.read_csv(test_labels_path)
    X_test = []
    # y_test = []
    
    # for _, row in test_df.iterrows():
    #     img = Image.open(os.path.join(test_path, row['image']))
    #     img = img.resize((28, 28))
    #     img_array = np.array(img).flatten() / 255.0
    #     X_test.append(img_array)
        # y_test.append(row['label'])
    
    for img_file in sorted(os.listdir(test_path)):  # Sorted for consistency
        img_path = os.path.join(test_path, img_file)
        img = img.resize((28, 28))
        img_array = np.array(img).flatten() / 255.0
        X_test.append(img_array)
    
    X_test = np.array(X_test)
    # y_test = np.array(y_test).reshape(-1, 1)
    # y_test = one_hot_encode(y_test, 43)
    
    return X_train, y_train, X_test


def run_experiment(hidden_layers, train_data_path, test_data_path, output_folder_path):
    # Load data
    X_train, y_train, X_test = load_data3(train_data_path, test_data_path)
    
    # Split training data into train and validation (80-20 split)
    n_samples = X_train.shape[0]
    indices = np.random.permutation(n_samples)
    split = int(0.8 * n_samples)
    
    X_train_split = X_train[indices[:split]]
    y_train_split = y_train[indices[:split]]
    X_val = X_train[indices[split:]]
    y_val = y_train[indices[split:]]
    
    # Initialize neural network
    input_size = 28 * 28 * 3  # 2352
    output_size = 43
    
    nn = NeuralNetwork(input_size, hidden_layers, output_size)
    
    # Train the network
    epochs = 150
    batch_size = 32
    initial_learning_rate = 0.01
    
    print(f"\nTraining network with architecture: {hidden_layers}")
    train_loss, val_loss, train_acc, val_acc = nn.train(
        X_train_split, y_train_split, X_val, y_val, 
        epochs, batch_size, initial_learning_rate
    )
    
    # Evaluate on test set
    test_pred = nn.predict(X_test)
    # test_true = np.argmax(y_test, axis=1)
    # test_true = np.toarray(test_true)
    # test_acc = np.mean(test_true == test_pred)
    # print(f"Test Accuracy with architecture {hidden_layers}: {test_acc:.4f}")
    
    # Calculate metrics
    # train_pred = nn.predict(X_train)
    # train_true = np.argmax(y_train, axis=1)
    # train_true = np.toarray(train_true)

    
    # train_metrics = calculate_metrics(train_true, train_pred, 43)
    # test_metrics = calculate_metrics(test_true, test_pred, 43)
    
    # Calculate average F1 scores
    # avg_train_f1 = np.mean([metrics['f1'] for metrics in train_metrics.values()])
    # avg_test_f1 = np.mean([metrics['f1'] for metrics in test_metrics.values()])
    
    # print(f"Average Train F1 Score: {avg_train_f1:.4f}")
    # print(f"Average Test F1 Score: {avg_test_f1:.4f}")
    
    # Save predictions
    # arch_name = '_'.join(map(str, hidden_layers))
    predictions = pd.DataFrame({'prediction': test_pred})
    predictions.to_csv(os.path.join(output_folder_path, f'prediction_d.csv'), index=False)
    
    return 

def main3(train_data_path, test_data_path, output_folder_path):
    architectures = [
        [512, 256, 128, 64]
    ]
    
    train_f1_scores = []
    test_f1_scores = []
    depths = []
    
    for arch in architectures:
        run_experiment(
            arch, train_data_path, test_data_path, 
            output_folder_path
        )
        # train_f1_scores.append(avg_train_f1)
        # test_f1_scores.append(avg_test_f1)
        # depths.append(depth)
    
    # Plot F1 scores vs network depth
    # plt.figure(figsize=(10, 6))
    # plt.plot(depths, train_f1_scores, 'o-', label='Train F1 Score')
    # plt.plot(depths, test_f1_scores, 'o-', label='Test F1 Score')
    # plt.xlabel('Network Depth (Number of Hidden Layers)')
    # plt.ylabel('Average F1 Score')
    # plt.title('Average F1 Score vs Network Depth (Adaptive LR)')
    # plt.xticks(depths)
    # plt.legend()
    # plt.grid(True)
    # plt.savefig(os.path.join(output_folder_path, 'f1_vs_network_depth_adaptive_lr.png'))
    # plt.close()

if __name__ == "__main__":
    # import argparse
    
    # parser = argparse.ArgumentParser()
    # parser.add_argument('train_data_path', type=str)
    # parser.add_argument('test_data_path', type=str)
    # parser.add_argument('output_folder_path', type=str)
    # parser.add_argument('question_part', type=str)
    
    # args = parser.parse_args()
    
    # # Assuming test_labels.csv is in the test_data_path folder
    # test_labels_path = os.path.join(args.test_data_path, 'test_labels.csv')
    
    # if args.question_part == 'd':
    #     main(args.train_data_path, args.test_data_path, args.output_folder_path, test_labels_path)
    train_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/train"
    test_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test"
    output_folder_path=""
    
    # Assuming test_labels.csv is in the test_data_path folder
    test_labels_path = "/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test_labels.csv"
    
    # if args.question_part == 'a':
    main(train_data_path, test_data_path, output_folder_path, test_labels_path)



import sys
import pandas as pd
from first_2 import main1
from third_2 import main2
from fourth_2 import main3
from fifth_2 import main4
from sixth_2 import main5


if __name__ == "__main__":
    # Check for correct number of command-line arguments
<A NAME="1"></A><FONT color = #00FF00><A HREF="match203-1.html#1" TARGET="1"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    if len(sys.argv) != 5:
        print("Usage: python decision_tree.py &lt;train_data_path&gt; &lt;validation_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
        print("Example: python decision_tree.py data/train.csv data/valid.csv data/test.csv output/ d")
        sys.exit(1)

    # Parse command-line arguments
    train_path = sys.argv[1]
    test_path = sys.argv[2]
    output_folder = sys.argv[3]
</FONT>    question_part = sys.argv[4].lower()


    if question_part == 'b':
        main1(train_path, test_path, output_folder)
    elif question_part == 'c':
        main2(train_path, test_path, output_folder)
<A NAME="2"></A><FONT color = #0000FF><A HREF="match203-1.html#2" TARGET="1"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    elif question_part == 'd':
        main3(train_path, test_path, output_folder)
    elif question_part == 'e':
        main4(train_path, test_path, output_folder)
    elif question_part== 'f':
        main5(train_path, test_path, output_folder)
    else:
        print("!ERROR!")
</FONT>    





import pandas as pd
import numpy as np
from math import log2
import matplotlib.pyplot as plt

class DecisionTree2:
    def __init__(self, max_depth=None):
        self.max_depth = max_depth
        self.tree = None
        
    def _entropy(self, y):
        """Calculate entropy of a target variable"""
        counts = y.value_counts()
        probabilities = counts / len(y)
        return -sum(probabilities * np.log2(probabilities))
    
    def _mutual_information(self, X_col, y):
        """Calculate mutual information between a feature and target"""
        if X_col.dtype == 'object':  # Categorical
            # For categorical, do k-way split
            unique_values = X_col.unique()
            weighted_entropy = 0
            for value in unique_values:
                subset = y[X_col == value]
                weight = len(subset) / len(y)
                weighted_entropy += weight * self._entropy(subset)
            return self._entropy(y) - weighted_entropy
        else:  # Numerical
            # For numerical, split at median
            median = X_col.median()
            left = y[X_col &lt;= median]
            right = y[X_col &gt; median]
            weight_left = len(left) / len(y)
            weight_right = len(right) / len(y)
            weighted_entropy = weight_left * self._entropy(left) + weight_right * self._entropy(right)
            return self._entropy(y) - weighted_entropy
    
    def _find_best_split(self, X, y):
        """Find the best feature to split on"""
        best_feature = None
        best_gain = -1
        
        for feature in X.columns:
            gain = self._mutual_information(X[feature], y)
            if gain &gt; best_gain:
                best_gain = gain
                best_feature = feature
                
        return best_feature, best_gain
    
    def _build_tree(self, X, y, depth=0):
        """Recursively build the decision tree"""
        # Stopping conditions
        if depth == self.max_depth or len(y.unique()) == 1:
            return y.mode()[0]  # Return most common class
        
        # Find best split
        best_feature, best_gain = self._find_best_split(X, y)
        
        if best_gain == 0:  # No information gain
            return y.mode()[0]
        
        node = {'feature': best_feature, 'gain': best_gain, 'depth': depth}
        
        if X[best_feature].dtype == 'object':  # Categorical
            unique_values = X[best_feature].unique()
            node['type'] = 'categorical'
            node['children'] = {}
            
            for value in unique_values:
                subset_X = X[X[best_feature] == value].drop(columns=[best_feature])
                subset_y = y[X[best_feature] == value]
                
                if len(subset_y) == 0:
                    node['children'][value] = y.mode()[0]
                else:
                    node['children'][value] = self._build_tree(subset_X, subset_y, depth+1)
        else:  # Numerical
            median = X[best_feature].median()
            node['type'] = 'numerical'
            node['split_value'] = median
            node['children'] = {'left': None, 'right': None}
            
            # Left child (&lt;= median)
            left_X = X[X[best_feature] &lt;= median]
            left_y = y[X[best_feature] &lt;= median]
            if len(left_y) &gt; 0:
                node['children']['left'] = self._build_tree(left_X, left_y, depth+1)
            else:
                node['children']['left'] = y.mode()[0]
            
            # Right child (&gt; median)
            right_X = X[X[best_feature] &gt; median]
            right_y = y[X[best_feature] &gt; median]
            if len(right_y) &gt; 0:
                node['children']['right'] = self._build_tree(right_X, right_y, depth+1)
            else:
                node['children']['right'] = y.mode()[0]
        
        return node
    
    def fit(self, X, y):
        """Fit the decision tree to the data"""
        self.tree = self._build_tree(X, y)
        return self
    
    def _predict_instance(self, x, node):
        """Predict a single instance"""
        if isinstance(node, str):  # Leaf node
            return node
        
        feature = node['feature']
        
        if node['type'] == 'categorical':
            if x[feature] in node['children']:
                return self._predict_instance(x, node['children'][x[feature]])
            else:  # Unseen category
                return list(node['children'].values())[0]  # Return first child's prediction
        else:  # Numerical
            if x[feature] &lt;= node['split_value']:
                return self._predict_instance(x, node['children']['left'])
            else:
                return self._predict_instance(x, node['children']['right'])
    
    def predict(self, X):
        """Predict for multiple instances"""
        return X.apply(lambda x: self._predict_instance(x, self.tree), axis=1)
    
    def accuracy(self, X, y):
        """Calculate accuracy"""
        preds = self.predict(X)
        return (preds == y).mean()
    def save_pred_for_depth55(self, X, output_folder):
        """Save predictions for depth 20"""
        preds = self.predict(X)
        output_df = pd.DataFrame({'prediction': preds})
        output_df.to_csv(f"{output_folder}/predictions_b.csv", index=False)
        print(f"Predictions saved to {output_folder}/predictions_b.csv")

if __name__ == "__main__":

    # Load data
    train = pd.read_csv('../Adata/train.csv')
    valid = pd.read_csv('../Adata/valid.csv')
    test = pd.read_csv('../Adata/test.csv')

    # Identify categorical columns with more than 2 categories
    categorical_cols = train.select_dtypes(include=['object']).columns
    multi_cat_cols = [col for col in categorical_cols if len(train[col].unique()) &gt;= 2]

    # Apply one-hot encoding to these columns
    def one_hot_encode(df, cols):
        for col in cols:
            dummies = pd.get_dummies(df[col], prefix=col)
            df = pd.concat([df.drop(col, axis=1), dummies], axis=1)
        return df

    # Apply to all datasets
    train_encoded = one_hot_encode(train.copy(), multi_cat_cols)
    valid_encoded = one_hot_encode(valid.copy(), multi_cat_cols)
    test_encoded = one_hot_encode(test.copy(), multi_cat_cols)

    # Get column headers for train_encoded
    train_encoded_columns = train_encoded.columns.tolist()
    train_encoded_columns = set(train_encoded_columns)

    # Get column headers for valid_encoded
    valid_encoded_columns = valid_encoded.columns.tolist()
    valid_encoded_columns = set(valid_encoded_columns)

    # Get column headers for test_encoded
    test_encoded_columns = test_encoded.columns.tolist()
    test_encoded_columns = set(test_encoded_columns)

    #Union of all columns
    all_columns = train_encoded_columns.union(valid_encoded_columns).union(test_encoded_columns)

    # Add missing columns to each DataFrame with default value 0
    for col in all_columns:
        if col not in train_encoded.columns:
            train_encoded[col] = False
        if col not in valid_encoded.columns:
            valid_encoded[col] = False
        if col not in test_encoded.columns:
            test_encoded[col] = False


    # Separate features and target
    X_train = train_encoded.drop(columns=['income_ &lt;=50K','income_ &gt;50K'])
    y_train = train['income']
    X_valid = valid_encoded.drop(columns=['income_ &lt;=50K','income_ &gt;50K'])
    y_valid = valid['income']
    X_test = test_encoded.drop(columns=['income_ &lt;=50K','income_ &gt;50K'])
    y_test = test['income']

    # Experiment with different depths for one-hot encoded data
    depths_encoded = [25, 35, 45, 55]
    train_accuracies_encoded = []
    test_accuracies_encoded = []

    for depth in depths_encoded:
        print(f"Training tree with max_depth={depth} (one-hot encoded)")
        tree = DecisionTree2(max_depth=depth)
        tree.fit(X_train, y_train)
        
        train_acc = tree.accuracy(X_train, y_train)
        test_acc = tree.accuracy(X_test, y_test)
        
        train_accuracies_encoded.append(train_acc)
        test_accuracies_encoded.append(test_acc)
        
        print(f"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}")

    # Plot results
    plt.figure(figsize=(10, 6))
    plt.plot(depths_encoded, train_accuracies_encoded, label='Train Accuracy', marker='o')
    plt.plot(depths_encoded, test_accuracies_encoded, label='Test Accuracy', marker='o')
    plt.xlabel('Maximum Depth')
    plt.ylabel('Accuracy')
    plt.title('Decision Tree Performance(OHE) vs. Maximum Depth')
    plt.legend()
    plt.grid()
    plt.show()

    # Evaluate on test set with best depth
    best_depth_encoded = depths_encoded[np.argmax(valid_accuracies_encoded)]
    print(f"\nBest depth based on validation (OHE): {best_depth_encoded}")




import os
import numpy as np
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict

class NeuralNetwork2:
    def __init__(self, input_size, hidden_layers, output_size):
        self.input_size = input_size
        self.hidden_layers = hidden_layers
        self.output_size = output_size
        
        # Initialize weights and biases
        self.weights = []
        self.biases = []
        
        # Input to first hidden layer
        prev_size = input_size
        for size in hidden_layers:
            self.weights.append(np.random.randn(prev_size, size) * np.sqrt(2./prev_size))
            self.biases.append(np.zeros(size))
            prev_size = size
        
        # Last hidden to output layer
        self.weights.append(np.random.randn(prev_size, output_size) * np.sqrt(2./prev_size))
        self.biases.append(np.zeros(output_size))
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))
    
    def sigmoid_derivative(self, x):
        return x * (1 - x)
    
    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forward(self, X):
        self.activations = [X]
        self.z_values = []
        
        # Hidden layers with sigmoid activation
        for i in range(len(self.hidden_layers)):
            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
            a = self.sigmoid(z)
            self.z_values.append(z)
            self.activations.append(a)
        
        # Output layer with softmax activation
        z = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
        a = self.softmax(z)
        self.z_values.append(z)
        self.activations.append(a)
        
        return a
    
    def backward(self, X, y, learning_rate):
        m = X.shape[0]
        deltas = []
        
        # Output layer error
        error = self.activations[-1] - y
        delta = error  # For softmax with cross-entropy
        deltas.insert(0, delta)
        
        # Backpropagate through hidden layers
        for i in range(len(self.hidden_layers), 0, -1):
            error = np.dot(deltas[0], self.weights[i].T)
            delta = error * self.sigmoid_derivative(self.activations[i])
            deltas.insert(0, delta)
        
        # Update weights and biases
        for i in range(len(self.weights)):
            dw = np.dot(self.activations[i].T, deltas[i]) / m
            db = np.sum(deltas[i], axis=0) / m
            self.weights[i] -= learning_rate * dw
            self.biases[i] -= learning_rate * db
    
    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size, learning_rate):
        n_samples = X_train.shape[0]
        n_batches = n_samples // batch_size
        
        train_loss_history = []
        val_loss_history = []
        train_acc_history = []
        val_acc_history = []
        
        for epoch in range(epochs):
            # Shuffle data
            permutation = np.random.permutation(n_samples)
            X_shuffled = X_train[permutation]
            y_shuffled = y_train[permutation]
            
            epoch_loss = 0
            
            for i in range(n_batches):
                # Get mini-batch
                start = i * batch_size
                end = start + batch_size
                X_batch = X_shuffled[start:end]
                y_batch = y_shuffled[start:end]
                
                # Forward pass
                output = self.forward(X_batch)
                
                # Compute loss
                loss = -np.mean(np.sum(y_batch * np.log(output + 1e-15), axis=1))
                epoch_loss += loss
                
                # Backward pass
                self.backward(X_batch, y_batch, learning_rate)
            
            # Calculate average epoch loss
            epoch_loss /= n_batches
            train_loss_history.append(epoch_loss)
            
            # Calculate validation loss
            val_output = self.forward(X_val)
            val_loss = -np.mean(np.sum(y_val * np.log(val_output + 1e-15), axis=1))
            val_loss_history.append(val_loss)
            
            # Calculate accuracies
            train_pred = np.argmax(self.forward(X_train), axis=1)
            train_true = np.argmax(y_train, axis=1)
            train_acc = np.mean(train_true == train_pred)
            train_acc_history.append(train_acc)
            
            val_pred = np.argmax(val_output, axis=1)
            val_true = np.argmax(y_val, axis=1)
            val_acc = np.mean(val_true == val_pred)
            val_acc_history.append(val_acc)
            
            print(f"Epoch {epoch+1}/{epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, "
                  f"Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}")

            if epoch &gt; 1 and abs(val_loss_history[-1] - val_loss_history[-2]) &lt; 1e-4:
                print(f"Early stopping at epoch {epoch+1} due to minimal change in validation loss.")
                break
            
        return train_loss_history, val_loss_history, train_acc_history, val_acc_history
    
    def predict(self, X):
        return np.argmax(self.forward(X), axis=1)

def one_hot_encode2(y, num_classes):
    """Manual one-hot encoding implementation"""
    y_onehot = np.zeros((len(y), num_classes))
    y_onehot[np.arange(len(y)), y.flatten()] = 1
    return y_onehot

def calculate_metrics2(true_labels, pred_labels, num_classes):
    """Calculate precision, recall, and F1 score for each class"""
    metrics = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})
    
    for true, pred in zip(true_labels, pred_labels):
        if true == pred:
            metrics[true]['tp'] += 1
        else:
            metrics[true]['fn'] += 1
            metrics[pred]['fp'] += 1
    
    results = {}
    for class_id in range(num_classes):
        tp = metrics[class_id]['tp']
        fp = metrics[class_id]['fp']
        fn = metrics[class_id]['fn']
        
        precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0
        recall = tp / (tp + fn) if (tp + fn) &gt; 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) &gt; 0 else 0
        
        results[class_id] = {
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    
    return results

def load_data2(train_path, test_path):
    # Load training data
    X_train = []
    y_train = []
    
    for label in range(43):
        folder = os.path.join(train_path, f"{label:05d}")
        for file in os.listdir(folder):
            if file.endswith('.jpg'):
                img = Image.open(os.path.join(folder, file))
                img = img.resize((28, 28))
                img_array = np.array(img).flatten() / 255.0
                X_train.append(img_array)
                y_train.append(label)
    
    X_train = np.array(X_train)
    y_train = np.array(y_train).reshape(-1, 1)
    
    # Manual one-hot encoding
    y_train = one_hot_encode1(y_train, 43)
    
    # Load test data
    # test_df = pd.read_csv(test_labels_path)
    X_test = []
    # y_test = []
    
    # for _, row in test_df.iterrows():
    #     img = Image.open(os.path.join(test_path, row['image']))
    #     img = img.resize((28, 28))
    #     img_array = np.array(img).flatten() / 255.0
    #     X_test.append(img_array)
        # y_test.append(row['label'])
    
    for img_file in sorted(os.listdir(test_path)):  # Sorted for consistency
        img_path = os.path.join(test_path, img_file)
        img = img.resize((28, 28))
        img_array = np.array(img).flatten() / 255.0
        X_test.append(img_array)
    
    X_test = np.array(X_test)
    # y_test = np.array(y_test).reshape(-1, 1)
    # y_test = one_hot_encode(y_test, 43)
    
    return X_train, y_train, X_test

def run_experiment(hidden_units, train_data_path, test_data_path, output_folder_path):
    # Load data
    X_train, y_train, X_test, y_test = load_data(train_data_path, test_data_path)
    
    # Split training data into train and validation (80-20 split)
    n_samples = X_train.shape[0]
    indices = np.random.permutation(n_samples)
    split = int(0.8 * n_samples)
    
    X_train_split = X_train[indices[:split]]
    y_train_split = y_train[indices[:split]]
    X_val = X_train[indices[split:]]
    y_val = y_train[indices[split:]]
    
    # Initialize neural network
    input_size = 28 * 28 * 3  # 2352
    hidden_layers = [hidden_units]
    output_size = 43
    
    nn = NeuralNetwork(input_size, hidden_layers, output_size)
    
    # Train the network
    epochs = 150
    batch_size = 32
    learning_rate = 0.01
    
    print(f"\nTraining network with {hidden_units} hidden units")
    train_loss, val_loss, train_acc, val_acc = nn.train(
        X_train_split, y_train_split, X_val, y_val, 
        epochs, batch_size, learning_rate
    )
    
    # Evaluate on test set
    test_pred = nn.predict(X_test)
    test_true = np.argmax(y_test, axis=1)
    test_acc = np.mean(test_true == test_pred)
    print(f"Test Accuracy with {hidden_units} hidden units: {test_acc:.4f}")
    
    # Calculate metrics
    train_pred = nn.predict(X_train)
    train_true = np.argmax(y_train, axis=1)
    
    train_metrics = calculate_metrics(train_true, train_pred, 43)
    test_metrics = calculate_metrics(test_true, test_pred, 43)
    
    
    # Calculate average F1 scores
    avg_train_f1 = np.mean([metrics['f1'] for metrics in train_metrics.values()])
    avg_test_f1 = np.mean([metrics['f1'] for metrics in test_metrics.values()])

    avg_train_precision = np.mean([metrics['precision'] for metrics in train_metrics.values()])
    avg_train_recall = np.mean([metrics['recall'] for metrics in train_metrics.values()])
    avg_test_precision = np.mean([metrics['precision'] for metrics in test_metrics.values()])
    avg_test_recall = np.mean([metrics['recall'] for metrics in test_metrics.values()])

    # Print metrics as tables

    
    print(f"Average Train F1 Score: {avg_train_f1:.4f}")
    print(f"Average Test F1 Score: {avg_test_f1:.4f}")

    print(f"Average Train Precision: {avg_train_precision:.4f}")
    print(f"Average Train Recall: {avg_train_recall:.4f}")

    print(f"Average Test Precision: {avg_test_precision:.4f}")
    print(f"Average Test Recall: {avg_test_recall:.4f}")
    
    # Save predictions
    predictions = pd.DataFrame({'prediction': test_pred})
    predictions.to_csv(os.path.join(output_folder_path, f'prediction_b_{hidden_units}.csv'), index=False)
    
    return avg_train_f1, avg_test_f1

def main(train_data_path, test_data_path, output_folder_path, test_labels_path):
    hidden_units_list = [1, 5, 10, 50, 100]
    train_f1_scores = []
    test_f1_scores = []
    
    for hidden_units in hidden_units_list:
        avg_train_f1, avg_test_f1 = run_experiment(
            hidden_units, train_data_path, test_data_path, 
            output_folder_path, test_labels_path
        )
        train_f1_scores.append(avg_train_f1)
        test_f1_scores.append(avg_test_f1)
    
    # Plot F1 scores vs hidden units
    # plt.figure(figsize=(10, 6))
    # plt.plot(hidden_units_list, train_f1_scores, 'o-', label='Train F1 Score')
    # plt.plot(hidden_units_list, test_f1_scores, 'o-', label='Test F1 Score')
    # plt.xlabel('Number of Hidden Units')
    # plt.ylabel('Average F1 Score')
    # plt.title('Average F1 Score vs Number of Hidden Units')
    # plt.legend()
    # plt.grid(True)
    # plt.savefig(os.path.join(output_folder_path, 'f1_vs_hidden_units.png'))
    # plt.close()

if __name__ == "__main__":
    # import argparse
    
    # parser = argparse.ArgumentParser()
    # parser.add_argument('train_data_path', type=str)
    # parser.add_argument('test_data_path', type=str)
    # parser.add_argument('output_folder_path', type=str)
    # parser.add_argument('question_part', type=str)
    
    # args = parser.parse_args()
    
    # Assuming test_labels.csv is in the test_data_path folder
    # test_labels_path = os.path.join(args.test_data_path, 'test_labels.csv')
    
    # if args.question_part == 'b':
        # main(args.train_data_path, args.test_data_path, args.output_folder_path, test_labels_path)
    train_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/train"
    test_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test"
    output_folder_path=""
    
    # Assuming test_labels.csv is in the test_data_path folder
    test_labels_path = "/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test_labels.csv"
    
    # if args.question_part == 'a':
    main(train_data_path, test_data_path, output_folder_path, test_labels_path)



import os
import numpy as np
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler

def load_data(train_path, test_path):
    # Load training data
    X_train = []
    y_train = []
    
    for label in range(43):
        folder = os.path.join(train_path, f"{label:05d}")
        for file in os.listdir(folder):
            if file.endswith('.jpg'):
                img = Image.open(os.path.join(folder, file))
                img = img.resize((28, 28))
                img_array = np.array(img).flatten() / 255.0
                X_train.append(img_array)
                y_train.append(label)
    
    X_train = np.array(X_train)
    y_train = np.array(y_train)
    
    # Manual one-hot encoding
    # y_train = one_hot_encode(y_train, 43)
    
    # Load test data
    # test_df = pd.read_csv(test_labels_path)
    X_test = []
    # y_test = []
    
    # for _, row in test_df.iterrows():
    #     img = Image.open(os.path.join(test_path, row['image']))
    #     img = img.resize((28, 28))
    #     img_array = np.array(img).flatten() / 255.0
    #     X_test.append(img_array)
        # y_test.append(row['label'])
    
    for img_file in sorted(os.listdir(test_path)):  # Sorted for consistency
        img_path = os.path.join(test_path, img_file)
        img = img.resize((28, 28))
        img_array = np.array(img).flatten() / 255.0
        X_test.append(img_array)
    
    X_test = np.array(X_test)
    # y_test = np.array(y_test).reshape(-1, 1)
    # y_test = one_hot_encode(y_test, 43)
    
    return X_train, y_train, X_test


def calculate_metrics(true_labels, pred_labels, num_classes):
    """Calculate precision, recall, and F1 score for each class"""
    metrics = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})
    
    for true, pred in zip(true_labels, pred_labels):
        if true == pred:
            metrics[true]['tp'] += 1
        else:
            metrics[true]['fn'] += 1
            metrics[pred]['fp'] += 1
    
    results = {}
    for class_id in range(num_classes):
        tp = metrics[class_id]['tp']
        fp = metrics[class_id]['fp']
        fn = metrics[class_id]['fn']
        
        precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0
        recall = tp / (tp + fn) if (tp + fn) &gt; 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) &gt; 0 else 0
        
        results[class_id] = {
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    
    return results

def run_experiment(hidden_layers, X_train, y_train, X_test, output_folder_path):
    # Standardize the data
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Create MLPClassifier with specified parameters
    mlp = MLPClassifier(
        hidden_layer_sizes=hidden_layers,
        activation='relu',
        solver='sgd',
        alpha=0,
        batch_size=32,
        learning_rate='invscaling',
        learning_rate_init=0.01,
        max_iter=250,
        random_state=42,
        early_stopping=True,
        validation_fraction=0.2
    )
    
    print(f"\nTraining MLPClassifier with architecture: {hidden_layers}")
    mlp.fit(X_train_scaled, y_train)
    
    # Evaluate on test set
    test_pred = mlp.predict(X_test_scaled)
    # test_acc = np.mean(y_test == test_pred)
    # print(f"Test Accuracy with architecture {hidden_layers}: {test_acc:.4f}")
    
    # Calculate metrics
    # train_pred = mlp.predict(X_train_scaled)
    
    # train_metrics = calculate_metrics(y_train, train_pred, 43)
    # test_metrics = calculate_metrics(y_test, test_pred, 43)
    
    # Calculate average F1 scores
    # avg_train_f1 = np.mean([metrics['f1'] for metrics in train_metrics.values()])
    # avg_test_f1 = np.mean([metrics['f1'] for metrics in test_metrics.values()])
    
    # print(f"Average Train F1 Score: {avg_train_f1:.4f}")
    # print(f"Average Test F1 Score: {avg_test_f1:.4f}")
    
    # Save predictions
    # arch_name = '_'.join(map(str, hidden_layers))
    predictions = pd.DataFrame({'prediction': test_pred})
    predictions.to_csv(os.path.join(output_folder_path, f'prediction_f.csv'), index=False)
    
    return 

def main5(train_data_path, test_data_path, output_folder_path):
    # Load data
    X_train, y_train, X_test = load_data(train_data_path, test_data_path)
    
    architectures = [
        (512, 256, 128, 64)
    ]
    
    train_f1_scores = []
    test_f1_scores = []
    depths = []
    
    for arch in architectures:
         run_experiment(
            arch, X_train, y_train, X_test, output_folder_path
        )
        # train_f1_scores.append(avg_train_f1)
        # test_f1_scores.append(avg_test_f1)
        # depths.append(depth)
    
    # Plot F1 scores vs network depth
    # plt.figure(figsize=(10, 6))
    # plt.plot(depths, train_f1_scores, 'o-', label='Train F1 Score')
    # plt.plot(depths, test_f1_scores, 'o-', label='Test F1 Score')
    # plt.xlabel('Network Depth (Number of Hidden Layers)')
    # plt.ylabel('Average F1 Score')
    # plt.title('Average F1 Score vs Network Depth (MLPClassifier)')
    # plt.xticks(depths)
    # plt.legend()
    # plt.grid(True)
    # plt.savefig(os.path.join(output_folder_path, 'f1_vs_network_depth_mlp.png'))
    # plt.close()

if __name__ == "__main__":
    import argparse
    
    # parser = argparse.ArgumentParser()
    # parser.add_argument('train_data_path', type=str)
    # parser.add_argument('test_data_path', type=str)
    # parser.add_argument('output_folder_path', type=str)
    # parser.add_argument('question_part', type=str)
    
    # args = parser.parse_args()
    
    # # Assuming test_labels.csv is in the test_data_path folder
    # test_labels_path = os.path.join(args.test_data_path, 'test_labels.csv')
    
    # if args.question_part == 'f':
    #     main(args.train_data_path, args.test_data_path, args.output_folder_path, test_labels_path)
    train_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/train"
    test_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test"
    output_folder_path=""
    
    # Assuming test_labels.csv is in the test_data_path folder
    test_labels_path = "/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test_labels.csv"
    
    # if args.question_part == 'a':
    main(train_data_path, test_data_path, output_folder_path, test_labels_path)




import pandas as pd
import numpy as np
from math import log2
import matplotlib.pyplot as plt
import copy # Needed for deep copying the tree

class DecisionTree3:
    def __init__(self, max_depth=None):
        self.max_depth = max_depth
        self.tree = None
        self.original_tree = None # Store the original tree before pruning

    def _entropy(self, y):
        """Calculate entropy of a target variable"""
        # Handle empty or single-class subsets gracefully
        if len(y) == 0 or len(y.unique()) &lt;= 1:
            return 0
        counts = y.value_counts()
        probabilities = counts / len(y)
        # Add small epsilon to avoid log2(0)
        probabilities = probabilities[probabilities &gt; 0] # Filter out zero probabilities
        return -sum(probabilities * np.log2(probabilities))

    def _mutual_information(self, X_col, y):
        """Calculate mutual information between a feature and target"""
        if len(y) == 0:
            return 0 # No information gain if subset is empty

        current_entropy = self._entropy(y)
        weighted_entropy = 0

        if X_col.dtype == 'object':  # Categorical
            unique_values = X_col.unique()
            for value in unique_values:
                subset_y = y[X_col == value]
                weight = len(subset_y) / len(y)
                if weight &gt; 0: # Avoid calculation for empty subsets
                    weighted_entropy += weight * self._entropy(subset_y)
        else:  # Numerical
            # Handle case where all values are the same
            if X_col.nunique() &lt;= 1:
                return 0 # Cannot split if all values are the same
            median = X_col.median()
            left_y = y[X_col &lt;= median]
            right_y = y[X_col &gt; median]

            # Avoid division by zero if len(y) is zero (handled earlier)
            weight_left = len(left_y) / len(y)
            weight_right = len(right_y) / len(y)

            if weight_left &gt; 0:
                weighted_entropy += weight_left * self._entropy(left_y)
            if weight_right &gt; 0:
                 weighted_entropy += weight_right * self._entropy(right_y)

        return current_entropy - weighted_entropy

    def _find_best_split(self, X, y):
        """Find the best feature to split on"""
        best_feature = None
        best_gain = -1

        # Handle case where X might be empty (e.g., after dropping columns)
        if X.empty:
            return None, 0

        for feature in X.columns:
            # Skip if feature has only one unique value in the current subset
            if X[feature].nunique() &lt;= 1:
                continue
            gain = self._mutual_information(X[feature], y)
            if gain &gt; best_gain:
                best_gain = gain
                best_feature = feature

        # If no gain found (e.g., all features constant), return None
        if best_gain &lt;= 0:
             return None, 0

        return best_feature, best_gain

    def _build_tree(self, X, y, depth=0):
        """Recursively build the decision tree"""
        # --- MODIFICATION: Calculate majority class early ---
        majority_class = y.mode()[0] if not y.empty else None

        # Stopping conditions
        # 1. Max depth reached
        # 2. All targets are the same
        # 3. No features left to split on
        # 4. No data left (should ideally not happen with checks, but good fallback)
        if depth == self.max_depth or len(y.unique()) &lt;= 1 or X.empty or len(y) == 0:
             # Use previously calculated majority_class if available, else calculate if needed
             return majority_class if majority_class is not None else (y.mode()[0] if not y.empty else None)

        # Find best split
        best_feature, best_gain = self._find_best_split(X, y)

        # 5. No informative split found (gain is 0 or less)
        if best_feature is None or best_gain &lt;= 0:
            return majority_class # Return majority class of current node

        # --- MODIFICATION: Store majority class in the node ---
        node = {
            'feature': best_feature,
            'gain': best_gain,
            'depth': depth,
            'majority_class': majority_class, # Store for pruning
            'samples': len(y) # Store sample count (optional, but useful)
        }

        feature_values = X[best_feature] # Store the column for splitting

        if feature_values.dtype == 'object':  # Categorical
            unique_values = feature_values.unique()
            node['type'] = 'categorical'
            node['children'] = {}

            for value in unique_values:
                # Ensure subsetting works even if value is not present
                subset_indices = X[best_feature] == value
                subset_X = X.loc[subset_indices].drop(columns=[best_feature])
                subset_y = y.loc[subset_indices]

                # If a split leads to an empty subset, assign the parent's majority class
                if len(subset_y) == 0:
                    node['children'][value] = majority_class
                else:
                    node['children'][value] = self._build_tree(subset_X, subset_y, depth + 1)
        else:  # Numerical
            median = feature_values.median()
            node['type'] = 'numerical'
            node['split_value'] = median
            node['children'] = {'left': None, 'right': None}

            # Left child (&lt;= median)
            left_indices = feature_values &lt;= median
            left_X = X.loc[left_indices] # Keep the splitting feature for potential future splits deeper down
            left_y = y.loc[left_indices]
            if len(left_y) &gt; 0:
                node['children']['left'] = self._build_tree(left_X, left_y, depth + 1)
            else:
                node['children']['left'] = majority_class # Parent's majority

            # Right child (&gt; median)
            right_indices = feature_values &gt; median
            right_X = X.loc[right_indices] # Keep the splitting feature
            right_y = y.loc[right_indices]
            if len(right_y) &gt; 0:
                node['children']['right'] = self._build_tree(right_X, right_y, depth + 1)
            else:
                node['children']['right'] = majority_class # Parent's majority

        return node

    def fit(self, X, y):
        """Fit the decision tree to the data"""
        self.tree = self._build_tree(X, y)
        self.original_tree = copy.deepcopy(self.tree) # Keep a copy before pruning
        return self

    # --- Use a helper for prediction to allow passing different tree structures ---
    def _predict_instance(self, x, node):
        """Predict a single instance using a given tree node"""
        # If it's a leaf node (string prediction)
        if not isinstance(node, dict):
            return node

        feature = node['feature']

        # Check if feature exists in instance (can happen with OHE differences)
        if feature not in x:
             # Fallback: return the majority class stored at this node if feature is missing
             return node.get('majority_class', None) # Add default None

        if node['type'] == 'categorical':
            value = x[feature]
            if value in node['children']:
                return self._predict_instance(x, node['children'][value])
            else:
                # Unseen category: return the majority class of the current node
                return node['majority_class']
        else:  # Numerical
            value = x[feature]
            # Handle non-numeric data gracefully if it slips through
            try:
                split_value = node['split_value']
                if value &lt;= split_value:
                    return self._predict_instance(x, node['children']['left'])
                else:
                    return self._predict_instance(x, node['children']['right'])
            except TypeError:
                 # If comparison fails (e.g., value is not numeric)
                 return node.get('majority_class', None) # Fallback

    def predict(self, X, tree_to_use=None):
        """Predict for multiple instances using the specified tree"""
        target_tree = tree_to_use if tree_to_use is not None else self.tree
        if target_tree is None:
            raise ValueError("The tree has not been fitted yet.")
        # Handle case where the root itself might be a leaf
        if not isinstance(target_tree, dict):
             return pd.Series([target_tree] * len(X), index=X.index)
             
        return X.apply(lambda x: self._predict_instance(x, target_tree), axis=1)

    def accuracy(self, X, y, tree_to_use=None):
        """Calculate accuracy using the specified tree"""
        target_tree = tree_to_use if tree_to_use is not None else self.tree
        if target_tree is None:
             return 0.0 # Or raise error
        # Handle case where tree is just a leaf node
        if not isinstance(target_tree, dict):
             if target_tree is None: return 0.0 # No prediction possible
             preds = pd.Series([target_tree] * len(X), index=X.index)
        else:
             preds = self.predict(X, target_tree)
        
        # Ensure comparison works even if y or preds contains None
        valid_comparison = (preds.notna() & y.notna())
        return (preds[valid_comparison] == y[valid_comparison]).mean() if valid_comparison.any() else 0.0


    # --- Pruning Helper Methods ---

    def _count_nodes(self, node):
        """Recursively count the total number of nodes (internal + leaf)"""
        if not isinstance(node, dict):
            return 1  # Leaf node
        
        count = 1 # Count the current internal node
        if node['type'] == 'categorical':
            for child_node in node['children'].values():
                count += self._count_nodes(child_node)
        else: # Numerical
            count += self._count_nodes(node['children']['left'])
            count += self._count_nodes(node['children']['right'])
        return count

    def _get_internal_nodes(self, node, parent=None, child_key=None):
        """
        Recursively find all internal nodes.
        Returns a list of dictionaries, each containing:
        'node': reference to the internal node dictionary
        'parent': reference to the parent node dictionary (None for root)
        'child_key': the key ('left', 'right', or category value) in the parent's children dict
                      that points to this node.
        """
        nodes = []
        if not isinstance(node, dict):
            return nodes # It's a leaf, stop recursion

        # Current node is internal, add it (if it's not the root being passed initially)
        # We only prune nodes *below* the root initially, though the root could become prunable later.
        # Let's re-evaluate: we *can* prune any internal node.
        nodes.append({
            'node': node,
            'parent': parent,
            'child_key': child_key
        })

        # Recurse on children
        children_dict = node.get('children', {})
        if node['type'] == 'categorical':
            for key, child_node in children_dict.items():
                 nodes.extend(self._get_internal_nodes(child_node, parent=node, child_key=key))
        elif node['type'] == 'numerical':
             if 'left' in children_dict:
                 nodes.extend(self._get_internal_nodes(children_dict['left'], parent=node, child_key='left'))
             if 'right' in children_dict:
                  nodes.extend(self._get_internal_nodes(children_dict['right'], parent=node, child_key='right'))
                 
        return nodes

    # --- Post-Pruning Method ---

    def prune(self, X_valid, y_valid):
        """
        Perform greedy post-pruning based on validation set accuracy.
        Returns a history of pruning steps: [{'nodes': count, 'accuracy': acc}]
        Modifies self.tree in place.
        """
        if self.tree is None:
            print("Tree not fitted. Cannot prune.")
            return []
            
        # Start with the current tree (already a deep copy of original in fit)
        current_best_tree = copy.deepcopy(self.tree)
        initial_accuracy = self.accuracy(X_valid, y_valid, tree_to_use=current_best_tree)
        if initial_accuracy is None: initial_accuracy = 0.0 # Handle no tree case

        pruning_history = [{
            'nodes': self._count_nodes(current_best_tree),
            'accuracy': initial_accuracy,
            'tree': copy.deepcopy(current_best_tree) # Store tree state
        }]
        print(f"Initial validation accuracy: {initial_accuracy:.4f}, Nodes: {pruning_history[0]['nodes']}")

        while True:
            internal_nodes_info = self._get_internal_nodes(current_best_tree)
            
            # Filter out nodes that are already leaves if logic error happened
            internal_nodes_info = [info for info in internal_nodes_info if isinstance(info['node'], dict)]

            if not internal_nodes_info:
                print("No internal nodes left to prune.")
                break # No internal nodes left

            best_accuracy_improvement = -1.0 # We need actual improvement
            best_pruned_tree = None
            node_to_prune_info = None

            current_accuracy = pruning_history[-1]['accuracy'] # Accuracy before this iteration's pruning

            # Iterate through all potential internal nodes to prune
            for node_info in internal_nodes_info:
                parent = node_info['parent']
                child_key = node_info['child_key']
                node_to_replace = node_info['node']
                
                # --- Temporarily prune this node ---
                # Get the majority class to replace the subtree with
                majority_class_leaf = node_to_replace['majority_class']

                # Need to modify the *parent's* reference. Handle root case.
                original_subtree = None
                temp_tree_to_test = copy.deepcopy(current_best_tree) # Test on a copy

                # Find the parent and node again within the deep copied structure
                # This is inefficient. A better way might be to pass paths or use node IDs.
                # Let's stick to references for now, assuming deepcopy maintains structure okay.
                # We need to find the *corresponding* parent/node in the temp_tree.
                # This requires traversing temp_tree based on the path derived from node_info.
                # --- Simpler approach: Modify in place and restore ---
                
                if parent is None: # Pruning the root node
                    original_subtree = current_best_tree # Store the whole tree
                    current_best_tree = majority_class_leaf # Temporarily replace root
                else:
                     # Find the correct parent reference in the current tree structure before modification
                     # This assumes node_info['parent'] points to the node within current_best_tree
                     actual_parent = node_info['parent']
                     original_subtree = actual_parent['children'][child_key]
                     actual_parent['children'][child_key] = majority_class_leaf


                # --- Evaluate the temporarily pruned tree ---
                try:
                     accuracy_after_prune = self.accuracy(X_valid, y_valid, tree_to_use=current_best_tree)
                     if accuracy_after_prune is None: accuracy_after_prune = 0.0
                except Exception as e:
                     print(f"Error calculating accuracy during pruning: {e}")
                     accuracy_after_prune = 0.0 # Penalize errors

                improvement = accuracy_after_prune - current_accuracy

                # --- Restore the original subtree ---
                if parent is None:
                    current_best_tree = original_subtree # Restore original tree if root was pruned
                else:
                    actual_parent['children'][child_key] = original_subtree # Put back the original child

                # --- Check if this prune is the best so far ---
                # We want the prune that results in the highest *absolute* accuracy,
                # but it must be higher than the current best accuracy.
                # Let's track the best *resulting* accuracy.
                
                if accuracy_after_prune &gt; current_accuracy : # Strict improvement required
                     if accuracy_after_prune &gt; best_accuracy_improvement: # Found a better prune
                         best_accuracy_improvement = accuracy_after_prune
                         node_to_prune_info = node_info # Remember which node led to this

            # --- After checking all nodes, perform the best prune permanently ---
            if node_to_prune_info is not None:
                # Perform the actual prune on current_best_tree
                parent = node_to_prune_info['parent']
                child_key = node_to_prune_info['child_key']
                node_to_replace = node_to_prune_info['node']
                majority_class_leaf = node_to_replace['majority_class']

                if parent is None: # Pruning the root
                    print(f"Pruning root node. Replacing with '{majority_class_leaf}'.")
                    current_best_tree = majority_class_leaf
                else:
                     # Need to ensure 'parent' refers to the node inside current_best_tree
                     # If references held from _get_internal_nodes, this should work.
                     print(f"Pruning node at depth {node_to_replace.get('depth','N/A')} (feature: {node_to_replace.get('feature','N/A')}). Replacing with '{majority_class_leaf}'.")
                     parent['children'][child_key] = majority_class_leaf

                num_nodes = self._count_nodes(current_best_tree)
                new_accuracy = best_accuracy_improvement # This is the accuracy *after* the best prune

                pruning_history.append({
                    'nodes': num_nodes,
                    'accuracy': new_accuracy,
                    'tree': copy.deepcopy(current_best_tree) # Store tree state
                })
                print(f"Pruned. New validation accuracy: {new_accuracy:.4f}, Nodes: {num_nodes}")

            else:
                # No pruning candidate resulted in improvement
                print("No further improvement found. Stopping pruning.")
                break # Exit the while loop

        # Update the tree in the object instance to the best pruned version found
        self.tree = pruning_history[-1]['tree']
        print(f"Final pruned tree validation accuracy: {pruning_history[-1]['accuracy']:.4f}, Nodes: {pruning_history[-1]['nodes']}")
        return pruning_history
    
        


        


if __name__ == "__main__":

    # --- Main Script Execution ---

    # Load data (adjust paths as needed)
    try:
        train = pd.read_csv('../Adata/train.csv')
        valid = pd.read_csv('../Adata/valid.csv')
        test = pd.read_csv('../Adata/test.csv')
    except FileNotFoundError:
        print("Error: Dataset files not found. Make sure train.csv, valid.csv, and test.csv are in a directory named 'Adata' relative to the script.")
        exit()


    # --- Preprocessing for One-Hot Encoding (Part 1b setup) ---
    print("Preprocessing data with One-Hot Encoding...")

    # Target variable name might differ, ensure it's correct
    target_col_name = 'income' # Assuming this is the column name before OHE
    target_value_high = '&gt;50K' # Assuming this is one of the values

    # Check if target column exists
    if target_col_name not in train.columns:
        print(f"Error: Target column '{target_col_name}' not found in train data.")
        # Attempt to find income columns if they were already OHE'd in CSV
        if 'income_ &gt;50K' in train.columns:
            print("Found 'income_ &gt;50K'. Reconstructing target variable.")
            train[target_col_name] = np.where(train['income_ &gt;50K'] == True, '&gt;50K', '&lt;=50K')
            valid[target_col_name] = np.where(valid['income_ &gt;50K'] == True, '&gt;50K', '&lt;=50K')
            test[target_col_name] = np.where(test['income_ &gt;50K'] == True, '&gt;50K', '&lt;=50K')
        else:
            exit()


    # Identify categorical columns with more than 1 category (binary can be kept as is sometimes, but OHE handles all)
    categorical_cols = train.select_dtypes(include=['object']).columns.tolist()
    # Exclude the target column if it's object type
    if target_col_name in categorical_cols:
        categorical_cols.remove(target_col_name)

    # Apply one-hot encoding
    def one_hot_encode(df, cols_to_encode, train_cols=None):
        df_encoded = df.copy()
        # Encode specified columns
        df_encoded = pd.get_dummies(df_encoded, columns=cols_to_encode, dummy_na=False)

        if train_cols is not None:
            # Add missing columns (present in train, not in current df)
            missing_cols = set(train_cols) - set(df_encoded.columns)
            for c in missing_cols:
                # Avoid adding back the original target column if it was numeric/boolean
                if c != target_col_name and not c.startswith(target_col_name + '_'):
                    df_encoded[c] = 0 # Or False, depending on expected type
            # Ensure order and presence of all training columns, except target
            df_encoded = df_encoded.reindex(columns=train_cols, fill_value=0) # Or False
        return df_encoded

    # Encode Train and get column names
    train_encoded = pd.get_dummies(train.copy(), columns=categorical_cols, dummy_na=False)
    train_encoded_columns = train_encoded.columns.tolist()

    # Encode Valid and Test using Train columns for consistency
    valid_encoded = one_hot_encode(valid.copy(), categorical_cols, train_encoded_columns)
    test_encoded = one_hot_encode(test.copy(), categorical_cols, train_encoded_columns)


    # --- Align columns after potential inconsistencies ---
    # This step is crucial if OHE creates different columns in train/valid/test
    # (e.g., a category exists in valid but not train)

    # Get all unique columns across all sets (excluding target)
    all_cols = set(train_encoded.columns) | set(valid_encoded.columns) | set(test_encoded.columns)
    if target_col_name in all_cols:
        all_cols.remove(target_col_name)
    # If OHE target columns exist, remove them too
    ohe_target_cols = [c for c in all_cols if c.startswith(target_col_name + '_')]
    for c in ohe_target_cols:
        all_cols.remove(c)

    feature_columns = sorted(list(all_cols)) # Use sorted list for consistent order

    # Reindex all dataframes to have the same feature columns
    X_train = train_encoded.reindex(columns=feature_columns, fill_value=0)
    y_train = train[target_col_name] # Original target column

    X_valid = valid_encoded.reindex(columns=feature_columns, fill_value=0)
    y_valid = valid[target_col_name]

    X_test = test_encoded.reindex(columns=feature_columns, fill_value=0)
    y_test = test[target_col_name]

    print("Data preprocessing finished.")
    print(f"X_train shape: {X_train.shape}, X_valid shape: {X_valid.shape}, X_test shape: {X_test.shape}")


    # --- Experimentation (Part 1c: Pruning trees from 1b) ---

    # Depths from part 1b
    # depths_encoded = [25, 35, 45, 55]
    depths_encoded = [5, 10, 15, 20] # Original depths for OHE
    pruning_results = {} # Store pruning history and final accuracies

    print("\n--- Starting Experiment: Post-Pruning (Part 1c) ---")

    for depth in depths_encoded:
        print(f"\nTraining tree with initial max_depth={depth} (one-hot encoded)")
        tree = DecisionTree3(max_depth=depth)
        tree.fit(X_train, y_train) # Fit on training data

        train_acc_before = tree.accuracy(X_train, y_train, tree.original_tree)
        valid_acc_before = tree.accuracy(X_valid, y_valid, tree.original_tree)
        test_acc_before = tree.accuracy(X_test, y_test, tree.original_tree)
        nodes_before = tree._count_nodes(tree.original_tree)
        print(f"BEFORE Pruning (Depth {depth}): Nodes={nodes_before}, TrainAcc={train_acc_before:.4f}, ValidAcc={valid_acc_before:.4f}, TestAcc={test_acc_before:.4f}")


        print(f"\nPruning tree initially grown to depth={depth}...")
        # Prune using the VALIDATION set
        history = tree.prune(X_valid, y_valid)

        # Evaluate the FINAL PRUNED tree
        train_acc_after = tree.accuracy(X_train, y_train) # Uses the pruned self.tree
        valid_acc_after = tree.accuracy(X_valid, y_valid)
        test_acc_after = tree.accuracy(X_test, y_test)
        nodes_after = tree._count_nodes(tree.tree) # Nodes in the final pruned tree

        print(f"AFTER Pruning (Initial Depth {depth}): Nodes={nodes_after}, TrainAcc={train_acc_after:.4f}, ValidAcc={valid_acc_after:.4f}, TestAcc={test_acc_after:.4f}")

        #save predictions on X_test after pruning to output_folder
        output_folder = '../Adata'
        preds = tree.predict(X_test)
        output_df = pd.DataFrame({'predictions': preds})
        output_df.to_csv(f"{output_folder}/predictions_d.csv", index=False)

        pruning_results[depth] = {
            'history': history,
            'nodes_before': nodes_before,
            'train_acc_before': train_acc_before,
            'valid_acc_before': valid_acc_before,
            'test_acc_before': test_acc_before,
            'nodes_after': nodes_after,
            'train_acc_after': train_acc_after,
            'valid_acc_after': valid_acc_after,
            'test_acc_after': test_acc_after
        }


    # --- Plotting Results (Accuracy vs. Number of Nodes during Pruning) ---
    print("\n--- Plotting Pruning Results ---")
    plt.figure(figsize=(12, 8))

    for depth in depths_encoded:
        history = pruning_results[depth]['history']
        if not history: # Skip if pruning failed or didn't happen
            continue

        nodes = [step['nodes'] for step in history]
        valid_accuracies = [step['accuracy'] for step in history]

        # Plot validation accuracy vs nodes for this initial depth
        # Sort by nodes ascending for plotting line correctly (pruning might not always reduce nodes if root is pruned)
        sorted_data = sorted(zip(nodes, valid_accuracies))
        nodes_sorted = [n for n, a in sorted_data]
        valid_accuracies_sorted = [a for n, a in sorted_data]
        
        # Add marker for the final pruned state
        final_nodes = pruning_results[depth]['nodes_after']
        final_valid_acc = pruning_results[depth]['valid_acc_after']
        
        plt.plot(nodes_sorted, valid_accuracies_sorted, marker='.', linestyle='-', label=f'Initial Depth {depth}')
        plt.scatter([final_nodes], [final_valid_acc], s=100, edgecolors='black', facecolors='none', marker='o', label=f'Final (Depth {depth})')


    plt.xlabel('Number of Nodes in Tree')
    plt.ylabel('Validation Accuracy')
    plt.title('Validation Accuracy vs. Number of Nodes during Post-Pruning')
    plt.legend(title="Initial Max Depth", bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True)
    plt.gca().invert_xaxis() # Typically pruning reduces nodes, so plot right-to-left
    plt.tight_layout()
    # plt.show()
    # Save the figure to a file
    plt.savefig('pruning_results.png', dpi=300, bbox_inches='tight')


    # --- Optional: Plot Train/Test Accuracy vs. Nodes ---
    plt.figure(figsize=(12, 8))

    for depth in depths_encoded:
        results = pruning_results[depth]
        history = results['history']
        if not history: continue

        nodes_list = []
        train_acc_list = []
        test_acc_list = []

        # Calculate train/test accuracy for each step in history
        for step in history:
            nodes = step['nodes']
            tree_state = step['tree']
            # Need to re-calculate train/test acc for intermediate trees stored in history
            train_acc = tree.accuracy(X_train, y_train, tree_to_use=tree_state)
            test_acc = tree.accuracy(X_test, y_test, tree_to_use=tree_state)
            
            nodes_list.append(nodes)
            train_acc_list.append(train_acc)
            test_acc_list.append(test_acc)

        # Sort by nodes for plotting
        sorted_train = sorted(zip(nodes_list, train_acc_list))
        nodes_sorted_tr = [n for n, a in sorted_train]
        train_acc_sorted = [a for n, a in sorted_train]
        
        sorted_test = sorted(zip(nodes_list, test_acc_list))
        nodes_sorted_te = [n for n, a in sorted_test]
        test_acc_sorted = [a for n, a in sorted_test]

        plt.plot(nodes_sorted_tr, train_acc_sorted, marker='.', linestyle='--', label=f'Train (Initial Depth {depth})')
        plt.plot(nodes_sorted_te, test_acc_sorted, marker='x', linestyle=':', label=f'Test (Initial Depth {depth})')


    plt.xlabel('Number of Nodes in Tree')
    plt.ylabel('Accuracy')
    plt.title('Train/Test Accuracy vs. Number of Nodes during Post-Pruning')
    plt.legend(title="Dataset & Initial Depth", bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True)
    plt.gca().invert_xaxis()
    plt.tight_layout()
    # plt.show()
    plt.savefig('pruning_results2.png', dpi=300, bbox_inches='tight')



    # --- Final Comments ---
    print("\n--- Pruning Summary ---")
    for depth in depths_encoded:
        res = pruning_results[depth]
        print(f"Initial Depth: {depth}")
        print(f"  Before Pruning: Nodes={res['nodes_before']}, Valid Acc={res['valid_acc_before']:.4f}, Test Acc={res['test_acc_before']:.4f}")
        print(f"  After Pruning:  Nodes={res['nodes_after']}, Valid Acc={res['valid_acc_after']:.4f}, Test Acc={res['test_acc_after']:.4f}")
        improvement = res['valid_acc_after'] - res['valid_acc_before']
        print(f"  Validation Improvement: {improvement:+.4f}")


    print("\n--- End of Script ---")

    # --- END OF MODIFIED second.py ---






import os
import numpy as np
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict

class NeuralNetwork:
    def __init__(self, input_size, hidden_layers, output_size):
        self.input_size = input_size
        self.hidden_layers = hidden_layers
        self.output_size = output_size
        
        # Initialize weights and biases
        self.weights = []
        self.biases = []
        
        # Input to first hidden layer
        prev_size = input_size
        for size in hidden_layers:
            self.weights.append(np.random.randn(prev_size, size) * np.sqrt(2./prev_size))
            self.biases.append(np.zeros(size))
            prev_size = size
        
        # Last hidden to output layer
        self.weights.append(np.random.randn(prev_size, output_size) * np.sqrt(2./prev_size))
        self.biases.append(np.zeros(output_size))
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))
    
    def sigmoid_derivative(self, x):
        return x * (1 - x)
    
    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forward(self, X):
        self.activations = [X]
        self.z_values = []
        
        # Hidden layers with sigmoid activation
        for i in range(len(self.hidden_layers)):
            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
            a = self.sigmoid(z)
            self.z_values.append(z)
            self.activations.append(a)
        
        # Output layer with softmax activation
        z = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
        a = self.softmax(z)
        self.z_values.append(z)
        self.activations.append(a)
        
        return a
    
    def backward(self, X, y, learning_rate):
        m = X.shape[0]
        deltas = []
        
        # Output layer error
        error = self.activations[-1] - y
        delta = error  # For softmax with cross-entropy
        deltas.insert(0, delta)
        
        # Backpropagate through hidden layers
        for i in range(len(self.hidden_layers), 0, -1):
            error = np.dot(deltas[0], self.weights[i].T)
            delta = error * self.sigmoid_derivative(self.activations[i])
            deltas.insert(0, delta)
        
        # Update weights and biases
        for i in range(len(self.weights)):
            dw = np.dot(self.activations[i].T, deltas[i]) / m
            db = np.sum(deltas[i], axis=0) / m
            self.weights[i] -= learning_rate * dw
            self.biases[i] -= learning_rate * db
    
    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size, learning_rate):
        n_samples = X_train.shape[0]
        n_batches = n_samples // batch_size
        
        train_loss_history = []
        val_loss_history = []
        train_acc_history = []
        val_acc_history = []
        
        for epoch in range(epochs):
            # Shuffle data
            permutation = np.random.permutation(n_samples)
            X_shuffled = X_train[permutation]
            y_shuffled = y_train[permutation]
            
            epoch_loss = 0
            
            for i in range(n_batches):
                # Get mini-batch
                start = i * batch_size
                end = start + batch_size
                X_batch = X_shuffled[start:end]
                y_batch = y_shuffled[start:end]
                
                # Forward pass
                output = self.forward(X_batch)
                
                # Compute loss
                loss = -np.mean(np.sum(y_batch * np.log(output + 1e-15), axis=1))
                epoch_loss += loss
                
                # Backward pass
                self.backward(X_batch, y_batch, learning_rate)
            
            # Calculate average epoch loss
            epoch_loss /= n_batches
            train_loss_history.append(epoch_loss)
            
            # Calculate validation loss
            val_output = self.forward(X_val)
            val_loss = -np.mean(np.sum(y_val * np.log(val_output + 1e-15), axis=1))
            val_loss_history.append(val_loss)
            
            # Calculate accuracies
            train_pred = np.argmax(self.forward(X_train), axis=1)
            train_true = np.argmax(y_train, axis=1)
            train_acc = np.mean(train_true == train_pred)
            train_acc_history.append(train_acc)
            
            val_pred = np.argmax(val_output, axis=1)
            val_true = np.argmax(y_val, axis=1)
            val_acc = np.mean(val_true == val_pred)
            val_acc_history.append(val_acc)
            
            print(f"Epoch {epoch+1}/{epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, "
                  f"Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}")
            # Early stopping based on validation loss
            if epoch &gt; 1 and abs(val_loss_history[-1] - val_loss_history[-2]) &lt; 1e-4:
                print(f"Early stopping at epoch {epoch+1} due to minimal change in validation loss.")
                break

        
        return train_loss_history, val_loss_history, train_acc_history, val_acc_history
    
    def predict(self, X):
        return np.argmax(self.forward(X), axis=1)

def one_hot_encode2(y, num_classes):
    """Manual one-hot encoding implementation"""
    y_onehot = np.zeros((len(y), num_classes))
    y_onehot[np.arange(len(y)), y.flatten()] = 1
    return y_onehot

def calculate_metrics(true_labels, pred_labels, num_classes):
    """Calculate precision, recall, and F1 score for each class"""
    metrics = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})
    
    for true, pred in zip(true_labels, pred_labels):
        if true == pred:
            metrics[true]['tp'] += 1
        else:
            metrics[true]['fn'] += 1
            metrics[pred]['fp'] += 1
    
    results = {}
    for class_id in range(num_classes):
        tp = metrics[class_id]['tp']
        fp = metrics[class_id]['fp']
        fn = metrics[class_id]['fn']
        
        precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0
        recall = tp / (tp + fn) if (tp + fn) &gt; 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) &gt; 0 else 0
        
        results[class_id] = {
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    
    return results

def load_data2(train_path, test_path):
    # Load training data
    X_train = []
    y_train = []
    
    for label in range(43):
        folder = os.path.join(train_path, f"{label:05d}")
        for file in os.listdir(folder):
            if file.endswith('.jpg'):
                img = Image.open(os.path.join(folder, file))
                img = img.resize((28, 28))
                img_array = np.array(img).flatten() / 255.0
                X_train.append(img_array)
                y_train.append(label)
    
    X_train = np.array(X_train)
    y_train = np.array(y_train).reshape(-1, 1)
    
    # Manual one-hot encoding
    y_train = one_hot_encode2(y_train, 43)
    
    # Load test data
    # test_df = pd.read_csv(test_labels_path)
    X_test = []
    # y_test = []
    
    # for _, row in test_df.iterrows():
    #     img = Image.open(os.path.join(test_path, row['image']))
    #     img = img.resize((28, 28))
    #     img_array = np.array(img).flatten() / 255.0
    #     X_test.append(img_array)
        # y_test.append(row['label'])
    
    for img_file in sorted(os.listdir(test_path)):  # Sorted for consistency
        img_path = os.path.join(test_path, img_file)
        img = img.resize((28, 28))
        img_array = np.array(img).flatten() / 255.0
        X_test.append(img_array)
    
    X_test = np.array(X_test)
    # y_test = np.array(y_test).reshape(-1, 1)
    # y_test = one_hot_encode(y_test, 43)
    
    return X_train, y_train, X_test


def run_experiment(hidden_layers, train_data_path, test_data_path, output_folder_path):
    # Load data
    X_train, y_train, X_test = load_data2(train_data_path, test_data_path)
    
    # Split training data into train and validation (80-20 split)
    n_samples = X_train.shape[0]
    indices = np.random.permutation(n_samples)
    split = int(0.8 * n_samples)
    
    X_train_split = X_train[indices[:split]]
    y_train_split = y_train[indices[:split]]
    X_val = X_train[indices[split:]]
    y_val = y_train[indices[split:]]
    
    # Initialize neural network
    input_size = 28 * 28 * 3  # 2352
    output_size = 43
    
    nn = NeuralNetwork(input_size, hidden_layers, output_size)
    
    # Train the network
    epochs = 150
    batch_size = 32
    learning_rate = 0.01
    
    print(f"\nTraining network with architecture: {hidden_layers}")
    train_loss, val_loss, train_acc, val_acc = nn.train(
        X_train_split, y_train_split, X_val, y_val, 
        epochs, batch_size, learning_rate
    )
    
    # Evaluate on test set
    test_pred = nn.predict(X_test)
    # test_true = np.argmax(y_test, axis=1)
    # test_acc = np.mean(test_true == test_pred)
    # print(f"Test Accuracy with architecture {hidden_layers}: {test_acc:.4f}")
    
    # Calculate metrics
    # train_pred = nn.predict(X_train)
    # train_true = np.argmax(y_train, axis=1)
    
    # train_metrics = calculate_metrics(train_true, train_pred, 43)
    # test_metrics = calculate_metrics(test_true, test_pred, 43)
    
    # Calculate average F1 scores
    # avg_train_f1 = np.mean([metrics['f1'] for metrics in train_metrics.values()])
    # avg_test_f1 = np.mean([metrics['f1'] for metrics in test_metrics.values()])

    # avg_train_precision = np.mean([metrics['precision'] for metrics in train_metrics.values()])
    # avg_train_recall = np.mean([metrics['recall'] for metrics in train_metrics.values()])
    # avg_test_precision = np.mean([metrics['precision'] for metrics in test_metrics.values()])
    # avg_test_recall = np.mean([metrics['recall'] for metrics in test_metrics.values()])

    # Print metrics as tables

    
    # print(f"Average Train F1 Score: {avg_train_f1:.4f}")
    # print(f"Average Test F1 Score: {avg_test_f1:.4f}")

    # print(f"Average Train Precision: {avg_train_precision:.4f}")
    # print(f"Average Train Recall: {avg_train_recall:.4f}")

    # print(f"Average Test Precision: {avg_test_precision:.4f}")
    # print(f"Average Test Recall: {avg_test_recall:.4f}")
    
    # Save predictions
    predictions = pd.DataFrame({'prediction': test_pred})
    predictions.to_csv(os.path.join(output_folder_path, f'prediction_c.csv'), index=False)
    
    return 

def main2(train_data_path, test_data_path, output_folder_path):
    architectures = [
        [512, 256, 128, 64]
    ]
    
    train_f1_scores = []
    # test_f1_scores = []
    depths = []
    
    for arch in architectures:
        run_experiment(
            arch, train_data_path, test_data_path, 
            output_folder_path
        )
        # train_f1_scores.append(avg_train_f1)
        # test_f1_scores.append(avg_test_f1)
    #     depths.append(depth)
    
    # # Plot F1 scores vs network depth
    # plt.figure(figsize=(10, 6))
    # plt.plot(depths, train_f1_scores, 'o-', label='Train F1 Score')
    # plt.plot(depths, test_f1_scores, 'o-', label='Test F1 Score')
    # plt.xlabel('Network Depth (Number of Hidden Layers)')
    # plt.ylabel('Average F1 Score')
    # plt.title('Average F1 Score vs Network Depth')
    # plt.xticks(depths)
    # plt.legend()
    # plt.grid(True)
    # plt.savefig(os.path.join(output_folder_path, 'f1_vs_network_depth.png'))
    # plt.close()

if __name__ == "__main__":
    # import argparse
    
    # parser = argparse.ArgumentParser()
    # parser.add_argument('train_data_path', type=str)
    # parser.add_argument('test_data_path', type=str)
    # parser.add_argument('output_folder_path', type=str)
    # parser.add_argument('question_part', type=str)
    
    # args = parser.parse_args()
    
    # # Assuming test_labels.csv is in the test_data_path folder
    # test_labels_path = os.path.join(args.test_data_path, 'test_labels.csv')
    
    # if args.question_part == 'c':
    #     main(args.train_data_path, args.test_data_path, args.output_folder_path, test_labels_path)

    train_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/train"
    test_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test"
    output_folder_path=""
    
    # Assuming test_labels.csv is in the test_data_path folder
    test_labels_path = "/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test_labels.csv"
    
    main(train_data_path, test_data_path, output_folder_path, test_labels_path)



import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier # Added for Part 1(e)
from sklearn.model_selection import GridSearchCV # Added for Part 1(e)
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import sys
import os
import time # Added to time GridSearchCV

# --- load_and_preprocess_data function remains the same ---
def load_and_preprocess_data(train_path, valid_path, test_path):
    """Loads train, validation, and test data and performs one-hot encoding."""
    try:
        train_df = pd.read_csv(train_path)
        valid_df = pd.read_csv(valid_path)
        test_df = pd.read_csv(test_path)
    except FileNotFoundError as e:
        print(f"Error loading data file: {e}. Please check file paths.")
        sys.exit(1)
    except Exception as e:
        print(f"An error occurred while reading the CSV files: {e}")
        sys.exit(1)

    # Separate target variable
    y_train = train_df['income']
    y_valid = valid_df['income']
    y_test = test_df['income']

    # Drop target variable from features
    X_train = train_df.drop('income', axis=1)
    X_valid = valid_df.drop('income', axis=1)
    X_test = test_df.drop('income', axis=1)

    # Identify categorical features (assuming object type)
    categorical_cols = X_train.select_dtypes(include=['object']).columns

    # Apply one-hot encoding
    # Combine train, valid, test to ensure consistent encoding
    combined_X = pd.concat([X_train, X_valid, X_test], keys=['train', 'valid', 'test'])
    # Use pd.get_dummies with drop_first=False as RF might handle multicollinearity differently,
    # and it aligns better with Sci-kit learn's internal handling mentioned in part 1(d) notes.
    # Let's stick to drop_first=True for consistency with part d unless results are poor.
    combined_X_encoded = pd.get_dummies(combined_X, columns=categorical_cols, drop_first=True)

    # Separate back into train, valid, test sets
    X_train_encoded = combined_X_encoded.loc['train']
    X_valid_encoded = combined_X_encoded.loc['valid']
    X_test_encoded = combined_X_encoded.loc['test']

    # Ensure all datasets have the same columns after encoding
    X_valid_encoded = X_valid_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)
    X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)

    # Ensure column order consistency (important for some models)
    X_valid_encoded = X_valid_encoded[X_train_encoded.columns]
    X_test_encoded = X_test_encoded[X_train_encoded.columns]

    return X_train_encoded, y_train, X_valid_encoded, y_valid, X_test_encoded, y_test


# --- NEW FUNCTION for Part 1(e) ---
def part_e_random_forest(X_train, y_train, X_valid, y_valid, X_test, y_test):
    """Performs analysis for Part 1(e) using RandomForestClassifier and GridSearchCV."""
    print("\n--- Part 1(e): Random Forest with GridSearchCV ---")

    # Define the parameter grid
    param_grid = {
        'n_estimators': [50, 150, 250, 350],          # 50 to 350 in steps of 100
        'max_features': np.round(np.arange(0.1, 1.01, 0.2), 2).tolist(), # 0.1 to 1.0 in steps of 0.2 -&gt; [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]
        'min_samples_split': list(range(2, 11, 2)) # 2 to 10 in steps of 2 -&gt; [2, 4, 6, 8, 10]
    }
    # Note: Using np.round for max_features to handle potential floating point inaccuracies with arange.
    # Making sure 1.0 is included if the range implies it. np.arange(0.1, 1.1, 0.2) achieves this.
    print("Parameter Grid for GridSearchCV:")
    print(param_grid)

    # Initialize the base RandomForestClassifier
    # criterion='entropy' as specified
    # oob_score=True is crucial for reporting OOB accuracy later
    # random_state for reproducibility
    # n_jobs=-1 to use all available CPU cores (speeds up training significantly)
    rf = RandomForestClassifier(criterion='entropy', oob_score=True, random_state=42, n_jobs=-1)

    # Initialize GridSearchCV
    # estimator: the model to tune (rf)
    # param_grid: the hyperparameters to search
    # scoring='accuracy': The metric to evaluate parameter combinations.
    # cv=5: Use 5-fold cross-validation within the grid search on the training data.
    #       The prompt mentions using OOB accuracy for *tuning*. While GridSearchCV primarily uses CV score for ranking,
    #       setting oob_score=True in the RF ensures the OOB score is *calculated* for the best model after refitting.
    #       Using CV is standard practice with GridSearchCV for robust parameter selection.
    # verbose=2: Show progress messages during grid search.
    # refit=True: (Default) Automatically retrain the best model found on the entire training dataset.
    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,
                               scoring='accuracy', cv=5, verbose=2, n_jobs=-1, refit=True)

    # Perform the grid search on the training data
    print("\nStarting GridSearchCV for Random Forest (this may take some time)...")
    start_time = time.time()
    grid_search.fit(X_train, y_train)
    end_time = time.time()
    print(f"GridSearchCV finished in {end_time - start_time:.2f} seconds.")

    # Get the best model and parameters
    best_params = grid_search.best_params_
    best_rf_model = grid_search.best_estimator_ # This model is already refitted on the full X_train

    print(f"\nBest Parameters found by GridSearchCV: {best_params}")

    # Report Accuracies for the *best* model found
    # 1. Out-of-Bag (OOB) Accuracy
    # This score is calculated on the data points *not* included in the bootstrap sample for each tree,
    # providing an unbiased estimate of performance on unseen data, computed during the training of the final best model.
    try:
        oob_accuracy = best_rf_model.oob_score_
        print(f"Out-of-Bag (OOB) Accuracy of Best Model: {oob_accuracy:.4f}")
    except AttributeError:
        print("OOB score not available (perhaps oob_score=False was used in the base estimator?).")
        oob_accuracy = None # Handle case where it might not be available

    # 2. Training Accuracy
    y_train_pred = best_rf_model.predict(X_train)
    train_accuracy = accuracy_score(y_train, y_train_pred)
    print(f"Training Accuracy of Best Model: {train_accuracy:.4f}")

    # 3. Validation Accuracy
    y_valid_pred = best_rf_model.predict(X_valid)
    valid_accuracy = accuracy_score(y_valid, y_valid_pred)
    print(f"Validation Accuracy of Best Model: {valid_accuracy:.4f}")

    # 4. Test Accuracy
    y_test_pred = best_rf_model.predict(X_test)
    test_accuracy = accuracy_score(y_test, y_test_pred)
    print(f"Test Accuracy of Best Model: {test_accuracy:.4f}")

    return best_rf_model

# --- save_predictions function remains the same ---
def save_predictions(model, X_test, output_path):
    """Saves model predictions on the test set to a CSV file."""
    try:
        predictions = model.predict(X_test)
        pred_df = pd.DataFrame({'prediction': predictions})
        # Ensure output directory exists
        # os.makedirs(os.path.dirname(output_path), exist_ok=True)
        pred_df.to_csv(output_path, index=False)
        print(f"\nPredictions saved to {output_path}")
    except Exception as e:
        print(f"Error saving predictions: {e}")


# if __name__ == "__main__":
#     # Check for correct number of command-line arguments
#     if len(sys.argv) != 6:
#         print("Usage: python decision_tree.py &lt;train_data_path&gt; &lt;validation_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
#         print("Example: python decision_tree.py data/train.csv data/valid.csv data/test.csv output/ e") # Updated example
#         sys.exit(1)

#     # Parse command-line arguments
#     train_path = sys.argv[1]
#     valid_path = sys.argv[2]
#     test_path = sys.argv[3]
#     output_folder = sys.argv[4]
#     question_part = sys.argv[5].lower() # Convert to lower case

#     # Validate question_part argument
#     valid_parts = ['d', 'e'] # Add 'a', 'b', 'c' if/when implemented
#     if question_part not in valid_parts:
#         print(f"Error: question_part must be one of {valid_parts}. You provided '{question_part}'.")
#         sys.exit(1)

#     # Load and preprocess data
#     print("Loading and preprocessing data...")
#     X_train, y_train, X_valid, y_valid, X_test, y_test = load_and_preprocess_data(train_path, valid_path, test_path)
#     print("Data loaded and preprocessed successfully.")
#     print(f"Shape after preprocessing - Train X: {X_train.shape}, Valid X: {X_valid.shape}, Test X: {X_test.shape}")


#     final_model = None # Initialize variable to hold the model for prediction saving

#     if question_part == 'd':
#         # Run Part 1(d) analyses
#         best_model_depth, val_acc_depth = part_d_max_depth(X_train, y_train, X_valid, y_valid, X_test, y_test)
#         best_model_alpha, val_acc_alpha = part_d_ccp_alpha(X_train, y_train, X_valid, y_valid, X_test, y_test)

#         # --- Comparison Comments (Part 1(d) vs Parts 1(b)/1(c)) ---
#         print("\n--- Comparison Comments (Part 1(d) vs Parts 1(b)/1(c)) ---")
#         print("Note: These comments assume hypothetical results from Parts 1(b) and 1(c).")

#         print("\nComparison with Part 1(b) (One-Hot Encoding, Varying Depth):")
#         # (Comments remain the same as before)
#         print(f"- The scikit-learn implementation in Part 1(d)(i) uses entropy criterion and varies max_depth ({[25, 35, 45, 55]}).")
#         print("- This is directly comparable to Part 1(b) which also used one-hot encoding and varied depth (though potentially different ranges).")
#         print("- We would expect similar trends: training accuracy generally increases or plateaus with depth, while test/validation accuracy might peak and then decrease due to overfitting.")
#         print(f"- The best scikit-learn model from varying depth achieved validation accuracy {val_acc_depth:.4f}. This should be compared to the best validation accuracy obtained in Part 1(b).")
#         print("- Differences in accuracy could arise from slight implementation variations (e.g., handling of continuous features if different, specific split logic) between the custom implementation and scikit-learn.")

#         print("\nComparison with Part 1(c) (Post-Pruning):")
#         # (Comments remain the same as before)
#         print("- Part 1(d)(ii) uses scikit-learn's cost-complexity pruning (ccp_alpha) which is a form of pre-pruning (applied during growth) or post-pruning depending on how it's used, but conceptually related to controlling model complexity like post-pruning in 1(c).")
#         print("- Part 1(c) involved growing a tree (likely deep, based on 1(b)) and then *post-pruning* nodes based on validation accuracy.")
#         print(f"- The best scikit-learn model using ccp_alpha achieved validation accuracy {val_acc_alpha:.4f}. This should be compared to the best validation accuracy obtained after post-pruning in Part 1(c).")
#         print("- Both methods aim to combat overfitting. Cost-complexity pruning (ccp_alpha) finds a sequence of subtrees optimized for complexity vs. error, while the greedy post-pruning in 1(c) removes nodes iteratively based purely on validation gain.")
#         print("- The results might differ. Scikit-learn's pruning is often effective, but the best approach (depth limit, ccp_alpha, or custom post-pruning) can be dataset-dependent.")
#         print("- Scikit-learn's optimized implementation might also lead to performance differences compared to a from-scratch implementation.")

#         # Determine the overall best model based on validation accuracy *within part d*
#         # Note: The problem asks to use validation set to determine best depth/alpha *for that subpart*,
#         # not necessarily choose between depth/alpha for the final model of part d. Let's pick the better one for saving predictions.
#         if best_model_depth is None and best_model_alpha is None:
#              print("\nWarning: No best model found in Part 1(d). Cannot save predictions.")
#         elif best_model_depth is None:
#              print("\nChoosing best model from ccp_alpha variation (Part d) for final predictions.")
#              final_model = best_model_alpha
#         elif best_model_alpha is None:
#              print("\nChoosing best model from max_depth variation (Part d) for final predictions.")
#              final_model = best_model_depth
#         elif val_acc_depth &gt;= val_acc_alpha:
#             print("\nChoosing best model from max_depth variation (Part d) for final predictions.")
#             final_model = best_model_depth
#         else:
#             print("\nChoosing best model from ccp_alpha variation (Part d) for final predictions.")
#             final_model = best_model_alpha

#     elif question_part == 'e':
#         # Run Part 1(e) analysis
#         final_model = part_e_random_forest(X_train, y_train, X_valid, y_valid, X_test, y_test)
#         # Comparison comments are printed inside part_e_random_forest function

#     # Define the output file path based on the executed part
#     output_file_path = os.path.join(output_folder, f"prediction_{question_part}.csv")

#     # Save predictions of the chosen best model (if one was selected)
#     if final_model is not None:
#         save_predictions(final_model, X_test, output_file_path)
#     else:
#         print(f"\nNo final model selected or trained for Part 1({question_part}). Predictions not saved.")

#     print(f"\nPart 1({question_part}) execution completed.")

train_path = "../Adata/train.csv"
valid_path = "../Adata/valid.csv"
test_path = "../Adata/test.csv"

print("Loading and preprocessing data...")
X_train, y_train, X_valid, y_valid, X_test, y_test = load_and_preprocess_data(train_path, valid_path, test_path)
print("Data loaded and preprocessed successfully.")

# Run Part 1(e) analyses
final_model = part_e_random_forest(X_train, y_train, X_valid, y_valid, X_test, y_test)


#Save predictions of the chosen best model

output_folder = "output.csv"

save_predictions(final_model, X_test, output_folder)



import pandas as pd
import numpy as np
from math import log2
import matplotlib.pyplot as plt

class DecisionTree:
    def __init__(self, max_depth=None):
        self.max_depth = max_depth
        self.tree = None
        
    def _entropy(self, y):
        """Calculate entropy of a target variable"""
        counts = y.value_counts()
        probabilities = counts / len(y)
        return -sum(probabilities * np.log2(probabilities))
    
    def _mutual_information(self, X_col, y):
        """Calculate mutual information between a feature and target"""
        if X_col.dtype == 'object':  # Categorical
            # For categorical, do k-way split
            unique_values = X_col.unique()
            weighted_entropy = 0
            for value in unique_values:
                subset = y[X_col == value]
                weight = len(subset) / len(y)
                weighted_entropy += weight * self._entropy(subset)
            return self._entropy(y) - weighted_entropy
        else:  # Numerical
            # For numerical, split at median
            median = X_col.median()
            left = y[X_col &lt;= median]
            right = y[X_col &gt; median]
            weight_left = len(left) / len(y)
            weight_right = len(right) / len(y)
            weighted_entropy = weight_left * self._entropy(left) + weight_right * self._entropy(right)
            return self._entropy(y) - weighted_entropy
    
    def _find_best_split(self, X, y):
        """Find the best feature to split on"""
        best_feature = None
        best_gain = -1
        
        for feature in X.columns:
            gain = self._mutual_information(X[feature], y)
            if gain &gt; best_gain:
                best_gain = gain
                best_feature = feature
                
        return best_feature, best_gain
    
    def _build_tree(self, X, y, depth=0):
        """Recursively build the decision tree"""
        # Stopping conditions
        if depth == self.max_depth or len(y.unique()) == 1:
            return y.mode()[0]  # Return most common class
        
        # Find best split
        best_feature, best_gain = self._find_best_split(X, y)
        
        if best_gain == 0:  # No information gain
            return y.mode()[0]
        
        node = {'feature': best_feature, 'gain': best_gain, 'depth': depth}
        
        if X[best_feature].dtype == 'object':  # Categorical
            unique_values = X[best_feature].unique()
            node['type'] = 'categorical'
            node['children'] = {}
            
            for value in unique_values:
                subset_X = X[X[best_feature] == value].drop(columns=[best_feature])
                subset_y = y[X[best_feature] == value]
                
                if len(subset_y) == 0:
                    node['children'][value] = y.mode()[0]
                else:
                    node['children'][value] = self._build_tree(subset_X, subset_y, depth+1)
        else:  # Numerical
            median = X[best_feature].median()
            node['type'] = 'numerical'
            node['split_value'] = median
            node['children'] = {'left': None, 'right': None}
            
            # Left child (&lt;= median)
            left_X = X[X[best_feature] &lt;= median]
            left_y = y[X[best_feature] &lt;= median]
            if len(left_y) &gt; 0:
                node['children']['left'] = self._build_tree(left_X, left_y, depth+1)
            else:
                node['children']['left'] = y.mode()[0]
            
            # Right child (&gt; median)
            right_X = X[X[best_feature] &gt; median]
            right_y = y[X[best_feature] &gt; median]
            if len(right_y) &gt; 0:
                node['children']['right'] = self._build_tree(right_X, right_y, depth+1)
            else:
                node['children']['right'] = y.mode()[0]
        
        return node
    
    def fit(self, X, y):
        """Fit the decision tree to the data"""
        self.tree = self._build_tree(X, y)
        return self
    
    def _predict_instance(self, x, node):
        """Predict a single instance"""
        if isinstance(node, str):  # Leaf node
            return node
        
        feature = node['feature']
        
        if node['type'] == 'categorical':
            if x[feature] in node['children']:
                return self._predict_instance(x, node['children'][x[feature]])
            else:  # Unseen category
                return list(node['children'].values())[0]  # Return first child's prediction
        else:  # Numerical
            if x[feature] &lt;= node['split_value']:
                return self._predict_instance(x, node['children']['left'])
            else:
                return self._predict_instance(x, node['children']['right'])
    
    def predict(self, X):
        """Predict for multiple instances"""
        return X.apply(lambda x: self._predict_instance(x, self.tree), axis=1)

    
    def accuracy(self, X, y):
        """Calculate accuracy"""
        preds = self.predict(X)
        return (preds == y).mean()

# Load data
train = pd.read_csv('../Adata/train.csv')
valid = pd.read_csv('../Adata/valid.csv')
test = pd.read_csv('../Adata/test.csv')

# Separate features and target
X_train = train.drop(columns=['income'])
y_train = train['income']
X_valid = valid.drop(columns=['income'])
y_valid = valid['income']
X_test = test.drop(columns=['income'])
y_test = test['income']

# Experiment with different depths
depths = [5, 10, 15, 20]
train_accuracies = []
test_accuracies = []

for depth in depths:
    print(f"Training tree with max_depth={depth}")
    tree = DecisionTree(max_depth=depth)
    tree.fit(X_train, y_train)
    
    train_acc = tree.accuracy(X_train, y_train)
    test_acc = tree.accuracy(X_test, y_test)
    
    train_accuracies.append(train_acc)
    test_accuracies.append(test_acc)
    
    print(f"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}")

# Plot results
plt.figure(figsize=(10, 6))
plt.plot(depths, train_accuracies, label='Train Accuracy', marker='o')
plt.plot(depths, test_accuracies, label='Test Accuracy', marker='o')
plt.xlabel('Maximum Depth')
plt.ylabel('Accuracy')
plt.title('Decision Tree Performance vs. Maximum Depth')
plt.legend()
plt.grid()
plt.show()

# Evaluate on test set with best depth
best_depth = depths[np.argmax(test_accuracies)]
print(f"\nBest depth based on validation: {best_depth}")





import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import sys
import os

def load_and_preprocess_data(train_path, valid_path, test_path):
    """Loads train, validation, and test data and performs one-hot encoding."""
    try:
        train_df = pd.read_csv(train_path)
        valid_df = pd.read_csv(valid_path)
        test_df = pd.read_csv(test_path)
    except FileNotFoundError as e:
        print(f"Error loading data file: {e}. Please check file paths.")
        sys.exit(1)
    except Exception as e:
        print(f"An error occurred while reading the CSV files: {e}")
        sys.exit(1)

    # Separate target variable
    y_train = train_df['income']
    y_valid = valid_df['income']
    y_test = test_df['income']



    # Drop target variable from features
    X_train = train_df.drop('income', axis=1)
    X_valid = valid_df.drop('income', axis=1)
    X_test = test_df.drop('income', axis=1)



    # Identify categorical features (assuming object type)
    categorical_cols = X_train.select_dtypes(include=['object']).columns

    # Apply one-hot encoding
    # Combine train, valid, test to ensure consistent encoding
    combined_X = pd.concat([X_train, X_valid, X_test], keys=['train', 'valid', 'test'])
    combined_X_encoded = pd.get_dummies(combined_X, columns=categorical_cols, drop_first=True) # drop_first=True helps reduce multicollinearity

    # Separate back into train, valid, test sets
    X_train_encoded = combined_X_encoded.loc['train']
    X_valid_encoded = combined_X_encoded.loc['valid']
    X_test_encoded = combined_X_encoded.loc['test']

    # Ensure all datasets have the same columns after encoding
    X_valid_encoded = X_valid_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)
    X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)

    return X_train_encoded, y_train, X_valid_encoded, y_valid, X_test_encoded, y_test

def part_d_max_depth(X_train, y_train, X_valid, y_valid, X_test, y_test):
    """Performs analysis for Part 1(d) varying max_depth."""
    print("\n--- Part 1(d) (i): Varying max_depth ---")
    max_depths = [25, 35, 45, 55]
    train_accuracies = []
    valid_accuracies = []
    test_accuracies = []

    best_val_acc = -1
    best_depth = -1
    best_model_depth = None

    print("Max Depth | Train Acc | Valid Acc | Test Acc")
    print("------------------------------------------")
    for depth in max_depths:
        # Initialize and train the model
        model = DecisionTreeClassifier(criterion='entropy', max_depth=depth, random_state=42)
        model.fit(X_train, y_train)

        # Predict and calculate accuracies
        y_train_pred = model.predict(X_train)
        y_valid_pred = model.predict(X_valid)
        y_test_pred = model.predict(X_test)

        train_acc = accuracy_score(y_train, y_train_pred)
        valid_acc = accuracy_score(y_valid, y_valid_pred)
        test_acc = accuracy_score(y_test, y_test_pred)

        train_accuracies.append(train_acc)
        valid_accuracies.append(valid_acc)
        test_accuracies.append(test_acc)

        print(f"{depth:&lt;9} | {train_acc:.4f}    | {valid_acc:.4f}   | {test_acc:.4f}")

        # Track best model based on validation accuracy
        if valid_acc &gt; best_val_acc:
            best_val_acc = valid_acc
            best_depth = depth
            best_model_depth = model


    # Plotting
    plt.figure(figsize=(10, 6))
    plt.plot(max_depths, train_accuracies, marker='o', label='Train Accuracy')
    plt.plot(max_depths, test_accuracies, marker='s', label='Test Accuracy')
    plt.plot(max_depths, valid_accuracies, marker='^', label='Validation Accuracy')
    plt.xlabel('Maximum Depth')
    plt.ylabel('Accuracy')
    plt.title('Decision Tree Accuracy vs. Maximum Depth (Criterion=Entropy)')
    plt.xticks(max_depths)
    plt.legend()
    plt.grid(True)
    plt.show()


    print(f"\nBest max_depth based on validation accuracy: {best_depth} (Validation Acc: {best_val_acc:.4f})")
    # Test accuracy for the best model chosen by validation set
    best_depth_test_acc = accuracy_score(y_test, best_model_depth.predict(X_test))
    print(f"Test accuracy for best max_depth ({best_depth}): {best_depth_test_acc:.4f}")

    return best_model_depth, best_val_acc

def part_d_ccp_alpha(X_train, y_train, X_valid, y_valid, X_test, y_test):
    """Performs analysis for Part 1(d) varying ccp_alpha."""
    print("\n--- Part 1(d) (ii): Varying ccp_alpha ---")
    ccp_alphas = [0.001, 0.01, 0.1, 0.2]
    train_accuracies = []
    valid_accuracies = []
    test_accuracies = []

    best_val_acc = -1
    best_alpha = -1
    best_model_alpha = None

    print("ccp_alpha | Train Acc | Valid Acc | Test Acc")
    print("-------------------------------------------")
    for alpha in ccp_alphas:
        # Initialize and train the model (default max_depth=None)
        model = DecisionTreeClassifier(criterion='entropy', ccp_alpha=alpha, random_state=42)
        model.fit(X_train, y_train)

        # Predict and calculate accuracies
        y_train_pred = model.predict(X_train)
        y_valid_pred = model.predict(X_valid)
        y_test_pred = model.predict(X_test)

        train_acc = accuracy_score(y_train, y_train_pred)
        valid_acc = accuracy_score(y_valid, y_valid_pred)
        test_acc = accuracy_score(y_test, y_test_pred)

        train_accuracies.append(train_acc)
        valid_accuracies.append(valid_acc)
        test_accuracies.append(test_acc)

        print(f"{alpha:&lt;9} | {train_acc:.4f}    | {valid_acc:.4f}   | {test_acc:.4f}")

        # Track best model based on validation accuracy
        if valid_acc &gt; best_val_acc:
            best_val_acc = valid_acc
            best_alpha = alpha
            best_model_alpha = model

    # Plotting
    plt.figure(figsize=(10, 6))
    plt.plot(ccp_alphas, train_accuracies, marker='o', label='Train Accuracy')
    plt.plot(ccp_alphas, test_accuracies, marker='s', label='Test Accuracy')
    plt.plot(ccp_alphas, valid_accuracies, marker='^', label='Validation Accuracy')
    plt.xlabel('ccp_alpha (Pruning Parameter)')
    plt.ylabel('Accuracy')
    plt.xscale('log') # Use log scale for better visualization if needed
    plt.title('Decision Tree Accuracy vs. ccp_alpha (Criterion=Entropy)')
    plt.xticks(ccp_alphas, labels=[str(a) for a in ccp_alphas])
    plt.legend()
    plt.grid(True)
    plt.show()

    print(f"\nBest ccp_alpha based on validation accuracy: {best_alpha} (Validation Acc: {best_val_acc:.4f})")
     # Test accuracy for the best model chosen by validation set
    best_alpha_test_acc = accuracy_score(y_test, best_model_alpha.predict(X_test))
    print(f"Test accuracy for best ccp_alpha ({best_alpha}): {best_alpha_test_acc:.4f}")

    return best_model_alpha, best_val_acc

def save_predictions(model, X_test, output_path):
    """Saves model predictions on the test set to a CSV file."""
    try:
        predictions = model.predict(X_test)
        pred_df = pd.DataFrame({'prediction': predictions})
        # Ensure output directory exists
        # os.makedirs(os.path.dirname(output_path), exist_ok=True)
        pred_df.to_csv(output_path, index=False)
        print(f"\nPredictions saved to {output_path}")
    except Exception as e:
        print(f"Error saving predictions: {e}")


# if __name__ == "__main__":
#     # Check for correct number of command-line arguments
#     if len(sys.argv) != 6:
#         print("Usage: python decision_tree.py &lt;train_data_path&gt; &lt;validation_data_path&gt; &lt;test_data_path&gt; &lt;output_folder_path&gt; &lt;question_part&gt;")
#         print("Example: python decision_tree.py data/train.csv data/valid.csv data/test.csv output/ d")
#         sys.exit(1)

#     # Parse command-line arguments
#     train_path = sys.argv[1]
#     valid_path = sys.argv[2]
#     test_path = sys.argv[3]
#     output_folder = sys.argv[4]
#     question_part = sys.argv[5].lower() # Convert to lower case

#     if question_part != 'd':
#         print(f"This script only implements Part 1(d). You provided '{question_part}'.")
#         sys.exit(1)

#     # Load and preprocess data
#     print("Loading and preprocessing data...")
#     X_train, y_train, X_valid, y_valid, X_test, y_test = load_and_preprocess_data(train_path, valid_path, test_path)
#     print("Data loaded and preprocessed successfully.")

#     # Run Part 1(d) analyses
#     best_model_depth, val_acc_depth = part_d_max_depth(X_train, y_train, X_valid, y_valid, X_test, y_test)
#     best_model_alpha, val_acc_alpha = part_d_ccp_alpha(X_train, y_train, X_valid, y_valid, X_test, y_test)

#     # --- Comparison Comments (as requested in Part 1(d)) ---
#     print("\n--- Comparison Comments (Part 1(d) vs Parts 1(b)/1(c)) ---")
#     print("Note: These comments assume hypothetical results from Parts 1(b) and 1(c).")

#     print("\nComparison with Part 1(b) (One-Hot Encoding, Varying Depth):")
#     print(f"- The scikit-learn implementation in Part 1(d)(i) uses entropy criterion and varies max_depth ({[25, 35, 45, 55]}).")
#     print("- This is directly comparable to Part 1(b) which also used one-hot encoding and varied depth (though potentially different ranges).")
#     print("- We would expect similar trends: training accuracy generally increases or plateaus with depth, while test/validation accuracy might peak and then decrease due to overfitting.")
#     print(f"- The best scikit-learn model from varying depth achieved validation accuracy {val_acc_depth:.4f}. This should be compared to the best validation accuracy obtained in Part 1(b).")
#     print("- Differences in accuracy could arise from slight implementation variations (e.g., handling of continuous features if different, specific split logic) between the custom implementation and scikit-learn.")

#     print("\nComparison with Part 1(c) (Post-Pruning):")
#     print("- Part 1(d)(ii) uses scikit-learn's cost-complexity pruning (ccp_alpha) which is a form of pre-pruning (applied during growth) or post-pruning depending on how it's used, but conceptually related to controlling model complexity like post-pruning in 1(c).")
#     print("- Part 1(c) involved growing a tree (likely deep, based on 1(b)) and then *post-pruning* nodes based on validation accuracy.")
#     print(f"- The best scikit-learn model using ccp_alpha achieved validation accuracy {val_acc_alpha:.4f}. This should be compared to the best validation accuracy obtained after post-pruning in Part 1(c).")
#     print("- Both methods aim to combat overfitting. Cost-complexity pruning (ccp_alpha) finds a sequence of subtrees optimized for complexity vs. error, while the greedy post-pruning in 1(c) removes nodes iteratively based purely on validation gain.")
#     print("- The results might differ. Scikit-learn's pruning is often effective, but the best approach (depth limit, ccp_alpha, or custom post-pruning) can be dataset-dependent.")
#     print("- Scikit-learn's optimized implementation might also lead to performance differences compared to a from-scratch implementation.")

#     # Determine the overall best model based on validation accuracy
#     if val_acc_depth &gt;= val_acc_alpha:
#         print("\nChoosing best model from max_depth variation for final predictions.")
#         final_model = best_model_depth
#     else:
#         print("\nChoosing best model from ccp_alpha variation for final predictions.")
#         final_model = best_model_alpha

#     # Define the output file path
#     output_file_path = os.path.join(output_folder, f"prediction_{question_part}.csv")

#     # Save predictions of the chosen best model
#     save_predictions(final_model, X_test, output_file_path)

#     print("\nPart 1(d) execution completed.")

# Load and preprocess data
train_path = "../Adata/train.csv"
valid_path = "../Adata/valid.csv"
test_path = "../Adata/test.csv"

print("Loading and preprocessing data...")
X_train, y_train, X_valid, y_valid, X_test, y_test = load_and_preprocess_data(train_path, valid_path, test_path)
print("Data loaded and preprocessed successfully.")

# Run Part 1(d) analyses
best_model_depth, val_acc_depth = part_d_max_depth(X_train, y_train, X_valid, y_valid, X_test, y_test)
best_model_alpha, val_acc_alpha = part_d_ccp_alpha(X_train, y_train, X_valid, y_valid, X_test, y_test)

#Save predictions of the chosen best model

output_folder = "output.csv"

save_predictions(best_model_alpha, X_test, output_folder)






import pandas as pd
import numpy as np
from math import log2
import matplotlib.pyplot as plt

class DecisionTree:
    def __init__(self, max_depth=None):
        self.max_depth = max_depth
        self.tree = None
        
    def _entropy(self, y):
        """Calculate entropy of a target variable"""
        counts = y.value_counts()
        probabilities = counts / len(y)
        return -sum(probabilities * np.log2(probabilities))
    
    def _mutual_information(self, X_col, y):
        """Calculate mutual information between a feature and target"""
        if X_col.dtype == 'object':  # Categorical
            # For categorical, do k-way split
            unique_values = X_col.unique()
            weighted_entropy = 0
            for value in unique_values:
                subset = y[X_col == value]
                weight = len(subset) / len(y)
                weighted_entropy += weight * self._entropy(subset)
            return self._entropy(y) - weighted_entropy
        else:  # Numerical
            # For numerical, split at median
            median = X_col.median()
            left = y[X_col &lt;= median]
            right = y[X_col &gt; median]
            weight_left = len(left) / len(y)
            weight_right = len(right) / len(y)
            weighted_entropy = weight_left * self._entropy(left) + weight_right * self._entropy(right)
            return self._entropy(y) - weighted_entropy
    
    def _find_best_split(self, X, y):
        """Find the best feature to split on"""
        best_feature = None
        best_gain = -1
        
        for feature in X.columns:
            gain = self._mutual_information(X[feature], y)
            if gain &gt; best_gain:
                best_gain = gain
                best_feature = feature
                
        return best_feature, best_gain
    
    def _build_tree(self, X, y, depth=0):
        """Recursively build the decision tree"""
        # Stopping conditions
        if depth == self.max_depth or len(y.unique()) == 1:
            return y.mode()[0]  # Return most common class
        
        # Find best split
        best_feature, best_gain = self._find_best_split(X, y)
        
        if best_gain == 0:  # No information gain
            return y.mode()[0]
        
        node = {'feature': best_feature, 'gain': best_gain, 'depth': depth}
        
        if X[best_feature].dtype == 'object':  # Categorical
            unique_values = X[best_feature].unique()
            node['type'] = 'categorical'
            node['children'] = {}
            
            for value in unique_values:
                subset_X = X[X[best_feature] == value].drop(columns=[best_feature])
                subset_y = y[X[best_feature] == value]
                
                if len(subset_y) == 0:
                    node['children'][value] = y.mode()[0]
                else:
                    node['children'][value] = self._build_tree(subset_X, subset_y, depth+1)
        else:  # Numerical
            median = X[best_feature].median()
            node['type'] = 'numerical'
            node['split_value'] = median
            node['children'] = {'left': None, 'right': None}
            
            # Left child (&lt;= median)
            left_X = X[X[best_feature] &lt;= median]
            left_y = y[X[best_feature] &lt;= median]
            if len(left_y) &gt; 0:
                node['children']['left'] = self._build_tree(left_X, left_y, depth+1)
            else:
                node['children']['left'] = y.mode()[0]
            
            # Right child (&gt; median)
            right_X = X[X[best_feature] &gt; median]
            right_y = y[X[best_feature] &gt; median]
            if len(right_y) &gt; 0:
                node['children']['right'] = self._build_tree(right_X, right_y, depth+1)
            else:
                node['children']['right'] = y.mode()[0]
        
        return node
    
    def fit(self, X, y):
        """Fit the decision tree to the data"""
        self.tree = self._build_tree(X, y)
        return self
    
    def _predict_instance(self, x, node):
        """Predict a single instance"""
        if isinstance(node, str):  # Leaf node
            return node
        
        feature = node['feature']
        
        if node['type'] == 'categorical':
            if x[feature] in node['children']:
                return self._predict_instance(x, node['children'][x[feature]])
            else:  # Unseen category
                return list(node['children'].values())[0]  # Return first child's prediction
        else:  # Numerical
            if x[feature] &lt;= node['split_value']:
                return self._predict_instance(x, node['children']['left'])
            else:
                return self._predict_instance(x, node['children']['right'])
    
    def predict(self, X):
        """Predict for multiple instances"""
        return X.apply(lambda x: self._predict_instance(x, self.tree), axis=1)
    
    def accuracy(self, X, y):
        """Calculate accuracy"""
        preds = self.predict(X)
        return (preds == y).mean()

# Load data
train = pd.read_csv('../Adata/train.csv')
valid = pd.read_csv('../Adata/valid.csv')
test = pd.read_csv('../Adata/test.csv')

# Identify categorical columns with more than 2 categories
categorical_cols = train.select_dtypes(include=['object']).columns
multi_cat_cols = [col for col in categorical_cols if len(train[col].unique()) &gt;= 2]

# Apply one-hot encoding to these columns
def one_hot_encode(df, cols):
    for col in cols:
        dummies = pd.get_dummies(df[col], prefix=col)
        df = pd.concat([df.drop(col, axis=1), dummies], axis=1)
    return df

# Apply to all datasets
train_encoded = one_hot_encode(train.copy(), multi_cat_cols)
valid_encoded = one_hot_encode(valid.copy(), multi_cat_cols)
test_encoded = one_hot_encode(test.copy(), multi_cat_cols)

# Get column headers for train_encoded
train_encoded_columns = train_encoded.columns.tolist()
train_encoded_columns = set(train_encoded_columns)

# Get column headers for valid_encoded
valid_encoded_columns = valid_encoded.columns.tolist()
valid_encoded_columns = set(valid_encoded_columns)

# Get column headers for test_encoded
test_encoded_columns = test_encoded.columns.tolist()
test_encoded_columns = set(test_encoded_columns)

#Union of all columns
all_columns = train_encoded_columns.union(valid_encoded_columns).union(test_encoded_columns)

# Add missing columns to each DataFrame with default value 0
for col in all_columns:
    if col not in train_encoded.columns:
        train_encoded[col] = False
    if col not in valid_encoded.columns:
        valid_encoded[col] = False
    if col not in test_encoded.columns:
        test_encoded[col] = False


# Separate features and target
X_train = train_encoded.drop(columns=['income_ &lt;=50K','income_ &gt;50K'])
y_train = train['income']
X_valid = valid_encoded.drop(columns=['income_ &lt;=50K','income_ &gt;50K'])
y_valid = valid['income']
X_test = test_encoded.drop(columns=['income_ &lt;=50K','income_ &gt;50K'])
y_test = test['income']

# Experiment with different depths for one-hot encoded data
depths_encoded = [25, 35, 45, 55]
train_accuracies_encoded = []
test_accuracies_encoded = []

for depth in depths_encoded:
    print(f"Training tree with max_depth={depth} (one-hot encoded)")
    tree = DecisionTree(max_depth=depth)
    tree.fit(X_train, y_train)
    
    train_acc = tree.accuracy(X_train, y_train)
    test_acc = tree.accuracy(X_test, y_test)
    
    train_accuracies_encoded.append(train_acc)
    test_accuracies_encoded.append(test_acc)
    
    print(f"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}")

# Plot results
plt.figure(figsize=(10, 6))
plt.plot(depths_encoded, train_accuracies_encoded, label='Train Accuracy', marker='o')
plt.plot(depths_encoded, test_accuracies_encoded, label='Test Accuracy', marker='o')
plt.xlabel('Maximum Depth')
plt.ylabel('Accuracy')
plt.title('Decision Tree Performance(OHE) vs. Maximum Depth')
plt.legend()
plt.grid()
plt.show()

# Evaluate on test set with best depth
best_depth_encoded = depths_encoded[np.argmax(valid_accuracies_encoded)]
print(f"\nBest depth based on validation (OHE): {best_depth_encoded}")






# --- START OF MODIFIED second.py ---

import pandas as pd
import numpy as np
from math import log2
import matplotlib.pyplot as plt
import copy # Needed for deep copying the tree

class DecisionTree:
    def __init__(self, max_depth=None):
        self.max_depth = max_depth
        self.tree = None
        self.original_tree = None # Store the original tree before pruning

    def _entropy(self, y):
        """Calculate entropy of a target variable"""
        # Handle empty or single-class subsets gracefully
        if len(y) == 0 or len(y.unique()) &lt;= 1:
            return 0
        counts = y.value_counts()
        probabilities = counts / len(y)
        # Add small epsilon to avoid log2(0)
        probabilities = probabilities[probabilities &gt; 0] # Filter out zero probabilities
        return -sum(probabilities * np.log2(probabilities))

    def _mutual_information(self, X_col, y):
        """Calculate mutual information between a feature and target"""
        if len(y) == 0:
            return 0 # No information gain if subset is empty

        current_entropy = self._entropy(y)
        weighted_entropy = 0

        if X_col.dtype == 'object':  # Categorical
            unique_values = X_col.unique()
            for value in unique_values:
                subset_y = y[X_col == value]
                weight = len(subset_y) / len(y)
                if weight &gt; 0: # Avoid calculation for empty subsets
                    weighted_entropy += weight * self._entropy(subset_y)
        else:  # Numerical
            # Handle case where all values are the same
            if X_col.nunique() &lt;= 1:
                return 0 # Cannot split if all values are the same
            median = X_col.median()
            left_y = y[X_col &lt;= median]
            right_y = y[X_col &gt; median]

            # Avoid division by zero if len(y) is zero (handled earlier)
            weight_left = len(left_y) / len(y)
            weight_right = len(right_y) / len(y)

            if weight_left &gt; 0:
                weighted_entropy += weight_left * self._entropy(left_y)
            if weight_right &gt; 0:
                 weighted_entropy += weight_right * self._entropy(right_y)

        return current_entropy - weighted_entropy

    def _find_best_split(self, X, y):
        """Find the best feature to split on"""
        best_feature = None
        best_gain = -1

        # Handle case where X might be empty (e.g., after dropping columns)
        if X.empty:
            return None, 0

        for feature in X.columns:
            # Skip if feature has only one unique value in the current subset
            if X[feature].nunique() &lt;= 1:
                continue
            gain = self._mutual_information(X[feature], y)
            if gain &gt; best_gain:
                best_gain = gain
                best_feature = feature

        # If no gain found (e.g., all features constant), return None
        if best_gain &lt;= 0:
             return None, 0

        return best_feature, best_gain

    def _build_tree(self, X, y, depth=0):
        """Recursively build the decision tree"""
        # --- MODIFICATION: Calculate majority class early ---
        majority_class = y.mode()[0] if not y.empty else None

        # Stopping conditions
        # 1. Max depth reached
        # 2. All targets are the same
        # 3. No features left to split on
        # 4. No data left (should ideally not happen with checks, but good fallback)
        if depth == self.max_depth or len(y.unique()) &lt;= 1 or X.empty or len(y) == 0:
             # Use previously calculated majority_class if available, else calculate if needed
             return majority_class if majority_class is not None else (y.mode()[0] if not y.empty else None)

        # Find best split
        best_feature, best_gain = self._find_best_split(X, y)

        # 5. No informative split found (gain is 0 or less)
        if best_feature is None or best_gain &lt;= 0:
            return majority_class # Return majority class of current node

        # --- MODIFICATION: Store majority class in the node ---
        node = {
            'feature': best_feature,
            'gain': best_gain,
            'depth': depth,
            'majority_class': majority_class, # Store for pruning
            'samples': len(y) # Store sample count (optional, but useful)
        }

        feature_values = X[best_feature] # Store the column for splitting

        if feature_values.dtype == 'object':  # Categorical
            unique_values = feature_values.unique()
            node['type'] = 'categorical'
            node['children'] = {}

            for value in unique_values:
                # Ensure subsetting works even if value is not present
                subset_indices = X[best_feature] == value
                subset_X = X.loc[subset_indices].drop(columns=[best_feature])
                subset_y = y.loc[subset_indices]

                # If a split leads to an empty subset, assign the parent's majority class
                if len(subset_y) == 0:
                    node['children'][value] = majority_class
                else:
                    node['children'][value] = self._build_tree(subset_X, subset_y, depth + 1)
        else:  # Numerical
            median = feature_values.median()
            node['type'] = 'numerical'
            node['split_value'] = median
            node['children'] = {'left': None, 'right': None}

            # Left child (&lt;= median)
            left_indices = feature_values &lt;= median
            left_X = X.loc[left_indices] # Keep the splitting feature for potential future splits deeper down
            left_y = y.loc[left_indices]
            if len(left_y) &gt; 0:
                node['children']['left'] = self._build_tree(left_X, left_y, depth + 1)
            else:
                node['children']['left'] = majority_class # Parent's majority

            # Right child (&gt; median)
            right_indices = feature_values &gt; median
            right_X = X.loc[right_indices] # Keep the splitting feature
            right_y = y.loc[right_indices]
            if len(right_y) &gt; 0:
                node['children']['right'] = self._build_tree(right_X, right_y, depth + 1)
            else:
                node['children']['right'] = majority_class # Parent's majority

        return node

    def fit(self, X, y):
        """Fit the decision tree to the data"""
        self.tree = self._build_tree(X, y)
        self.original_tree = copy.deepcopy(self.tree) # Keep a copy before pruning
        return self

    # --- Use a helper for prediction to allow passing different tree structures ---
    def _predict_instance(self, x, node):
        """Predict a single instance using a given tree node"""
        # If it's a leaf node (string prediction)
        if not isinstance(node, dict):
            return node

        feature = node['feature']

        # Check if feature exists in instance (can happen with OHE differences)
        if feature not in x:
             # Fallback: return the majority class stored at this node if feature is missing
             return node.get('majority_class', None) # Add default None

        if node['type'] == 'categorical':
            value = x[feature]
            if value in node['children']:
                return self._predict_instance(x, node['children'][value])
            else:
                # Unseen category: return the majority class of the current node
                return node['majority_class']
        else:  # Numerical
            value = x[feature]
            # Handle non-numeric data gracefully if it slips through
            try:
                split_value = node['split_value']
                if value &lt;= split_value:
                    return self._predict_instance(x, node['children']['left'])
                else:
                    return self._predict_instance(x, node['children']['right'])
            except TypeError:
                 # If comparison fails (e.g., value is not numeric)
                 return node.get('majority_class', None) # Fallback

    def predict(self, X, tree_to_use=None):
        """Predict for multiple instances using the specified tree"""
        target_tree = tree_to_use if tree_to_use is not None else self.tree
        if target_tree is None:
            raise ValueError("The tree has not been fitted yet.")
        # Handle case where the root itself might be a leaf
        if not isinstance(target_tree, dict):
             return pd.Series([target_tree] * len(X), index=X.index)
             
        return X.apply(lambda x: self._predict_instance(x, target_tree), axis=1)

    def accuracy(self, X, y, tree_to_use=None):
        """Calculate accuracy using the specified tree"""
        target_tree = tree_to_use if tree_to_use is not None else self.tree
        if target_tree is None:
             return 0.0 # Or raise error
        # Handle case where tree is just a leaf node
        if not isinstance(target_tree, dict):
             if target_tree is None: return 0.0 # No prediction possible
             preds = pd.Series([target_tree] * len(X), index=X.index)
        else:
             preds = self.predict(X, target_tree)
        
        # Ensure comparison works even if y or preds contains None
        valid_comparison = (preds.notna() & y.notna())
        return (preds[valid_comparison] == y[valid_comparison]).mean() if valid_comparison.any() else 0.0


    # --- Pruning Helper Methods ---

    def _count_nodes(self, node):
        """Recursively count the total number of nodes (internal + leaf)"""
        if not isinstance(node, dict):
            return 1  # Leaf node
        
        count = 1 # Count the current internal node
        if node['type'] == 'categorical':
            for child_node in node['children'].values():
                count += self._count_nodes(child_node)
        else: # Numerical
            count += self._count_nodes(node['children']['left'])
            count += self._count_nodes(node['children']['right'])
        return count

    def _get_internal_nodes(self, node, parent=None, child_key=None):
        """
        Recursively find all internal nodes.
        Returns a list of dictionaries, each containing:
        'node': reference to the internal node dictionary
        'parent': reference to the parent node dictionary (None for root)
        'child_key': the key ('left', 'right', or category value) in the parent's children dict
                      that points to this node.
        """
        nodes = []
        if not isinstance(node, dict):
            return nodes # It's a leaf, stop recursion

        # Current node is internal, add it (if it's not the root being passed initially)
        # We only prune nodes *below* the root initially, though the root could become prunable later.
        # Let's re-evaluate: we *can* prune any internal node.
        nodes.append({
            'node': node,
            'parent': parent,
            'child_key': child_key
        })

        # Recurse on children
        children_dict = node.get('children', {})
        if node['type'] == 'categorical':
            for key, child_node in children_dict.items():
                 nodes.extend(self._get_internal_nodes(child_node, parent=node, child_key=key))
        elif node['type'] == 'numerical':
             if 'left' in children_dict:
                 nodes.extend(self._get_internal_nodes(children_dict['left'], parent=node, child_key='left'))
             if 'right' in children_dict:
                  nodes.extend(self._get_internal_nodes(children_dict['right'], parent=node, child_key='right'))
                 
        return nodes

    # --- Post-Pruning Method ---

    def prune(self, X_valid, y_valid):
        """
        Perform greedy post-pruning based on validation set accuracy.
        Returns a history of pruning steps: [{'nodes': count, 'accuracy': acc}]
        Modifies self.tree in place.
        """
        if self.tree is None:
            print("Tree not fitted. Cannot prune.")
            return []
            
        # Start with the current tree (already a deep copy of original in fit)
        current_best_tree = copy.deepcopy(self.tree)
        initial_accuracy = self.accuracy(X_valid, y_valid, tree_to_use=current_best_tree)
        if initial_accuracy is None: initial_accuracy = 0.0 # Handle no tree case

        pruning_history = [{
            'nodes': self._count_nodes(current_best_tree),
            'accuracy': initial_accuracy,
            'tree': copy.deepcopy(current_best_tree) # Store tree state
        }]
        print(f"Initial validation accuracy: {initial_accuracy:.4f}, Nodes: {pruning_history[0]['nodes']}")

        while True:
            internal_nodes_info = self._get_internal_nodes(current_best_tree)
            
            # Filter out nodes that are already leaves if logic error happened
            internal_nodes_info = [info for info in internal_nodes_info if isinstance(info['node'], dict)]

            if not internal_nodes_info:
                print("No internal nodes left to prune.")
                break # No internal nodes left

            best_accuracy_improvement = -1.0 # We need actual improvement
            best_pruned_tree = None
            node_to_prune_info = None

            current_accuracy = pruning_history[-1]['accuracy'] # Accuracy before this iteration's pruning

            # Iterate through all potential internal nodes to prune
            for node_info in internal_nodes_info:
                parent = node_info['parent']
                child_key = node_info['child_key']
                node_to_replace = node_info['node']
                
                # --- Temporarily prune this node ---
                # Get the majority class to replace the subtree with
                majority_class_leaf = node_to_replace['majority_class']

                # Need to modify the *parent's* reference. Handle root case.
                original_subtree = None
                temp_tree_to_test = copy.deepcopy(current_best_tree) # Test on a copy

                # Find the parent and node again within the deep copied structure
                # This is inefficient. A better way might be to pass paths or use node IDs.
                # Let's stick to references for now, assuming deepcopy maintains structure okay.
                # We need to find the *corresponding* parent/node in the temp_tree.
                # This requires traversing temp_tree based on the path derived from node_info.
                # --- Simpler approach: Modify in place and restore ---
                
                if parent is None: # Pruning the root node
                    original_subtree = current_best_tree # Store the whole tree
                    current_best_tree = majority_class_leaf # Temporarily replace root
                else:
                     # Find the correct parent reference in the current tree structure before modification
                     # This assumes node_info['parent'] points to the node within current_best_tree
                     actual_parent = node_info['parent']
                     original_subtree = actual_parent['children'][child_key]
                     actual_parent['children'][child_key] = majority_class_leaf


                # --- Evaluate the temporarily pruned tree ---
                try:
                     accuracy_after_prune = self.accuracy(X_valid, y_valid, tree_to_use=current_best_tree)
                     if accuracy_after_prune is None: accuracy_after_prune = 0.0
                except Exception as e:
                     print(f"Error calculating accuracy during pruning: {e}")
                     accuracy_after_prune = 0.0 # Penalize errors

                improvement = accuracy_after_prune - current_accuracy

                # --- Restore the original subtree ---
                if parent is None:
                    current_best_tree = original_subtree # Restore original tree if root was pruned
                else:
                    actual_parent['children'][child_key] = original_subtree # Put back the original child

                # --- Check if this prune is the best so far ---
                # We want the prune that results in the highest *absolute* accuracy,
                # but it must be higher than the current best accuracy.
                # Let's track the best *resulting* accuracy.
                
                if accuracy_after_prune &gt; current_accuracy : # Strict improvement required
                     if accuracy_after_prune &gt; best_accuracy_improvement: # Found a better prune
                         best_accuracy_improvement = accuracy_after_prune
                         node_to_prune_info = node_info # Remember which node led to this

            # --- After checking all nodes, perform the best prune permanently ---
            if node_to_prune_info is not None:
                # Perform the actual prune on current_best_tree
                parent = node_to_prune_info['parent']
                child_key = node_to_prune_info['child_key']
                node_to_replace = node_to_prune_info['node']
                majority_class_leaf = node_to_replace['majority_class']

                if parent is None: # Pruning the root
                    print(f"Pruning root node. Replacing with '{majority_class_leaf}'.")
                    current_best_tree = majority_class_leaf
                else:
                     # Need to ensure 'parent' refers to the node inside current_best_tree
                     # If references held from _get_internal_nodes, this should work.
                     print(f"Pruning node at depth {node_to_replace.get('depth','N/A')} (feature: {node_to_replace.get('feature','N/A')}). Replacing with '{majority_class_leaf}'.")
                     parent['children'][child_key] = majority_class_leaf

                num_nodes = self._count_nodes(current_best_tree)
                new_accuracy = best_accuracy_improvement # This is the accuracy *after* the best prune

                pruning_history.append({
                    'nodes': num_nodes,
                    'accuracy': new_accuracy,
                    'tree': copy.deepcopy(current_best_tree) # Store tree state
                })
                print(f"Pruned. New validation accuracy: {new_accuracy:.4f}, Nodes: {num_nodes}")

            else:
                # No pruning candidate resulted in improvement
                print("No further improvement found. Stopping pruning.")
                break # Exit the while loop

        # Update the tree in the object instance to the best pruned version found
        self.tree = pruning_history[-1]['tree']
        print(f"Final pruned tree validation accuracy: {pruning_history[-1]['accuracy']:.4f}, Nodes: {pruning_history[-1]['nodes']}")
        return pruning_history


# --- Main Script Execution ---

# Load data (adjust paths as needed)
try:
    train = pd.read_csv('../Adata/train.csv')
    valid = pd.read_csv('../Adata/valid.csv')
    test = pd.read_csv('../Adata/test.csv')
except FileNotFoundError:
    print("Error: Dataset files not found. Make sure train.csv, valid.csv, and test.csv are in a directory named 'Adata' relative to the script.")
    exit()


# --- Preprocessing for One-Hot Encoding (Part 1b setup) ---
print("Preprocessing data with One-Hot Encoding...")

# Target variable name might differ, ensure it's correct
target_col_name = 'income' # Assuming this is the column name before OHE
target_value_high = '&gt;50K' # Assuming this is one of the values

# Check if target column exists
if target_col_name not in train.columns:
     print(f"Error: Target column '{target_col_name}' not found in train data.")
     # Attempt to find income columns if they were already OHE'd in CSV
     if 'income_ &gt;50K' in train.columns:
         print("Found 'income_ &gt;50K'. Reconstructing target variable.")
         train[target_col_name] = np.where(train['income_ &gt;50K'] == True, '&gt;50K', '&lt;=50K')
         valid[target_col_name] = np.where(valid['income_ &gt;50K'] == True, '&gt;50K', '&lt;=50K')
         test[target_col_name] = np.where(test['income_ &gt;50K'] == True, '&gt;50K', '&lt;=50K')
     else:
         exit()


# Identify categorical columns with more than 1 category (binary can be kept as is sometimes, but OHE handles all)
categorical_cols = train.select_dtypes(include=['object']).columns.tolist()
# Exclude the target column if it's object type
if target_col_name in categorical_cols:
    categorical_cols.remove(target_col_name)

# Apply one-hot encoding
def one_hot_encode(df, cols_to_encode, train_cols=None):
    df_encoded = df.copy()
    # Encode specified columns
    df_encoded = pd.get_dummies(df_encoded, columns=cols_to_encode, dummy_na=False)

    if train_cols is not None:
        # Add missing columns (present in train, not in current df)
        missing_cols = set(train_cols) - set(df_encoded.columns)
        for c in missing_cols:
            # Avoid adding back the original target column if it was numeric/boolean
            if c != target_col_name and not c.startswith(target_col_name + '_'):
                 df_encoded[c] = 0 # Or False, depending on expected type
        # Ensure order and presence of all training columns, except target
        df_encoded = df_encoded.reindex(columns=train_cols, fill_value=0) # Or False
    return df_encoded

# Encode Train and get column names
train_encoded = pd.get_dummies(train.copy(), columns=categorical_cols, dummy_na=False)
train_encoded_columns = train_encoded.columns.tolist()

# Encode Valid and Test using Train columns for consistency
valid_encoded = one_hot_encode(valid.copy(), categorical_cols, train_encoded_columns)
test_encoded = one_hot_encode(test.copy(), categorical_cols, train_encoded_columns)


# --- Align columns after potential inconsistencies ---
# This step is crucial if OHE creates different columns in train/valid/test
# (e.g., a category exists in valid but not train)

# Get all unique columns across all sets (excluding target)
all_cols = set(train_encoded.columns) | set(valid_encoded.columns) | set(test_encoded.columns)
if target_col_name in all_cols:
    all_cols.remove(target_col_name)
# If OHE target columns exist, remove them too
ohe_target_cols = [c for c in all_cols if c.startswith(target_col_name + '_')]
for c in ohe_target_cols:
    all_cols.remove(c)

feature_columns = sorted(list(all_cols)) # Use sorted list for consistent order

# Reindex all dataframes to have the same feature columns
X_train = train_encoded.reindex(columns=feature_columns, fill_value=0)
y_train = train[target_col_name] # Original target column

X_valid = valid_encoded.reindex(columns=feature_columns, fill_value=0)
y_valid = valid[target_col_name]

X_test = test_encoded.reindex(columns=feature_columns, fill_value=0)
y_test = test[target_col_name]

print("Data preprocessing finished.")
print(f"X_train shape: {X_train.shape}, X_valid shape: {X_valid.shape}, X_test shape: {X_test.shape}")


# --- Experimentation (Part 1c: Pruning trees from 1b) ---

# Depths from part 1b
# depths_encoded = [25, 35, 45, 55]
depths_encoded = [5, 10, 15, 20] # Original depths for OHE
pruning_results = {} # Store pruning history and final accuracies

print("\n--- Starting Experiment: Post-Pruning (Part 1c) ---")

for depth in depths_encoded:
    print(f"\nTraining tree with initial max_depth={depth} (one-hot encoded)")
    tree = DecisionTree(max_depth=depth)
    tree.fit(X_train, y_train) # Fit on training data

    train_acc_before = tree.accuracy(X_train, y_train, tree.original_tree)
    valid_acc_before = tree.accuracy(X_valid, y_valid, tree.original_tree)
    test_acc_before = tree.accuracy(X_test, y_test, tree.original_tree)
    nodes_before = tree._count_nodes(tree.original_tree)
    print(f"BEFORE Pruning (Depth {depth}): Nodes={nodes_before}, TrainAcc={train_acc_before:.4f}, ValidAcc={valid_acc_before:.4f}, TestAcc={test_acc_before:.4f}")


    print(f"\nPruning tree initially grown to depth={depth}...")
    # Prune using the VALIDATION set
    history = tree.prune(X_valid, y_valid)

    # Evaluate the FINAL PRUNED tree
    train_acc_after = tree.accuracy(X_train, y_train) # Uses the pruned self.tree
    valid_acc_after = tree.accuracy(X_valid, y_valid)
    test_acc_after = tree.accuracy(X_test, y_test)
    nodes_after = tree._count_nodes(tree.tree) # Nodes in the final pruned tree

    print(f"AFTER Pruning (Initial Depth {depth}): Nodes={nodes_after}, TrainAcc={train_acc_after:.4f}, ValidAcc={valid_acc_after:.4f}, TestAcc={test_acc_after:.4f}")

    pruning_results[depth] = {
        'history': history,
        'nodes_before': nodes_before,
        'train_acc_before': train_acc_before,
        'valid_acc_before': valid_acc_before,
        'test_acc_before': test_acc_before,
        'nodes_after': nodes_after,
        'train_acc_after': train_acc_after,
        'valid_acc_after': valid_acc_after,
        'test_acc_after': test_acc_after
    }


# --- Plotting Results (Accuracy vs. Number of Nodes during Pruning) ---
print("\n--- Plotting Pruning Results ---")
plt.figure(figsize=(12, 8))

for depth in depths_encoded:
    history = pruning_results[depth]['history']
    if not history: # Skip if pruning failed or didn't happen
        continue

    nodes = [step['nodes'] for step in history]
    valid_accuracies = [step['accuracy'] for step in history]

    # Plot validation accuracy vs nodes for this initial depth
    # Sort by nodes ascending for plotting line correctly (pruning might not always reduce nodes if root is pruned)
    sorted_data = sorted(zip(nodes, valid_accuracies))
    nodes_sorted = [n for n, a in sorted_data]
    valid_accuracies_sorted = [a for n, a in sorted_data]
    
    # Add marker for the final pruned state
    final_nodes = pruning_results[depth]['nodes_after']
    final_valid_acc = pruning_results[depth]['valid_acc_after']
    
    plt.plot(nodes_sorted, valid_accuracies_sorted, marker='.', linestyle='-', label=f'Initial Depth {depth}')
    plt.scatter([final_nodes], [final_valid_acc], s=100, edgecolors='black', facecolors='none', marker='o', label=f'Final (Depth {depth})')


plt.xlabel('Number of Nodes in Tree')
plt.ylabel('Validation Accuracy')
plt.title('Validation Accuracy vs. Number of Nodes during Post-Pruning')
plt.legend(title="Initial Max Depth", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.gca().invert_xaxis() # Typically pruning reduces nodes, so plot right-to-left
plt.tight_layout()
# plt.show()
# Save the figure to a file
plt.savefig('pruning_results.png', dpi=300, bbox_inches='tight')


# --- Optional: Plot Train/Test Accuracy vs. Nodes ---
plt.figure(figsize=(12, 8))

for depth in depths_encoded:
    results = pruning_results[depth]
    history = results['history']
    if not history: continue

    nodes_list = []
    train_acc_list = []
    test_acc_list = []

    # Calculate train/test accuracy for each step in history
    for step in history:
        nodes = step['nodes']
        tree_state = step['tree']
        # Need to re-calculate train/test acc for intermediate trees stored in history
        train_acc = tree.accuracy(X_train, y_train, tree_to_use=tree_state)
        test_acc = tree.accuracy(X_test, y_test, tree_to_use=tree_state)
        
        nodes_list.append(nodes)
        train_acc_list.append(train_acc)
        test_acc_list.append(test_acc)

    # Sort by nodes for plotting
    sorted_train = sorted(zip(nodes_list, train_acc_list))
    nodes_sorted_tr = [n for n, a in sorted_train]
    train_acc_sorted = [a for n, a in sorted_train]
    
    sorted_test = sorted(zip(nodes_list, test_acc_list))
    nodes_sorted_te = [n for n, a in sorted_test]
    test_acc_sorted = [a for n, a in sorted_test]

    plt.plot(nodes_sorted_tr, train_acc_sorted, marker='.', linestyle='--', label=f'Train (Initial Depth {depth})')
    plt.plot(nodes_sorted_te, test_acc_sorted, marker='x', linestyle=':', label=f'Test (Initial Depth {depth})')


plt.xlabel('Number of Nodes in Tree')
plt.ylabel('Accuracy')
plt.title('Train/Test Accuracy vs. Number of Nodes during Post-Pruning')
plt.legend(title="Dataset & Initial Depth", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.gca().invert_xaxis()
plt.tight_layout()
# plt.show()
plt.savefig('pruning_results2.png', dpi=300, bbox_inches='tight')



# --- Final Comments ---
print("\n--- Pruning Summary ---")
for depth in depths_encoded:
     res = pruning_results[depth]
     print(f"Initial Depth: {depth}")
     print(f"  Before Pruning: Nodes={res['nodes_before']}, Valid Acc={res['valid_acc_before']:.4f}, Test Acc={res['test_acc_before']:.4f}")
     print(f"  After Pruning:  Nodes={res['nodes_after']}, Valid Acc={res['valid_acc_after']:.4f}, Test Acc={res['test_acc_after']:.4f}")
     improvement = res['valid_acc_after'] - res['valid_acc_before']
     print(f"  Validation Improvement: {improvement:+.4f}")


print("\n--- End of Script ---")

# --- END OF MODIFIED second.py ---






import os
import numpy as np
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict
import math

class NeuralNetwork:
    def __init__(self, input_size, hidden_layers, output_size):
        self.input_size = input_size
        self.hidden_layers = hidden_layers
        self.output_size = output_size
        
        # Initialize weights and biases
        self.weights = []
        self.biases = []
        
        # Input to first hidden layer
        prev_size = input_size
        for size in hidden_layers:
            self.weights.append(np.random.randn(prev_size, size) * np.sqrt(2./prev_size))
            self.biases.append(np.zeros(size))
            prev_size = size
        
        # Last hidden to output layer
        self.weights.append(np.random.randn(prev_size, output_size) * np.sqrt(2./prev_size))
        self.biases.append(np.zeros(output_size))
    
    def relu(self, x):
        return np.maximum(0, x)
    
    def relu_derivative(self, x):
        # Subgradient at 0 is 1 (common choice)
        return (x &gt; 0).astype(float)
    
    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forward(self, X):
        self.activations = [X]
        self.z_values = []
        
        # Hidden layers with ReLU activation
        for i in range(len(self.hidden_layers)):
            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
            a = self.relu(z)
            self.z_values.append(z)
            self.activations.append(a)
        
        # Output layer with softmax activation
        z = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
        a = self.softmax(z)
        self.z_values.append(z)
        self.activations.append(a)
        
        return a
    
    def backward(self, X, y, learning_rate):
        m = X.shape[0]
        deltas = []
        
        # Output layer error
        error = self.activations[-1] - y
        delta = error  # For softmax with cross-entropy
        deltas.insert(0, delta)
        
        # Backpropagate through hidden layers
        for i in range(len(self.hidden_layers), 0, -1):
            error = np.dot(deltas[0], self.weights[i].T)
            delta = error * self.relu_derivative(self.z_values[i-1])  # Using z_values for ReLU derivative
            deltas.insert(0, delta)
        
        # Update weights and biases
        for i in range(len(self.weights)):
            dw = np.dot(self.activations[i].T, deltas[i]) / m
            db = np.sum(deltas[i], axis=0) / m
            self.weights[i] -= learning_rate * dw
            self.biases[i] -= learning_rate * db
    
    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size, initial_learning_rate):
        n_samples = X_train.shape[0]
        n_batches = n_samples // batch_size
        
        train_loss_history = []
        val_loss_history = []
        train_acc_history = []
        val_acc_history = []
        
        for epoch in range(epochs):
            # Adaptive learning rate
            current_lr = initial_learning_rate / math.sqrt(epoch + 1)
            
            # Shuffle data
            permutation = np.random.permutation(n_samples)
            X_shuffled = X_train[permutation]
            y_shuffled = y_train[permutation]
            
            epoch_loss = 0
            
            for i in range(n_batches):
                # Get mini-batch
                start = i * batch_size
                end = start + batch_size
                X_batch = X_shuffled[start:end]
                y_batch = y_shuffled[start:end]
                
                # Forward pass
                output = self.forward(X_batch)
                
                # Compute loss
                loss = -np.mean(np.sum(y_batch * np.log(output + 1e-15), axis=1))
                epoch_loss += loss
                
                # Backward pass
                self.backward(X_batch, y_batch, current_lr)
            
            # Calculate average epoch loss
            epoch_loss /= n_batches
            train_loss_history.append(epoch_loss)
            
            # Calculate validation loss
            val_output = self.forward(X_val)
            val_loss = -np.mean(np.sum(y_val * np.log(val_output + 1e-15), axis=1))
            val_loss_history.append(val_loss)
            
            # Calculate accuracies
            train_pred = np.argmax(self.forward(X_train), axis=1)
            train_true = np.argmax(y_train, axis=1)
            train_acc = np.mean(train_true == train_pred)
            train_acc_history.append(train_acc)
            
            val_pred = np.argmax(val_output, axis=1)
            val_true = np.argmax(y_val, axis=1)
            val_acc = np.mean(val_true == val_pred)
            val_acc_history.append(val_acc)
            
            print(f"Epoch {epoch+1}/{epochs}, LR: {current_lr:.5f}, Train Loss: {epoch_loss:.4f}, "
                  f"Val Loss: {val_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}")
        
        return train_loss_history, val_loss_history, train_acc_history, val_acc_history
    
    def predict(self, X):
        return np.argmax(self.forward(X), axis=1)

def one_hot_encode(y, num_classes):
    """Manual one-hot encoding implementation"""
    y_onehot = np.zeros((len(y), num_classes))
    y_onehot[np.arange(len(y)), y.flatten()] = 1
    return y_onehot

def calculate_metrics(true_labels, pred_labels, num_classes):
    """Calculate precision, recall, and F1 score for each class"""
    metrics = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})
    
    for true, pred in zip(true_labels, pred_labels):
        if true == pred:
            metrics[true]['tp'] += 1
        else:
            metrics[true]['fn'] += 1
            metrics[pred]['fp'] += 1
    
    results = {}
    for class_id in range(num_classes):
        tp = metrics[class_id]['tp']
        fp = metrics[class_id]['fp']
        fn = metrics[class_id]['fn']
        
        precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0
        recall = tp / (tp + fn) if (tp + fn) &gt; 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) &gt; 0 else 0
        
        results[class_id] = {
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    
    return results

def load_data(train_path, test_path, test_labels_path):
    # Load training data
    X_train = []
    y_train = []
    
    for label in range(43):
        folder = os.path.join(train_path, f"{label:05d}")
        for file in os.listdir(folder):
            if file.endswith('.jpg'):
                img = Image.open(os.path.join(folder, file))
                img = img.resize((28, 28))
                img_array = np.array(img).flatten() / 255.0
                X_train.append(img_array)
                y_train.append(label)
    
    X_train = np.array(X_train)
    y_train = np.array(y_train).reshape(-1, 1)
    
    # Manual one-hot encoding
    y_train = one_hot_encode(y_train, 43)
    
    # Load test data
    test_df = pd.read_csv(test_labels_path)
    X_test = []
    y_test = []
    
    for _, row in test_df.iterrows():
        img = Image.open(os.path.join(test_path, row['image']))
        img = img.resize((28, 28))
        img_array = np.array(img).flatten() / 255.0
        X_test.append(img_array)
        y_test.append(row['label'])
    
    X_test = np.array(X_test)
    y_test = np.array(y_test).reshape(-1, 1)
    y_test = one_hot_encode(y_test, 43)
    
    return X_train, y_train, X_test, y_test

def run_experiment(hidden_layers, train_data_path, test_data_path, output_folder_path, test_labels_path):
    # Load data
    X_train, y_train, X_test, y_test = load_data(train_data_path, test_data_path, test_labels_path)
    
    # Split training data into train and validation (80-20 split)
    n_samples = X_train.shape[0]
    indices = np.random.permutation(n_samples)
    split = int(0.8 * n_samples)
    
    X_train_split = X_train[indices[:split]]
    y_train_split = y_train[indices[:split]]
    X_val = X_train[indices[split:]]
    y_val = y_train[indices[split:]]
    
    # Initialize neural network
    input_size = 28 * 28 * 3  # 2352
    output_size = 43
    
    nn = NeuralNetwork(input_size, hidden_layers, output_size)
    
    # Train the network
    epochs = 50
    batch_size = 32
    initial_learning_rate = 0.01
    
    print(f"\nTraining network with architecture: {hidden_layers}")
    train_loss, val_loss, train_acc, val_acc = nn.train(
        X_train_split, y_train_split, X_val, y_val, 
        epochs, batch_size, initial_learning_rate
    )
    
    # Evaluate on test set
    test_pred = nn.predict(X_test)
    test_true = np.argmax(y_test, axis=1)
    
    test_acc = np.mean(test_true == test_pred)
    print(f"Test Accuracy with architecture {hidden_layers}: {test_acc:.4f}")
    
    # Calculate metrics
    train_pred = nn.predict(X_train)
    train_true = np.argmax(y_train, axis=1)
    
    train_metrics = calculate_metrics(train_true, train_pred, 43)
    test_metrics = calculate_metrics(test_true, test_pred, 43)
    
    # Calculate average F1 scores
    avg_train_f1 = np.mean([metrics['f1'] for metrics in train_metrics.values()])
    avg_test_f1 = np.mean([metrics['f1'] for metrics in test_metrics.values()])
    
    print(f"Average Train F1 Score: {avg_train_f1:.4f}")
    print(f"Average Test F1 Score: {avg_test_f1:.4f}")
    
    # Save predictions
    arch_name = '_'.join(map(str, hidden_layers))
    predictions = pd.DataFrame({'prediction': test_pred})
    predictions.to_csv(os.path.join(output_folder_path, f'prediction_e_{arch_name}.csv'), index=False)
    
    return avg_train_f1, avg_test_f1, len(hidden_layers)

def main(train_data_path, test_data_path, output_folder_path, test_labels_path):
    architectures = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]
    
    train_f1_scores = []
    test_f1_scores = []
    depths = []
    
    for arch in architectures:
        avg_train_f1, avg_test_f1, depth = run_experiment(
            arch, train_data_path, test_data_path, 
            output_folder_path, test_labels_path
        )
        train_f1_scores.append(avg_train_f1)
        test_f1_scores.append(avg_test_f1)
        depths.append(depth)
    
    # Plot F1 scores vs network depth
    plt.figure(figsize=(10, 6))
    plt.plot(depths, train_f1_scores, 'o-', label='Train F1 Score')
    plt.plot(depths, test_f1_scores, 'o-', label='Test F1 Score')
    plt.xlabel('Network Depth (Number of Hidden Layers)')
    plt.ylabel('Average F1 Score')
    plt.title('Average F1 Score vs Network Depth (ReLU Activation)')
    plt.xticks(depths)
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(output_folder_path, 'f1_vs_network_depth_relu.png'))
    plt.close()

if __name__ == "__main__":
    # import argparse
    
    # parser = argparse.ArgumentParser()
    # parser.add_argument('train_data_path', type=str)
    # parser.add_argument('test_data_path', type=str)
    # parser.add_argument('output_folder_path', type=str)
    # parser.add_argument('question_part', type=str)
    
    # args = parser.parse_args()
    
    # # Assuming test_labels.csv is in the test_data_path folder
    # test_labels_path = os.path.join(args.test_data_path, 'test_labels.csv')
    
    # if args.question_part == 'e':
    #     main(args.train_data_path, args.test_data_path, args.output_folder_path, test_labels_path)
    train_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/train"
    test_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test"
    output_folder_path=""
    
    # Assuming test_labels.csv is in the test_data_path folder
    test_labels_path = "/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test_labels.csv"
    
    main(train_data_path, test_data_path, output_folder_path, test_labels_path)



import os
import numpy as np
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt

class NeuralNetwork:
    def __init__(self, input_size, hidden_layers, output_size):
        self.input_size = input_size
        self.hidden_layers = hidden_layers
        self.output_size = output_size
        
        # Initialize weights and biases
        self.weights = []
        self.biases = []
        
        # Input to first hidden layer
        prev_size = input_size
        for size in hidden_layers:
            self.weights.append(np.random.randn(prev_size, size) * np.sqrt(2./prev_size))
            self.biases.append(np.zeros(size))
            prev_size = size
        
        # Last hidden to output layer
        self.weights.append(np.random.randn(prev_size, output_size) * np.sqrt(2./prev_size))
        self.biases.append(np.zeros(output_size))
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))
    
    def sigmoid_derivative(self, x):
        return x * (1 - x)
    
    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forward(self, X):
        self.activations = [X]
        self.z_values = []
        
        # Hidden layers with sigmoid activation
        for i in range(len(self.hidden_layers)):
            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
            a = self.sigmoid(z)
            self.z_values.append(z)
            self.activations.append(a)
        
        # Output layer with softmax activation
        z = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
        a = self.softmax(z)
        self.z_values.append(z)
        self.activations.append(a)
        
        return a
    
    def backward(self, X, y, learning_rate):
        m = X.shape[0]
        deltas = []
        
        # Output layer error
        error = self.activations[-1] - y
        delta = error  # For softmax with cross-entropy
        deltas.insert(0, delta)
        
        # Backpropagate through hidden layers
        for i in range(len(self.hidden_layers), 0, -1):
            error = np.dot(deltas[0], self.weights[i].T)
            delta = error * self.sigmoid_derivative(self.activations[i])
            deltas.insert(0, delta)
        
        # Update weights and biases
        for i in range(len(self.weights)):
            dw = np.dot(self.activations[i].T, deltas[i]) / m
            db = np.sum(deltas[i], axis=0) / m
            self.weights[i] -= learning_rate * dw
            self.biases[i] -= learning_rate * db
    
    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size, learning_rate):
        n_samples = X_train.shape[0]
        n_batches = n_samples // batch_size
        
        train_loss_history = []
        val_loss_history = []
        train_acc_history = []
        val_acc_history = []
        
        for epoch in range(epochs):
            # Shuffle data
            permutation = np.random.permutation(n_samples)
            X_shuffled = X_train[permutation]
            y_shuffled = y_train[permutation]
            
            epoch_loss = 0
            
            for i in range(n_batches):
                # Get mini-batch
                start = i * batch_size
                end = start + batch_size
                X_batch = X_shuffled[start:end]
                y_batch = y_shuffled[start:end]
                
                # Forward pass
                output = self.forward(X_batch)
                
                # Compute loss
                loss = -np.mean(np.sum(y_batch * np.log(output + 1e-15), axis=1))
                epoch_loss += loss
                
                # Backward pass
                self.backward(X_batch, y_batch, learning_rate)
            
            # Calculate average epoch loss
            epoch_loss /= n_batches
            train_loss_history.append(epoch_loss)
            
            # Calculate validation loss
            val_output = self.forward(X_val)
            val_loss = -np.mean(np.sum(y_val * np.log(val_output + 1e-15), axis=1))
            val_loss_history.append(val_loss)
            
            # Calculate accuracies
            train_pred = np.argmax(self.forward(X_train), axis=1)
            train_true = np.argmax(y_train, axis=1)
            train_acc = np.mean(train_true == train_pred)
            train_acc_history.append(train_acc)
            
            val_pred = np.argmax(val_output, axis=1)
            val_true = np.argmax(y_val, axis=1)
            val_acc = np.mean(val_true == val_pred)
            val_acc_history.append(val_acc)
            
            print(f"Epoch {epoch+1}/{epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, "
                  f"Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}")
            
            # Early stopping based on validation loss
            if epoch &gt; 1 and abs(val_loss_history[-1] - val_loss_history[-2]) &lt; 1e-4:
                print(f"Early stopping at epoch {epoch+1} due to minimal change in validation loss.")
                break
        
        return train_loss_history, val_loss_history, train_acc_history, val_acc_history
    
    def predict(self, X):
        return np.argmax(self.forward(X), axis=1)

def one_hot_encode(y, num_classes):
    """Manual one-hot encoding implementation"""
    y_onehot = np.zeros((len(y), num_classes))
    y_onehot[np.arange(len(y)), y.flatten()] = 1
    return y_onehot

def load_data(train_path, test_path, test_labels_path):
    # Load training data
    X_train = []
    y_train = []
    
    for label in range(43):
        folder = os.path.join(train_path, f"{label:05d}")
        for file in os.listdir(folder):
            if file.endswith('.jpg'):
                img = Image.open(os.path.join(folder, file))
                img = img.resize((28, 28))
                img_array = np.array(img).flatten() / 255.0
                X_train.append(img_array)
                y_train.append(label)
    
    X_train = np.array(X_train)
    y_train = np.array(y_train).reshape(-1, 1)
    
    # Manual one-hot encoding
    y_train = one_hot_encode(y_train, 43)
    
    # Load test data
    test_df = pd.read_csv(test_labels_path)
    X_test = []
    y_test = []
    
    for _, row in test_df.iterrows():
        img = Image.open(os.path.join(test_path, row['image']))
        img = img.resize((28, 28))
        img_array = np.array(img).flatten() / 255.0
        X_test.append(img_array)
        y_test.append(row['label'])
    
    X_test = np.array(X_test)
    y_test = np.array(y_test).reshape(-1, 1)
    y_test = one_hot_encode(y_test, 43)
    
    return X_train, y_train, X_test, y_test

def main(train_data_path, test_data_path, output_folder_path, test_labels_path):
    # Load data
    X_train, y_train, X_test, y_test = load_data(train_data_path, test_data_path, test_labels_path)
    
    # Split training data into train and validation (80-20 split)
    n_samples = X_train.shape[0]
    indices = np.random.permutation(n_samples)
    split = int(0.8 * n_samples)
    
    X_train_split = X_train[indices[:split]]
    y_train_split = y_train[indices[:split]]
    X_val = X_train[indices[split:]]
    y_val = y_train[indices[split:]]
    
    # Initialize neural network
    input_size = 28 * 28 * 3  # 2352
    hidden_layers = [100]  # Single hidden layer with 100 units (will be varied in part b)
    output_size = 43
    
    nn = NeuralNetwork(input_size, hidden_layers, output_size)
    
    # Train the network
    epochs = 150
    batch_size = 32
    learning_rate = 0.01
    
    train_loss, val_loss, train_acc, val_acc = nn.train(
        X_train_split, y_train_split, X_val, y_val, 
        epochs, batch_size, learning_rate
    )
    
    # Plot training and validation loss
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(train_loss, label='Train Loss')
    plt.plot(val_loss, label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    
    # Plot training and validation accuracy
    plt.subplot(1, 2, 2)
    plt.plot(train_acc, label='Train Accuracy')
    plt.plot(val_acc, label='Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_folder_path, 'training_plots.png'))
    plt.close()
    
    # Evaluate on test set
    test_pred = nn.predict(X_test)
    test_true = np.argmax(y_test, axis=1)
    test_pred = np.array(test_pred)

    test_acc = np.mean(test_true == test_pred)
    print(f"Test Accuracy: {test_acc:.4f}")
    
    # Save predictions
    predictions = pd.DataFrame({'prediction': test_pred})
    predictions.to_csv(os.path.join(output_folder_path, 'prediction_a.csv'), index=False)

if __name__ == "__main__":
    # import argparse
    
    # parser = argparse.ArgumentParser()
    # parser.add_argument('train_data_path', type=str)
    # parser.add_argument('test_data_path', type=str)
    # parser.add_argument('output_folder_path', type=str)
    # parser.add_argument('question_part', type=str)
    
    # args = parser.parse_args()
    train_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/train"
    test_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test"
    output_folder_path=""
    
    # Assuming test_labels.csv is in the test_data_path folder
    test_labels_path = "/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test_labels.csv"
    
    # if args.question_part == 'a':
    main(train_data_path, test_data_path, output_folder_path, test_labels_path)



import os
import numpy as np
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict
import math

class NeuralNetwork:
    def __init__(self, input_size, hidden_layers, output_size):
        self.input_size = input_size
        self.hidden_layers = hidden_layers
        self.output_size = output_size
        
        # Initialize weights and biases
        self.weights = []
        self.biases = []
        
        # Input to first hidden layer
        prev_size = input_size
        for size in hidden_layers:
            self.weights.append(np.random.randn(prev_size, size) * np.sqrt(2./prev_size))
            self.biases.append(np.zeros(size))
            prev_size = size
        
        # Last hidden to output layer
        self.weights.append(np.random.randn(prev_size, output_size) * np.sqrt(2./prev_size))
        self.biases.append(np.zeros(output_size))
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))
    
    def sigmoid_derivative(self, x):
        return x * (1 - x)
    
    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forward(self, X):
        self.activations = [X]
        self.z_values = []
        
        # Hidden layers with sigmoid activation
        for i in range(len(self.hidden_layers)):
            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
            a = self.sigmoid(z)
            self.z_values.append(z)
            self.activations.append(a)
        
        # Output layer with softmax activation
        z = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
        a = self.softmax(z)
        self.z_values.append(z)
        self.activations.append(a)
        
        return a
    
    def backward(self, X, y, learning_rate):
        m = X.shape[0]
        deltas = []
        
        # Output layer error
        error = self.activations[-1] - y
        delta = error  # For softmax with cross-entropy
        deltas.insert(0, delta)
        
        # Backpropagate through hidden layers
        for i in range(len(self.hidden_layers), 0, -1):
            error = np.dot(deltas[0], self.weights[i].T)
            delta = error * self.sigmoid_derivative(self.activations[i])
            deltas.insert(0, delta)
        
        # Update weights and biases
        for i in range(len(self.weights)):
            dw = np.dot(self.activations[i].T, deltas[i]) / m
            db = np.sum(deltas[i], axis=0) / m
            self.weights[i] -= learning_rate * dw
            self.biases[i] -= learning_rate * db
    
    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size, initial_learning_rate):
        n_samples = X_train.shape[0]
        n_batches = n_samples // batch_size
        
        train_loss_history = []
        val_loss_history = []
        train_acc_history = []
        val_acc_history = []
        
        for epoch in range(epochs):
            # Adaptive learning rate
            current_lr = initial_learning_rate / math.sqrt(epoch + 1)
            
            # Shuffle data
            permutation = np.random.permutation(n_samples)
            X_shuffled = X_train[permutation]
            y_shuffled = y_train[permutation]
            
            epoch_loss = 0
            
            for i in range(n_batches):
                # Get mini-batch
                start = i * batch_size
                end = start + batch_size
                X_batch = X_shuffled[start:end]
                y_batch = y_shuffled[start:end]
                
                # Forward pass
                output = self.forward(X_batch)
                
                # Compute loss
                loss = -np.mean(np.sum(y_batch * np.log(output + 1e-15), axis=1))
                epoch_loss += loss
                
                # Backward pass
                self.backward(X_batch, y_batch, current_lr)
            
            # Calculate average epoch loss
            epoch_loss /= n_batches
            train_loss_history.append(epoch_loss)
            
            # Calculate validation loss
            val_output = self.forward(X_val)
            val_loss = -np.mean(np.sum(y_val * np.log(val_output + 1e-15), axis=1))
            val_loss_history.append(val_loss)
            
            # Calculate accuracies
            train_pred = np.argmax(self.forward(X_train), axis=1)
            train_true = np.argmax(y_train, axis=1)
            train_acc = np.mean(train_true == train_pred)
            train_acc_history.append(train_acc)
            
            val_pred = np.argmax(val_output, axis=1)
            val_true = np.argmax(y_val, axis=1)
            val_acc = np.mean(val_true == val_pred)
            val_acc_history.append(val_acc)
            
            print(f"Epoch {epoch+1}/{epochs}, LR: {current_lr:.5f}, Train Loss: {epoch_loss:.4f}, "
                  f"Val Loss: {val_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}")

            #stopping criterion
            
        
        return train_loss_history, val_loss_history, train_acc_history, val_acc_history
    
    def predict(self, X):
        return np.argmax(self.forward(X), axis=1)

def one_hot_encode(y, num_classes):
    """Manual one-hot encoding implementation"""
    y_onehot = np.zeros((len(y), num_classes))
    y_onehot[np.arange(len(y)), y.flatten()] = 1
    return y_onehot

def calculate_metrics(true_labels, pred_labels, num_classes):
    """Calculate precision, recall, and F1 score for each class"""
    metrics = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})
    
    for true, pred in zip(true_labels, pred_labels):
        if true == pred:
            metrics[true]['tp'] += 1
        else:
            metrics[true]['fn'] += 1
            metrics[pred]['fp'] += 1
    
    results = {}
    for class_id in range(num_classes):
        tp = metrics[class_id]['tp']
        fp = metrics[class_id]['fp']
        fn = metrics[class_id]['fn']
        
        precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0
        recall = tp / (tp + fn) if (tp + fn) &gt; 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) &gt; 0 else 0
        
        results[class_id] = {
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    
    return results

def load_data(train_path, test_path, test_labels_path):
    # Load training data
    X_train = []
    y_train = []
    
    for label in range(43):
        folder = os.path.join(train_path, f"{label:05d}")
        for file in os.listdir(folder):
            if file.endswith('.jpg'):
                img = Image.open(os.path.join(folder, file))
                img = img.resize((28, 28))
                img_array = np.array(img).flatten() / 255.0
                X_train.append(img_array)
                y_train.append(label)
    
    X_train = np.array(X_train)
    y_train = np.array(y_train).reshape(-1, 1)
    
    # Manual one-hot encoding
    y_train = one_hot_encode(y_train, 43)
    
    # Load test data
    test_df = pd.read_csv(test_labels_path)
    X_test = []
    y_test = []
    
    for _, row in test_df.iterrows():
        img = Image.open(os.path.join(test_path, row['image']))
        img = img.resize((28, 28))
        img_array = np.array(img).flatten() / 255.0
        X_test.append(img_array)
        y_test.append(row['label'])
    
    X_test = np.array(X_test)
    y_test = np.array(y_test).reshape(-1, 1)
    y_test = one_hot_encode(y_test, 43)
    
    return X_train, y_train, X_test, y_test

def run_experiment(hidden_layers, train_data_path, test_data_path, output_folder_path, test_labels_path):
    # Load data
    X_train, y_train, X_test, y_test = load_data(train_data_path, test_data_path, test_labels_path)
    
    # Split training data into train and validation (80-20 split)
    n_samples = X_train.shape[0]
    indices = np.random.permutation(n_samples)
    split = int(0.8 * n_samples)
    
    X_train_split = X_train[indices[:split]]
    y_train_split = y_train[indices[:split]]
    X_val = X_train[indices[split:]]
    y_val = y_train[indices[split:]]
    
    # Initialize neural network
    input_size = 28 * 28 * 3  # 2352
    output_size = 43
    
    nn = NeuralNetwork(input_size, hidden_layers, output_size)
    
    # Train the network
    epochs = 50
    batch_size = 32
    initial_learning_rate = 0.01
    
    print(f"\nTraining network with architecture: {hidden_layers}")
    train_loss, val_loss, train_acc, val_acc = nn.train(
        X_train_split, y_train_split, X_val, y_val, 
        epochs, batch_size, initial_learning_rate
    )
    
    # Evaluate on test set
    test_pred = nn.predict(X_test)
    test_true = np.argmax(y_test, axis=1)
    test_true = np.toarray(test_true)
    test_acc = np.mean(test_true == test_pred)
    print(f"Test Accuracy with architecture {hidden_layers}: {test_acc:.4f}")
    
    # Calculate metrics
    train_pred = nn.predict(X_train)
    train_true = np.argmax(y_train, axis=1)
    train_true = np.toarray(train_true)

    
    train_metrics = calculate_metrics(train_true, train_pred, 43)
    test_metrics = calculate_metrics(test_true, test_pred, 43)
    
    # Calculate average F1 scores
    avg_train_f1 = np.mean([metrics['f1'] for metrics in train_metrics.values()])
    avg_test_f1 = np.mean([metrics['f1'] for metrics in test_metrics.values()])
    
    print(f"Average Train F1 Score: {avg_train_f1:.4f}")
    print(f"Average Test F1 Score: {avg_test_f1:.4f}")
    
    # Save predictions
    arch_name = '_'.join(map(str, hidden_layers))
    predictions = pd.DataFrame({'prediction': test_pred})
    predictions.to_csv(os.path.join(output_folder_path, f'prediction_d_{arch_name}.csv'), index=False)
    
    return avg_train_f1, avg_test_f1, len(hidden_layers)

def main(train_data_path, test_data_path, output_folder_path, test_labels_path):
    architectures = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]
    
    train_f1_scores = []
    test_f1_scores = []
    depths = []
    
    for arch in architectures:
        avg_train_f1, avg_test_f1, depth = run_experiment(
            arch, train_data_path, test_data_path, 
            output_folder_path, test_labels_path
        )
        train_f1_scores.append(avg_train_f1)
        test_f1_scores.append(avg_test_f1)
        depths.append(depth)
    
    # Plot F1 scores vs network depth
    plt.figure(figsize=(10, 6))
    plt.plot(depths, train_f1_scores, 'o-', label='Train F1 Score')
    plt.plot(depths, test_f1_scores, 'o-', label='Test F1 Score')
    plt.xlabel('Network Depth (Number of Hidden Layers)')
    plt.ylabel('Average F1 Score')
    plt.title('Average F1 Score vs Network Depth (Adaptive LR)')
    plt.xticks(depths)
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(output_folder_path, 'f1_vs_network_depth_adaptive_lr.png'))
    plt.close()

if __name__ == "__main__":
    # import argparse
    
    # parser = argparse.ArgumentParser()
    # parser.add_argument('train_data_path', type=str)
    # parser.add_argument('test_data_path', type=str)
    # parser.add_argument('output_folder_path', type=str)
    # parser.add_argument('question_part', type=str)
    
    # args = parser.parse_args()
    
    # # Assuming test_labels.csv is in the test_data_path folder
    # test_labels_path = os.path.join(args.test_data_path, 'test_labels.csv')
    
    # if args.question_part == 'd':
    #     main(args.train_data_path, args.test_data_path, args.output_folder_path, test_labels_path)
    train_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/train"
    test_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test"
    output_folder_path=""
    
    # Assuming test_labels.csv is in the test_data_path folder
    test_labels_path = "/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test_labels.csv"
    
    # if args.question_part == 'a':
    main(train_data_path, test_data_path, output_folder_path, test_labels_path)



import os
import numpy as np
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict

class NeuralNetwork:
    def __init__(self, input_size, hidden_layers, output_size):
        self.input_size = input_size
        self.hidden_layers = hidden_layers
        self.output_size = output_size
        
        # Initialize weights and biases
        self.weights = []
        self.biases = []
        
        # Input to first hidden layer
        prev_size = input_size
        for size in hidden_layers:
            self.weights.append(np.random.randn(prev_size, size) * np.sqrt(2./prev_size))
            self.biases.append(np.zeros(size))
            prev_size = size
        
        # Last hidden to output layer
        self.weights.append(np.random.randn(prev_size, output_size) * np.sqrt(2./prev_size))
        self.biases.append(np.zeros(output_size))
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))
    
    def sigmoid_derivative(self, x):
        return x * (1 - x)
    
    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forward(self, X):
        self.activations = [X]
        self.z_values = []
        
        # Hidden layers with sigmoid activation
        for i in range(len(self.hidden_layers)):
            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
            a = self.sigmoid(z)
            self.z_values.append(z)
            self.activations.append(a)
        
        # Output layer with softmax activation
        z = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
        a = self.softmax(z)
        self.z_values.append(z)
        self.activations.append(a)
        
        return a
    
    def backward(self, X, y, learning_rate):
        m = X.shape[0]
        deltas = []
        
        # Output layer error
        error = self.activations[-1] - y
        delta = error  # For softmax with cross-entropy
        deltas.insert(0, delta)
        
        # Backpropagate through hidden layers
        for i in range(len(self.hidden_layers), 0, -1):
            error = np.dot(deltas[0], self.weights[i].T)
            delta = error * self.sigmoid_derivative(self.activations[i])
            deltas.insert(0, delta)
        
        # Update weights and biases
        for i in range(len(self.weights)):
            dw = np.dot(self.activations[i].T, deltas[i]) / m
            db = np.sum(deltas[i], axis=0) / m
            self.weights[i] -= learning_rate * dw
            self.biases[i] -= learning_rate * db
    
    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size, learning_rate):
        n_samples = X_train.shape[0]
        n_batches = n_samples // batch_size
        
        train_loss_history = []
        val_loss_history = []
        train_acc_history = []
        val_acc_history = []
        
        for epoch in range(epochs):
            # Shuffle data
            permutation = np.random.permutation(n_samples)
            X_shuffled = X_train[permutation]
            y_shuffled = y_train[permutation]
            
            epoch_loss = 0
            
            for i in range(n_batches):
                # Get mini-batch
                start = i * batch_size
                end = start + batch_size
                X_batch = X_shuffled[start:end]
                y_batch = y_shuffled[start:end]
                
                # Forward pass
                output = self.forward(X_batch)
                
                # Compute loss
                loss = -np.mean(np.sum(y_batch * np.log(output + 1e-15), axis=1))
                epoch_loss += loss
                
                # Backward pass
                self.backward(X_batch, y_batch, learning_rate)
            
            # Calculate average epoch loss
            epoch_loss /= n_batches
            train_loss_history.append(epoch_loss)
            
            # Calculate validation loss
            val_output = self.forward(X_val)
            val_loss = -np.mean(np.sum(y_val * np.log(val_output + 1e-15), axis=1))
            val_loss_history.append(val_loss)
            
            # Calculate accuracies
            train_pred = np.argmax(self.forward(X_train), axis=1)
            train_true = np.argmax(y_train, axis=1)
            train_acc = np.mean(train_true == train_pred)
            train_acc_history.append(train_acc)
            
            val_pred = np.argmax(val_output, axis=1)
            val_true = np.argmax(y_val, axis=1)
            val_acc = np.mean(val_true == val_pred)
            val_acc_history.append(val_acc)
            
            print(f"Epoch {epoch+1}/{epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, "
                  f"Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}")

            if epoch &gt; 1 and abs(val_loss_history[-1] - val_loss_history[-2]) &lt; 1e-4:
                print(f"Early stopping at epoch {epoch+1} due to minimal change in validation loss.")
                break
            
        return train_loss_history, val_loss_history, train_acc_history, val_acc_history
    
    def predict(self, X):
        return np.argmax(self.forward(X), axis=1)

def one_hot_encode(y, num_classes):
    """Manual one-hot encoding implementation"""
    y_onehot = np.zeros((len(y), num_classes))
    y_onehot[np.arange(len(y)), y.flatten()] = 1
    return y_onehot

def calculate_metrics(true_labels, pred_labels, num_classes):
    """Calculate precision, recall, and F1 score for each class"""
    metrics = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})
    
    for true, pred in zip(true_labels, pred_labels):
        if true == pred:
            metrics[true]['tp'] += 1
        else:
            metrics[true]['fn'] += 1
            metrics[pred]['fp'] += 1
    
    results = {}
    for class_id in range(num_classes):
        tp = metrics[class_id]['tp']
        fp = metrics[class_id]['fp']
        fn = metrics[class_id]['fn']
        
        precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0
        recall = tp / (tp + fn) if (tp + fn) &gt; 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) &gt; 0 else 0
        
        results[class_id] = {
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    
    return results

def load_data(train_path, test_path, test_labels_path):
    # Load training data
    X_train = []
    y_train = []
    
    for label in range(43):
        folder = os.path.join(train_path, f"{label:05d}")
        for file in os.listdir(folder):
            if file.endswith('.jpg'):
                img = Image.open(os.path.join(folder, file))
                img = img.resize((28, 28))
                img_array = np.array(img).flatten() / 255.0
                X_train.append(img_array)
                y_train.append(label)
    
    X_train = np.array(X_train)
    y_train = np.array(y_train).reshape(-1, 1)
    
    # Manual one-hot encoding
    y_train = one_hot_encode(y_train, 43)
    
    # Load test data
    test_df = pd.read_csv(test_labels_path)
    X_test = []
    y_test = []
    
    for _, row in test_df.iterrows():
        img = Image.open(os.path.join(test_path, row['image']))
        img = img.resize((28, 28))
        img_array = np.array(img).flatten() / 255.0
        X_test.append(img_array)
        y_test.append(row['label'])
    
    X_test = np.array(X_test)
    y_test = np.array(y_test).reshape(-1, 1)
    y_test = one_hot_encode(y_test, 43)
    
    return X_train, y_train, X_test, y_test

def run_experiment(hidden_units, train_data_path, test_data_path, output_folder_path, test_labels_path):
    # Load data
    X_train, y_train, X_test, y_test = load_data(train_data_path, test_data_path, test_labels_path)
    
    # Split training data into train and validation (80-20 split)
    n_samples = X_train.shape[0]
    indices = np.random.permutation(n_samples)
    split = int(0.8 * n_samples)
    
    X_train_split = X_train[indices[:split]]
    y_train_split = y_train[indices[:split]]
    X_val = X_train[indices[split:]]
    y_val = y_train[indices[split:]]
    
    # Initialize neural network
    input_size = 28 * 28 * 3  # 2352
    hidden_layers = [hidden_units]
    output_size = 43
    
    nn = NeuralNetwork(input_size, hidden_layers, output_size)
    
    # Train the network
    epochs = 150
    batch_size = 32
    learning_rate = 0.01
    
    print(f"\nTraining network with {hidden_units} hidden units")
    train_loss, val_loss, train_acc, val_acc = nn.train(
        X_train_split, y_train_split, X_val, y_val, 
        epochs, batch_size, learning_rate
    )
    
    # Evaluate on test set
    test_pred = nn.predict(X_test)
    test_true = np.argmax(y_test, axis=1)
    test_acc = np.mean(test_true == test_pred)
    print(f"Test Accuracy with {hidden_units} hidden units: {test_acc:.4f}")
    
    # Calculate metrics
    train_pred = nn.predict(X_train)
    train_true = np.argmax(y_train, axis=1)
    
    train_metrics = calculate_metrics(train_true, train_pred, 43)
    test_metrics = calculate_metrics(test_true, test_pred, 43)
    
    
    # Calculate average F1 scores
    avg_train_f1 = np.mean([metrics['f1'] for metrics in train_metrics.values()])
    avg_test_f1 = np.mean([metrics['f1'] for metrics in test_metrics.values()])

    avg_train_precision = np.mean([metrics['precision'] for metrics in train_metrics.values()])
    avg_train_recall = np.mean([metrics['recall'] for metrics in train_metrics.values()])
    avg_test_precision = np.mean([metrics['precision'] for metrics in test_metrics.values()])
    avg_test_recall = np.mean([metrics['recall'] for metrics in test_metrics.values()])

    # Print metrics as tables

    
    print(f"Average Train F1 Score: {avg_train_f1:.4f}")
    print(f"Average Test F1 Score: {avg_test_f1:.4f}")

    print(f"Average Train Precision: {avg_train_precision:.4f}")
    print(f"Average Train Recall: {avg_train_recall:.4f}")

    print(f"Average Test Precision: {avg_test_precision:.4f}")
    print(f"Average Test Recall: {avg_test_recall:.4f}")
    
    # Save predictions
    predictions = pd.DataFrame({'prediction': test_pred})
    predictions.to_csv(os.path.join(output_folder_path, f'prediction_b_{hidden_units}.csv'), index=False)
    
    return avg_train_f1, avg_test_f1

def main(train_data_path, test_data_path, output_folder_path, test_labels_path):
    hidden_units_list = [1, 5, 10, 50, 100]
    train_f1_scores = []
    test_f1_scores = []
    
    for hidden_units in hidden_units_list:
        avg_train_f1, avg_test_f1 = run_experiment(
            hidden_units, train_data_path, test_data_path, 
            output_folder_path, test_labels_path
        )
        train_f1_scores.append(avg_train_f1)
        test_f1_scores.append(avg_test_f1)
    
    # Plot F1 scores vs hidden units
    plt.figure(figsize=(10, 6))
    plt.plot(hidden_units_list, train_f1_scores, 'o-', label='Train F1 Score')
    plt.plot(hidden_units_list, test_f1_scores, 'o-', label='Test F1 Score')
    plt.xlabel('Number of Hidden Units')
    plt.ylabel('Average F1 Score')
    plt.title('Average F1 Score vs Number of Hidden Units')
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(output_folder_path, 'f1_vs_hidden_units.png'))
    plt.close()

if __name__ == "__main__":
    # import argparse
    
    # parser = argparse.ArgumentParser()
    # parser.add_argument('train_data_path', type=str)
    # parser.add_argument('test_data_path', type=str)
    # parser.add_argument('output_folder_path', type=str)
    # parser.add_argument('question_part', type=str)
    
    # args = parser.parse_args()
    
    # Assuming test_labels.csv is in the test_data_path folder
    # test_labels_path = os.path.join(args.test_data_path, 'test_labels.csv')
    
    # if args.question_part == 'b':
        # main(args.train_data_path, args.test_data_path, args.output_folder_path, test_labels_path)
    train_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/train"
    test_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test"
    output_folder_path=""
    
    # Assuming test_labels.csv is in the test_data_path folder
    test_labels_path = "/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test_labels.csv"
    
    # if args.question_part == 'a':
    main(train_data_path, test_data_path, output_folder_path, test_labels_path)



import os
import numpy as np
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler

def load_data(train_path, test_path, test_labels_path):
    # Load training data
    X_train = []
    y_train = []
    
    for label in range(43):
        folder = os.path.join(train_path, f"{label:05d}")
        for file in os.listdir(folder):
            if file.endswith('.jpg'):
                img = Image.open(os.path.join(folder, file))
                img = img.resize((28, 28))
                img_array = np.array(img).flatten() / 255.0
                X_train.append(img_array)
                y_train.append(label)
    
    X_train = np.array(X_train)
    y_train = np.array(y_train)
    
    # Load test data
    test_df = pd.read_csv(test_labels_path)
    X_test = []
    y_test = []
    
    for _, row in test_df.iterrows():
        img = Image.open(os.path.join(test_path, row['image']))
        img = img.resize((28, 28))
        img_array = np.array(img).flatten() / 255.0
        X_test.append(img_array)
        y_test.append(row['label'])
    
    X_test = np.array(X_test)
    y_test = np.array(y_test)
    
    return X_train, y_train, X_test, y_test

def calculate_metrics(true_labels, pred_labels, num_classes):
    """Calculate precision, recall, and F1 score for each class"""
    metrics = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})
    
    for true, pred in zip(true_labels, pred_labels):
        if true == pred:
            metrics[true]['tp'] += 1
        else:
            metrics[true]['fn'] += 1
            metrics[pred]['fp'] += 1
    
    results = {}
    for class_id in range(num_classes):
        tp = metrics[class_id]['tp']
        fp = metrics[class_id]['fp']
        fn = metrics[class_id]['fn']
        
        precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0
        recall = tp / (tp + fn) if (tp + fn) &gt; 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) &gt; 0 else 0
        
        results[class_id] = {
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    
    return results

def run_experiment(hidden_layers, X_train, y_train, X_test, y_test, output_folder_path):
    # Standardize the data
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Create MLPClassifier with specified parameters
    mlp = MLPClassifier(
        hidden_layer_sizes=hidden_layers,
        activation='relu',
        solver='sgd',
        alpha=0,
        batch_size=32,
        learning_rate='invscaling',
        learning_rate_init=0.01,
        max_iter=50,
        random_state=42,
        early_stopping=True,
        validation_fraction=0.2
    )
    
    print(f"\nTraining MLPClassifier with architecture: {hidden_layers}")
    mlp.fit(X_train_scaled, y_train)
    
    # Evaluate on test set
    test_pred = mlp.predict(X_test_scaled)
    test_acc = np.mean(y_test == test_pred)
    print(f"Test Accuracy with architecture {hidden_layers}: {test_acc:.4f}")
    
    # Calculate metrics
    train_pred = mlp.predict(X_train_scaled)
    
    train_metrics = calculate_metrics(y_train, train_pred, 43)
    test_metrics = calculate_metrics(y_test, test_pred, 43)
    
    # Calculate average F1 scores
    avg_train_f1 = np.mean([metrics['f1'] for metrics in train_metrics.values()])
    avg_test_f1 = np.mean([metrics['f1'] for metrics in test_metrics.values()])
    
    print(f"Average Train F1 Score: {avg_train_f1:.4f}")
    print(f"Average Test F1 Score: {avg_test_f1:.4f}")
    
    # Save predictions
    arch_name = '_'.join(map(str, hidden_layers))
    predictions = pd.DataFrame({'prediction': test_pred})
    predictions.to_csv(os.path.join(output_folder_path, f'prediction_f_{arch_name}.csv'), index=False)
    
    return avg_train_f1, avg_test_f1, len(hidden_layers)

def main(train_data_path, test_data_path, output_folder_path, test_labels_path):
    # Load data
    X_train, y_train, X_test, y_test = load_data(train_data_path, test_data_path, test_labels_path)
    
    architectures = [
        (512,),
        (512, 256),
        (512, 256, 128),
        (512, 256, 128, 64)
    ]
    
    train_f1_scores = []
    test_f1_scores = []
    depths = []
    
    for arch in architectures:
        avg_train_f1, avg_test_f1, depth = run_experiment(
            arch, X_train, y_train, X_test, y_test, output_folder_path
        )
        train_f1_scores.append(avg_train_f1)
        test_f1_scores.append(avg_test_f1)
        depths.append(depth)
    
    # Plot F1 scores vs network depth
    plt.figure(figsize=(10, 6))
    plt.plot(depths, train_f1_scores, 'o-', label='Train F1 Score')
    plt.plot(depths, test_f1_scores, 'o-', label='Test F1 Score')
    plt.xlabel('Network Depth (Number of Hidden Layers)')
    plt.ylabel('Average F1 Score')
    plt.title('Average F1 Score vs Network Depth (MLPClassifier)')
    plt.xticks(depths)
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(output_folder_path, 'f1_vs_network_depth_mlp.png'))
    plt.close()

if __name__ == "__main__":
    import argparse
    
    # parser = argparse.ArgumentParser()
    # parser.add_argument('train_data_path', type=str)
    # parser.add_argument('test_data_path', type=str)
    # parser.add_argument('output_folder_path', type=str)
    # parser.add_argument('question_part', type=str)
    
    # args = parser.parse_args()
    
    # # Assuming test_labels.csv is in the test_data_path folder
    # test_labels_path = os.path.join(args.test_data_path, 'test_labels.csv')
    
    # if args.question_part == 'f':
    #     main(args.train_data_path, args.test_data_path, args.output_folder_path, test_labels_path)
    train_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/train"
    test_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test"
    output_folder_path=""
    
    # Assuming test_labels.csv is in the test_data_path folder
    test_labels_path = "/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test_labels.csv"
    
    # if args.question_part == 'a':
    main(train_data_path, test_data_path, output_folder_path, test_labels_path)



import os
import numpy as np
from PIL import Image
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict

class NeuralNetwork:
    def __init__(self, input_size, hidden_layers, output_size):
        self.input_size = input_size
        self.hidden_layers = hidden_layers
        self.output_size = output_size
        
        # Initialize weights and biases
        self.weights = []
        self.biases = []
        
        # Input to first hidden layer
        prev_size = input_size
        for size in hidden_layers:
            self.weights.append(np.random.randn(prev_size, size) * np.sqrt(2./prev_size))
            self.biases.append(np.zeros(size))
            prev_size = size
        
        # Last hidden to output layer
        self.weights.append(np.random.randn(prev_size, output_size) * np.sqrt(2./prev_size))
        self.biases.append(np.zeros(output_size))
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))
    
    def sigmoid_derivative(self, x):
        return x * (1 - x)
    
    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forward(self, X):
        self.activations = [X]
        self.z_values = []
        
        # Hidden layers with sigmoid activation
        for i in range(len(self.hidden_layers)):
            z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
            a = self.sigmoid(z)
            self.z_values.append(z)
            self.activations.append(a)
        
        # Output layer with softmax activation
        z = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
        a = self.softmax(z)
        self.z_values.append(z)
        self.activations.append(a)
        
        return a
    
    def backward(self, X, y, learning_rate):
        m = X.shape[0]
        deltas = []
        
        # Output layer error
        error = self.activations[-1] - y
        delta = error  # For softmax with cross-entropy
        deltas.insert(0, delta)
        
        # Backpropagate through hidden layers
        for i in range(len(self.hidden_layers), 0, -1):
            error = np.dot(deltas[0], self.weights[i].T)
            delta = error * self.sigmoid_derivative(self.activations[i])
            deltas.insert(0, delta)
        
        # Update weights and biases
        for i in range(len(self.weights)):
            dw = np.dot(self.activations[i].T, deltas[i]) / m
            db = np.sum(deltas[i], axis=0) / m
            self.weights[i] -= learning_rate * dw
            self.biases[i] -= learning_rate * db
    
    def train(self, X_train, y_train, X_val, y_val, epochs, batch_size, learning_rate):
        n_samples = X_train.shape[0]
        n_batches = n_samples // batch_size
        
        train_loss_history = []
        val_loss_history = []
        train_acc_history = []
        val_acc_history = []
        
        for epoch in range(epochs):
            # Shuffle data
            permutation = np.random.permutation(n_samples)
            X_shuffled = X_train[permutation]
            y_shuffled = y_train[permutation]
            
            epoch_loss = 0
            
            for i in range(n_batches):
                # Get mini-batch
                start = i * batch_size
                end = start + batch_size
                X_batch = X_shuffled[start:end]
                y_batch = y_shuffled[start:end]
                
                # Forward pass
                output = self.forward(X_batch)
                
                # Compute loss
                loss = -np.mean(np.sum(y_batch * np.log(output + 1e-15), axis=1))
                epoch_loss += loss
                
                # Backward pass
                self.backward(X_batch, y_batch, learning_rate)
            
            # Calculate average epoch loss
            epoch_loss /= n_batches
            train_loss_history.append(epoch_loss)
            
            # Calculate validation loss
            val_output = self.forward(X_val)
            val_loss = -np.mean(np.sum(y_val * np.log(val_output + 1e-15), axis=1))
            val_loss_history.append(val_loss)
            
            # Calculate accuracies
            train_pred = np.argmax(self.forward(X_train), axis=1)
            train_true = np.argmax(y_train, axis=1)
            train_acc = np.mean(train_true == train_pred)
            train_acc_history.append(train_acc)
            
            val_pred = np.argmax(val_output, axis=1)
            val_true = np.argmax(y_val, axis=1)
            val_acc = np.mean(val_true == val_pred)
            val_acc_history.append(val_acc)
            
            print(f"Epoch {epoch+1}/{epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, "
                  f"Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}")
            # Early stopping based on validation loss
            if epoch &gt; 1 and abs(val_loss_history[-1] - val_loss_history[-2]) &lt; 1e-4:
                print(f"Early stopping at epoch {epoch+1} due to minimal change in validation loss.")
                break

        
        return train_loss_history, val_loss_history, train_acc_history, val_acc_history
    
    def predict(self, X):
        return np.argmax(self.forward(X), axis=1)

def one_hot_encode(y, num_classes):
    """Manual one-hot encoding implementation"""
    y_onehot = np.zeros((len(y), num_classes))
    y_onehot[np.arange(len(y)), y.flatten()] = 1
    return y_onehot

def calculate_metrics(true_labels, pred_labels, num_classes):
    """Calculate precision, recall, and F1 score for each class"""
    metrics = defaultdict(lambda: {'tp': 0, 'fp': 0, 'fn': 0})
    
    for true, pred in zip(true_labels, pred_labels):
        if true == pred:
            metrics[true]['tp'] += 1
        else:
            metrics[true]['fn'] += 1
            metrics[pred]['fp'] += 1
    
    results = {}
    for class_id in range(num_classes):
        tp = metrics[class_id]['tp']
        fp = metrics[class_id]['fp']
        fn = metrics[class_id]['fn']
        
        precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0
        recall = tp / (tp + fn) if (tp + fn) &gt; 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) &gt; 0 else 0
        
        results[class_id] = {
            'precision': precision,
            'recall': recall,
            'f1': f1
        }
    
    return results

def load_data(train_path, test_path, test_labels_path):
    # Load training data
    X_train = []
    y_train = []
    
    for label in range(43):
        folder = os.path.join(train_path, f"{label:05d}")
        for file in os.listdir(folder):
            if file.endswith('.jpg'):
                img = Image.open(os.path.join(folder, file))
                img = img.resize((28, 28))
                img_array = np.array(img).flatten() / 255.0
                X_train.append(img_array)
                y_train.append(label)
    
    X_train = np.array(X_train)
    y_train = np.array(y_train).reshape(-1, 1)
    
    # Manual one-hot encoding
    y_train = one_hot_encode(y_train, 43)
    
    # Load test data
    test_df = pd.read_csv(test_labels_path)
    X_test = []
    y_test = []
    
    for _, row in test_df.iterrows():
        img = Image.open(os.path.join(test_path, row['image']))
        img = img.resize((28, 28))
        img_array = np.array(img).flatten() / 255.0
        X_test.append(img_array)
        y_test.append(row['label'])
    
    X_test = np.array(X_test)
    y_test = np.array(y_test).reshape(-1, 1)
    y_test = one_hot_encode(y_test, 43)
    
    return X_train, y_train, X_test, y_test

def run_experiment(hidden_layers, train_data_path, test_data_path, output_folder_path, test_labels_path):
    # Load data
    X_train, y_train, X_test, y_test = load_data(train_data_path, test_data_path, test_labels_path)
    
    # Split training data into train and validation (80-20 split)
    n_samples = X_train.shape[0]
    indices = np.random.permutation(n_samples)
    split = int(0.8 * n_samples)
    
    X_train_split = X_train[indices[:split]]
    y_train_split = y_train[indices[:split]]
    X_val = X_train[indices[split:]]
    y_val = y_train[indices[split:]]
    
    # Initialize neural network
    input_size = 28 * 28 * 3  # 2352
    output_size = 43
    
    nn = NeuralNetwork(input_size, hidden_layers, output_size)
    
    # Train the network
    epochs = 150
    batch_size = 32
    learning_rate = 0.01
    
    print(f"\nTraining network with architecture: {hidden_layers}")
    train_loss, val_loss, train_acc, val_acc = nn.train(
        X_train_split, y_train_split, X_val, y_val, 
        epochs, batch_size, learning_rate
    )
    
    # Evaluate on test set
    test_pred = nn.predict(X_test)
    test_true = np.argmax(y_test, axis=1)
    test_acc = np.mean(test_true == test_pred)
    print(f"Test Accuracy with architecture {hidden_layers}: {test_acc:.4f}")
    
    # Calculate metrics
    train_pred = nn.predict(X_train)
    train_true = np.argmax(y_train, axis=1)
    
    train_metrics = calculate_metrics(train_true, train_pred, 43)
    test_metrics = calculate_metrics(test_true, test_pred, 43)
    
    # Calculate average F1 scores
    avg_train_f1 = np.mean([metrics['f1'] for metrics in train_metrics.values()])
    avg_test_f1 = np.mean([metrics['f1'] for metrics in test_metrics.values()])

    avg_train_precision = np.mean([metrics['precision'] for metrics in train_metrics.values()])
    avg_train_recall = np.mean([metrics['recall'] for metrics in train_metrics.values()])
    avg_test_precision = np.mean([metrics['precision'] for metrics in test_metrics.values()])
    avg_test_recall = np.mean([metrics['recall'] for metrics in test_metrics.values()])

    # Print metrics as tables

    
    print(f"Average Train F1 Score: {avg_train_f1:.4f}")
    print(f"Average Test F1 Score: {avg_test_f1:.4f}")

    print(f"Average Train Precision: {avg_train_precision:.4f}")
    print(f"Average Train Recall: {avg_train_recall:.4f}")

    print(f"Average Test Precision: {avg_test_precision:.4f}")
    print(f"Average Test Recall: {avg_test_recall:.4f}")
    
    # Save predictions
    arch_name = '_'.join(map(str, hidden_layers))
    predictions = pd.DataFrame({'prediction': test_pred})
    predictions.to_csv(os.path.join(output_folder_path, f'prediction_c_{arch_name}.csv'), index=False)
    
    return avg_train_f1, avg_test_f1, len(hidden_layers)

def main(train_data_path, test_data_path, output_folder_path, test_labels_path):
    architectures = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]
    
    train_f1_scores = []
    test_f1_scores = []
    depths = []
    
    for arch in architectures:
        avg_train_f1, avg_test_f1, depth = run_experiment(
            arch, train_data_path, test_data_path, 
            output_folder_path, test_labels_path
        )
        train_f1_scores.append(avg_train_f1)
        test_f1_scores.append(avg_test_f1)
        depths.append(depth)
    
    # Plot F1 scores vs network depth
    plt.figure(figsize=(10, 6))
    plt.plot(depths, train_f1_scores, 'o-', label='Train F1 Score')
    plt.plot(depths, test_f1_scores, 'o-', label='Test F1 Score')
    plt.xlabel('Network Depth (Number of Hidden Layers)')
    plt.ylabel('Average F1 Score')
    plt.title('Average F1 Score vs Network Depth')
    plt.xticks(depths)
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(output_folder_path, 'f1_vs_network_depth.png'))
    plt.close()

if __name__ == "__main__":
    # import argparse
    
    # parser = argparse.ArgumentParser()
    # parser.add_argument('train_data_path', type=str)
    # parser.add_argument('test_data_path', type=str)
    # parser.add_argument('output_folder_path', type=str)
    # parser.add_argument('question_part', type=str)
    
    # args = parser.parse_args()
    
    # # Assuming test_labels.csv is in the test_data_path folder
    # test_labels_path = os.path.join(args.test_data_path, 'test_labels.csv')
    
    # if args.question_part == 'c':
    #     main(args.train_data_path, args.test_data_path, args.output_folder_path, test_labels_path)

    train_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/train"
    test_data_path="/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test"
    output_folder_path=""
    
    # Assuming test_labels.csv is in the test_data_path folder
    test_labels_path = "/home/hunter/Downloads/Acads/COL774/Assignment 3/B_data/test_labels.csv"
    
    main(train_data_path, test_data_path, output_folder_path, test_labels_path)

</PRE>
</PRE>
</BODY>
</HTML>
