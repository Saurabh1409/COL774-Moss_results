<HTML>
<HEAD>
<TITLE>./A3_processed_new_hash/combined_Q0XYE.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A3_processed_new_hash/combined_Z4Z0A.py<p><PRE>


import pandas as pd
import numpy as np
from collections import Counter
import matplotlib.pyplot as plt
from collections import defaultdict
import sys

#############################
# Part A: Decision Tree Construction
#############################

class Node:
    def __init__(self):
        self.split_feature = None
        self.split_value = None  # For numerical features (median value)
        self.categories = None  # For categorical features (list of unique values)
        self.children = {}      # For storing child nodes: keys 'left'/'right' for numeric, or category values for categorical
        self.label = None       # If leaf, stores the class label
        self.current_labels = None  # Labels of instances at this node (used for unknown categorical values)

class DecisionTree:
    def __init__(self, max_depth=5):
        self.max_depth = max_depth
        self.root = Node()
        self.numerical_features = ['age', 'fnlwgt', 'education.num', 
                                   'capital.gain', 'capital.loss', 'hours.per.week']
        self.categorical_features = ['workclass', 'education', 'marital.status',
                                     'occupation', 'relationship', 'race', 
                                     'sex', 'native.country']
        
    def _entropy(self, y):
        counts = Counter(y)
        proportions = [cnt/len(y) for cnt in counts.values()]
        return -sum(p * np.log2(p) for p in proportions if p &gt; 0)
    
    def _information_gain(self, parent, splits):
        total = sum(len(split) for split in splits)
        remainder = sum((len(s)/total) * self._entropy(s) for s in splits)
        return self._entropy(parent) - remainder
    
    def _best_split(self, X, y):
        best_gain = -1
        best_feature = None
        best_split = None
        
        for feature in X.columns:
            if feature in self.numerical_features:
                # Numerical feature: split at median
                median = X[feature].median()
                left_mask = X[feature] &lt;= median
                splits = [y[left_mask], y[~left_mask]]
                gain = self._information_gain(y, splits)
                
                if gain &gt; best_gain:
                    best_gain = gain
                    best_feature = feature
                    best_split = median
            else:
                # Categorical feature: k-way split based on unique values
                unique_vals = X[feature].unique()
                splits = [y[X[feature] == val] for val in unique_vals]
                if len(splits) &gt; 1:
                    gain = self._information_gain(y, splits)
                    if gain &gt; best_gain:
                        best_gain = gain
                        best_feature = feature
                        best_split = unique_vals
                        
        return best_feature, best_split
    
    def _grow_tree(self, node, X, y, depth):
        # print(f"[Tree Growth] Depth {depth} | {len(y)} samples")
        node.current_labels = y.tolist()  # store current labels at the node
        
        # Base cases
        if len(y) == 0:
            node.label = 0  # default fallback class if no samples
            print("[Leaf] Empty node. Fallback label 0.")
            return
        
        if depth &gt;= self.max_depth or len(set(y)) == 1:
            node.label = Counter(y).most_common(1)[0][0]
            # print(f"[Leaf] Reached max depth or pure node. Label set to {node.label}")
            return

        feature, split_val = self._best_split(X, y)
        if feature is None:
            node.label = Counter(y).most_common(1)[0][0]
            # print(f"[Leaf] No good split found. Label set to {node.label}")
            return

        node.split_feature = feature
        # print(f"[Split] Feature: {feature} at depth {depth}")

        if feature in self.numerical_features:
            node.split_value = split_val
            left_mask = X[feature] &lt;= split_val
            right_mask = ~left_mask

            # Left child
            node.children['left'] = Node()
            if left_mask.any():
                self._grow_tree(node.children['left'], X[left_mask], y[left_mask], depth+1)
            else:
                node.children['left'].label = Counter(y).most_common(1)[0][0]
                # print(f"[Leaf] No samples for left child. Using parent's majority label.")

            # Right child
            node.children['right'] = Node()
            if right_mask.any():
                self._grow_tree(node.children['right'], X[right_mask], y[right_mask], depth+1)
            else:
                node.children['right'].label = Counter(y).most_common(1)[0][0]
                # print(f"[Leaf] No samples for right child. Using parent's majority label.")
        
        else:
            # Categorical feature: k-way split
            node.categories = split_val
            for category in split_val:
                mask = X[feature] == category
                child = Node()
                node.children[category] = child
                if mask.any():
                    # print(f"[Categorical Split] Creating child for category '{category}' with {mask.sum()} samples")
                    self._grow_tree(child, X[mask], y[mask], depth+1)
                else:
                    child.label = Counter(y).most_common(1)[0][0]
                    # print(f"[Leaf] Category '{category}' has no samples. Using parent's majority label.")
    
    def fit(self, X, y):
        # print(f"[Fit] Training Decision Tree with max depth {self.max_depth}")
        self._grow_tree(self.root, X, y, 0)
        
    def _predict_sample(self, sample, node, path):
        path.append(node)
        if node.label is not None:
            return node.label
        
        feature = node.split_feature
        if feature in self.numerical_features:
            if sample[feature] &lt;= node.split_value:
                return self._predict_sample(sample, node.children['left'], path)
            else:
                return self._predict_sample(sample, node.children['right'], path)
        else:
            category = sample[feature]
            if category in node.children:
                return self._predict_sample(sample, node.children[category], path)
            else:
                return Counter(node.current_labels).most_common(1)[0][0]
    
    def predict(self, X):
        predictions = []
        for index, row in X.iterrows():
            path = []
            pred = self._predict_sample(row, self.root, path)
            predictions.append(pred)
        return predictions

#############################
# Part B: One-Hot Encoding Decision Tree
#############################

# For one-hot encoding, we will transform categorical features that have more than 2 categories.
# We use pandas.get_dummies on the required columns.
def one_hot_encode_df(df, categorical_features):
    print("[One-Hot Encoding] Transforming categorical features using one-hot encoding...")
    # You may choose to exclude features with only 2 categories if desired.
    df_encoded = pd.get_dummies(df, columns=categorical_features, drop_first=False)
    return df_encoded

# We can reuse the DecisionTree class for one-hot encoded data.
# In practice, the features become all numerical (0/1) so we update the list accordingly.
class OHE_DecisionTree(DecisionTree):
    def __init__(self, max_depth=5):
        # When data is one-hot encoded, all features are numerical.
        super().__init__(max_depth)
        self.numerical_features = None  # we will set this after fitting based on the dataframe columns
        self.categorical_features = []  # none left after one-hot encoding

    def fit(self, X, y):
        self.numerical_features = list(X.columns)  # all features are numeric now
        print(f"[Fit OHE] Training OHE Decision Tree with max depth {self.max_depth}")
        super().fit(X, y)

#############################
# Part C: Post-Pruning Implementation
#############################

import copy

class PrunableDecisionTree(OHE_DecisionTree):
    def __init__(self, max_depth=5):
        super().__init__(max_depth)
        self.node_id = 0
        
    def clone(self):
        """Create a deep copy of the tree instance"""
        return copy.deepcopy(self)
    
    def _grow_tree(self, node, X, y, depth):
        node.id = self.node_id
        self.node_id += 1
        super()._grow_tree(node, X, y, depth)

def post_prune(tree, X_val, y_val, X_train, y_train, X_test, y_test):
    print("\n[Post-Pruning] Starting optimized pruning process...")
    pruned_tree = tree.clone()
    
    # Get validation paths and predictions
    val_paths, val_preds = get_validation_paths(pruned_tree, X_val)
    current_acc = np.mean(np.array(val_preds) == np.array(y_val))
    print(f"Initial validation accuracy: {current_acc:.4f}")
    
    # Metrics for plotting
    train_accs = []
    val_accs = []
    test_accs = []
    nodes_count = []
    
    def count_nodes(node):
        if node.label is not None:
            return 1
        return 1 + sum(count_nodes(child) for child in node.children.values())
    
    train_accs.append(np.mean(np.array(pruned_tree.predict(X_train)) == np.array(y_train)))
    val_accs.append(current_acc)
    test_accs.append(np.mean(np.array(pruned_tree.predict(X_test)) == np.array(y_test)))
    nodes_count.append(count_nodes(pruned_tree.root))
    
    # Build initial node statistics
    node_stats = build_node_stats(pruned_tree.root, val_paths, y_val, val_preds)
    
    iteration = 0
    while True:
        iteration += 1
        print(f"\n[Pruning Iteration {iteration}]")
        
        best_node = None
        best_delta = 0
        
        # Identify the best candidate node to prune
        for node in node_stats:
            stats = node_stats[node]
            if stats['prunable']:
                delta = stats['leaf_correct'] - stats['current_correct']
                if delta &gt; best_delta:
                    best_delta = delta
                    best_node = node
        
        if best_node is None or best_delta &lt;= 0:
            print("No more beneficial nodes to prune")
            break
            
        print(f"Pruning node {best_node.id} with delta {best_delta}")
        best_node.children = {}
        best_node.label = Counter(best_node.current_labels).most_common(1)[0][0]
        
        # Update predictions for samples affected by this prune
        affected_samples = node_stats[best_node]['samples']
        update_predictions(val_preds, affected_samples, best_node.label, y_val)
        
        # Recalculate node statistics
        node_stats = build_node_stats(pruned_tree.root, val_paths, y_val, val_preds)
        
        new_acc = np.mean(np.array(val_preds) == np.array(y_val))
        print(f"New validation accuracy: {new_acc:.4f}")
        if new_acc &gt;= current_acc:
            current_acc = new_acc
            train_accs.append(np.mean(np.array(pruned_tree.predict(X_train)) == np.array(y_train)))
            val_accs.append(new_acc)
            test_accs.append(np.mean(np.array(pruned_tree.predict(X_test)) == np.array(y_test)))
            nodes_count.append(count_nodes(pruned_tree.root))
        else:
            print("Accuracy decreased, stopping pruning")
            break
            
    print(f"[Prune Tree] Final validation accuracy after pruning: {current_acc:.4f}")
    return pruned_tree, (train_accs, val_accs, test_accs, nodes_count)

def get_validation_paths(tree, X_val):
    paths = []
    preds = []
    for idx, row in X_val.iterrows():
        path = []
        pred = tree._predict_sample(row, tree.root, path)
        paths.append(path)
        preds.append(pred)
    return paths, preds

def build_node_stats(root, val_paths, y_val, val_preds):
    node_stats = {}
    node_samples = defaultdict(list)
    
    for sample_idx, path in enumerate(val_paths):
        for node in path:
            node_samples[node].append(sample_idx)
    
    for node in node_samples:
        samples = node_samples[node]
        current_correct = sum(1 for s in samples if val_preds[s] == y_val.iloc[s])
        majority_class = Counter(node.current_labels).most_common(1)[0][0]
        leaf_correct = sum(1 for s in samples if majority_class == y_val.iloc[s])
        prunable = all(child.label is not None for child in node.children.values()) if node.children else False
        node_stats[node] = {
            'samples': samples,
            'current_correct': current_correct,
            'leaf_correct': leaf_correct,
            'prunable': prunable
        }
    
    return node_stats

def update_predictions(preds, sample_indices, new_label, y_true):
    for idx in sample_indices:
        preds[idx] = new_label

#############################
# Main: Load Data and Run Parts A, B, and C
#############################

def main():
    train_address = sys.argv[1]
    valid_address = sys.argv[2]
    test_address  = sys.argv[3]
    output_folder = sys.argv[4]
    qeustion_part = sys.argv[5]

    # Load the datasets
    print("[Data] Loading train.csv, valid.csv, and test.csv ...")
    train_df = pd.read_csv(train_address)
    valid_df = pd.read_csv(valid_address)
    test_df  = pd.read_csv(test_address)

    # Assume the target column is named 'income' where &gt;50K is positive (we map to 1) and &lt;=50K to 0.
    target_map = {"&gt;50K": 1, "&lt;=50K": 0}
    train_df['income'] = train_df['income'].str.strip().map(target_map)
    valid_df['income'] = valid_df['income'].str.strip().map(target_map)
    test_df['income']  = test_df['income'].str.strip().map(target_map)

    # Separate features and target
    X_train = train_df.drop("income", axis=1)
    y_train = train_df["income"]
    X_valid = valid_df.drop("income", axis=1)
    y_valid = valid_df["income"]
    X_test  = test_df.drop("income", axis=1)
    y_test  = test_df["income"]

    #############################
    # Part A Execution
    #############################
    if qeustion_part == 'a':
        depths_a = [5, 10, 15, 20]
        train_accuracies_a = []
        test_accuracies_a = []
        print("\n=====================")
        print("PART A: Decision Tree Construction")
        print("=====================")
        for depth in depths_a:
            print(f"\n[Part A] Training Decision Tree with max depth {depth}")
            tree = DecisionTree(max_depth=depth)
            tree.fit(X_train, y_train)
            train_pred = tree.predict(X_train)
            test_pred  = tree.predict(X_test)
            train_acc = np.mean(np.array(train_pred) == np.array(y_train))
            test_acc  = np.mean(np.array(test_pred) == np.array(y_test))
            train_accuracies_a.append(train_acc)
            test_accuracies_a.append(test_acc)
            print(f"[Part A] Max Depth: {depth} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f}")

            if depth == 20:
                final_test_pred = ["&lt;=50K" if pred == 0 else "&gt;50K" for pred in test_pred]
                final_test_df = pd.DataFrame({"prediction": final_test_pred})
                final_test_df.to_csv(f"{output_folder}/prediction_a.csv", index=False)

        # plt.figure(figsize=(8,5))
        # plt.plot(depths_a, train_accuracies_a, marker='o', label="Train Accuracy")
        # plt.plot(depths_a, test_accuracies_a, marker='s', label="Test Accuracy")
        # plt.xlabel("Max Depth")
        # plt.ylabel("Accuracy")
        # plt.title("Part A: Accuracy vs. Max Depth")
        # plt.legend()
        # plt.show()

    if qeustion_part == 'b' or qeustion_part == 'c':
        categorical_features = ['workclass', 'education', 'marital.status',
                                'occupation', 'relationship', 'race', 
                                'sex', 'native.country']
        
        # Strip whitespace first
        for col in categorical_features:
            train_df[col] = train_df[col].str.strip()
            valid_df[col] = valid_df[col].str.strip()
            test_df[col]  = test_df[col].str.strip()
        
        # One-hot encode datasets (ensure you drop the target column if needed)
        X_train_ohe = one_hot_encode_df(train_df.drop("income", axis=1), categorical_features)
        X_valid_ohe = one_hot_encode_df(valid_df.drop("income", axis=1), categorical_features)
        X_test_ohe  = one_hot_encode_df(test_df.drop("income", axis=1), categorical_features)
        
        # Reindex validation and test sets to match training set columns
        X_valid_ohe = X_valid_ohe.reindex(columns=X_train_ohe.columns, fill_value=0)
        X_test_ohe = X_test_ohe.reindex(columns=X_train_ohe.columns, fill_value=0)
        
        if qeustion_part == 'b':
            depths_b = [25, 35, 45, 55]
            train_accuracies_b = []
            test_accuracies_b = []
            print("\n=====================")
            print("PART B: One-Hot Encoding Decision Tree")
            print("=====================")
            for depth in depths_b:
                print(f"\n[Part B] Training OHE Decision Tree with max depth {depth}")
                ohe_tree = OHE_DecisionTree(max_depth=depth)
                ohe_tree.fit(X_train_ohe, y_train)
                train_pred = ohe_tree.predict(X_train_ohe)
                test_pred  = ohe_tree.predict(X_test_ohe)
                train_acc = np.mean(np.array(train_pred) == np.array(y_train))
                test_acc  = np.mean(np.array(test_pred) == np.array(y_test))
                train_accuracies_b.append(train_acc)
                test_accuracies_b.append(test_acc)
                print(f"[Part B] Max Depth: {depth} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f}")

                if depth == 55:
                    final_test_pred = ["&lt;=50K" if pred == 0 else "&gt;50K" for pred in test_pred]
                    final_test_df = pd.DataFrame({"prediction": final_test_pred})
                    final_test_df.to_csv(f"{output_folder}/prediction_b.csv", index=False)

        if qeustion_part == 'c':
            depths_c = [25, 35, 45, 55]
            print("\n=====================")
            print("PART C: Post-Pruning")
            print("=====================")
            
            for depth in depths_c:
                print(f"\n[Part C] Processing post-pruning for OHE Decision Tree with max depth {depth}")
                
                # Build the prunable tree for the current depth
                prunable_tree = PrunableDecisionTree(max_depth=depth)
                prunable_tree.fit(X_train_ohe, y_train)
                
                print(f"[Part C] Starting post-pruning using validation set for tree with max depth {depth}")
                pruned_tree, (train_acc_list, val_acc_list, test_acc_list, nodes_list) = post_prune(
                    prunable_tree, X_valid_ohe, y_valid, X_train_ohe, y_train, X_test_ohe, y_test
                )

                print(f"[Part C] Final validation accuracy after pruning: {val_acc_list[-1]:.4f}")
                test_pred = pruned_tree.predict(X_test_ohe)

                if depth == 55:
                    final_test_pred = ["&lt;=50K" if pred == 0 else "&gt;50K" for pred in test_pred]
                    final_test_df = pd.DataFrame({"prediction": final_test_pred})
                    final_test_df.to_csv(f"{output_folder}/prediction_c.csv", index=False)
                
                # # Plot training, validation, and test accuracies vs. number of nodes
                # plt.figure(figsize=(10,6))
                # plt.plot(nodes_list, train_acc_list, marker='o', label="Train Accuracy")
                # plt.plot(nodes_list, val_acc_list, marker='s', label="Validation Accuracy")
                # plt.plot(nodes_list, test_acc_list, marker='^', label="Test Accuracy")
                # plt.xlabel("Number of Nodes (approx.)")
                # plt.ylabel("Accuracy")
                # plt.title(f"Part C: Accuracy vs. Number of Nodes After Post-Pruning (Depth {depth})")
                # plt.legend()
                # plt.show()

    #############################
    # Part B Execution: One-Hot Encoding Decision Tree
    #############################
    # depths_b = [25, 35, 45, 55]
    # print("\n=====================")
    # print("PART B: One-Hot Encoding Decision Tree")
    # print("=====================")
    # Identify categorical features
    # One-hot encode each dataset after stripping whitespace.


    # train_accuracies_b = []
    # test_accuracies_b = []
    # for depth in depths_b:
    #     print(f"\n[Part B] Training OHE Decision Tree with max depth {depth}")
    #     ohe_tree = OHE_DecisionTree(max_depth=depth)
    #     ohe_tree.fit(X_train_ohe, y_train)
    #     train_pred = ohe_tree.predict(X_train_ohe)
    #     test_pred  = ohe_tree.predict(X_test_ohe)
    #     train_acc = np.mean(np.array(train_pred) == np.array(y_train))
    #     test_acc  = np.mean(np.array(test_pred) == np.array(y_test))
    #     train_accuracies_b.append(train_acc)
    #     test_accuracies_b.append(test_acc)
    #     print(f"[Part B] Max Depth: {depth} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f}")

    # plt.figure(figsize=(8,5))
    # plt.plot(depths_b, train_accuracies_b, marker='o', label="Train Accuracy")
    # plt.plot(depths_b, test_accuracies_b, marker='s', label="Test Accuracy")
    # plt.xlabel("Max Depth")
    # plt.ylabel("Accuracy")
    # plt.title("Part B: Accuracy vs. Max Depth (One-Hot Encoding)")
    # plt.legend()
    # plt.show()

    if qeustion_part == 'd' or qeustion_part == 'e':
        import pandas as pd
        from sklearn.preprocessing import OneHotEncoder
        from sklearn.tree import DecisionTreeClassifier
        from sklearn.metrics import accuracy_score
        import matplotlib.pyplot as plt

        # Load datasets
        train = train_df
        valid = valid_df
        test = test_df

        def preprocess(df):
            # Clean income column
            df['income'] = df['income'].astype(str).str.strip().str.upper()
            
            # Handle unexpected values
            valid_incomes = {'&lt;=50K', '&gt;50K'}
            mask = df['income'].isin(valid_incomes)
            
            if not mask.all():
                print(f"Found {len(df) - mask.sum()} invalid income entries:")
                print(df[~mask]['income'].unique())
                df = df[mask].copy()
            
            X = df.drop(columns=['income'])
            y = df['income'].map({'&lt;=50K': 0, '&gt;50K': 1}).astype(int)
            return X, y

        # Verify preprocessing
        X_train, y_train = preprocess(train)
        print("\nUnique income values in training:", y_train.unique())

        X_valid, y_valid = preprocess(valid)
        print("Unique income values in validation:", y_valid.unique())

        X_test, y_test = preprocess(test)
        print("Unique income values in testing:", y_test.unique())

        # One-hot encode categorical features (to match part b)
        cat_cols = X_train.select_dtypes(include='object').columns
        ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)
        X_train_ohe = pd.DataFrame(
            ohe.fit_transform(X_train[cat_cols]),
            columns=ohe.get_feature_names_out(cat_cols)  # Get proper feature names
        )
        X_valid_ohe = pd.DataFrame(
            ohe.transform(X_valid[cat_cols]),
            columns=ohe.get_feature_names_out(cat_cols)
        )
        X_test_ohe = pd.DataFrame(
            ohe.transform(X_test[cat_cols]),
            columns=ohe.get_feature_names_out(cat_cols)
        )

        # Convert numerical column names to strings
        num_cols = [str(col) for col in X_train.select_dtypes(exclude='object').columns]

        # Create final DataFrames with all string column names
        X_train_full = pd.concat([
            X_train[num_cols].reset_index(drop=True),
            X_train_ohe.rename(columns=str)  # Ensure all columns are strings
        ], axis=1)

        X_valid_full = pd.concat([
            X_valid[num_cols].reset_index(drop=True),
            X_valid_ohe.rename(columns=str)
        ], axis=1)

        X_test_full = pd.concat([
            X_test[num_cols].reset_index(drop=True),
            X_test_ohe.rename(columns=str)
        ], axis=1)

        # (i) Vary max_depth
        depths = [25, 35, 45, 55]
        train_acc, valid_acc, test_acc = [], [], []

        for depth in depths:
            clf = DecisionTreeClassifier(criterion='entropy', max_depth=depth)
            clf.fit(X_train_full, y_train)
            
            train_acc.append(accuracy_score(y_train, clf.predict(X_train_full)))
            valid_acc.append(accuracy_score(y_valid, clf.predict(X_valid_full)))
            test_acc.append(accuracy_score(y_test, clf.predict(X_test_full)))

            if depth == 25 and qeustion_part == 'd':
                test_pred = clf.predict(X_test_full)
                final_test_pred = ["&lt;=50K" if pred == 0 else "&gt;50K" for pred in test_pred]
                final_test_df = pd.DataFrame({"prediction": final_test_pred})
                final_test_df.to_csv(f"{output_folder}/prediction_d.csv", index=False)

        # (ii) Cost-complexity pruning
        full_tree = DecisionTreeClassifier(criterion='entropy')
        path = full_tree.cost_complexity_pruning_path(X_train_full, y_train)
        ccp_alphas = [0.001, 0.01, 0.1, 0.2]

        train_acc_ccp, valid_acc_ccp, test_acc_ccp = [], [], []

        for ccp_alpha in ccp_alphas:
            clf = DecisionTreeClassifier(criterion='entropy', ccp_alpha=ccp_alpha)
            clf.fit(X_train_full, y_train)
            
            train_acc_ccp.append(accuracy_score(y_train, clf.predict(X_train_full)))
            valid_acc_ccp.append(accuracy_score(y_valid, clf.predict(X_valid_full)))
            test_acc_ccp.append(accuracy_score(y_test, clf.predict(X_test_full)))

        if qeustion_part == 'e':

            from sklearn.ensemble import RandomForestClassifier
            from sklearn.model_selection import ParameterGrid
            from sklearn.metrics import accuracy_score
            import pandas as pd

            # Define parameter grid
            param_grid = {
                'n_estimators': [50, 150, 250, 350],
                'max_features': [0.1, 0.3, 0.5, 0.7, 0.9, 1.0],
                'min_samples_split': [2, 4, 6, 8, 10]
            }

            results = []

            # Grid search with OOB scoring
            for params in ParameterGrid(param_grid):
                rf = RandomForestClassifier(
                    criterion='entropy',
                    oob_score=True,
                    random_state=42,
                    n_jobs=-1,
                    **params
                )
                rf.fit(X_train_full, y_train)
                
                # Calculate metrics
                train_acc = accuracy_score(y_train, rf.predict(X_train_full))
                oob_acc = rf.oob_score_
                valid_acc = accuracy_score(y_valid, rf.predict(X_valid_full))
                test_acc = accuracy_score(y_test, rf.predict(X_test_full))
                
                results.append({
                    **params,
                    'train_acc': train_acc,
                    'oob_acc': oob_acc,
                    'valid_acc': valid_acc,
                    'test_acc': test_acc
                })

            # Find best model based on OOB score
            results_df = pd.DataFrame(results)
            best_idx = results_df['oob_acc'].idxmax()
            best_params = results_df.loc[best_idx]

            # Train final model with best parameters
            final_rf = RandomForestClassifier(
                criterion='entropy',
                oob_score=True,
                random_state=42,
                n_jobs=-1,
                n_estimators=int(best_params['n_estimators']),
                max_features=float(best_params['max_features']),
                min_samples_split=int(best_params['min_samples_split'])
            )
            final_rf.fit(X_train_full, y_train)

            print("Optimal Parameters:")
            print(best_params[['n_estimators', 'max_features', 'min_samples_split']])

            test_pred = final_rf.predict(X_test_full)
            final_test_pred = ["&lt;=50K" if pred == 0 else "&gt;50K" for pred in test_pred]
            final_test_df = pd.DataFrame({"prediction": final_test_pred})
            final_test_df.to_csv(f"{output_folder}/prediction_e.csv", index=False)

            
    ############################


if __name__ == '__main__':
    main()




import sys 

train_dir = sys.argv[1]
valid_dir = sys.argv[2]
test_dir = sys.argv[3]
output_folder = sys.argv[4]
question_part = sys.argv[5]

if question_part == "b":

    import numpy as np
    import os
    from PIL import Image
    import pandas as pd
    from sklearn.preprocessing import OneHotEncoder
    from sklearn.metrics import precision_score, recall_score, f1_score
    import matplotlib.pyplot as plt

    class NeuralNetwork:
        def __init__(self, input_size, hidden_arch, output_size, batch_size=32):
            self.input_size = input_size
            self.hidden_arch = hidden_arch
            self.output_size = output_size
            self.batch_size = batch_size
            
            # Initialize parameters
            self.weights = []
            self.biases = []
            layers = [input_size] + hidden_arch + [output_size]
            self.last = None
            
            for i in range(len(layers)-1):
                self.weights.append(np.random.randn(layers[i], layers[i+1]) * np.sqrt(2. / layers[i]))
                self.biases.append(np.zeros((1, layers[i+1])))
        
        def sigmoid(self, x):
            return 1 / (1 + np.exp(-x))

        def sigmoid_derivative(self, x):
            return self.sigmoid(x) * (1 - self.sigmoid(x))

        def softmax(self, x):
            exps = np.exp(x - np.max(x, axis=1, keepdims=True))
            return exps / np.sum(exps, axis=1, keepdims=True)

        def forward(self, X):
            self.activations = [X]
            self.z_values = []
            
            # Hidden layers
            for i in range(len(self.hidden_arch)):
                z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
                self.z_values.append(z)
                self.activations.append(self.sigmoid(z))
            
            # Output layer
            z_out = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
            self.z_values.append(z_out)
            output = self.softmax(z_out)
            self.activations.append(output)
            
            return output

        def compute_loss(self, y_true):
            m = y_true.shape[0]
            log_likelihood = -np.log(self.activations[-1] + 1e-8) * y_true
            return np.sum(log_likelihood) / m

        def backward(self, X, y_true):
            m = X.shape[0]
            gradients_w = []
            gradients_b = []
            
            # Output layer gradient
            delta = (self.activations[-1] - y_true) / m
            gradients_w.append(np.dot(self.activations[-2].T, delta))
            gradients_b.append(np.sum(delta, axis=0, keepdims=True))
            
            # Hidden layers gradients
            for l in range(len(self.hidden_arch)-1, -1, -1):
                delta = np.dot(delta, self.weights[l+1].T) * self.sigmoid_derivative(self.z_values[l])
                gradients_w.insert(0, np.dot(self.activations[l].T, delta))
                gradients_b.insert(0, np.sum(delta, axis=0, keepdims=True))
            
            return gradients_w, gradients_b

        def update_parameters(self, gradients_w, gradients_b, learning_rate):
            for i in range(len(self.weights)):
                self.weights[i] -= learning_rate * gradients_w[i]
                self.biases[i] -= learning_rate * gradients_b[i]

        def train(self, X, y, learning_rate=0.01, epochs=1000, verbose=True):
            encoder = OneHotEncoder(sparse_output=False)
            y_onehot = encoder.fit_transform(y.reshape(-1, 1))
            
            for epoch in range(epochs):
                # Shuffle data
                permutation = np.random.permutation(X.shape[0])
                X_shuffled = X[permutation]
                y_shuffled = y_onehot[permutation]
                
                for i in range(0, X.shape[0], self.batch_size):
                    # Get mini-batch
<A NAME="1"></A><FONT color = #00FF00><A HREF="match44-0.html#1" TARGET="0"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

                    X_batch = X_shuffled[i:i+self.batch_size]
                    y_batch = y_shuffled[i:i+self.batch_size]
                    
                    # Forward pass
                    self.forward(X_batch)
                    
                    # Backward pass
                    grad_w, grad_b = self.backward(X_batch, y_batch)
</FONT>                    
                    # Update parameters
                    self.update_parameters(grad_w, grad_b, learning_rate)
                
                # Calculate training loss
                output = self.forward(X)
                loss = self.compute_loss(y_onehot)

                # Use a tolerance to stop if loss converges (here, 1% tolerance)
                if self.last is not None and abs(self.last - loss) &lt; loss * 0.001:
                    if verbose:
                        print(f"Converged at epoch {epoch} with Loss = {loss:.4f}")
                    break
                self.last = loss
                
                if epoch % 10 == 0 and verbose:
                    print(f"Epoch {epoch}: Loss = {loss:.4f}")

        def predict(self, X):
            probs = self.forward(X)
            return np.argmax(probs, axis=1)
        
        def accuracy(self, y_true, y_pred):
            recall = recall_score(y_true, y_pred, average='macro')
            precision = precision_score(y_true, y_pred, average='macro')
            f1 = f1_score(y_true, y_pred, average='macro')
            return recall, precision, f1

    def preprocess_image(image_path):
        try:
            img = Image.open(image_path).convert('RGB')
            img = img.resize((28, 28))
            return np.array(img).flatten() / 255.0
        except Exception as e:
            print(f"Error processing {image_path}: {str(e)}")
            return None
        
    # Example usage:
    # Data is images (in jpg format) where they are stored in their respective class directories
    # directory = '/kaggle/input/neural-net/Q2'
    # train_directory = os.path.join(directory, 'train')
    # test_directory = os.path.join(directory, 'test')
    train_directory = train_dir
    test_directory = test_dir
    directory = os.path.dirname(train_directory)
    X_train, y_train = [], []
    X_test, y_test_dict, y_test = [], {}, []

    # Before loading data, check directory existence
    print(f"Train directory exists: {os.path.exists(train_directory)}")
    print(f"Test directory exists: {os.path.exists(test_directory)}")
    
    # Load training data
<A NAME="0"></A><FONT color = #FF0000><A HREF="match44-0.html#0" TARGET="0"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    for class_dir in os.listdir(train_directory):
        class_path = os.path.join(train_directory, class_dir)
        if os.path.isdir(class_path):
            for img_file in os.listdir(class_path):
</FONT>                img_path = os.path.join(class_path, img_file)
                img_data = preprocess_image(img_path)
                if img_data is not None:
                    X_train.append(img_data)
                    y_train.append(int(class_dir))

    test_df = pd.read_csv(os.path.join(directory, 'test_labels.csv'), header=0)
    for index, row in test_df.iterrows():
        y_test_dict[row['image']] = row['label']

    # Load test data
    test_image_count = 0
    for img_file in os.listdir(test_directory):
        img_path = os.path.join(test_directory, img_file)
        if not os.path.isfile(img_path):
            continue
        img_data = preprocess_image(img_path)
        if img_data is not None:
            X_test.append(img_data)
            y_test.append(int(y_test_dict[img_file]))
            test_image_count += 1
                
    print(f"Loaded {test_image_count} test images")

    # Convert lists to numpy arrays and adjust sizes if necessary
    X_train = np.array(X_train)
    y_train = np.array(y_train[:len(X_train)])
    
    X_test = np.array(X_test)
    y_test = np.array(y_test[:len(X_test)])
    
    print(f"Final training data shape: {X_train.shape}")
    print(f"Final test data shape: {X_test.shape}")

#     # --- Uncomment this section if you want to run a simple experiment with a single hidden layer ---
    f1_list = []
    for neuron in [1, 5, 10, 50, 100]:
        nn = NeuralNetwork(input_size=2352, hidden_arch=[neuron], output_size=43, batch_size=32)
        nn.train(X_train, y_train, epochs=1000, learning_rate=0.01)
        y_pred = nn.predict(X_test)
        recall, precision, f1 = nn.accuracy(y_test, y_pred)
        print(f"Neuron {neuron} =&gt; Recall: {recall:.4f}, Precision: {precision:.4f}, F1 Score: {f1:.4f}")
        f1_list.append(f1)
        if neuron == 100:
            test_pred = y_pred
            # convert to prediction.csv
            test_pred_df = pd.DataFrame(test_pred, columns=['prediction'])
            test_pred_df.to_csv(os.path.join(output_folder, 'prediction_b.csv'), index=False)

if question_part == "c":
    import numpy as np
    import os
    from PIL import Image
    import pandas as pd
    from sklearn.preprocessing import OneHotEncoder
    from sklearn.metrics import precision_score, recall_score, f1_score
    import matplotlib.pyplot as plt

    class NeuralNetwork:
        def __init__(self, input_size, hidden_arch, output_size, batch_size=32):
            self.input_size = input_size
            self.hidden_arch = hidden_arch
            self.output_size = output_size
            self.batch_size = batch_size
            
            # Initialize parameters
            self.weights = []
            self.biases = []
            layers = [input_size] + hidden_arch + [output_size]
            self.last_val_accuracy = None  # For convergence checking
            
            for i in range(len(layers)-1):
                self.weights.append(np.random.randn(layers[i], layers[i+1]) * np.sqrt(2. / layers[i]))
                self.biases.append(np.zeros((1, layers[i+1])))
        
        def sigmoid(self, x):
            return 1 / (1 + np.exp(-x))

        def sigmoid_derivative(self, x):
            return self.sigmoid(x) * (1 - self.sigmoid(x))

        def softmax(self, x):
            exps = np.exp(x - np.max(x, axis=1, keepdims=True))
            return exps / np.sum(exps, axis=1, keepdims=True)

        def forward(self, X):
            self.activations = [X]
            self.z_values = []
            
            # Hidden layers
            for i in range(len(self.hidden_arch)):
                z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
                self.z_values.append(z)
                self.activations.append(self.sigmoid(z))
            
            # Output layer
            z_out = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
            self.z_values.append(z_out)
            output = self.softmax(z_out)
            self.activations.append(output)
            
            return output

        def compute_loss(self, y_true):
            m = y_true.shape[0]
            log_likelihood = -np.log(self.activations[-1] + 1e-8) * y_true
            return np.sum(log_likelihood) / m

        def backward(self, X, y_true):
            m = X.shape[0]
            gradients_w = []
            gradients_b = []
            
            # Output layer gradient
            delta = (self.activations[-1] - y_true) / m
            gradients_w.append(np.dot(self.activations[-2].T, delta))
            gradients_b.append(np.sum(delta, axis=0, keepdims=True))
            
            # Hidden layers gradients
            for l in range(len(self.hidden_arch)-1, -1, -1):
                delta = np.dot(delta, self.weights[l+1].T) * self.sigmoid_derivative(self.z_values[l])
                gradients_w.insert(0, np.dot(self.activations[l].T, delta))
                gradients_b.insert(0, np.sum(delta, axis=0, keepdims=True))
            
            return gradients_w, gradients_b

        def update_parameters(self, gradients_w, gradients_b, learning_rate, epoch):
            for i in range(len(self.weights)):
                self.weights[i] -= (learning_rate) * gradients_w[i]
                self.biases[i] -= (learning_rate) * gradients_b[i]

        def train(self, X, y, learning_rate=0.01, epochs=1000, verbose=True, tol=0.01):
            # One-hot encode labels
            encoder = OneHotEncoder(sparse_output=False)
            y_onehot = encoder.fit_transform(y.reshape(-1, 1))
            
            # Split data: 90% training and 10% validation
            n = X.shape[0]
            indices = np.random.permutation(n)
            split_idx = int(0.9 * n)
            X_train_split = X[indices[:split_idx]]
            y_train_split = y_onehot[indices[:split_idx]]
            X_val = X[indices[split_idx:]]
            y_val = y_onehot[indices[split_idx:]]
            
            prev_val_accuracy = None

            best_count = 0
            
            for epoch in range(epochs):
                # Shuffle training split
                permutation = np.random.permutation(X_train_split.shape[0])
                X_train_shuffled = X_train_split[permutation]
                y_train_shuffled = y_train_split[permutation]
                
                # Mini-batch training on the training split
                for i in range(0, X_train_shuffled.shape[0], self.batch_size):
<A NAME="2"></A><FONT color = #0000FF><A HREF="match44-0.html#2" TARGET="0"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

                    X_batch = X_train_shuffled[i:i+self.batch_size]
                    y_batch = y_train_shuffled[i:i+self.batch_size]
                    self.forward(X_batch)
                    grad_w, grad_b = self.backward(X_batch, y_batch)
</FONT>                    self.update_parameters(grad_w, grad_b, learning_rate, epoch+1)
                
                # Evaluate on validation set at the end of the epoch
                val_preds = self.predict(X_val)  # predicted labels
                true_val = np.argmax(y_val, axis=1)
                val_accuracy = np.mean(val_preds == true_val)
                
                if verbose and epoch % 10 == 0:
                    print(f"Epoch {epoch}: Validation Accuracy = {val_accuracy:.4f}")
                
                # Check for convergence using validation accuracy difference
                # if prev_val_accuracy is not None and abs(val_accuracy - prev_val_accuracy) &lt; tol * val_accuracy:
                #     if verbose:
                #         print(f"Converged at epoch {epoch} with Validation Accuracy = {val_accuracy:.4f}")
                #     break

                if prev_val_accuracy is not None:
                    if val_accuracy &gt; prev_val_accuracy:
                        best_count = 0
                    else:
                        best_count += 1
                        if best_count &gt; 10:
                            if verbose:
                                print(f"Early stopping at epoch {epoch} with Validation Accuracy = {val_accuracy:.4f}")
                            break

                prev_val_accuracy = val_accuracy

        def predict(self, X):
            probs = self.forward(X)
            return np.argmax(probs, axis=1)
        
        def accuracy(self, y_true, y_pred):
            recall = recall_score(y_true, y_pred, average='macro')
            precision = precision_score(y_true, y_pred, average='macro')
            f1 = f1_score(y_true, y_pred, average='macro')
            return recall, precision, f1

    def preprocess_image(image_path):
        try:
            img = Image.open(image_path).convert('RGB')
            img = img.resize((28, 28))
            return np.array(img).flatten() / 255.0
        except Exception as e:
            print(f"Error processing {image_path}: {str(e)}")
            return None
        
    
    train_directory = train_dir
    test_directory = test_dir
    directory = os.path.dirname(train_directory)

    X_train, y_train = [], []
    X_test, y_test_dict, y_test = [], {}, []

    # Check directory existence
    print(f"Train directory exists: {os.path.exists(train_directory)}")
    print(f"Test directory exists: {os.path.exists(test_directory)}")
    
    # Load training data
<A NAME="3"></A><FONT color = #00FFFF><A HREF="match44-0.html#3" TARGET="0"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    for class_dir in os.listdir(train_directory):
        class_path = os.path.join(train_directory, class_dir)
        if os.path.isdir(class_path):
            for img_file in os.listdir(class_path):
</FONT>                img_path = os.path.join(class_path, img_file)
                img_data = preprocess_image(img_path)
                if img_data is not None:
                    X_train.append(img_data)
                    y_train.append(int(class_dir))

    test_df = pd.read_csv(os.path.join(directory, 'test_labels.csv'), header=0)
    for index, row in test_df.iterrows():
        y_test_dict[row['image']] = row['label']

    # Load test data
    test_image_count = 0
    for img_file in os.listdir(test_directory):
        img_path = os.path.join(test_directory, img_file)
        if not os.path.isfile(img_path):
            continue
        img_data = preprocess_image(img_path)
        if img_data is not None:
            X_test.append(img_data)
            y_test.append(int(y_test_dict[img_file]))
            test_image_count += 1
                
    print(f"Loaded {test_image_count} test images")

    # Convert lists to numpy arrays
    X_train = np.array(X_train)
    y_train = np.array(y_train[:len(X_train)])
    X_test = np.array(X_test)
    y_test = np.array(y_test[:len(X_test)])
    
    print(f"Final training data shape: {X_train.shape}")
    print(f"Final test data shape: {X_test.shape}")

    # --- Experiment with different hidden layer architectures ---
    hidden_layer_architectures = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]

    # Initialize result lists
    results_f1_scores_train = []
    results_f1_scores_test = []
    
    for architecture in hidden_layer_architectures:
        nn_model = NeuralNetwork(input_size=2352,
                                hidden_arch=architecture,
                                output_size=43,
                                batch_size=32)
        
        # Train using the modified training function with a validation set
        nn_model.train(X_train, y_train, epochs=1000, learning_rate=0.01)
        
        predictions_train = nn_model.predict(X_train)
        predictions_test = nn_model.predict(X_test)
        
        # Compute performance metrics
        _, _, f1_train_avg = nn_model.accuracy(y_train, predictions_train)
        _, _, f1_test_avg = nn_model.accuracy(y_test, predictions_test)
        
        results_f1_scores_train.append(f1_train_avg)
        results_f1_scores_test.append(f1_test_avg)


        if architecture == hidden_layer_architectures[-1]:
            test_pred = predictions_test
            # convert to prediction.csv
            test_pred_df = pd.DataFrame(test_pred, columns=['prediction'])
            test_pred_df.to_csv(os.path.join(output_folder, 'prediction_c.csv'), index=False)

if question_part == 'd':
    import numpy as np
    import os
    from PIL import Image
    import pandas as pd
    from sklearn.preprocessing import OneHotEncoder
    from sklearn.metrics import precision_score, recall_score, f1_score
    import matplotlib.pyplot as plt
    import sklearn.neural_network as nn

    class NeuralNetwork:
        def __init__(self, input_size, hidden_arch, output_size, batch_size=32):
            self.input_size = input_size
            self.hidden_arch = hidden_arch
            self.output_size = output_size
            self.batch_size = batch_size
            
            # Initialize parameters
            self.weights = []
            self.biases = []
            layers = [input_size] + hidden_arch + [output_size]
            self.last_val_accuracy = None  # For convergence checking
            
            for i in range(len(layers)-1):
                self.weights.append(np.random.randn(layers[i], layers[i+1]) * np.sqrt(2. / layers[i]))
                self.biases.append(np.zeros((1, layers[i+1])))
        
        def sigmoid(self, x):
            return 1 / (1 + np.exp(-x))

        def sigmoid_derivative(self, x):
            return self.sigmoid(x) * (1 - self.sigmoid(x))

        def softmax(self, x):
            exps = np.exp(x - np.max(x, axis=1, keepdims=True))
            return exps / np.sum(exps, axis=1, keepdims=True)

        def forward(self, X):
            self.activations = [X]
            self.z_values = []
            
            # Hidden layers
            for i in range(len(self.hidden_arch)):
                z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
                self.z_values.append(z)
                self.activations.append(self.sigmoid(z))
            
            # Output layer
            z_out = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
            self.z_values.append(z_out)
            output = self.softmax(z_out)
            self.activations.append(output)
            
            return output

        def compute_loss(self, y_true):
            m = y_true.shape[0]
            log_likelihood = -np.log(self.activations[-1] + 1e-8) * y_true
            return np.sum(log_likelihood) / m

        def backward(self, X, y_true):
            m = X.shape[0]
            gradients_w = []
            gradients_b = []
            
            # Output layer gradient
            delta = (self.activations[-1] - y_true) / m
            gradients_w.append(np.dot(self.activations[-2].T, delta))
            gradients_b.append(np.sum(delta, axis=0, keepdims=True))
            
            # Hidden layers gradients
            for l in range(len(self.hidden_arch)-1, -1, -1):
                delta = np.dot(delta, self.weights[l+1].T) * self.sigmoid_derivative(self.z_values[l])
                gradients_w.insert(0, np.dot(self.activations[l].T, delta))
                gradients_b.insert(0, np.sum(delta, axis=0, keepdims=True))
            
            return gradients_w, gradients_b

        def update_parameters(self, gradients_w, gradients_b, learning_rate, epoch):
            for i in range(len(self.weights)):
                self.weights[i] -= (learning_rate / np.sqrt(epoch)) * gradients_w[i]
                self.biases[i] -= (learning_rate / np.sqrt(epoch)) * gradients_b[i]

        def train(self, X, y, learning_rate=0.01, epochs=1000, verbose=True, tol=0.01):
            # One-hot encode labels
            encoder = OneHotEncoder(sparse_output=False)
            y_onehot = encoder.fit_transform(y.reshape(-1, 1))
            
            # Split data: 90% training and 10% validation
            n = X.shape[0]
            indices = np.random.permutation(n)
            split_idx = int(0.9 * n)
            X_train_split = X[indices[:split_idx]]
            y_train_split = y_onehot[indices[:split_idx]]
            X_val = X[indices[split_idx:]]
            y_val = y_onehot[indices[split_idx:]]
            
            prev_val_accuracy = None

            best_count = 0
            
            for epoch in range(epochs):
                # Shuffle training split
                permutation = np.random.permutation(X_train_split.shape[0])
                X_train_shuffled = X_train_split[permutation]
                y_train_shuffled = y_train_split[permutation]
                
                # Mini-batch training on the training split
                for i in range(0, X_train_shuffled.shape[0], self.batch_size):
<A NAME="4"></A><FONT color = #FF00FF><A HREF="match44-0.html#4" TARGET="0"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

                    X_batch = X_train_shuffled[i:i+self.batch_size]
                    y_batch = y_train_shuffled[i:i+self.batch_size]
                    self.forward(X_batch)
                    grad_w, grad_b = self.backward(X_batch, y_batch)
</FONT>                    self.update_parameters(grad_w, grad_b, learning_rate, epoch+1)
                
                # Evaluate on validation set at the end of the epoch
                val_preds = self.predict(X_val)  # predicted labels
                true_val = np.argmax(y_val, axis=1)
                val_accuracy = np.mean(val_preds == true_val)
                
                if verbose and epoch % 10 == 0:
                    print(f"Epoch {epoch}: Validation Accuracy = {val_accuracy:.4f}")
                
                # Check for convergence using validation accuracy difference
                # if prev_val_accuracy is not None and abs(val_accuracy - prev_val_accuracy) &lt; tol * val_accuracy:
                #     if verbose:
                #         print(f"Converged at epoch {epoch} with Validation Accuracy = {val_accuracy:.4f}")
                #     break

                if prev_val_accuracy is not None:
                    if val_accuracy &gt; prev_val_accuracy:
                        best_count = 0
                    else:
                        best_count += 1
                        if best_count &gt; 10:
                            if verbose:
                                print(f"Early stopping at epoch {epoch} with Validation Accuracy = {val_accuracy:.4f}")
                            break

                prev_val_accuracy = val_accuracy

        def predict(self, X):
            probs = self.forward(X)
            return np.argmax(probs, axis=1)
        
        def accuracy(self, y_true, y_pred):
            recall = recall_score(y_true, y_pred, average='macro')
            precision = precision_score(y_true, y_pred, average='macro')
            f1 = f1_score(y_true, y_pred, average='macro')
            return recall, precision, f1

    def preprocess_image(image_path):
        try:
            img = Image.open(image_path).convert('RGB')
            img = img.resize((28, 28))
            return np.array(img).flatten() / 255.0
        except Exception as e:
            print(f"Error processing {image_path}: {str(e)}")
            return None
        
    if __name__ == "__main__":
        # Example usage:
        # Data is images (in jpg format) where they are stored in their respective class directories
        # directory = '/kaggle/input/neural-net/Q2'
        # train_directory = os.path.join(directory, 'train')
        # test_directory = os.path.join(directory, 'test')
        train_directory = train_dir
        test_directory = test_dir
        directory = os.path.dirname(train_directory)
        X_train, y_train = [], []
        X_test, y_test_dict, y_test = [], {}, []

        # Check directory existence
        print(f"Train directory exists: {os.path.exists(train_directory)}")
        print(f"Test directory exists: {os.path.exists(test_directory)}")
        
        # Load training data
<A NAME="5"></A><FONT color = #FF0000><A HREF="match44-0.html#5" TARGET="0"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        for class_dir in os.listdir(train_directory):
            class_path = os.path.join(train_directory, class_dir)
            if os.path.isdir(class_path):
                for img_file in os.listdir(class_path):
</FONT>                    img_path = os.path.join(class_path, img_file)
                    img_data = preprocess_image(img_path)
                    if img_data is not None:
                        X_train.append(img_data)
                        y_train.append(int(class_dir))

        test_df = pd.read_csv(os.path.join(directory, 'test_labels.csv'), header=0)
        for index, row in test_df.iterrows():
            y_test_dict[row['image']] = row['label']

        # Load test data
        test_image_count = 0
        for img_file in os.listdir(test_directory):
            img_path = os.path.join(test_directory, img_file)
            if not os.path.isfile(img_path):
                continue
            img_data = preprocess_image(img_path)
            if img_data is not None:
                X_test.append(img_data)
                y_test.append(int(y_test_dict[img_file]))
                test_image_count += 1
                    
        print(f"Loaded {test_image_count} test images")

        # Convert lists to numpy arrays
        X_train = np.array(X_train)
        y_train = np.array(y_train[:len(X_train)])
        X_test = np.array(X_test)
        y_test = np.array(y_test[:len(X_test)])
        
        print(f"Final training data shape: {X_train.shape}")
        print(f"Final test data shape: {X_test.shape}")

        hidden_layer_architectures = [
            [512],
            [512, 256],
            [512, 256, 128],
            [512, 256, 128, 64]
        ]
        results_f1_scores_train = []
        results_f1_scores_test = []

        # MLP
        for architecture in hidden_layer_architectures:
            nn_model = nn.MLPClassifier(hidden_arch=architecture,
                                    output_size=43,
                                    batch_size=32,
                                    early_stopping=True, validation_fraction=0.05, max_iter=1000)
            
            # how to decide the stopping criteria?
            nn_model.fit(X_train, y_train)
            predictions_train = nn_model.predict(X_train)
            predictions_test = nn_model.predict(X_test)

            # Compute performance metrics
            def accuracy(self, y_true, y_pred):
                recall = recall_score(y_true, y_pred, average='macro')
                precision = precision_score(y_true, y_pred, average='macro')
                f1 = f1_score(y_true, y_pred, average='macro')
                return recall, precision, f1
            
            _, _, f1_train_avg = accuracy(y_train, predictions_train)
            _, _, f1_test_avg = accuracy(y_test, predictions_test)

            results_f1_scores_train.append(f1_train_avg)
            results_f1_scores_test.append(f1_test_avg)

            if architecture == hidden_layer_architectures[-1]:
                test_pred = predictions_test
                # convert to prediction.csv
                test_pred_df = pd.DataFrame(test_pred, columns=['prediction'])
                test_pred_df.to_csv(os.path.join(output_folder, 'prediction_d.csv'), index=False)

if question_part == 'e':
    import numpy as np
    import os
    from PIL import Image
    import pandas as pd
    from sklearn.preprocessing import OneHotEncoder
    from sklearn.metrics import precision_score, recall_score, f1_score
    import matplotlib.pyplot as plt
    import sklearn.neural_network as nn

    class NeuralNetwork:
        def __init__(self, input_size, hidden_arch, output_size, batch_size=32):
            self.input_size = input_size
            self.hidden_arch = hidden_arch
            self.output_size = output_size
            self.batch_size = batch_size
            
            # Initialize parameters
            self.weights = []
            self.biases = []
            layers = [input_size] + hidden_arch + [output_size]
            self.last_val_accuracy = None  # For convergence checking
            
            for i in range(len(layers)-1):
                self.weights.append(np.random.randn(layers[i], layers[i+1]) * np.sqrt(2. / layers[i]))
                self.biases.append(np.zeros((1, layers[i+1])))
        
        def sigmoid(self, x):
            return 1 / (1 + np.exp(-x))

        def sigmoid_derivative(self, x):
            return self.sigmoid(x) * (1 - self.sigmoid(x))

        def softmax(self, x):
            exps = np.exp(x - np.max(x, axis=1, keepdims=True))
            return exps / np.sum(exps, axis=1, keepdims=True)

        def forward(self, X):
            self.activations = [X]
            self.z_values = []
            
            # Hidden layers
            for i in range(len(self.hidden_arch)):
                z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
                self.z_values.append(z)
                self.activations.append(self.sigmoid(z))
            
            # Output layer
            z_out = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
            self.z_values.append(z_out)
            output = self.softmax(z_out)
            self.activations.append(output)
            
            return output

        def compute_loss(self, y_true):
            m = y_true.shape[0]
            log_likelihood = -np.log(self.activations[-1] + 1e-8) * y_true
            return np.sum(log_likelihood) / m

        def backward(self, X, y_true):
            m = X.shape[0]
            gradients_w = []
            gradients_b = []
            
            # Output layer gradient
            delta = (self.activations[-1] - y_true) / m
            gradients_w.append(np.dot(self.activations[-2].T, delta))
            gradients_b.append(np.sum(delta, axis=0, keepdims=True))
            
            # Hidden layers gradients
            for l in range(len(self.hidden_arch)-1, -1, -1):
                delta = np.dot(delta, self.weights[l+1].T) * self.sigmoid_derivative(self.z_values[l])
                gradients_w.insert(0, np.dot(self.activations[l].T, delta))
                gradients_b.insert(0, np.sum(delta, axis=0, keepdims=True))
            
            return gradients_w, gradients_b

        def update_parameters(self, gradients_w, gradients_b, learning_rate, epoch):
            for i in range(len(self.weights)):
                self.weights[i] -= (learning_rate / np.sqrt(epoch)) * gradients_w[i]
                self.biases[i] -= (learning_rate / np.sqrt(epoch)) * gradients_b[i]

        def train(self, X, y, learning_rate=0.01, epochs=1000, verbose=True, tol=0.01):
            # One-hot encode labels
            encoder = OneHotEncoder(sparse_output=False)
            y_onehot = encoder.fit_transform(y.reshape(-1, 1))
            
            # Split data: 90% training and 10% validation
            n = X.shape[0]
            indices = np.random.permutation(n)
            split_idx = int(0.9 * n)
            X_train_split = X[indices[:split_idx]]
            y_train_split = y_onehot[indices[:split_idx]]
            X_val = X[indices[split_idx:]]
            y_val = y_onehot[indices[split_idx:]]
            
            prev_val_accuracy = None

            best_count = 0
            
            for epoch in range(epochs):
                # Shuffle training split
                permutation = np.random.permutation(X_train_split.shape[0])
                X_train_shuffled = X_train_split[permutation]
                y_train_shuffled = y_train_split[permutation]
                
                # Mini-batch training on the training split
                for i in range(0, X_train_shuffled.shape[0], self.batch_size):
<A NAME="6"></A><FONT color = #00FF00><A HREF="match44-0.html#6" TARGET="0"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

                    X_batch = X_train_shuffled[i:i+self.batch_size]
                    y_batch = y_train_shuffled[i:i+self.batch_size]
                    self.forward(X_batch)
                    grad_w, grad_b = self.backward(X_batch, y_batch)
</FONT>                    self.update_parameters(grad_w, grad_b, learning_rate, epoch+1)
                
                # Evaluate on validation set at the end of the epoch
                val_preds = self.predict(X_val)  # predicted labels
                true_val = np.argmax(y_val, axis=1)
                val_accuracy = np.mean(val_preds == true_val)
                
                if verbose and epoch % 10 == 0:
                    print(f"Epoch {epoch}: Validation Accuracy = {val_accuracy:.4f}")
                
                # Check for convergence using validation accuracy difference
                # if prev_val_accuracy is not None and abs(val_accuracy - prev_val_accuracy) &lt; tol * val_accuracy:
                #     if verbose:
                #         print(f"Converged at epoch {epoch} with Validation Accuracy = {val_accuracy:.4f}")
                #     break

                if prev_val_accuracy is not None:
                    if val_accuracy &gt; prev_val_accuracy:
                        best_count = 0
                    else:
                        best_count += 1
                        if best_count &gt; 10:
                            if verbose:
                                print(f"Early stopping at epoch {epoch} with Validation Accuracy = {val_accuracy:.4f}")
                            break

                prev_val_accuracy = val_accuracy

        def predict(self, X):
            probs = self.forward(X)
            return np.argmax(probs, axis=1)
        
        def accuracy(self, y_true, y_pred):
            recall = recall_score(y_true, y_pred, average='macro')
            precision = precision_score(y_true, y_pred, average='macro')
            f1 = f1_score(y_true, y_pred, average='macro')
            return recall, precision, f1

    def preprocess_image(image_path):
        try:
            img = Image.open(image_path).convert('RGB')
            img = img.resize((28, 28))
            return np.array(img).flatten() / 255.0
        except Exception as e:
            print(f"Error processing {image_path}: {str(e)}")
            return None
        
    
    train_directory = train_dir
    test_directory = test_dir
    directory = os.path.dirname(train_directory)
    X_train, y_train = [], []
    X_test, y_test_dict, y_test = [], {}, []

    # Check directory existence
    print(f"Train directory exists: {os.path.exists(train_directory)}")
    print(f"Test directory exists: {os.path.exists(test_directory)}")
    
    # Load training data
<A NAME="7"></A><FONT color = #0000FF><A HREF="match44-0.html#7" TARGET="0"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    for class_dir in os.listdir(train_directory):
        class_path = os.path.join(train_directory, class_dir)
        if os.path.isdir(class_path):
            for img_file in os.listdir(class_path):
</FONT>                img_path = os.path.join(class_path, img_file)
                img_data = preprocess_image(img_path)
                if img_data is not None:
                    X_train.append(img_data)
                    y_train.append(int(class_dir))

    test_df = pd.read_csv(os.path.join(directory, 'test_labels.csv'), header=0)
    for index, row in test_df.iterrows():
        y_test_dict[row['image']] = row['label']

    # Load test data
    test_image_count = 0
    for img_file in os.listdir(test_directory):
        img_path = os.path.join(test_directory, img_file)
        if not os.path.isfile(img_path):
            continue
        img_data = preprocess_image(img_path)
        if img_data is not None:
            X_test.append(img_data)
            y_test.append(int(y_test_dict[img_file]))
            test_image_count += 1
                
    print(f"Loaded {test_image_count} test images")

    # Convert lists to numpy arrays
    X_train = np.array(X_train)
    y_train = np.array(y_train[:len(X_train)])
    X_test = np.array(X_test)
    y_test = np.array(y_test[:len(X_test)])
    
    print(f"Final training data shape: {X_train.shape}")
    print(f"Final test data shape: {X_test.shape}")

    hidden_layer_architectures = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]
    results_f1_scores_train = []
    results_f1_scores_test = []

    # MLP
    for architecture in hidden_layer_architectures:
        nn_model = nn.MLPClassifier(hidden_arch=architecture,
                                output_size=43,
                                batch_size=32,
                                solver='sgd', 
                                activation='relu',
                                alpha=0, learning_rate='invscaling',
                                early_stopping=True, validation_fraction=0.05, max_iter=1000)
        
        # how to decide the stopping criteria?
        nn_model.fit(X_train, y_train)
        predictions_train = nn_model.predict(X_train)
        predictions_test = nn_model.predict(X_test)

        # Compute performance metrics
        def accuracy(self, y_true, y_pred):
            recall = recall_score(y_true, y_pred, average='macro')
            precision = precision_score(y_true, y_pred, average='macro')
            f1 = f1_score(y_true, y_pred, average='macro')
            return recall, precision, f1
        
        _, _, f1_train_avg = accuracy(y_train, predictions_train)
        _, _, f1_test_avg = accuracy(y_test, predictions_test)

        results_f1_scores_train.append(f1_train_avg)
        results_f1_scores_test.append(f1_test_avg)

        if architecture == hidden_layer_architectures[-1]:
            test_pred = predictions_test
            # convert to prediction.csv
            test_pred_df = pd.DataFrame(test_pred, columns=['prediction'])
            test_pred_df.to_csv(os.path.join(output_folder, 'prediction_e.csv'), index=False)

if question_part == 'f':
    import numpy as np
    import os
    from PIL import Image
    import pandas as pd
    from sklearn.preprocessing import OneHotEncoder
    from sklearn.metrics import precision_score, recall_score, f1_score
    import matplotlib.pyplot as plt
    import sklearn.neural_network as nn

    class NeuralNetwork:
        def __init__(self, input_size, hidden_arch, output_size, batch_size=32):
            self.input_size = input_size
            self.hidden_arch = hidden_arch
            self.output_size = output_size
            self.batch_size = batch_size
            
            # Initialize parameters
            self.weights = []
            self.biases = []
            layers = [input_size] + hidden_arch + [output_size]
            self.last_val_accuracy = None  # For convergence checking
            
            for i in range(len(layers)-1):
                self.weights.append(np.random.randn(layers[i], layers[i+1]) * np.sqrt(2. / layers[i]))
                self.biases.append(np.zeros((1, layers[i+1])))
        
        def sigmoid(self, x):
            return 1 / (1 + np.exp(-x))

        def sigmoid_derivative(self, x):
            return self.sigmoid(x) * (1 - self.sigmoid(x))

        def softmax(self, x):
            exps = np.exp(x - np.max(x, axis=1, keepdims=True))
            return exps / np.sum(exps, axis=1, keepdims=True)

        def forward(self, X):
            self.activations = [X]
            self.z_values = []
            
            # Hidden layers
            for i in range(len(self.hidden_arch)):
                z = np.dot(self.activations[-1], self.weights[i]) + self.biases[i]
                self.z_values.append(z)
                self.activations.append(self.sigmoid(z))
            
            # Output layer
            z_out = np.dot(self.activations[-1], self.weights[-1]) + self.biases[-1]
            self.z_values.append(z_out)
            output = self.softmax(z_out)
            self.activations.append(output)
            
            return output

        def compute_loss(self, y_true):
            m = y_true.shape[0]
            log_likelihood = -np.log(self.activations[-1] + 1e-8) * y_true
            return np.sum(log_likelihood) / m

        def backward(self, X, y_true):
            m = X.shape[0]
            gradients_w = []
            gradients_b = []
            
            # Output layer gradient
            delta = (self.activations[-1] - y_true) / m
            gradients_w.append(np.dot(self.activations[-2].T, delta))
            gradients_b.append(np.sum(delta, axis=0, keepdims=True))
            
            # Hidden layers gradients
            for l in range(len(self.hidden_arch)-1, -1, -1):
                delta = np.dot(delta, self.weights[l+1].T) * self.sigmoid_derivative(self.z_values[l])
                gradients_w.insert(0, np.dot(self.activations[l].T, delta))
                gradients_b.insert(0, np.sum(delta, axis=0, keepdims=True))
            
            return gradients_w, gradients_b

        def update_parameters(self, gradients_w, gradients_b, learning_rate, epoch):
            for i in range(len(self.weights)):
                self.weights[i] -= (learning_rate / np.sqrt(epoch)) * gradients_w[i]
                self.biases[i] -= (learning_rate / np.sqrt(epoch)) * gradients_b[i]

        def train(self, X, y, learning_rate=0.01, epochs=1000, verbose=True, tol=0.01):
            # One-hot encode labels
            encoder = OneHotEncoder(sparse_output=False)
            y_onehot = encoder.fit_transform(y.reshape(-1, 1))
            
            # Split data: 90% training and 10% validation
            n = X.shape[0]
            indices = np.random.permutation(n)
            split_idx = int(0.9 * n)
            X_train_split = X[indices[:split_idx]]
            y_train_split = y_onehot[indices[:split_idx]]
            X_val = X[indices[split_idx:]]
            y_val = y_onehot[indices[split_idx:]]
            
            prev_val_accuracy = None

            best_count = 0
            
            for epoch in range(epochs):
                # Shuffle training split
                permutation = np.random.permutation(X_train_split.shape[0])
                X_train_shuffled = X_train_split[permutation]
                y_train_shuffled = y_train_split[permutation]
                
                # Mini-batch training on the training split
                for i in range(0, X_train_shuffled.shape[0], self.batch_size):
<A NAME="8"></A><FONT color = #00FFFF><A HREF="match44-0.html#8" TARGET="0"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

                    X_batch = X_train_shuffled[i:i+self.batch_size]
                    y_batch = y_train_shuffled[i:i+self.batch_size]
                    self.forward(X_batch)
                    grad_w, grad_b = self.backward(X_batch, y_batch)
</FONT>                    self.update_parameters(grad_w, grad_b, learning_rate, epoch+1)
                
                # Evaluate on validation set at the end of the epoch
                val_preds = self.predict(X_val)  # predicted labels
                true_val = np.argmax(y_val, axis=1)
                val_accuracy = np.mean(val_preds == true_val)
                
                if verbose and epoch % 10 == 0:
                    print(f"Epoch {epoch}: Validation Accuracy = {val_accuracy:.4f}")
                
                # Check for convergence using validation accuracy difference
                # if prev_val_accuracy is not None and abs(val_accuracy - prev_val_accuracy) &lt; tol * val_accuracy:
                #     if verbose:
                #         print(f"Converged at epoch {epoch} with Validation Accuracy = {val_accuracy:.4f}")
                #     break

                if prev_val_accuracy is not None:
                    if val_accuracy &gt; prev_val_accuracy:
                        best_count = 0
                    else:
                        best_count += 1
                        if best_count &gt; 10:
                            if verbose:
                                print(f"Early stopping at epoch {epoch} with Validation Accuracy = {val_accuracy:.4f}")
                            break

                prev_val_accuracy = val_accuracy

        def predict(self, X):
            probs = self.forward(X)
            return np.argmax(probs, axis=1)
        
        def accuracy(self, y_true, y_pred):
            recall = recall_score(y_true, y_pred, average='macro')
            precision = precision_score(y_true, y_pred, average='macro')
            f1 = f1_score(y_true, y_pred, average='macro')
            return recall, precision, f1

    def preprocess_image(image_path):
        try:
            img = Image.open(image_path).convert('RGB')
            img = img.resize((28, 28))
            return np.array(img).flatten() / 255.0
        except Exception as e:
            print(f"Error processing {image_path}: {str(e)}")
            return None
        
    train_directory = train_dir
    test_directory = test_dir
    directory = os.path.dirname(train_directory)
    X_train, y_train = [], []
    X_test, y_test_dict, y_test = [], {}, []

    # Check directory existence
    print(f"Train directory exists: {os.path.exists(train_directory)}")
    print(f"Test directory exists: {os.path.exists(test_directory)}")

    # Load training data
<A NAME="9"></A><FONT color = #FF00FF><A HREF="match44-0.html#9" TARGET="0"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    for class_dir in os.listdir(train_directory):
        class_path = os.path.join(train_directory, class_dir)
        if os.path.isdir(class_path):
            for img_file in os.listdir(class_path):
</FONT>                img_path = os.path.join(class_path, img_file)
                img_data = preprocess_image(img_path)
                if img_data is not None:
                    X_train.append(img_data)
                    y_train.append(int(class_dir))

    test_df = pd.read_csv(os.path.join(directory, 'test_labels.csv'), header=0)
    for index, row in test_df.iterrows():
        y_test_dict[row['image']] = row['label']

    # Load test data
    test_image_count = 0
    for img_file in os.listdir(test_directory):
        img_path = os.path.join(test_directory, img_file)
        if not os.path.isfile(img_path):
            continue
        img_data = preprocess_image(img_path)
        if img_data is not None:
            X_test.append(img_data)
            y_test.append(int(y_test_dict[img_file]))
            test_image_count += 1
                
    print(f"Loaded {test_image_count} test images")

    # Convert lists to numpy arrays
    X_train = np.array(X_train)
    y_train = np.array(y_train[:len(X_train)])
    X_test = np.array(X_test)
    y_test = np.array(y_test[:len(X_test)])

    print(f"Final training data shape: {X_train.shape}")
    print(f"Final test data shape: {X_test.shape}")

    hidden_layer_architectures = [
        [512],
        [512, 256],
        [512, 256, 128],
        [512, 256, 128, 64]
    ]
    results_f1_scores_train = []
    results_f1_scores_test = []

    # MLP
    for architecture in hidden_layer_architectures:
        nn_model = nn.MLPClassifier(input_size=2352,
                                    hidden_arch=architecture,
                                    output_size=43,
                                    batch_size=32,
                                    solver='sgd', 
                                    activation='relu',
                                    alpha=0, learning_rate='invscaling',
                                    early_stopping=True, validation_fraction=0.05, max_iter=1000)
        
        # how to decide the stopping criteria?
        nn_model.fit(X_train, y_train)
        predictions_train = nn_model.predict(X_train)
        predictions_test = nn_model.predict(X_test)

        # Compute performance metrics
        def accuracy(self, y_true, y_pred):
            recall = recall_score(y_true, y_pred, average='macro')
            precision = precision_score(y_true, y_pred, average='macro')
            f1 = f1_score(y_true, y_pred, average='macro')
            return recall, precision, f1
        
        _, _, f1_train_avg = accuracy(y_train, predictions_train)
        _, _, f1_test_avg = accuracy(y_test, predictions_test)

        results_f1_scores_train.append(f1_train_avg)
        results_f1_scores_test.append(f1_test_avg)

        if architecture == hidden_layer_architectures[-1]:
            test_pred = predictions_test
            # convert to prediction.csv
            test_pred_df = pd.DataFrame(test_pred, columns=['prediction'])
            test_pred_df.to_csv(os.path.join(output_folder, 'prediction_f.csv'), index=False)

</PRE>
</PRE>
</BODY>
</HTML>
