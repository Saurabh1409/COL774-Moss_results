<HTML>
<HEAD>
<TITLE>./A2_processed_new_hash_2/combined_DFEHC.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A2_processed_new_hash_2/combined_KQ3JZ.py<p><PRE>


#!/usr/bin/env python
# coding: utf-8

# In[2]:


import numpy as np
import pandas as pd
import re
from collections import defaultdict
from wordcloud import WordCloud
import matplotlib.pyplot as plt

class NaiveBayes:
    def __init__(self):
        self.class_priors = {}
        self.word_probs = {}
        self.vocab = set()
        self.class_counts = defaultdict(int)
        self.word_counts = defaultdict(lambda: defaultdict(int))
        self.total_words = defaultdict(int)
        self.smoothing = 1

    def fit(self, df, smoothing, class_col="Class Index", text_col="Tokenized Description"):
        """Train the Naïve Bayes classifier."""
<A NAME="6"></A><FONT color = #00FF00><A HREF="match44-0.html#6" TARGET="0"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        self.smoothing = smoothing

        # Count occurrences
        for _, row in df.iterrows():
            label = row[class_col]
            words = row[text_col]

            self.class_counts[label] += 1
</FONT>            self.total_words[label] += len(words)

            for word in words:
                self.vocab.add(word)
                self.word_counts[label][word] += 1

        total_samples = sum(self.class_counts.values())

        # Compute priors P(y)
        self.class_priors = {label: np.log(count / total_samples) for label, count in self.class_counts.items()}

        # Compute word likelihoods P(x | y)
        self.word_probs = {}
        for label in self.class_counts:
            self.word_probs[label] = {}
            for word in self.vocab:
                self.word_probs[label][word] = np.log(
                    (self.word_counts[label][word] + self.smoothing) /
                    (self.total_words[label] + len(self.vocab) * self.smoothing)
                )

    def predict(self, df, text_col="Tokenized Description", predicted_col="Predicted"):
        """Predict the class of the input data."""
        predictions = []
        for _, row in df.iterrows():
            words = row[text_col]
            scores = {}

            for label in self.class_counts:
                scores[label] = self.class_priors[label] + sum(
                    self.word_probs[label].get(word, np.log(self.smoothing /
                    (self.total_words[label] + len(self.vocab) * self.smoothing)))
                    for word in words
                )

            predictions.append(max(scores, key=scores.get))

        df[predicted_col] = predictions

    def accuracy(self, df, class_col="Class Index", predicted_col="Predicted"):
        """Calculate accuracy of predictions."""
        correct = sum(df[class_col] == df[predicted_col])
        return correct / len(df)

    def generate_word_clouds(self):
        """Generate word clouds for each class."""
        for label in self.class_counts:
            word_freq = {word: self.word_counts[label][word] for word in self.word_counts[label]}
            wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)

            plt.figure(figsize=(8, 4))
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis('off')
            plt.title(f'Word Cloud for Class {label}')
            plt.show()

# Example Usage
# df_train and df_test should have 'Tokenized Description' and 'Class Index' columns
df_train=pd.read_csv('train.csv')
df_test=pd.read_csv('test.csv')
# First ten rows of train and test
# df_train=df_train.head(10)
# df_test=df_test.head(10)
df_train['Tokenized Description'] = df_train['Description'].apply(lambda x: x.lower().split())  # Simple tokenizer
df_test['Tokenized Description'] = df_test['Description'].apply(lambda x: x.lower().split())

model = NaiveBayes()
model.fit(df_train, smoothing=1.0)
model.predict(df_train)
model.predict(df_test)
print("Training Accuracy:", model.accuracy(df_train))
print("Test Accuracy:", model.accuracy(df_test))
model.generate_word_clouds()


# In[3]:


import numpy as np
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from collections import defaultdict
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Ensure NLTK resources are available
<A NAME="1"></A><FONT color = #00FF00><A HREF="match44-0.html#1" TARGET="0"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

class NaiveBayes:
    def __init__(self):
        self.class_priors = {}
        self.word_probs = {}
        self.vocab = set()
        self.class_counts = defaultdict(int)
</FONT>        self.word_counts = defaultdict(lambda: defaultdict(int))
        self.total_words = defaultdict(int)
        self.smoothing = 1

    def preprocess_text(self, words):
        """Remove stopwords and apply stemming."""
        return [stemmer.stem(word) for word in words if word not in stop_words]

    def fit(self, df, smoothing, class_col="Class Index", text_col="Tokenized Description"):
        """Train the Naïve Bayes classifier."""
        self.smoothing = smoothing

        # Count occurrences
        for _, row in df.iterrows():
            label = row[class_col]
            words = self.preprocess_text(row[text_col])  # Apply preprocessing

            self.class_counts[label] += 1
            self.total_words[label] += len(words)

            for word in words:
                self.vocab.add(word)
                self.word_counts[label][word] += 1

        total_samples = sum(self.class_counts.values())

        # Compute priors P(y)
        self.class_priors = {label: np.log(count / total_samples) for label, count in self.class_counts.items()}

        # Compute word likelihoods P(x | y)
        self.word_probs = {}
        for label in self.class_counts:
            self.word_probs[label] = {}
            for word in self.vocab:
                self.word_probs[label][word] = np.log(
                    (self.word_counts[label][word] + self.smoothing) /
                    (self.total_words[label] + len(self.vocab) * self.smoothing)
                )

    def predict(self, df, text_col="Tokenized Description", predicted_col="Predicted"):
        """Predict the class of the input data."""
        predictions = []
        for _, row in df.iterrows():
            words = self.preprocess_text(row[text_col])  # Apply preprocessing
            scores = {}

            for label in self.class_counts:
                scores[label] = self.class_priors[label] + sum(
                    self.word_probs[label].get(word, np.log(self.smoothing /
                    (self.total_words[label] + len(self.vocab) * self.smoothing)))
                    for word in words
                )

            predictions.append(max(scores, key=scores.get))

        df[predicted_col] = predictions

    def accuracy(self, df, class_col="Class Index", predicted_col="Predicted"):
        """Calculate accuracy of predictions."""
        correct = sum(df[class_col] == df[predicted_col])
        return correct / len(df)

    def generate_word_clouds(self):
        """Generate word clouds for each class."""
        for label in self.class_counts:
            word_freq = {word: self.word_counts[label][word] for word in self.word_counts[label]}
            wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)

            plt.figure(figsize=(8, 4))
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis('off')
            plt.title(f'Word Cloud for Class {label}')
            plt.show()

# Example Usage
# df_train and df_test should have 'Tokenized Description' and 'Class Index' columns
df_train=pd.read_csv('train.csv')
df_test=pd.read_csv('test.csv')
# First ten rows of train and test
# df_train=df_train.head(10)
# df_test=df_test.head(10)
df_train['Tokenized Description'] = df_train['Description'].apply(lambda x: x.lower().split())  # Simple tokenizer
df_test['Tokenized Description'] = df_test['Description'].apply(lambda x: x.lower().split())

model = NaiveBayes()
model.fit(df_train, smoothing=1.0)
model.predict(df_train)
model.predict(df_test)
print("Training Accuracy (Preprocessed):", model.accuracy(df_train))
print("Test Accuracy (Preprocessed):", model.accuracy(df_test))
model.generate_word_clouds()


# In[5]:


import numpy as np
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from collections import defaultdict
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report

# Ensure NLTK resources are available
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

class NaiveBayes:
    def __init__(self):
        self.class_priors = {}
        self.word_probs = {}
        self.vocab = set()
        self.class_counts = defaultdict(int)
        self.word_counts = defaultdict(lambda: defaultdict(int))
        self.total_words = defaultdict(int)
        self.smoothing = 1

    def preprocess_text(self, words, use_bigrams=False):
        """Remove stopwords, apply stemming, and optionally create bigrams."""
        words = [stemmer.stem(word) for word in words if word not in stop_words]

        if use_bigrams:
            bigrams = [' '.join(pair) for pair in zip(words, words[1:])]
            words += bigrams  # Combine unigrams + bigrams

        return words

    def fit(self, df, smoothing, class_col="Class Index", text_col="Tokenized Description", use_bigrams=False):
        """Train the Naïve Bayes classifier with unigrams + bigrams."""
        self.smoothing = smoothing

        # Count occurrences
        for _, row in df.iterrows():
            label = row[class_col]
            words = self.preprocess_text(row[text_col], use_bigrams)

            self.class_counts[label] += 1
            self.total_words[label] += len(words)

            for word in words:
                self.vocab.add(word)
                self.word_counts[label][word] += 1

        total_samples = sum(self.class_counts.values())

        # Compute priors P(y)
        self.class_priors = {label: np.log(count / total_samples) for label, count in self.class_counts.items()}

        # Compute word likelihoods P(x | y)
        self.word_probs = {}
        for label in self.class_counts:
            self.word_probs[label] = {}
            for word in self.vocab:
                self.word_probs[label][word] = np.log(
                    (self.word_counts[label][word] + self.smoothing) /
                    (self.total_words[label] + len(self.vocab) * self.smoothing)
                )

    def predict(self, df, text_col="Tokenized Description", predicted_col="Predicted", use_bigrams=False):
        """Predict the class of the input data."""
        predictions = []
        for _, row in df.iterrows():
            words = self.preprocess_text(row[text_col], use_bigrams)
            scores = {}

            for label in self.class_counts:
                scores[label] = self.class_priors[label] + sum(
                    self.word_probs[label].get(word, np.log(self.smoothing /
                    (self.total_words[label] + len(self.vocab) * self.smoothing)))
                    for word in words
                )

            predictions.append(max(scores, key=scores.get))

        df[predicted_col] = predictions

    def accuracy(self, df, class_col="Class Index", predicted_col="Predicted"):
        """Calculate accuracy of predictions."""
        correct = sum(df[class_col] == df[predicted_col])
        return correct / len(df)

    def generate_word_clouds(self):
        """Generate word clouds for each class."""
        for label in self.class_counts:
            word_freq = {word: self.word_counts[label][word] for word in self.word_counts[label]}
            wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)

            plt.figure(figsize=(8, 4))
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis('off')
            plt.title(f'Word Cloud for Class {label}')
            plt.show()

    def evaluate(self, df, class_col="Class Index", predicted_col="Predicted"):
        """Print precision, recall, and F1-score."""
        print(classification_report(df[class_col], df[predicted_col]))


# Example Usage
# df_train and df_test should have 'Tokenized Description' and 'Class Index' columns
df_train=pd.read_csv('train.csv')
df_test=pd.read_csv('test.csv')
# First ten rows of train and test
# df_train=df_train.head(10)
# df_test=df_test.head(10)
df_train['Tokenized Description'] = df_train['Title'].apply(lambda x: x.lower().split())  # Simple tokenizer
df_test['Tokenized Description'] = df_test['Title'].apply(lambda x: x.lower().split())

# Model training with unigrams + bigrams
model_bigram = NaiveBayes()
model_bigram.fit(df_train, smoothing=1.0, use_bigrams=True)
model_bigram.predict(df_train, use_bigrams=True)
model_bigram.predict(df_test, use_bigrams=True)

print("Training Accuracy (Bigram):", model_bigram.accuracy(df_train))
print("Test Accuracy (Bigram):", model_bigram.accuracy(df_test))
model_bigram.evaluate(df_test)
model_bigram.generate_word_clouds()


# In[9]:


import numpy as np
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from collections import defaultdict
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

class NaiveBayes:
    def __init__(self):
        self.class_priors = {}
        self.word_probs = {}
        self.vocab = set()
        self.class_counts = defaultdict(int)
        self.word_counts = defaultdict(lambda: defaultdict(int))
        self.total_words = defaultdict(int)
        self.smoothing = 1

    def preprocess_text(self, words, use_bigrams=False):
        """Remove stopwords, apply stemming, and optionally create bigrams."""
        words = [stemmer.stem(word) for word in words if word not in stop_words]

        if use_bigrams:
            bigrams = [' '.join(pair) for pair in zip(words, words[1:])]
            words += bigrams

        return words

    def fit(self, df, smoothing, class_col="Class Index", text_col="Tokenized Text", use_bigrams=False):
        """Train the Naïve Bayes classifier."""
        self.smoothing = smoothing

        for _, row in df.iterrows():
            label = row[class_col]
            words = self.preprocess_text(row[text_col], use_bigrams)

            self.class_counts[label] += 1
            self.total_words[label] += len(words)

            for word in words:
                self.vocab.add(word)
                self.word_counts[label][word] += 1

        total_samples = sum(self.class_counts.values())

        # Compute priors P(y)
        self.class_priors = {label: np.log(count / total_samples) for label, count in self.class_counts.items()}

        # Compute word likelihoods P(x | y)
        self.word_probs = {}
        for label in self.class_counts:
            self.word_probs[label] = {}
            for word in self.vocab:
                self.word_probs[label][word] = np.log(
                    (self.word_counts[label][word] + self.smoothing) /
                    (self.total_words[label] + len(self.vocab) * self.smoothing)
                )

    def predict(self, df, text_col="Tokenized Text", predicted_col="Predicted", use_bigrams=False):
        """Predict the class of the input data."""
        predictions = []
        for _, row in df.iterrows():
            words = self.preprocess_text(row[text_col], use_bigrams)
            scores = {}

            for label in self.class_counts:
                scores[label] = self.class_priors[label] + sum(
                    self.word_probs[label].get(word, np.log(self.smoothing /
                    (self.total_words[label] + len(self.vocab) * self.smoothing)))
                    for word in words
                )

            predictions.append(max(scores, key=scores.get))

        df[predicted_col] = predictions

    def accuracy(self, df, class_col="Class Index", predicted_col="Predicted"):
        """Calculate accuracy of predictions."""
        correct = sum(df[class_col] == df[predicted_col])
        return correct / len(df)

    def evaluate(self, df, class_col="Class Index", predicted_col="Predicted"):
        """Print precision, recall, and F1-score."""
        print(classification_report(df[class_col], df[predicted_col]))

    def plot_confusion_matrix(self, df, class_col="Class Index", predicted_col="Predicted"):
        """Draw a confusion matrix."""
        cm = confusion_matrix(df[class_col], df[predicted_col])
        labels = sorted(self.class_counts.keys())

        plt.figure(figsize=(6, 6))
        sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels, cmap="Blues")
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.title('Confusion Matrix')
        plt.show()


df_train=pd.read_csv('train.csv')
df_test=pd.read_csv('test.csv')
# First ten rows of train and test
# df_train=df_train.head(10)
# df_test=df_test.head(10)
df_train['Tokenized Description'] = df_train['Description'].apply(lambda x: x.lower().split())  # Simple tokenizer
df_test['Tokenized Description'] = df_test['Description'].apply(lambda x: x.lower().split())
df_train['Tokenized Title'] = df_train['Title'].apply(lambda x: x.lower().split())  # Simple tokenizer
df_test['Tokenized Title'] = df_test['Title'].apply(lambda x: x.lower().split())
# Merge title and description
<A NAME="2"></A><FONT color = #0000FF><A HREF="match44-0.html#2" TARGET="0"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

df_train["Tokenized Combined"] = df_train["Tokenized Title"] + df_train["Tokenized Description"]
df_test["Tokenized Combined"] = df_test["Tokenized Title"] + df_test["Tokenized Description"]

# Train with concatenated features
model_combined = NaiveBayes()
model_combined.fit(df_train, smoothing=1.0, text_col="Tokenized Combined", use_bigrams=True)
</FONT>model_combined.predict(df_test, text_col="Tokenized Combined", use_bigrams=True)

print("Test Accuracy (Concatenated Title + Description):", model_combined.accuracy(df_test))
model_combined.evaluate(df_test)
model_combined.plot_confusion_matrix(df_test)


# In[ ]:


class NaiveBayesDual:
    def __init__(self):
        self.model_title = NaiveBayes()
        self.model_desc = NaiveBayes()

    def fit(self, df, smoothing):
        self.model_title.fit(df, smoothing, text_col="Tokenized Title", use_bigrams=True)
        self.model_desc.fit(df, smoothing, text_col="Tokenized Description", use_bigrams=True)

    def predict(self, df):
      """Compute combined probabilities using title and description, then predict class."""
      predictions = []

      # Iterate over each sample
      for _, row in df.iterrows():
          # Preprocess tokens separately for title and description
          title_tokens = self.model_title.preprocess_text(row["Tokenized Title"], use_bigrams=True)
          desc_tokens = self.model_desc.preprocess_text(row["Tokenized Description"], use_bigrams=True)

          combined_scores = {}
          # Assume both models have the same set of classes.
          for label in self.model_title.class_counts:
              # Compute log probability from the title model
              score_title = self.model_title.class_priors[label] +                   sum(self.model_title.word_probs[label].get(token,
                      np.log(self.model_title.smoothing /
                            (self.model_title.total_words[label] + len(self.model_title.vocab)*self.model_title.smoothing)))
                      for token in title_tokens)
              # Compute log probability from the description model
              score_desc = self.model_desc.class_priors[label] +                   sum(self.model_desc.word_probs[label].get(token,
                      np.log(self.model_desc.smoothing /
                            (self.model_desc.total_words[label] + len(self.model_desc.vocab)*self.model_desc.smoothing)))
                      for token in desc_tokens)

              # Combine the scores. Note: if both models include the prior, you might need to adjust to avoid double counting.
              combined_scores[label] = score_title + score_desc  # or adjust as needed

          # Choose the label with the maximum combined log-probability
          predictions.append(max(combined_scores, key=combined_scores.get))

      df["Predicted"] = predictions


# Train separate models for title & description
model_dual = NaiveBayesDual()
model_dual.fit(df_train, smoothing=1.0)
model_dual.predict(df_test)

print("Test Accuracy (Separate Models for Title & Description):", model_dual.model_title.accuracy(df_test))
model_dual.model_desc.evaluate(df_test)
model_dual.model_desc.plot_confusion_matrix(df_test)


# In[ ]:


from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(ngram_range=(1, 2), stop_words="english")
X_train = tfidf.fit_transform(df_train["Tokenized Combined"].apply(lambda x: " ".join(x)))
X_test = tfidf.transform(df_test["Tokenized Combined"].apply(lambda x: " ".join(x)))

# Train a new Naive Bayes classifier using TF-IDF features

# Assume our custom NaïveBayes has a fit method that expects a column "Tokenized Combined"
model = NaiveBayes()
model.fit(df_train, smoothing=1.0, text_col="Tokenized Combined", use_bigrams=True)

def predict_tfidf(model, X, tfidf_vectorizer):
    """
    Predict using our custom Naive Bayes model with TF-IDF weights.

    Parameters:
        model: instance of our NaiveBayes model (already trained)
        X: TF-IDF feature matrix (sparse matrix)
        tfidf_vectorizer: the fitted TfidfVectorizer
    Returns:
        predictions: list of predicted class labels.
    """
    predictions = []
    # Build a reverse mapping: index -&gt; token
    index_to_token = {idx: token for token, idx in tfidf_vectorizer.vocabulary_.items()}

    # Loop over each document in the TF-IDF matrix
    for i in range(X.shape[0]):
        row = X.getrow(i)
        # row.nonzero()[1] gives the indices of nonzero features
        # row[0, col] gives the TF-IDF weight for that feature.
        tfidf_dict = {col: row[0, col] for col in row.nonzero()[1]}

        scores = {}
        # Loop over each class (assume model.class_counts keys are the class labels)
        for label in model.class_counts:
            # Start with the class prior (log probability)
            score = model.class_priors[label]
            for col, weight in tfidf_dict.items():
                token = index_to_token[col]
                # Only add if the token is in our model's vocabulary
                if token in model.vocab:
                    # Get the log probability of the token given the class
                    token_log_prob = model.word_probs[label].get(
                        token,
                        np.log(model.smoothing / (model.total_words[label] + len(model.vocab)*model.smoothing))
                    )
                    # Multiply by the TF-IDF weight
                    score += weight * token_log_prob
            scores[label] = score
        predictions.append(max(scores, key=scores.get))

    return predictions

# Use the predict_tfidf function with our custom model and TF-IDF matrix X_test
preds_tfidf = predict_tfidf(model, X_test, tfidf)

# If you wish, add these predictions to your dataframe:
df_test["Predicted_TFIDF"] = preds_tfidf

# Evaluate accuracy using your custom evaluation function or simply:
accuracy_tfidf = sum(df_test["Predicted_TFIDF"] == df_test["Class Index"]) / len(df_test)
print("Test Accuracy using TF-IDF features (custom NB):", accuracy_tfidf)


# In[7]:


train_labels = np.array(df_train['Class Index'])
test_labels = np.array(df_test['Class Index'])

# Determine the unique classes and their counts in the training set
unique_classes, counts = np.unique(train_labels, return_counts=True)

# Identify the most frequent class
most_frequent_class = unique_classes[np.argmax(counts)]

# Predict the most frequent class for every test sample
predictions = np.full(shape=test_labels.shape, fill_value=most_frequent_class)

# Calculate the accuracy: the fraction of test samples that are correctly predicted
accuracy = np.mean(predictions == test_labels)

print(most_frequent_class, accuracy)


# In[16]:


import numpy as np
import nltk
from nltk.stem import PorterStemmer

# Initialize the stemmer (make sure you have nltk resources downloaded)
stemmer = PorterStemmer()

def preprocess_enhanced(tokens):
    """
    Applies stemming, and adds additional feature tokens:
    - Document length category token
    - Average word length category token

    Parameters:
        tokens (list of str): Original token list (combined title and description).

    Returns:
        list of str: Enhanced token list.
    """
    # Apply stemming to each token
    stemmed = [stemmer.stem(token) for token in tokens]

    # --- Feature 1: Document Length Category ---
    length = len(stemmed)
    # You can adjust these bins as needed
    if length &lt;= 50:
        stemmed.append("len_short")
    elif length &lt;= 100:
        stemmed.append("len_medium")
    else:
        stemmed.append("len_long")

    # --- Feature 2: Average Word Length Category ---
    # Calculate average word length over the stemmed tokens
    if length &gt; 0:
        avg_word_len = np.mean([len(token) for token in stemmed])
    else:
        avg_word_len = 0
    # Binning the average word length (adjust thresholds as needed)
    if avg_word_len &lt; 4:
        stemmed.append("avg_short")
    elif avg_word_len &lt; 7:
        stemmed.append("avg_medium")
    else:
        stemmed.append("avg_long")

    return stemmed

# Assuming your dataframe already has a column "Tokenized Combined" containing the token list
# that combines title and description features.
# Apply the enhanced preprocessing on both training and test sets:
df_train["Enhanced_Tokens"] = df_train["Tokenized Combined"].apply(preprocess_enhanced)
df_test["Enhanced_Tokens"] = df_test["Tokenized Combined"].apply(preprocess_enhanced)

# (Optional) If you want to see the new tokens for a sample document, you can print:
print("Example Enhanced Tokens:", df_train["Enhanced_Tokens"].iloc[0])

# Now, train your custom Naïve Bayes classifier using these enhanced tokens.
# We assume that your custom NaiveBayes class has a fit() method that accepts a column name
# containing the tokenized text and a flag for using bigrams.
model_enhanced = NaiveBayes()
model_enhanced.fit(df_train, smoothing=1.0, text_col="Enhanced_Tokens", use_bigrams=True)

# Predict on the test set using your model’s predict method (assumed to be implemented).
# (If you have a custom prediction function, use that accordingly.)
preds_enhanced =model_enhanced.predict(df_test, text_col="Enhanced_Tokens", use_bigrams=True)

# Evaluate the accuracy.
accuracy_enhanced = model_enhanced.accuracy(df_test)
print("Test Accuracy using Enhanced Features (combined title+description, bigrams, stemming, extra features):", accuracy_enhanced)





import numpy as np
import pandas as pd
from collections import defaultdict

class NaiveBayes:
    def __init__(self):
        self.class_priors = {}
        self.word_probs = {}
        self.vocab = set()
        self.class_counts = defaultdict(int)
        self.word_counts = defaultdict(lambda: defaultdict(int))
        self.total_words = defaultdict(int)
        self.smoothing = 1

    def fit(self, df, smoothing, class_col="Class Index", text_col="Tokenized Description"):
        """Train the Naïve Bayes classifier."""
        self.smoothing = smoothing

        
        for _, row in df.iterrows():
            label = row[class_col]
            words = row[text_col]

            self.class_counts[label] += 1
            self.total_words[label] += len(words)

            for word in words:
                self.vocab.add(word)
                self.word_counts[label][word] += 1

        total_samples = sum(self.class_counts.values())

        
        self.class_priors = {label: np.log(count / total_samples) for label, count in self.class_counts.items()}

        
        self.word_probs = {}
        for label in self.class_counts:
            self.word_probs[label] = {}
            for word in self.vocab:
                self.word_probs[label][word] = np.log(
                    (self.word_counts[label][word] + self.smoothing) /
                    (self.total_words[label] + len(self.vocab) * self.smoothing)
                )

    def predict(self, df, text_col="Tokenized Description", predicted_col="Predicted"):
        """Predict the class of the input data."""
        predictions = []
        for _, row in df.iterrows():
            words = row[text_col]
            scores = {}

            for label in self.class_counts:
                scores[label] = self.class_priors[label] + sum(
                    self.word_probs[label].get(word, np.log(self.smoothing /
                    (self.total_words[label] + len(self.vocab) * self.smoothing)))
                    for word in words
                )

            predictions.append(max(scores, key=scores.get))

        df[predicted_col] = predictions



#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


# In[1]:


get_ipython().system('cp -r /kaggle/input/ass2q2/Q2 .')


# In[11]:


import os
import cv2
import numpy as np
import cvxopt
import cvxopt.solvers
import matplotlib.pyplot as plt

def preprocess_image(img, target_size=(100, 100)):
    """
    Preprocess a single image:
      1. Resize the image while keeping aspect ratio so that both dimensions are &gt;= target.
      2. Center crop the image to target_size.
      3. Normalize by dividing by 255.
      4. Return the processed image.
    """
    # Ensure image is in color (RGB) format
    if img is None:
        return None
    # Convert BGR to RGB if needed (cv2 loads in BGR)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    h, w = img.shape[:2]
    target_h, target_w = target_size
    
    # Scale so that both dimensions are at least the target dimensions.
    scale = max(target_h / h, target_w / w)
    new_w, new_h = int(w * scale), int(h * scale)
    resized = cv2.resize(img, (new_w, new_h))
    
    # Center crop to target_size.
    start_x = (new_w - target_w) // 2
    start_y = (new_h - target_h) // 2
    cropped = resized[start_y:start_y+target_h, start_x:start_x+target_w]
    
    # Normalize pixel values to [0, 1]
    norm_img = cropped.astype(np.float32) / 255.0
    return norm_img

def load_dataset(class_dirs, target_size=(100, 100)):
    """
    Given a list of folder paths (each folder corresponding to one class), load all images,
    preprocess them, flatten to a 1D vector of length 30,000, and assign labels (0 for first folder,
    1 for second folder).
    """
    X, y = [], []
    for label, folder in enumerate(class_dirs):
        for filename in os.listdir(folder):
            filepath = os.path.join(folder, filename)
            img = cv2.imread(filepath)
            if img is None:
                continue
            proc_img = preprocess_image(img, target_size)
            if proc_img is None or proc_img.shape[:2] != target_size:
                continue
            X.append(proc_img.flatten())  # flatten to 1D vector (100*100*3 = 30,000)
            y.append(label)
    return np.array(X), np.array(y)

class SupportVectorMachine:
    """
    SVM classifier using a linear kernel and the CVXOPT package to solve the dual QP.
    """
    def __init__(self):
        self.alpha = None  # Lagrange multipliers for support vectors
        self.sv = None     # Support vectors (training samples with non-zero alpha)
        self.sv_y = None   # Labels of support vectors
        self.w = None      # Weight vector (for linear kernel)
        self.b = None      # Bias term
    
    def fit(self, X, y, C=1.0):
        """
        Fit SVM by solving the dual problem.
        
        The dual QP is formulated as:
            minimize (1/2)*α^T P α - 1^T α
            subject to: y^T α = 0 and 0 &lt;= α_i &lt;= C.
        
        Here we assume input labels y are {0,1} and we map them to {-1, +1}.
        """
        N, D = X.shape
        
        # Convert labels: map 0 -&gt; -1 and 1 -&gt; +1
        y_mod = np.where(y==0, -1, 1).astype(np.double)
        
        # Compute Gram matrix for linear kernel
        K = np.dot(X, X.T)
        
        # Formulate matrices for CVXOPT:
        # P: m x m matrix with entries y_i * y_j * K_ij
        P = cvxopt.matrix(np.outer(y_mod, y_mod) * K)
        q = cvxopt.matrix(-np.ones(N))
        
        # G and h set up the inequality constraints 0 &lt;= alpha_i &lt;= C.
        G_std = -np.eye(N)  # for alpha_i &gt;= 0
        G_slack = np.eye(N) # for alpha_i &lt;= C
        G = cvxopt.matrix(np.vstack((G_std, G_slack)))
        h = cvxopt.matrix(np.hstack((np.zeros(N), C * np.ones(N))))
        
        # Equality constraint: sum_i alpha_i * y_i = 0
        A = cvxopt.matrix(y_mod.reshape(1, -1))
        b = cvxopt.matrix(0.0)
        
        # Solve QP problem using CVXOPT solver
        cvxopt.solvers.options['show_progress'] = False  # Suppress solver output
        solution = cvxopt.solvers.qp(P, q, G, h, A, b)
        alphas = np.ravel(solution['x'])
        
        # Identify support vectors: indices where alpha &gt; threshold
        sv_indices = alphas &gt; 1e-5
        self.alpha = alphas[sv_indices]
        self.sv = X[sv_indices]
        self.sv_y = y_mod[sv_indices]
        
        # (a) Print support vector information
        num_sv = len(self.alpha)
        print(f"Number of support vectors: {num_sv} out of {N} training samples "
              f"({100.0 * num_sv / N:.2f}%)")
        
        # (b) Compute weight vector w (only valid for linear kernel)
        # w = sum_i (alpha_i * y_i * x_i)
        self.w = np.sum((self.alpha * self.sv_y)[:, None] * self.sv, axis=0)
        
        # Compute intercept b.
        # Use only those support vectors that are not on the margin boundaries (0 &lt; alpha &lt; C)
        sv_non_bound = (alphas &gt; 1e-5) & (alphas &lt; C - 1e-5)
        if np.any(sv_non_bound):
            b_candidates = y_mod[sv_non_bound] - np.dot(X[sv_non_bound], self.w)
        else:
            # If none satisfy the condition, average over all support vectors.
            b_candidates = self.sv_y - np.dot(self.sv, self.w)
        self.b = np.mean(b_candidates)
    
    def predict(self, X):
        """
        Predict class labels for input samples X.
        Returns labels in {0, 1}.
        """
        pred = np.dot(X, self.w) + self.b
        # np.sign returns -1 or +1; map -1 back to label 0.
        y_pred = np.where(np.sign(pred) == -1, 0, 1)
        return y_pred

# ---------------------------
# Example usage:
# ---------------------------
# Assume you have two directories corresponding to the two classes of interest.
# Replace 'path_to_class_d' and 'path_to_class_dplus1' with the actual folder paths.
train_dirs = ['Q2/train/lightning', 'Q2/train/rain']
test_dirs  = ['Q2/test/lightning', 'Q2/test/rain']

# Load training and test datasets
print("Loading training data...")
X_train, y_train = load_dataset(train_dirs, target_size=(100, 100))
print("Loading test data...")
X_test, y_test = load_dataset(test_dirs, target_size=(100, 100))

# Train the SVM using CVXOPT
start_time = time.time()
svm = SupportVectorMachine()
svm.fit(X_train, y_train, C=1.0)
linear_train_time = time.time() - start_time

# Evaluate on test set
y_pred = svm.predict(X_test)
accuracy = np.mean(y_pred == y_test)
print(f"Test set accuracy: {accuracy * 100:.2f}%")
print(f"  CVXOPT Linear kernel:   {linear_train_time:.4f} sec")

# (c) Visualization:
# Sort support vectors by the magnitude of their alpha coefficients and select top 5.
sorted_indices = np.argsort(-svm.alpha)  # descending order
top5_indices = sorted_indices[:5]
top5_sv = svm.sv[top5_indices]

# Plot the top-5 support vectors (reshape each from (30000,) to (100,100,3))
<A NAME="7"></A><FONT color = #0000FF><A HREF="match44-0.html#7" TARGET="0"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

plt.figure(figsize=(12, 3))
for i in range(5):
    img = top5_sv[i].reshape(100, 100, 3)
    plt.subplot(1, 5, i+1)
</FONT>    plt.imshow(img)
    plt.title(f"SV {i+1}")
<A NAME="0"></A><FONT color = #FF0000><A HREF="match44-0.html#0" TARGET="0"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    plt.axis('off')
plt.suptitle("Top-5 Support Vectors")
plt.show()

# Reshape and plot the weight vector w as an image.
w_img = svm.w.reshape(100, 100, 3)
w_img = (w_img - w_img.min()) / (w_img.max() - w_img.min())
plt.figure(figsize=(4, 4))
plt.imshow(w_img, cmap='viridis')
plt.title("Weight Vector Visualization")
plt.axis('off')
plt.show()
</FONT>

# In[12]:


import os
import cv2
import numpy as np
import cvxopt
import cvxopt.solvers
import matplotlib.pyplot as plt

def preprocess_image(img, target_size=(100, 100)):
    """
    Preprocess a single image:
      1. Resize while preserving aspect ratio so that both dimensions are at least the target size.
      2. Center crop to target_size.
      3. Normalize pixel values to [0, 1].
      4. Return the processed image.
    """
    if img is None:
        return None
    # Convert BGR to RGB (cv2 loads in BGR)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    h, w = img.shape[:2]
    target_h, target_w = target_size

    # Scale so that both dimensions are &gt;= target dimensions.
    scale = max(target_h / h, target_w / w)
    new_w, new_h = int(w * scale), int(h * scale)
    resized = cv2.resize(img, (new_w, new_h))
    
    # Center crop
    start_x = (new_w - target_w) // 2
    start_y = (new_h - target_h) // 2
    cropped = resized[start_y:start_y+target_h, start_x:start_x+target_w]
    
    norm_img = cropped.astype(np.float32) / 255.0
    return norm_img

def load_dataset(class_dirs, target_size=(100, 100)):
    """
    Given a list of folder paths (each folder corresponding to one class), load images,
    preprocess them, flatten them to a 30,000-dimensional vector, and assign labels.
    The first folder gets label 0 and the second gets label 1.
    """
    X, y = [], []
    for label, folder in enumerate(class_dirs):
        for filename in os.listdir(folder):
            filepath = os.path.join(folder, filename)
            img = cv2.imread(filepath)
            if img is None:
                continue
            proc_img = preprocess_image(img, target_size)
            if proc_img is None or proc_img.shape[:2] != target_size:
                continue
            X.append(proc_img.flatten())  # 100*100*3 = 30000
            y.append(label)
    return np.array(X), np.array(y)

class SupportVectorMachine:
    """
    SVM classifier using the CVXOPT package.
    Supports 'linear' and 'gaussian' kernels.
    """
    def __init__(self):
        self.alpha = None   # Lagrange multipliers for support vectors
        self.sv = None      # Support vectors
        self.sv_y = None    # Their labels (in {-1, +1})
        self.w = None       # Weight vector (only for linear kernel)
        self.b = None       # Bias term
        self.sv_indices = None  # Indices of support vectors in the training set
        self.kernel = None
        self.gamma = None   # Only used for gaussian kernel

    def fit(self, X, y, C=1.0, kernel='linear', gamma=0.001):
        """
        Fit SVM by solving the dual QP.
        
        For the dual:
            minimize   (1/2) α^T P α - 1^T α
            subject to y^T α = 0  and 0 &lt;= α_i &lt;= C.
        
        For a Gaussian kernel, P is defined as:
            P_ij = y_i y_j exp(-gamma * ||x_i - x_j||^2).
        
        For the linear kernel, P is:
            P_ij = y_i y_j (x_i^T x_j).
        
        The labels y are expected to be in {0, 1} and are mapped to {-1, +1}.
        """
        N, D = X.shape
        y_mod = np.where(y == 0, -1, 1).astype(np.double)
        self.kernel = kernel

        if kernel == 'linear':
            K = np.dot(X, X.T)
        elif kernel == 'gaussian':
            # Compute the squared Euclidean distances:
            X_square = np.sum(X**2, axis=1).reshape(-1, 1)
            K = np.exp(-gamma * (X_square - 2 * np.dot(X, X.T) + X_square.T))
            self.gamma = gamma
        else:
            raise ValueError("Unsupported kernel.")

        # Construct QP parameters
        P = cvxopt.matrix(np.outer(y_mod, y_mod) * K)
        q = cvxopt.matrix(-np.ones(N))
        G_std = -np.eye(N)   # for alpha_i &gt;= 0
        G_slack = np.eye(N)  # for alpha_i &lt;= C
        G = cvxopt.matrix(np.vstack((G_std, G_slack)))
        h = cvxopt.matrix(np.hstack((np.zeros(N), C * np.ones(N))))
        A = cvxopt.matrix(y_mod.reshape(1, -1))
        b = cvxopt.matrix(0.0)

        # Solve the QP problem
        cvxopt.solvers.options['show_progress'] = False
        solution = cvxopt.solvers.qp(P, q, G, h, A, b)
        alphas = np.ravel(solution['x'])
        
        # Identify support vectors
        sv_indices = np.where(alphas &gt; 1e-5)[0]
        self.sv_indices = sv_indices
        self.alpha = alphas[sv_indices]
        self.sv = X[sv_indices]
        self.sv_y = y_mod[sv_indices]
        
        num_sv = len(self.alpha)
        print(f"Number of support vectors ({kernel} kernel): {num_sv} out of {N} training samples ({100.0 * num_sv / N:.2f}%)")
        
        if kernel == 'linear':
            # Compute weight vector w = sum_i alpha_i y_i x_i
            self.w = np.sum((self.alpha * self.sv_y)[:, None] * self.sv, axis=0)
            # Compute bias using support vectors not on the margin boundaries (if possible)
            sv_non_bound = (alphas &gt; 1e-5) & (alphas &lt; C - 1e-5)
            if np.any(sv_non_bound):
                b_candidates = y_mod[sv_non_bound] - np.dot(X[sv_non_bound], self.w)
            else:
                b_candidates = self.sv_y - np.dot(self.sv, self.w)
            self.b = np.mean(b_candidates)
        elif kernel == 'gaussian':
            # For the Gaussian kernel, we cannot compute w explicitly.
            # Compute bias for each support vector: 
            #   b = y_i - sum_j (alpha_j * y_j * K(x_j, x_i))
            X_sv = self.sv
            X_sv_square = np.sum(X_sv**2, axis=1).reshape(-1, 1)
            K_sv = np.exp(-gamma * (X_sv_square - 2 * np.dot(X_sv, X_sv.T) + X_sv_square.T))
            pred_sv = np.sum((self.alpha * self.sv_y)[None, :] * K_sv, axis=1)
            self.b = np.mean(self.sv_y - pred_sv)

    def predict(self, X):
        """
        Predict class labels for input samples X.
        Returns labels in {0, 1}.
        """
        if self.kernel == 'linear':
            pred = np.dot(X, self.w) + self.b
        elif self.kernel == 'gaussian':
            # Compute the kernel between X and the support vectors.
            X_sq = np.sum(X**2, axis=1).reshape(-1, 1)
            SV_sq = np.sum(self.sv**2, axis=1).reshape(1, -1)
            K_test = np.exp(-self.gamma * (X_sq - 2 * np.dot(X, self.sv.T) + SV_sq))
            pred = np.dot(K_test, self.alpha * self.sv_y) + self.b
        else:
            raise ValueError("Unsupported kernel.")
        
        # Map predictions: np.sign returns -1 or +1; convert -1 back to label 0.
        y_pred = np.where(np.sign(pred) == -1, 0, 1)
        return y_pred

# ---------------------------
# Example usage:
# ---------------------------

# Replace the following directory paths with your actual training and test folders.
train_dirs = ['Q2/train/lightning', 'Q2/train/rain']
test_dirs  = ['Q2/test/lightning', 'Q2/test/rain']

print("Loading training data...")
X_train, y_train = load_dataset(train_dirs, target_size=(100, 100))
print("Loading test data...")
X_test, y_test = load_dataset(test_dirs, target_size=(100, 100))

# Train SVM with a linear kernel (from part 1)

svm_linear = SupportVectorMachine()
svm_linear.fit(X_train, y_train, C=1.0, kernel='linear')
y_pred_linear = svm_linear.predict(X_test)
accuracy_linear = np.mean(y_pred_linear == y_test)
print(f"Test set accuracy (Linear kernel): {accuracy_linear * 100:.2f}%")

# Train SVM with a Gaussian kernel
start_time = time.time()
svm_gaussian = SupportVectorMachine()
svm_gaussian.fit(X_train, y_train, C=1.0, kernel='gaussian', gamma=0.001)
gaussian_train_time = time.time() - start_time
y_pred_gaussian = svm_gaussian.predict(X_test)
accuracy_gaussian = np.mean(y_pred_gaussian == y_test)
print(f"Test set accuracy (Gaussian kernel): {accuracy_gaussian * 100:.2f}%")
print(f"  CVXOPT Gaussian kernel:   {gaussian_train_time:.4f} sec")

# (a) Compare the number of support vectors between the two kernels
num_sv_linear = len(svm_linear.alpha)
num_sv_gaussian = len(svm_gaussian.alpha)
print(f"\nSupport Vectors Comparison:")
print(f"  Linear kernel: {num_sv_linear} support vectors")
print(f"  Gaussian kernel: {num_sv_gaussian} support vectors")

# Determine how many support vectors match between the two approaches.
common_sv = np.intersect1d(svm_linear.sv_indices, svm_gaussian.sv_indices)
print(f"  Number of support vectors common to both: {len(common_sv)}")

# (c) Plot the top-5 support vectors for the Gaussian kernel.
sorted_indices_gaussian = np.argsort(-svm_gaussian.alpha)[:5]
top5_sv_gaussian = svm_gaussian.sv[sorted_indices_gaussian]

<A NAME="8"></A><FONT color = #00FFFF><A HREF="match44-0.html#8" TARGET="0"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

plt.figure(figsize=(12, 3))
for i in range(5):
    img = top5_sv_gaussian[i].reshape(100, 100, 3)
    plt.subplot(1, 5, i+1)
</FONT>    plt.imshow(img)
    plt.title(f"SV {i+1}")
    plt.axis('off')
plt.suptitle("Top-5 Support Vectors (Gaussian Kernel)")
plt.show()

# (d) Compare test accuracies:
print("\nTest Accuracy Comparison:")
print(f"  Linear kernel accuracy:   {accuracy_linear * 100:.2f}%")
print(f"  Gaussian kernel accuracy: {accuracy_gaussian * 100:.2f}%")


# In[6]:


import time
import numpy as np
from sklearn.svm import SVC

# --- Assume X_train, y_train, X_test, y_test have been loaded/preprocessed ---
# --- Also assume that the CVXOPT SVM implementations from parts 1 & 2 have been run ---
# --- and that the variables 'svm_linear' and 'svm_gaussian' are available, with:
#       svm_linear.sv_indices, svm_linear.w, svm_linear.b for linear kernel, and
#       svm_gaussian.sv_indices for the Gaussian kernel. ---

# 1. Train scikit-learn SVM with linear kernel
start_time = time.time()
svm_linear_sklearn = SVC(kernel='linear', C=1.0)
svm_linear_sklearn.fit(X_train, y_train)
linear_train_time = time.time() - start_time

# 2. Train scikit-learn SVM with Gaussian (RBF) kernel
start_time = time.time()
svm_gaussian_sklearn = SVC(kernel='rbf', C=1.0, gamma=0.001)
svm_gaussian_sklearn.fit(X_train, y_train)
gaussian_train_time = time.time() - start_time

# (a) Compare number of support vectors (nSV)
nSV_linear_sklearn = len(svm_linear_sklearn.support_)
nSV_gaussian_sklearn = len(svm_gaussian_sklearn.support_)

print("Sklearn SVM (Linear):")
print(f"  Number of support vectors: {nSV_linear_sklearn}")
print("Sklearn SVM (Gaussian):")
print(f"  Number of support vectors: {nSV_gaussian_sklearn}")

# Compare with CVXOPT results:
# (Assuming 'svm_linear.sv_indices' and 'svm_gaussian.sv_indices' from earlier CVXOPT runs)
common_sv_linear = np.intersect1d(svm_linear.sv_indices, svm_linear_sklearn.support_)
common_sv_gaussian = np.intersect1d(svm_gaussian.sv_indices, svm_gaussian_sklearn.support_)

print("\nCommon support vectors with CVXOPT (Linear):", len(common_sv_linear))
print("Common support vectors with CVXOPT (Gaussian):", len(common_sv_gaussian))

# (b) Compare weight vector (w) and bias (b) for the linear kernel:
# For CVXOPT, we computed:
w_cvxopt = svm_linear.w  # shape: (30000,)
b_cvxopt = svm_linear.b

# For scikit-learn, the weight vector is stored in coef_ and bias in intercept_
w_sklearn = svm_linear_sklearn.coef_.flatten()  # shape: (30000,)
b_sklearn = svm_linear_sklearn.intercept_[0]

print("\nComparison of weight vector (first 10 elements):")
print("  CVXOPT w:", w_cvxopt[:10])
print("  Sklearn w:", w_sklearn[:10])
print("\nComparison of bias:")
print("  CVXOPT b:", b_cvxopt)
print("  Sklearn b:", b_sklearn)

# (c) Report test accuracy for both linear and Gaussian kernels using scikit-learn:
y_pred_linear_sklearn = svm_linear_sklearn.predict(X_test)
accuracy_linear_sklearn = np.mean(y_pred_linear_sklearn == y_test)

y_pred_gaussian_sklearn = svm_gaussian_sklearn.predict(X_test)
accuracy_gaussian_sklearn = np.mean(y_pred_gaussian_sklearn == y_test)

print("\nTest Accuracy (Sklearn):")
print(f"  Linear kernel:   {accuracy_linear_sklearn * 100:.2f}%")
print(f"  Gaussian kernel: {accuracy_gaussian_sklearn * 100:.2f}%")

# (d) Compare training times (computational cost)
# Assume you have recorded training times for CVXOPT runs as:
#   cvxopt_linear_time and cvxopt_gaussian_time (in seconds)
# For demonstration, we'll use placeholder values:
cvxopt_linear_time = 10.0  # e.g., 10 seconds (replace with actual measured time)
cvxopt_gaussian_time = 15.0  # e.g., 15 seconds (replace with actual measured time)

print("\nTraining Time Comparison:")
print(f"  CVXOPT Linear kernel:   {cvxopt_linear_time:.4f} sec")
print(f"  Sklearn Linear kernel:  {linear_train_time:.4f} sec")
print(f"  CVXOPT Gaussian kernel: {cvxopt_gaussian_time:.4f} sec")
print(f"  Sklearn Gaussian kernel: {gaussian_train_time:.4f} sec")


# In[13]:


import time
from sklearn.linear_model import SGDClassifier
from sklearn.svm import LinearSVC

# Assume X_train, y_train, X_test, y_test are already defined.

# --- Using SGDClassifier (SVM objective via SGD) ---
<A NAME="4"></A><FONT color = #FF00FF><A HREF="match44-0.html#4" TARGET="0"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

start_time = time.time()
sgd_clf = SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, random_state=42)
sgd_clf.fit(X_train, y_train)
sgd_train_time = time.time() - start_time
</FONT>sgd_train_accuracy = sgd_clf.score(X_train, y_train)
sgd_test_accuracy = sgd_clf.score(X_test, y_test)

# --- Using LIBLINEAR (via LinearSVC) ---
start_time = time.time()
linear_svc = LinearSVC(C=1.0, max_iter=1000, random_state=42)
linear_svc.fit(X_train, y_train)
svc_train_time = time.time() - start_time
svc_train_accuracy = linear_svc.score(X_train, y_train)
svc_test_accuracy = linear_svc.score(X_test, y_test)

print("SGD Classifier (SVM objective via SGD):")
print(f"  Training Time: {sgd_train_time:.4f} sec")
print(f"  Training Accuracy: {sgd_train_accuracy*100:.2f}%")
print(f"  Test Accuracy: {sgd_test_accuracy*100:.2f}%")

print("\nLIBLINEAR (LinearSVC):")
print(f"  Training Time: {svc_train_time:.4f} sec")
print(f"  Training Accuracy: {svc_train_accuracy*100:.2f}%")
print(f"  Test Accuracy: {svc_test_accuracy*100:.2f}%")


# In[3]:


import numpy as np
import cvxopt
import cvxopt.solvers
import os
import cv2
import matplotlib.pyplot as plt

# --- Helper functions for image preprocessing ---
def preprocess_image(img, target_size=(100, 100)):
    """
    Preprocess an image:
      1. Resize (keeping aspect ratio) so that both dimensions are &gt;= target_size.
      2. Center crop to target_size.
      3. Normalize to [0, 1].
    """
    if img is None:
        return None
    # Convert BGR to RGB
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    h, w = img.shape[:2]
    target_h, target_w = target_size

    # Scale image so that both dimensions are at least the target dimensions.
    scale = max(target_h / h, target_w / w)
    new_w, new_h = int(w * scale), int(h * scale)
    resized = cv2.resize(img, (new_w, new_h))
    
    # Center crop
    start_x = (new_w - target_w) // 2
    start_y = (new_h - target_h) // 2
    cropped = resized[start_y:start_y+target_h, start_x:start_x+target_w]
    
    norm_img = cropped.astype(np.float32) / 255.0
    return norm_img

def load_dataset(class_dirs, target_size=(100, 100)):
    """
    Given a list of folder paths (each corresponding to one class), load images,
    preprocess them, flatten to a 30,000-dimensional vector, and assign labels.
    The first folder gets label 0, the second gets label 1, etc.
    """
    X, y = [], []
    for label, folder in enumerate(class_dirs):
        for filename in os.listdir(folder):
            filepath = os.path.join(folder, filename)
            img = cv2.imread(filepath)
            if img is None:
                continue
            proc_img = preprocess_image(img, target_size)
            if proc_img is None or proc_img.shape[:2] != target_size:
                continue
            X.append(proc_img.flatten())  # Flattened image: 100*100*3 = 30000
            y.append(label)
    return np.array(X), np.array(y)

# --- CVXOPT-based binary SVM (Gaussian kernel) ---
class SupportVectorMachine:
    """
    Binary SVM using CVXOPT. Supports 'linear' and 'gaussian' kernels.
    Here we add a decision_function method to get the raw output.
    """
    def __init__(self):
        self.alpha = None   # Lagrange multipliers for support vectors
        self.sv = None      # Support vectors
        self.sv_y = None    # Their labels (in {-1, +1})
        self.w = None       # Weight vector (only for linear kernel)
        self.b = None       # Bias term
        self.sv_indices = None  # Indices of support vectors in training data
        self.kernel = None
        self.gamma = None   # Only for gaussian kernel

    def fit(self, X, y, C=1.0, kernel='linear', gamma=0.001):
        """
        Fit SVM by solving the dual QP:
            minimize (1/2) α^T P α - 1^T α,
            subject to y^T α = 0 and 0 &lt;= α_i &lt;= C.
        The labels y are expected to be in {-1, +1}.
        """
        N, D = X.shape
        self.kernel = kernel

        if kernel == 'linear':
            K = np.dot(X, X.T)
        elif kernel == 'gaussian':
            # Compute squared Euclidean distances (vectorized)
            X_sq = np.sum(X**2, axis=1).reshape(-1, 1)
            K = np.exp(-gamma * (X_sq - 2*np.dot(X, X.T) + X_sq.T))
            self.gamma = gamma
        else:
            raise ValueError("Unsupported kernel.")

        P = cvxopt.matrix(np.outer(y, y) * K)
        q = cvxopt.matrix(-np.ones(N))
        G_std = -np.eye(N)
        G_slack = np.eye(N)
        G = cvxopt.matrix(np.vstack((G_std, G_slack)))
        h = cvxopt.matrix(np.hstack((np.zeros(N), C * np.ones(N))))
        A = cvxopt.matrix(y.reshape(1, -1))
        b = cvxopt.matrix(0.0)

        cvxopt.solvers.options['show_progress'] = False
        solution = cvxopt.solvers.qp(P, q, G, h, A, b)
        alphas = np.ravel(solution['x'])

        sv_indices = np.where(alphas &gt; 1e-5)[0]
        self.sv_indices = sv_indices
        self.alpha = alphas[sv_indices]
        self.sv = X[sv_indices]
        self.sv_y = y[sv_indices]

        if kernel == 'linear':
            self.w = np.sum((self.alpha * self.sv_y)[:, None] * self.sv, axis=0)
            # Compute bias using support vectors (average over those not at bounds)
            sv_non_bound = (alphas &gt; 1e-5) & (alphas &lt; C - 1e-5)
            if np.any(sv_non_bound):
                b_candidates = y[sv_non_bound] - np.dot(X[sv_non_bound], self.w)
            else:
                b_candidates = self.sv_y - np.dot(self.sv, self.w)
            self.b = np.mean(b_candidates)
        elif kernel == 'gaussian':
            # Compute bias for gaussian kernel
            X_sv = self.sv
            X_sv_sq = np.sum(X_sv**2, axis=1).reshape(-1, 1)
            K_sv = np.exp(-gamma * (X_sv_sq - 2*np.dot(X_sv, X_sv.T) + X_sv_sq.T))
            pred_sv = np.sum((self.alpha * self.sv_y)[None, :] * K_sv, axis=1)
            self.b = np.mean(self.sv_y - pred_sv)

    def decision_function(self, X):
        """
        Compute the decision function values for input samples X.
        For a new sample x, compute: f(x) = sum_{i in SV} alpha_i * y_i * K(x_i, x) + b.
        """
        if self.kernel == 'linear':
            return np.dot(X, self.w) + self.b
        elif self.kernel == 'gaussian':
            X_sq = np.sum(X**2, axis=1).reshape(-1, 1)
            SV_sq = np.sum(self.sv**2, axis=1).reshape(1, -1)
            K_test = np.exp(-self.gamma * (X_sq - 2*np.dot(X, self.sv.T) + SV_sq))
            return np.dot(K_test, self.alpha * self.sv_y) + self.b
        else:
            raise ValueError("Unsupported kernel.")

    def predict(self, X):
        """
        Predict labels (mapping sign: negative-&gt; -1, non-negative-&gt; +1).
        """
        f = self.decision_function(X)
        return np.where(np.sign(f) == -1, -1, 1)

# --- One-vs-One Multi-Class SVM using CVXOPT ---
class MultiClassSVM:
    """
    Implements one-vs-one multi-class SVM using the CVXOPT-based binary SVM.
    For k classes (here, k=11), train k*(k-1)/2 binary classifiers.
    """
    def __init__(self, C=1.0, gamma=0.001):
        self.classifiers = []  # List of tuples: (class_i, class_j, classifier)
        self.C = C
        self.gamma = gamma

    def fit(self, X, y):
        """
        Train a binary SVM for each pair of classes.
        The labels for each binary classifier are mapped as:
           class_i -&gt; -1, class_j -&gt; +1.
        """
        self.classes_ = np.unique(y)
        num_classes = len(self.classes_)
        for i in range(num_classes):
            for j in range(i+1, num_classes):
                class_i = self.classes_[i]
                class_j = self.classes_[j]
                # Select training samples belonging to classes i and j.
<A NAME="5"></A><FONT color = #FF0000><A HREF="match44-0.html#5" TARGET="0"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

                indices = np.where((y == class_i) | (y == class_j))[0]
                X_pair = X[indices]
                y_pair = y[indices]
                # Map labels: class_i -&gt; -1, class_j -&gt; +1.
                y_pair_mapped = np.where(y_pair == class_i, -1, 1).astype(np.double)
</FONT>                # Train binary SVM with Gaussian kernel.
                svm = SupportVectorMachine()
                svm.fit(X_pair, y_pair_mapped, C=self.C, kernel='gaussian', gamma=self.gamma)
                # Store classifier with the corresponding class labels.
                self.classifiers.append((class_i, class_j, svm))

    def predict(self, X):
        """
        For each test sample, each classifier votes for one of its two classes.
        In case of a tie, choose the class with the highest cumulative decision score.
        """
        num_samples = X.shape[0]
        votes = np.zeros((num_samples, len(self.classes_)))   # vote counts for each class
        score_sum = np.zeros((num_samples, len(self.classes_))) # cumulative decision scores

        # For each binary classifier, get decision function and predicted label.
        for (class_i, class_j, svm) in self.classifiers:
            # Get decision function values
            f = svm.decision_function(X)
            # If f &gt;= 0, classifier predicts class_j; else, class_i.
            pred = np.where(f &gt;= 0, class_j, class_i)
            for idx in range(num_samples):
                if pred[idx] == class_i:
                    votes[idx, class_i] += 1
                    score_sum[idx, class_i] += -abs(f[idx])
                else:
                    votes[idx, class_j] += 1
                    score_sum[idx, class_j] += abs(f[idx])
                    
        # For each sample, choose the class with maximum votes.
        # In case of tie, choose the one with the highest cumulative score.
        final_pred = np.zeros(num_samples, dtype=int)
        for idx in range(num_samples):
            # Find the classes with maximum votes.
            max_vote = np.max(votes[idx])
            candidates = np.where(votes[idx] == max_vote)[0]
            if len(candidates) == 1:
                final_pred[idx] = candidates[0]
            else:
                # Tie-breaker: choose the candidate with highest cumulative decision score.
                candidate_scores = score_sum[idx, candidates]
                final_pred[idx] = candidates[np.argmax(candidate_scores)]
        return final_pred

# ---------------------------
# Example usage:
# ---------------------------
# Assume you have 11 folders (one for each class) for training and similarly for test data.
# Replace the folder paths in 'all_train_dirs' and 'all_test_dirs' with your actual directory paths.
all_train_dirs = [f'Q2/train/{i}' for i in ['dew','fogsmog','frost','glaze','hail','lightning','rain','rainbow','rime','sandstorm','snow']]
all_test_dirs  = [f'Q2/test/{i}' for i in ['dew','fogsmog','frost','glaze','hail','lightning','rain','rainbow','rime','sandstorm','snow']]

print("Loading multi-class training data...")
X_train, y_train = load_dataset(all_train_dirs, target_size=(100, 100))
print("Loading multi-class test data...")
X_test, y_test = load_dataset(all_test_dirs, target_size=(100, 100))

# Train the multi-class SVM (one-vs-one using Gaussian kernel)
<A NAME="3"></A><FONT color = #00FFFF><A HREF="match44-0.html#3" TARGET="0"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

multi_svm = MultiClassSVM(C=5.0, gamma=0.001)
multi_svm.fit(X_train, y_train)

# Predict on test set and report accuracy
y_pred = multi_svm.predict(X_test)
accuracy = np.mean(y_pred == y_test)
</FONT>print(f"\nMulti-class SVM Test Accuracy: {accuracy*100:.2f}%")


# In[ ]:





# In[ ]:


import time
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix

# ---------------------------
# Assume the following are already defined:
# X_train, y_train, X_test, y_test are the multi-class training and test sets
# (each image flattened to a 30000-dimensional vector).
# Also, multi_svm is the CVXOPT-based one-vs-one multi-class SVM (from part 5),
# with its .predict() method available.
# ---------------------------

# ====== 6. LIBSVM Multi-class SVM ======
# (a) Train using scikit-learn SVC with RBF kernel (γ = 0.001, C = 1.0)
start_time = time.time()
svm_libsvm = SVC(kernel='rbf', gamma=0.001, C=1.0)
svm_libsvm.fit(X_train, y_train)
libsvm_train_time = time.time() - start_time

# Classify the test examples
y_pred_libsvm = svm_libsvm.predict(X_test)
accuracy_libsvm = np.mean(y_pred_libsvm == y_test)
print("LIBSVM (scikit-learn) Multi-class SVM:")
print(f"  Test Accuracy: {accuracy_libsvm*100:.2f}%")
print(f"  Training Time: {libsvm_train_time:.4f} seconds")

# (b) Comparison with CVXOPT-based one-vs-one SVM
# Assume multi_svm is the CVXOPT one-vs-one model trained earlier.
start_time = time.time()
y_pred_cvxopt = multi_svm.predict(X_test)
cvxopt_predict_time = time.time() - start_time  # time for prediction only
accuracy_cvxopt = np.mean(y_pred_cvxopt == y_test)
print("\nCVXOPT one-vs-one Multi-class SVM (Gaussian kernel):")
print(f"  Test Accuracy: {accuracy_cvxopt*100:.2f}%")
# (Training time for CVXOPT is generally much higher; here we only report prediction time.)
print(f"  (Prediction Time: {cvxopt_predict_time:.4f} seconds)")
print("\nComparison:")
print("  LIBSVM (scikit-learn) is typically much faster in training compared to the CVXOPT-based solver.")
print("  The test accuracy may be comparable or slightly better with LIBSVM due to its optimized implementation.")


# ====== 7. Confusion Matrix and Misclassified Examples ======

# Confusion matrix for CVXOPT-based multi-class SVM
cm_cvxopt = confusion_matrix(y_test, y_pred_cvxopt)
plt.figure(figsize=(10, 8))
sns.heatmap(cm_cvxopt, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix - CVXOPT one-vs-one Multi-class SVM")
plt.xlabel("Predicted Class")
plt.ylabel("True Class")
plt.show()

# Confusion matrix for LIBSVM-based multi-class SVM
cm_libsvm = confusion_matrix(y_test, y_pred_libsvm)
plt.figure(figsize=(10, 8))
sns.heatmap(cm_libsvm, annot=True, fmt="d", cmap="Greens")
plt.title("Confusion Matrix - LIBSVM Multi-class SVM")
plt.xlabel("Predicted Class")
plt.ylabel("True Class")
plt.show()

# Analyze misclassifications: Which classes are confused most?
print("\nObservations from the confusion matrices:")
print("  - Look for blocks off the diagonal where certain classes are consistently misclassified.")
print("  - For example, if class 3 is often misclassified as class 4 (or vice versa),")
print("    this might indicate that these two classes share similar visual features.\n")

# Visualize 10 misclassified examples (using LIBSVM predictions here)
misclassified_indices = np.where(y_pred_libsvm != y_test)[0]
print(f"Total misclassified examples (LIBSVM): {len(misclassified_indices)}")
if len(misclassified_indices) &gt;= 10:
    sample_indices = np.random.choice(misclassified_indices, size=10, replace=False)
else:
    sample_indices = misclassified_indices

plt.figure(figsize=(15, 5))
for i, idx in enumerate(sample_indices):
    # Reshape the flattened image to (100, 100, 3)
    img = X_test[idx].reshape(100, 100, 3)
    true_label = y_test[idx]
    pred_label = y_pred_libsvm[idx]
    plt.subplot(2, 5, i+1)
    plt.imshow(img)
    plt.title(f"True: {true_label}\nPred: {pred_label}")
    plt.axis("off")
plt.suptitle("Examples of Misclassified Images (LIBSVM)")
plt.show()

print("\nComments:")
print("  - The confusion matrices reveal which classes are most often confused with each other.")
print("  - In the misclassified examples, one may notice that images with ambiguous or overlapping features")
print("    (e.g., similar weather conditions or similar color palettes) are harder to distinguish.")
print("  - These results are consistent with the inherent difficulty in the dataset and the limitations")
print("    of the kernel representation. The improved training time and often slightly higher accuracy")
print("    of LIBSVM make it more practical for such multi-class image classification tasks.")


# In[18]:


import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score

# Assume that X_train, y_train, X_test, y_test are already defined and preprocessed.
# X_train and X_test are arrays of shape (N, 30000) (flattened 100x100x3 images).
# y_train and y_test contain the corresponding labels.

# Define the candidate values for C
candidate_C = [1e-5, 1e-3, 1, 5, 10]

cv_scores = []   # To store 5-fold cross-validation accuracy
test_scores = [] # To store test set accuracy

print("Hyperparameter tuning (5-fold CV) results:")
for C_val in candidate_C:
    # Create SVM model with RBF kernel, fixed gamma=0.001, and current C value.
    svc = SVC(kernel='rbf', gamma=0.001, C=C_val)
    
    # Perform 5-fold cross-validation on the training data
    scores = cross_val_score(svc, X_train, y_train, cv=5, scoring='accuracy')
    mean_cv = np.mean(scores)
    cv_scores.append(mean_cv)
    
    # Train on the entire training set and evaluate on test set
    svc.fit(X_train, y_train)
    test_acc = svc.score(X_test, y_test)
    test_scores.append(test_acc)
    
    print(f"C = {C_val:&lt;8} 5-fold CV Accuracy = {mean_cv*100:.2f}%   Test Accuracy = {test_acc*100:.2f}%")

# Plotting the results:
plt.figure(figsize=(8, 6))
plt.plot(candidate_C, cv_scores, label="5-fold CV Accuracy", marker='o')
plt.plot(candidate_C, test_scores, label="Test Accuracy", marker='o')
plt.xscale('log')
plt.xlabel("C (log scale)")
plt.ylabel("Accuracy")
plt.title("Accuracy vs C for Gaussian Kernel SVM (γ = 0.001)")
plt.legend()
plt.grid(True)
plt.show()

# Determine the best C value based on CV accuracy
best_index = np.argmax(cv_scores)
best_C = candidate_C[best_index]
print(f"\nBest C value (based on 5-fold CV): {best_C}")

# Retrain SVM with the best C on the entire training set
best_svc = SVC(kernel='rbf', gamma=0.001, C=best_C)
best_svc.fit(X_train, y_train)
best_test_acc = best_svc.score(X_test, y_test)
print(f"Test Accuracy with best C ({best_C}): {best_test_acc*100:.2f}%")

# Comments:
print("\nComments:")
print("  - The plot shows how both the 5-fold CV accuracy and the test set accuracy vary as C changes.")
print("  - Typically, very small values of C (e.g., 1e-5 or 1e-3) underfit the data, resulting in lower accuracy.")
print("  - As C increases, the model becomes more flexible and may fit the training data better.")
print("  - However, too high a value of C may lead to overfitting.")
print("  - The best C value is the one that maximizes the CV accuracy while ideally also giving a high test accuracy.")
print("  - In our experiment, after selecting the best C and retraining on the entire training set,")
print("    we may observe an improvement (or at least no degradation) in test accuracy compared to our previous model.")


# In[2]:


import numpy as np
import matplotlib.pyplot as plt
from cuml.svm import SVC as cuSVC  # cuML's GPU-accelerated SVC
from sklearn.model_selection import KFold
import time
import os
import cv2

def preprocess_image(img, target_size=(100, 100)):
    """
    Preprocess an image:
      1. Resize (keeping aspect ratio) so that both dimensions are &gt;= target_size.
      2. Center crop to target_size.
      3. Normalize to [0, 1].
    """
    if img is None:
        return None
    # Convert BGR to RGB
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    h, w = img.shape[:2]
    target_h, target_w = target_size

    # Scale image so that both dimensions are at least the target dimensions.
    scale = max(target_h / h, target_w / w)
    new_w, new_h = int(w * scale), int(h * scale)
    resized = cv2.resize(img, (new_w, new_h))
    
    # Center crop
    start_x = (new_w - target_w) // 2
    start_y = (new_h - target_h) // 2
    cropped = resized[start_y:start_y+target_h, start_x:start_x+target_w]
    
    norm_img = cropped.astype(np.float32) / 255.0
    return norm_img
    
def load_dataset(class_dirs, target_size=(100, 100)):
    """
    Given a list of folder paths (each corresponding to one class), load images,
    preprocess them, flatten to a 30,000-dimensional vector, and assign labels.
    The first folder gets label 0, the second gets label 1, etc.
    """
    X, y = [], []
    for label, folder in enumerate(class_dirs):
        for filename in os.listdir(folder):
            filepath = os.path.join(folder, filename)
            img = cv2.imread(filepath)
            if img is None:
                continue
            proc_img = preprocess_image(img, target_size)
            if proc_img is None or proc_img.shape[:2] != target_size:
                continue
            X.append(proc_img.flatten())  # Flattened image: 100*100*3 = 30000
            y.append(label)
    return np.array(X), np.array(y)
    
# Replace the folder paths in 'all_train_dirs' and 'all_test_dirs' with your actual directory paths.
all_train_dirs = [f'Q2/train/{i}' for i in ['dew','fogsmog','frost','glaze','hail','lightning','rain','rainbow','rime','sandstorm','snow']]
all_test_dirs  = [f'Q2/test/{i}' for i in ['dew','fogsmog','frost','glaze','hail','lightning','rain','rainbow','rime','sandstorm','snow']]

print("Loading multi-class training data...")
X_train, y_train = load_dataset(all_train_dirs, target_size=(100, 100))
print("Loading multi-class test data...")
X_test, y_test = load_dataset(all_test_dirs, target_size=(100, 100))
# Assume X_train, y_train, X_test, y_test are already defined and preprocessed.
# X_train and X_test: shape (N, 30000) for flattened images.
# y_train and y_test: corresponding labels.

# Candidate C values
candidate_C = [1e-5, 1e-3, 1, 5, 10]

cv_scores = []   # 5-fold cross-validation accuracies
test_scores = [] # Test set accuracies

kf = KFold(n_splits=5, shuffle=True, random_state=42)

print("GPU Hyperparameter Tuning (using cuML SVC):")
for C_val in candidate_C:
    fold_scores = []
    for train_index, val_index in kf.split(X_train):
        X_tr, X_val = X_train[train_index], X_train[val_index]
        y_tr, y_val = y_train[train_index], y_train[val_index]
        # Create and train GPU SVC with fixed gamma and current C
        gpu_svc = cuSVC(kernel='rbf', gamma=0.001, C=C_val)
        gpu_svc.fit(X_tr, y_tr)
        y_val_pred = gpu_svc.predict(X_val)
        # Convert prediction to numpy array if needed
        if hasattr(y_val_pred, 'get'):
            y_val_pred = y_val_pred.get()
        fold_accuracy = np.mean(y_val_pred == y_val)
        fold_scores.append(fold_accuracy)
    mean_cv = np.mean(fold_scores)
    cv_scores.append(mean_cv)
    
    # Train on full training set and evaluate on test set
    gpu_svc_full = cuSVC(kernel='rbf', gamma=0.001, C=C_val)
    gpu_svc_full.fit(X_train, y_train)
    y_test_pred = gpu_svc_full.predict(X_test)
    if hasattr(y_test_pred, 'get'):
        y_test_pred = y_test_pred.get()
    test_acc = np.mean(y_test_pred == y_test)
    test_scores.append(test_acc)
    
    print(f"C = {C_val:&lt;8} 5-fold CV Accuracy = {mean_cv*100:.2f}%   Test Accuracy = {test_acc*100:.2f}%")

# Plot the cross-validation and test accuracies
plt.figure(figsize=(8, 6))
plt.plot(candidate_C, cv_scores, label="5-fold CV Accuracy", marker='o')
plt.plot(candidate_C, test_scores, label="Test Accuracy", marker='o')
plt.xscale('log')
plt.xlabel("C (log scale)")
plt.ylabel("Accuracy")
plt.title("GPU SVM Accuracy vs C (γ = 0.001)")
plt.legend()
plt.grid(True)
plt.show()

# Determine best C based on CV accuracy
best_index = np.argmax(cv_scores)
best_C = candidate_C[best_index]
print(f"\nBest C value (from 5-fold CV): {best_C}")

# Retrain final GPU SVC using best C on the entire training set and measure training time.
gpu_svc_best = cuSVC(kernel='rbf', gamma=0.001, C=best_C)
start_time = time.time()
gpu_svc_best.fit(X_train, y_train)
gpu_train_time = time.time() - start_time

y_test_pred_best = gpu_svc_best.predict(X_test)
if hasattr(y_test_pred_best, 'get'):
    y_test_pred_best = y_test_pred_best.get()
best_test_acc = np.mean(y_test_pred_best == y_test)

print(f"Test Accuracy with best C ({best_C}): {best_test_acc*100:.2f}%")
print(f"Training time on GPU with best C: {gpu_train_time:.4f} seconds")


# In[4]:


import numpy as np
import matplotlib.pyplot as plt
from cuml.svm import SVC as cumlSVC
from sklearn.model_selection import KFold
import time
import gc

import os
import cv2

def preprocess_image(img, target_size=(100, 100)):
    """
    Preprocess an image:
      1. Resize (keeping aspect ratio) so that both dimensions are &gt;= target_size.
      2. Center crop to target_size.
      3. Normalize to [0, 1].
    """
    if img is None:
        return None
    # Convert BGR to RGB
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    h, w = img.shape[:2]
    target_h, target_w = target_size

    # Scale image so that both dimensions are at least the target dimensions.
    scale = max(target_h / h, target_w / w)
    new_w, new_h = int(w * scale), int(h * scale)
    resized = cv2.resize(img, (new_w, new_h))
    
    # Center crop
    start_x = (new_w - target_w) // 2
    start_y = (new_h - target_h) // 2
    cropped = resized[start_y:start_y+target_h, start_x:start_x+target_w]
    
    norm_img = cropped.astype(np.float32) / 255.0
    return norm_img
    
def load_dataset(class_dirs, target_size=(100, 100)):
    """
    Given a list of folder paths (each corresponding to one class), load images,
    preprocess them, flatten to a 30,000-dimensional vector, and assign labels.
    The first folder gets label 0, the second gets label 1, etc.
    """
    X, y = [], []
    for label, folder in enumerate(class_dirs):
        for filename in os.listdir(folder):
            filepath = os.path.join(folder, filename)
            img = cv2.imread(filepath)
            if img is None:
                continue
            proc_img = preprocess_image(img, target_size)
            if proc_img is None or proc_img.shape[:2] != target_size:
                continue
            X.append(proc_img.flatten())  # Flattened image: 100*100*3 = 30000
            y.append(label)
    return np.array(X), np.array(y)
    
# Replace the folder paths in 'all_train_dirs' and 'all_test_dirs' with your actual directory paths.
all_train_dirs = [f'Q2/train/{i}' for i in ['dew','fogsmog','frost','glaze','hail','lightning','rain','rainbow','rime','sandstorm','snow']]
all_test_dirs  = [f'Q2/test/{i}' for i in ['dew','fogsmog','frost','glaze','hail','lightning','rain','rainbow','rime','sandstorm','snow']]

print("Loading multi-class training data...")
X_train, y_train = load_dataset(all_train_dirs, target_size=(100, 100))
print("Loading multi-class test data...")
X_test, y_test = load_dataset(all_test_dirs, target_size=(100, 100))
# Assume X_train, y_train, X_test, y_test are already defined and preprocessed.
# X_train and X_test: shape (N, 30000) for flattened images.
# y_train and y_test: corresponding labels.


# --- Convert data to float32 for GPU efficiency ---
X_train = X_train.astype(np.float32)
X_test = X_test.astype(np.float32)

# --- Subsample training data to reduce memory usage ---
# For example, use 2000 training examples (if available)
sample_size = 200
if X_train.shape[0] &gt; sample_size:
    subsample_indices = np.random.choice(X_train.shape[0], sample_size, replace=False)
    X_train_sub = X_train[subsample_indices]
    y_train_sub = y_train[subsample_indices]
else:
    X_train_sub = X_train
    y_train_sub = y_train

# Candidate values for C
candidate_C = [1e-5, 1e-3, 1, 5, 10]

cv_scores = []   # To store 5-fold CV accuracies
test_scores = [] # To store test accuracies

kf = KFold(n_splits=5, shuffle=True, random_state=42)

print("GPU Hyperparameter Tuning (using cuML SVC) on subsampled training data:")
for C_val in candidate_C:
    fold_scores = []
    # Run 5-fold CV on the subsampled training data
    for train_index, val_index in kf.split(X_train_sub):
        X_tr, X_val = X_train_sub[train_index], X_train_sub[val_index]
        y_tr, y_val = y_train_sub[train_index], y_train_sub[val_index]
        
        # Create and train cuML SVC with RBF kernel, fixed gamma=0.001, current C
        model = cumlSVC(kernel='rbf', gamma=0.001, C=C_val)
        model.fit(X_tr, y_tr)
        y_val_pred = model.predict(X_val)
        if hasattr(y_val_pred, "get"):
            y_val_pred = y_val_pred.get()  # Convert from cupy to numpy array if needed
        fold_acc = np.mean(y_val_pred == y_val)
        fold_scores.append(fold_acc)
        
        # Free memory for the fold
        del model
        gc.collect()
        
    mean_cv = np.mean(fold_scores)
    cv_scores.append(mean_cv)
    
    # Train on the full subsample and evaluate on the full test set
    model_full = cumlSVC(kernel='rbf', gamma=0.001, C=C_val)
    model_full.fit(X_train_sub, y_train_sub)
    y_test_pred = model_full.predict(X_test)
    if hasattr(y_test_pred, "get"):
        y_test_pred = y_test_pred.get()
    test_acc = np.mean(y_test_pred == y_test)
    test_scores.append(test_acc)
    
    del model_full
    gc.collect()
    
    print(f"C = {C_val:&lt;8} 5-fold CV Accuracy = {mean_cv*100:.2f}%   Test Accuracy = {test_acc*100:.2f}%")

# Plot the CV and test accuracies versus C (with log scale on x-axis)
plt.figure(figsize=(8,6))
plt.plot(candidate_C, cv_scores, marker='o', label="5-fold CV Accuracy")
plt.plot(candidate_C, test_scores, marker='o', label="Test Accuracy")
plt.xscale('log')
plt.xlabel("C (log scale)")
plt.ylabel("Accuracy")
plt.title("cuML SVC Accuracy vs C (γ = 0.001) on Subsampled Data")
plt.legend()
plt.grid(True)
plt.show()

# Determine the best C value based on CV accuracy
best_index = np.argmax(cv_scores)
best_C = candidate_C[best_index]
print(f"\nBest C value (from 5-fold CV on subsampled data): {best_C}")

# Retrain final model using the best C on the subsampled training set
model_best = cumlSVC(kernel='rbf', gamma=0.001, C=best_C)
start_time = time.time()
model_best.fit(X_train_sub, y_train_sub)
training_time = time.time() - start_time

y_test_pred_best = model_best.predict(X_test)
if hasattr(y_test_pred_best, "get"):
    y_test_pred_best = y_test_pred_best.get()
best_test_acc = np.mean(y_test_pred_best == y_test)
print(f"Test Accuracy with best C ({best_C}): {best_test_acc*100:.2f}%")
print(f"Training time on GPU with best C: {training_time:.4f} seconds")





import cvxopt
import cvxopt.solvers
import numpy as np

class SupportVectorMachine:
    def __init__(self):
        self.alpha = None   
        self.sv = None      
        self.sv_y = None    
        self.w = None       
        self.b = None       
        self.sv_indices = None  
        self.kernel = None
        self.gamma = None   

    def fit(self, X, y,kernel='linear', C=1.0, gamma=0.001):
        N, D = X.shape
        y_mod = np.where(y == 0, -1, 1).astype(np.double)
        self.kernel = kernel

        if kernel == 'linear':
            K = np.dot(X, X.T)
        elif kernel == 'gaussian':
            
            X_square = np.sum(X**2, axis=1).reshape(-1, 1)
            K = np.exp(-gamma * (X_square - 2 * np.dot(X, X.T) + X_square.T))
            self.gamma = gamma
        else:
            raise ValueError("Unsupported kernel.")

        
        P = cvxopt.matrix(np.outer(y_mod, y_mod) * K)
        q = cvxopt.matrix(-np.ones(N))
        G_std = -np.eye(N)   
        G_slack = np.eye(N)  
        G = cvxopt.matrix(np.vstack((G_std, G_slack)))
        h = cvxopt.matrix(np.hstack((np.zeros(N), C * np.ones(N))))
        A = cvxopt.matrix(y_mod.reshape(1, -1))
        b = cvxopt.matrix(0.0)

        
        cvxopt.solvers.options['show_progress'] = False
        solution = cvxopt.solvers.qp(P, q, G, h, A, b)
        alphas = np.ravel(solution['x'])
        
        
        sv_indices = np.where(alphas &gt; 1e-5)[0]
        self.sv_indices = sv_indices
        self.alpha = alphas[sv_indices]
        self.sv = X[sv_indices]
        self.sv_y = y_mod[sv_indices]
        
        num_sv = len(self.alpha)
        print(f"Number of support vectors ({kernel} kernel): {num_sv} out of {N} training samples ({100.0 * num_sv / N:.2f}%)")
        
        if kernel == 'linear':
            
            self.w = np.sum((self.alpha * self.sv_y)[:, None] * self.sv, axis=0)
            
            sv_non_bound = (alphas &gt; 1e-5) & (alphas &lt; C - 1e-5)
            if np.any(sv_non_bound):
                b_candidates = y_mod[sv_non_bound] - np.dot(X[sv_non_bound], self.w)
            else:
                b_candidates = self.sv_y - np.dot(self.sv, self.w)
            self.b = np.mean(b_candidates)
        elif kernel == 'gaussian':
            
            
            
            X_sv = self.sv
            X_sv_square = np.sum(X_sv**2, axis=1).reshape(-1, 1)
            K_sv = np.exp(-gamma * (X_sv_square - 2 * np.dot(X_sv, X_sv.T) + X_sv_square.T))
            pred_sv = np.sum((self.alpha * self.sv_y)[None, :] * K_sv, axis=1)
            self.b = np.mean(self.sv_y - pred_sv)

    def predict(self, X):
        """
        Predict class labels for input samples X.
        Returns labels in {0, 1}.
        """
        if self.kernel == 'linear':
            pred = np.dot(X, self.w) + self.b
        elif self.kernel == 'gaussian':
            
            X_sq = np.sum(X**2, axis=1).reshape(-1, 1)
            SV_sq = np.sum(self.sv**2, axis=1).reshape(1, -1)
            K_test = np.exp(-self.gamma * (X_sq - 2 * np.dot(X, self.sv.T) + SV_sq))
            pred = np.dot(K_test, self.alpha * self.sv_y) + self.b
        else:
            raise ValueError("Unsupported kernel.")
        
        
        y_pred = np.where(np.sign(pred) == -1, 0, 1)
        return y_pred

</PRE>
</PRE>
</BODY>
</HTML>
