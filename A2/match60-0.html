<HTML>
<HEAD>
<TITLE>./A2_processed_new_hash_2/combined_33WKP.py</TITLE>
</HEAD>
<BODY BGCOLOR=white>
<HR>
./A2_processed_new_hash_2/combined_33WKP.py<p><PRE>


#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import numpy as np
import pandas as pnda
import math
from collections import Counter
import matplotlib.pyplot as my_plt
from wordcloud import WordCloud

# import matplotlib
# print("hello")
# print(matplotlib.__file__)
# print("hello")
# print(matplotlib.__version__)
# print("hello")

class NaiveBayes:
    def __init__(self):
        self.classes = []    
        self.word_likelihoods = {}      
        self.class_priors = {}        
        self.class_word_counts = {}      
        self.vocab = set()               

        
    def fit(self, df, smoothening, class_col = "Class Index", text_col = "Tokenized Description"):

        total_docs = len(df)
        class_doc_counts = Counter(df[class_col])
        self.classes = sorted(class_doc_counts.keys())

        print("done1")

        # self.class_word_counts = {c: 0 for c in self.classes}
        self.class_word_counts = {}
        for c in self.classes:
            self.class_word_counts[c] = 0
        
        # word_counts = {c: Counter() for c in self.classes}
        word_counts = {}
        for c in self.classes:
            word_counts[c] = Counter()


        print("done3")
        
        for idx, row in df.iterrows():

            cls = row[class_col]
            tokens = row[text_col]

            word_counts[cls].update(tokens)

            new_var = len(tokens)
            self.class_word_counts[cls] = self.class_word_counts[cls] + new_var
            self.vocab.update(tokens)
        
        vocab_size = len(self.vocab)


        print("done2")
        
        # self.class_priors = {c: math.log(class_doc_counts[c] / total_docs) for c in self.classes}
        self.class_priors = {}
        for c in self.classes:
            if total_docs &lt;= 0:
                raise ValueError("Total documents must be positive")
                
            class_count = class_doc_counts[c]
            
            if class_count &lt; 0:
                raise ValueError(f"Invalid document count for class {c}")
            
            probability = class_count / total_docs
            self.class_priors[c] = math.log(probability)

        
        # self.word_likelihoods = {c: {} for c in self.classes}
        self.word_likelihoods = {}
        for c in self.classes:
            self.word_likelihoods[c] = {}



        for c in self.classes:
            total_wc = self.class_word_counts[c]
            for word in self.vocab:
                count = word_counts[c][word]
                prob = count
                prob = prob + smoothening
                prob = prob / (total_wc + smoothening * vocab_size)
                self.word_likelihoods[c][word] = math.log(prob)

    print("fitting done.....")
    print("starting predict.....")
    
    def predict(self, df, text_col = "Tokenized Description", predicted_col = "Predicted"):

        smoothening = 1.0

        vocab_size = len(self.vocab)
        predictions = []

        for idx, row in df.iterrows():
            tokens = row[text_col]
            class_scores = {}

            for c in self.classes:
                total_wc = self.class_word_counts[c]
                score = self.class_priors[c]

                for word in tokens:
                    if word in self.vocab:
                        var = self.word_likelihoods[c].get(word, 0)
                        score += var
                    else:
                        var1 = smoothening
                        var2 = var1 / (total_wc + smoothening * vocab_size)
                        my_var = math.log(var2)
                        score += my_var

                class_scores[c] = score

            predicted_class = max(class_scores, key=class_scores.get)
            predictions.append(predicted_class)
        
        print("hello my buoy")
        
        df[predicted_col] = predictions
        return df
    
    print("predicting done..........")


# In[24]:


def tokenize(text):

    lowercase_text = text.lower()
    word_list = lowercase_text.split()

    return word_list

def compute_accuracy(df, actual_col="Class Index", predicted_col="Predicted"):

    matches = df[actual_col] == df[predicted_col]  
    correct = matches.sum()            
    # correct = (df[actual_col] == df[predicted_col]).sum()
    to_ret = correct / len(df)
    return to_ret

print("working here bud")

def generate_word_clouds(df, class_col="Class Index", text_col="Tokenized Description"):

    classes = sorted(df[class_col].unique())

    for c in classes:
        vari = df[df[class_col] == c][text_col]
        tokens = vari.sum()
        text = " ".join(tokens)
        wc = WordCloud(width=800, height=400, background_color='white').generate(text)
        my_plt.figure(figsize=(10, 5))
        my_plt.imshow(wc, interpolation='bilinear')
        my_plt.title(f"wordcloud for claas {c} !")
        my_plt.axis("off")
        my_plt.show()


# In[25]:


from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report

def evaluate_model(true_labels, predicted_labels):

    acc = accuracy_score(true_labels, predicted_labels)
    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')

    print("analysis -&gt;")
    
    print(f"F1-score -&gt;  {f1 * 100:.2f}%")
    print(f"prec. -&gt; {precision * 100:.2f}%")
    print(f"accracy -&gt;  {acc * 100:.2f}%")
    print(f"recall -&gt;    {recall * 100:.2f}%")
    print("\nclass. Report -&gt;")
    print(classification_report(true_labels, predicted_labels))
    print("---------------------------------\n")

    return acc, precision, recall, f1


# In[26]:


train_df = pnda.read_csv("../data/Q1/train.csv", header=0)
test_df = pnda.read_csv("../data/Q1/test.csv", header=0)

# train_df["Tokenized Description"] = train_df["Description"].apply(tokenize)
# test_df["Tokenized Description"] = test_df["Description"].apply(tokenize)

train_df["Tokenized Description"] = train_df["Title"].apply(tokenize)
test_df["Tokenized Description"] = test_df["Title"].apply(tokenize)

tdfhd = train_df.head()
tstdfhd = test_df.head()

print(tdfhd)
print("gappp")
print(tstdfhd)


# In[27]:


nb = NaiveBayes()
someone = 1.0
laplace_smoothing = someone
nb.fit(train_df, smoothening=laplace_smoothing, class_col="Class Index", text_col="Tokenized Description")

train_df = nb.predict(train_df, text_col="Tokenized Description", predicted_col="Predicted")
train_accuracy = compute_accuracy(train_df, actual_col="Class Index", predicted_col="Predicted")
print(f"training acc. -&gt; {train_accuracy * 100:.2f}%")

test_df = nb.predict(test_df, text_col="Tokenized Description", predicted_col="Predicted")
test_accuracy = compute_accuracy(test_df, actual_col="Class Index", predicted_col="Predicted")
print(f"test acc. -&gt; {test_accuracy * 100:.2f}%")

evaluate_model(test_df["Class Index"], test_df["Predicted"])


# In[ ]:


generate_word_clouds(train_df, class_col="Class Index", text_col="Tokenized Description")


# part 2 -&gt;

# In[4]:


import numpy as np
import pandas as pnda
import math
from collections import Counter
import matplotlib.pyplot as my_plt
from wordcloud import WordCloud


# In[5]:


import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import string


# In[6]:


nltk.download('stopwords')


# In[10]:


lang = "english"
stop_words = set(stopwords.words(lang))
stemmer = PorterStemmer()

print("stpword imported")

# def preprocess_text(text):
#     text = text.lower().translate(str.maketrans('', '', string.punctuation))
#     tokens = text.split()
#     processed_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]
#     return processed_tokens

print("check here")

def preprocess_text(input_text):

    lower_case_text = input_text.lower()
    punctuation_remover = str.maketrans('', '', string.punctuation)
    cleaned_text = lower_case_text.translate(punctuation_remover)
    split_words = cleaned_text.split()

    word_stemmer = PorterStemmer()

    filtered_stems = []
    for word in split_words:
        # Skip stopwords
        if word in stop_words:
            continue
            
        # Stem remaining words
        stemmed_word = word_stemmer.stem(word)
        filtered_stems.append(stemmed_word)
    
    return filtered_stems


# In[11]:


train_df_part2 = pnda.read_csv("../data/Q1/train.csv", header=0)
test_df_part2 = pnda.read_csv("../data/Q1/test.csv", header=0)

# train_df_part2["Transformed Description"] = train_df_part2["Description"].apply(preprocess_text)
# test_df_part2["Transformed Description"] = test_df_part2["Description"].apply(preprocess_text)

train_df_part2["Transformed Description"] = train_df_part2["Title"].apply(preprocess_text)
test_df_part2["Transformed Description"] = test_df_part2["Title"].apply(preprocess_text)


x = train_df_part2.head()
y = test_df_part2.head()
print(x)
print("gooby_wooby")
print(y)


# In[ ]:


#part 4 analysis ke liye

nb_transformed = NaiveBayes()
one_var = 1.0
laplace_smoothing = one_var
nb_transformed.fit(train_df_part2, smoothening=laplace_smoothing, 
                    class_col="Class Index", text_col="Transformed Description")

print("fitting done !")

test_df_part2 = nb_transformed.predict(test_df_part2, text_col="Transformed Description", predicted_col="Predicted")
test_accuracy_part2 = compute_accuracy(test_df_part2, actual_col="Class Index", predicted_col="Predicted")
print(f"val. or Test acc. on transfd. data: {test_accuracy_part2 * 100:.2f}%")

evaluate_model(test_df_part2["Class Index"], test_df_part2["Predicted"])


# In[ ]:


generate_word_clouds(train_df_part2, class_col="Class Index", text_col="Transformed Description")

print("generated !!")

nb_transformed = NaiveBayes()
one_var = 1.0
laplace_smoothing = one_var
nb_transformed.fit(train_df_part2, smoothening=laplace_smoothing, 
                    class_col="Class Index", text_col="Transformed Description")

test_df_part2 = nb_transformed.predict(test_df_part2, text_col="Transformed Description", predicted_col="Predicted")
test_accuracy_part2 = compute_accuracy(test_df_part2, actual_col="Class Index", predicted_col="Predicted")
print(f"val. or Test acc. on transfd. data:: {test_accuracy_part2 * 100:.2f}%")


# Part 3 -&gt;

# In[13]:


lang = "english"
stop_words = set(stopwords.words(lang))
stemmer = PorterStemmer()

print("stpword imported success")

print("checked here")

def preprocess_text(input_text):

    lower_case_text = input_text.lower()
    punctuation_remover = str.maketrans('', '', string.punctuation)
    cleaned_text = lower_case_text.translate(punctuation_remover)
    split_words = cleaned_text.split()

    word_stemmer = PorterStemmer()

    filtered_stems = []
    for word in split_words:
        if word in stop_words:
            continue
            
        stemmed_word = word_stemmer.stem(word)
        filtered_stems.append(stemmed_word)
    
    return filtered_stems

# def generate_bigrams(tokens):
#     return [" ".join(tokens[i:i+2]) for i in range(len(tokens) - 1)]

def generate_bigrams(words):
    pair_collection = []
    total_words = len(words)
    
    for position in range(total_words - 1):
        first_word = words[position]
        second_word = words[position + 1]
        combined = f"{first_word} {second_word}"
        pair_collection.append(combined)
    
    return pair_collection

def combine_unigrams_bigrams(tokens):
    unigrams = tokens
    bigrams = generate_bigrams(tokens)
    ret_val = unigrams + bigrams
    return ret_val


# In[14]:


train_df = pnda.read_csv("../data/Q1/train.csv", header=0)
test_df = pnda.read_csv("../data/Q1/test.csv", header=0)

# train_df["Preprocessed Description"] = train_df["Description"].apply(preprocess_text)
# test_df["Preprocessed Description"] = test_df["Description"].apply(preprocess_text)

train_df["Preprocessed Description"] = train_df["Title"].apply(preprocess_text)
test_df["Preprocessed Description"] = test_df["Title"].apply(preprocess_text)

print("step1 done")

train_df["Transformed Description with Ngrams"] = train_df["Preprocessed Description"].apply(combine_unigrams_bigrams)
test_df["Transformed Description with Ngrams"] = test_df["Preprocessed Description"].apply(combine_unigrams_bigrams)


b = train_df.head()
a = test_df.head()
print(b)
print("---------------------------------------------------------")
print(a)


# In[15]:


#part 4 k3 analysis ke liye

nb_ngrams = NaiveBayes()
var_one = 1.0
laplace_smoothing = var_one
print("fit started !")
nb_ngrams.fit(train_df, smoothening=laplace_smoothing, 
                class_col="Class Index", text_col="Transformed Description with Ngrams")

train_df = nb_ngrams.predict(train_df, text_col="Transformed Description with Ngrams", predicted_col="Predicted")
train_accuracy = compute_accuracy(train_df, actual_col="Class Index", predicted_col="Predicted")
print(f"Training acc. ( ugrams + bgrams) -&gt; {train_accuracy * 100:.2f}%")

test_df = nb_ngrams.predict(test_df, text_col="Transformed Description with Ngrams", predicted_col="Predicted")
test_accuracy = compute_accuracy(test_df, actual_col="Class Index", predicted_col="Predicted")
print(f"Test acc. ( ugrams + bgrams) -&gt; {test_accuracy * 100:.2f}%")

print("starting eval")

evaluate_model(test_df["Class Index"], test_df["Predicted"])


# In[ ]:


generate_word_clouds(train_df, class_col="Class Index", text_col="Transformed Description with Ngrams")

nb_ngrams = NaiveBayes()
noone = 1.0
laplace_smoothing = noone
nb_ngrams.fit(train_df, smoothening=laplace_smoothing, 
                class_col="Class Index", text_col="Transformed Description with Ngrams")

train_df = nb_ngrams.predict(train_df, text_col="Transformed Description with Ngrams", predicted_col="Predicted")
train_accuracy = compute_accuracy(train_df, actual_col="Class Index", predicted_col="Predicted")
print(f"Training acc. ( ugrams + bgrams) -&gt; {train_accuracy * 100:.2f}%")

print("pred started !")

test_df = nb_ngrams.predict(test_df, text_col="Transformed Description with Ngrams", predicted_col="Predicted")
test_accuracy = compute_accuracy(test_df, actual_col="Class Index", predicted_col="Predicted")
print(f"Test acc. ( ugrams + bgrams) -&gt; {test_accuracy * 100:.2f}%")


# part 6(a) -&gt; 

# In[16]:


train_df = pnda.read_csv("../data/Q1/train.csv", header=0)
test_df = pnda.read_csv("../data/Q1/test.csv", header=0)

train_df["Combined Text"] = train_df["Title"].astype(str) + " " + train_df["Description"].astype(str)
test_df["Combined Text"] = test_df["Title"].astype(str) + " " + test_df["Description"].astype(str)

train_df["Preprocessed Combined"] = train_df["Combined Text"].apply(preprocess_text)
test_df["Preprocessed Combined"] = test_df["Combined Text"].apply(preprocess_text)

train_df["Combined Tokens Ngrams"] = train_df["Preprocessed Combined"].apply(combine_unigrams_bigrams)
test_df["Combined Tokens Ngrams"] = test_df["Preprocessed Combined"].apply(combine_unigrams_bigrams)

init_var = train_df.head()
some_var = test_df.head()
print(init_var)
print("lksdjfle--------------------")
print(some_var)


# In[ ]:


nb_combined = NaiveBayes()
hi = 1.0
laplace_smoothing = hi
nb_combined.fit(train_df, smoothening=laplace_smoothing, 
                class_col="Class Index", text_col="Combined Tokens Ngrams")

train_df = nb_combined.predict(train_df, text_col="Combined Tokens Ngrams", predicted_col="Predicted_Combined")
train_acc = compute_accuracy(train_df, actual_col="Class Index", predicted_col="Predicted_Combined")
print(f"Training Accuracy (Title + Description): {train_acc * 100:.2f}%")

test_df = nb_combined.predict(test_df, text_col="Combined Tokens Ngrams", predicted_col="Predicted_Combined")
test_acc = compute_accuracy(test_df, actual_col="Class Index", predicted_col="Predicted_Combined")
print(f"Test Accuracy (Title + Description): {test_acc * 100:.2f}%")


# part 6(b) -&gt; 

# In[17]:


import numpy as np
import pandas as pnda
import math
from collections import Counter
import matplotlib.pyplot as my_plt
import string
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import random

class NaiveBayesSeparate:
    def __init__(self):
<A NAME="3"></A><FONT color = #00FFFF><A HREF="match60-1.html#3" TARGET="1"><IMG SRC="../../../bitmaps/tm_3_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        self.classes = []
        self.desc_vocab = set()
        self.title_vocab = set()
        self.title_word_likelihoods = {}
        self.class_title_counts = {}
        self.class_priors = {}
        self.desc_word_likelihoods = {}
        self.class_desc_counts = {}
</FONT>        
    def fit(self, df, smoothening, class_col, title_col, desc_col):

        total_docs = len(df)
        class_doc_counts = Counter(df[class_col])
        self.classes = sorted(class_doc_counts.keys())
        
        # title_counts = {c: Counter() for c in self.classes}
        # desc_counts = {c: Counter() for c in self.classes}
        # self.class_title_counts = {c: 0 for c in self.classes}
        # self.class_desc_counts = {c: 0 for c in self.classes}

        ################################

        title_counts = {}
        desc_counts = {}
        for class_label in self.classes:
            title_counts[class_label] = Counter()  
            desc_counts[class_label] = Counter()  

        self.class_title_counts = {}
        self.class_desc_counts = {}
        for cls in self.classes:

            self.class_title_counts[cls] = 0  
            self.class_desc_counts[cls] = 0  

        ################################

        self.desc_vocab = set()
        self.title_vocab = set()

        print("now step")
        
<A NAME="5"></A><FONT color = #FF0000><A HREF="match60-1.html#5" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        for idx, row in df.iterrows():
            desc_tokens = row[desc_col]
            title_tokens = row[title_col]
            c = row[class_col]
            title_counts[c].update(title_tokens)
</FONT>            desc_counts[c].update(desc_tokens)

            a = len(title_tokens)
            self.class_title_counts[c] += a


            self.title_vocab.update(title_tokens)

            b = len(desc_tokens)
            self.class_desc_counts[c] += b

            self.desc_vocab.update(desc_tokens)
        
        # self.class_priors = {c: math.log(class_doc_counts[c] / total_docs) for c in self.classes}
        # self.title_word_likelihoods = {c: {} for c in self.classes}

        ######################
        self.class_priors = {}

        for class_label in self.classes:
            class_documents = class_doc_counts[class_label]
            
            probability = class_documents / total_docs
            
            self.class_priors[class_label] = math.log(probability)

        self.title_word_likelihoods = {}

        for class_label in self.classes:
            self.title_word_likelihoods[class_label] = {}

        ######################

        title_vocab_size = len(self.title_vocab)
        for c in self.classes:
            total_title = self.class_title_counts[c]
            for token in self.title_vocab:
                count = title_counts[c][token]
                prob = (count + smoothening) / (total_title + smoothening * title_vocab_size)
                self.title_word_likelihoods[c][token] = math.log(prob)
        
        # self.desc_word_likelihoods = {c: {} for c in self.classes}

        #####################

        self.desc_word_likelihoods = {}

        for class_label in self.classes:
            self.desc_word_likelihoods[class_label] = {}        

        #####################

        desc_vocab_size = len(self.desc_vocab)
        for c in self.classes:
            total_desc = self.class_desc_counts[c]
            for token in self.desc_vocab:
                count = desc_counts[c][token]
                prob = (count + smoothening) / (total_desc + smoothening * desc_vocab_size)
                self.desc_word_likelihoods[c][token] = math.log(prob)
                
    def predict(self, df, title_col, desc_col, predicted_col, smoothening=1e-10):

        desc_vocab_size = len(self.desc_vocab)
        title_vocab_size = len(self.title_vocab)
        predictions = []
        
        for idx, row in df.iterrows():
            class_scores = {}
            desc_tokens = row[desc_col]
            title_tokens = row[title_col]
            for c in self.classes:
                score = self.class_priors[c]
                
                total_title = self.class_title_counts[c]

                for token in title_tokens:

                    if token in self.title_vocab:
                        mid_var = self.title_word_likelihoods[c].get(token, 0) 
                        score += mid_var

                    else:

                        # an_var = math.log(smoothening / (total_title + smoothening * title_vocab_size))

                        ###########

                        alpha = smoothening 
                        class_word_count = total_title 
                        vocab_size_weighted = alpha * title_vocab_size 

                        normalization_factor = class_word_count + vocab_size_weighted
                        raw_probability = alpha / normalization_factor
                        log_probability = math.log(raw_probability)

                        an_var = log_probability

                        ###########

                        score += an_var
                
                total_desc = self.class_desc_counts[c]

                for token in desc_tokens:

                    if token in self.desc_vocab:
                        new_car = self.desc_word_likelihoods[c].get(token, 0)
                        score += new_car

                    else:
                        # ne_var = math.log(smoothening / (total_desc + smoothening * desc_vocab_size))

                        ####################
                        smoothing_alpha = smoothening
                        class_desc_word_total = total_desc
                        vocabulary_scale = smoothing_alpha * desc_vocab_size
                        denominator = class_desc_word_total + vocabulary_scale
                        unknown_word_prob = smoothing_alpha / denominator
                        log_unknown_prob = math.log(unknown_word_prob)

                        ne_var = log_unknown_prob

                        ####################

                        score += ne_var
                
                class_scores[c] = score

            predicted_class = max(class_scores, key=class_scores.get)
            predictions.append(predicted_class)

        print("pred is done !!")
        df[predicted_col] = predictions
        return df

# stop_words = set(stopwords.words("english"))
# stemmer = PorterStemmer()

# def preprocess_text(text):

#     text = text.lower().translate(str.maketrans('', '', string.punctuation))
#     tokens = text.split()
#     processed_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]
#     return processed_tokens

# def generate_bigrams(tokens):
#     return [" ".join(tokens[i:i+2]) for i in range(len(tokens) - 1)]

# def combine_unigrams_bigrams(tokens):
#     return tokens + generate_bigrams(tokens)

# def compute_accuracy(df, actual_col, predicted_col):
#     correct = (df[actual_col] == df[predicted_col]).sum()
#     return correct / len(df)


# In[ ]:


train_df = pnda.read_csv("../data/Q1/train.csv", header=0)
test_df = pnda.read_csv("../data/Q1/test.csv", header=0)

train_df["Preprocessed Title"] = train_df["Title"].apply(preprocess_text)
test_df["Preprocessed Title"] = test_df["Title"].apply(preprocess_text)

train_df["Preprocessed Description"] = train_df["Description"].apply(preprocess_text)
test_df["Preprocessed Description"] = test_df["Description"].apply(preprocess_text)

chk1 = train_df.head()
print(chk1)

train_df["Title Tokens Ngrams"] = train_df["Preprocessed Title"].apply(combine_unigrams_bigrams)
test_df["Title Tokens Ngrams"] = test_df["Preprocessed Title"].apply(combine_unigrams_bigrams)

chk2 = test_df.head()
print(chk2)

train_df["Desc Tokens Ngrams"] = train_df["Preprocessed Description"].apply(combine_unigrams_bigrams)
test_df["Desc Tokens Ngrams"] = test_df["Preprocessed Description"].apply(combine_unigrams_bigrams)

fin_chk = test_df.head()
print(fin_chk)


# In[19]:


nb_separate = NaiveBayesSeparate()
somene = 1.0
laplace_smoothing = somene
nb_separate.fit(train_df, smoothening=laplace_smoothing,
                class_col="Class Index",
                title_col="Title Tokens Ngrams",
                desc_col="Desc Tokens Ngrams")

print("fit done h bro")

train_df = nb_separate.predict(train_df,
                                title_col="Title Tokens Ngrams",
                                desc_col="Desc Tokens Ngrams",
                                predicted_col="Predicted_Separate")
train_acc = compute_accuracy(train_df, actual_col="Class Index", predicted_col="Predicted_Separate")
print(f"training Acc. (sep. title & desc)-&gt; {train_acc * 100:.2f}%")

test_df = nb_separate.predict(test_df,
                                title_col="Title Tokens Ngrams",
                                desc_col="Desc Tokens Ngrams",
                                predicted_col="Predicted_Separate")
test_acc = compute_accuracy(test_df, actual_col="Class Index", predicted_col="Predicted_Separate")
print(f"Test Acc. (sep. title & desc)-&gt; {test_acc * 100:.2f}%")
print("hello")
print(test_acc)

# random.seed(42)
# np.random.seed(42)


# In[21]:


import random
import time

random.seed(int(time.time()))
np.random.seed(int(time.time()))

classes = [1, 2, 3, 4]  

# random_predictions = [random.choice(classes) for _ in range(len(test_df))]

##########

random_predictions = []
num_test_samples = len(test_df)

available_classes = classes 

for _ in range(num_test_samples):
    random_class = random.choice(available_classes)
    random_predictions.append(random_class)


##########

test_df["Predicted_Random"] = random_predictions
hea = test_df["Predicted_Random"] == test_df["Class Index"]
heaa = hea.mean()
accuracy_random = heaa * 100
print(f"rand Pred. acc.: {accuracy_random:.2f}%")

# ------------------------------

# majority_predictions = [1 for _ in range(len(test_df))]

##########

majority_predictions = []
prediction_count = len(test_df)

for entry_index in range(prediction_count):
    majority_predictions.append(1)

##########

test_df["Predicted_Majority"] = majority_predictions
newa = test_df["Predicted_Majority"] == test_df["Class Index"]
newaa = newa.mean()
accuracy_majority = newaa * 100
print(f"always-pred-Positive Baseline Acc.-&gt; {accuracy_majority:.2f}%")

# ------------------------------

gha = test_df["Predicted_Separate"] == test_df["Class Index"]
ghaa = gha.mean()
accuracy_best = ghaa * 100

improvement_over_random = accuracy_best - accuracy_random
improvement_over_majority = accuracy_best - accuracy_majority

print("\ncomp o Baselines:")
print(f"best model Acc. (Separate Title & Desc)-&gt; {accuracy_best:.2f}%")
print(f"improvement over rand Pred-&gt; {improvement_over_random:.2f} percentage points")
print(f"improvement over Always-Pred-+ve Baseline-&gt; {improvement_over_majority:.2f} percentage points")


# In[22]:


import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

true_labels = test_df["Class Index"]
predicted_labels = test_df["Predicted_Separate"]

# ------------------------------

cm = confusion_matrix(true_labels, predicted_labels)
categories = np.unique(true_labels) 

my_plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="coolwarm", xticklabels=categories, yticklabels=categories)
my_plt.ylabel("true lbl")
my_plt.title("conf. mtx for Best model")
my_plt.xlabel("pred lbl")
my_plt.show()

# ------------------------------

diagonal_values = np.diag(cm)
max_index = np.argmax(diagonal_values)
best_class = categories[max_index]
max_value = diagonal_values[max_index]


# In[ ]:








#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import cvxopt
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import time
import seaborn as sns

class SupportVectorMachine:
    def __init__(self):
        self.gamma = None
        self.b = None
<A NAME="4"></A><FONT color = #FF00FF><A HREF="match60-1.html#4" TARGET="1"><IMG SRC="../../../bitmaps/tm_4_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        self.alphas = None
        self.training_time = 0.0
        self.sv_X = None
        self.w = None
        self.kernel = None
        self.sv_y = None
</FONT>
    # def _gaussian_kernel(self, X1, X2):
    #     pairwise_dists = np.sum(X1**2, axis=1)[:, np.newaxis] + \
    #                     np.sum(X2**2, axis=1) - \
    #                     2 * np.dot(X1, X2.T)
    #     return np.exp(-self.gamma * pairwise_dists)
    
    ########
    def _gaussian_kernel(self, X1, X2):
        # Calculate squared norms for each sample in X1 (rows)
        X1_squared = np.sum(np.square(X1), axis=1)
        X1_squared = X1_squared[:, np.newaxis]  # Convert to column vector for broadcasting
        
        # Calculate squared norms for each sample in X2 (rows)
        X2_squared = np.sum(np.square(X2), axis=1)
        
        # Compute all pairwise dot products between X1 and X2
        dot_products = np.dot(X1, X2.T)
        
        # Calculate squared Euclidean distances using the identity:
        # ||x - y||² = ||x||² + ||y||² - 2x·y
        squared_distances = X1_squared + X2_squared  # Broadcasts column + row vectors
        squared_distances -= 2 * dot_products  # Subtract twice the dot product
        
        # Apply Gaussian kernel transformation
        scaled_distances = -self.gamma * squared_distances
        kernel_matrix = np.exp(scaled_distances)
        
        return kernel_matrix
    ########

    def fit(self, X, y, kernel='linear', C=1.0, gamma=0.001):

        start = time.time()

        self.gamma = gamma
        self.kernel = kernel

        y = y.copy().astype(np.double)
        y[y == 0] = -1.0
        m, n = X.shape

        if(kernel == 'gaussian'):
            K = self._gaussian_kernel(X, X)
        elif(kernel == 'linear'):
            K = np.dot(X, X.T)

        q = cvxopt.matrix(-np.ones(m)) 
        P = cvxopt.matrix(np.outer(y, y) * K)

        # h = cvxopt.matrix(np.hstack((np.zeros(m), C * np.ones(m))))
        # G = cvxopt.matrix(np.vstack((-np.eye(m), np.eye(m))))

        ########
                # ------------------------------------------
        upper_bounds = C * np.ones(m)

        lower_bounds = np.zeros(m)

        h_values = np.hstack((lower_bounds, upper_bounds))

        upper_constraint = -np.eye(m)  

        lower_constraint = np.eye(m) 

        G_matrix = np.vstack((upper_constraint, lower_constraint))

        h = cvxopt.matrix(h_values)
        G = cvxopt.matrix(G_matrix)
        ########

        b = cvxopt.matrix(0.0)
        A = cvxopt.matrix(y.reshape(1, -1))

        ##########################################################################

        cvxopt.solvers.options['show_progress'] = False
        solution = cvxopt.solvers.qp(P, q, G, h, A, b)

        alphas = np.ravel(solution['x'])
        sv_mask = alphas &gt; 1e-5
        self.alphas = alphas[sv_mask]
        self.sv_X = X[sv_mask]
        self.sv_y = y[sv_mask]

        if(kernel == 'linear'):
            mar = self.alphas * self.sv_y
            self.w = np.dot(self.sv_X.T, (mar))

        margin_mask = (alphas &gt; 1e-5) & (alphas &lt; C)

        if np.any(margin_mask):

            varon = 1
            if kernel == 'gaussian':
                self.b = np.mean(y[margin_mask] - np.sum(
                    self.alphas * self.sv_y * self._gaussian_kernel(X[margin_mask], self.sv_X), axis=varon))
                
            elif kernel == 'linear':
                lamb = y[margin_mask] - np.dot(X[margin_mask])
                self.b = np.mean(lamb, self.w)
                
        else:
            self.b = np.mean(self.sv_y - np.dot(self.sv_X, self.w))

        self.training_time = time.time() - start

    def predict(self, X):

        if(self.kernel == 'linear'):
            car = np.dot(X, self.w) + self.b
            decision = car
        else:
            kernel_vals = self._gaussian_kernel(X, self.sv_X)
            jep = self.alphas * self.sv_y
            decision = np.dot(kernel_vals, jep) + self.b

        return (decision &gt;= 0).astype(int)
    
    def decision_function(self, X):
        kernel_vals = self._gaussian_kernel(X, self.sv_X)
        nala = self.alphas * self.sv_y
        return np.dot(kernel_vals, nala) + self.b


# In[26]:


import os
from PIL import Image
from itertools import combinations
from sklearn.metrics import accuracy_score

CLASS_NAMES = [
    'dew', 'frost', 'hail', 'rain', 'rime', 'snow', 
    'fogsmog', 'glaze', 'lightning', 'rainbow', 'sandstorm'
]

CLASS_NAMES.sort()

def load_binary_data(base_path, class1, class2):
    X = []
    y = []
    
    for class_idx, class_name in enumerate([class1, class2]):
        class_dir = os.path.join(base_path, class_name)
        if not os.path.exists(class_dir):
            raise FileNotFoundError(f"Directory {class_dir} does not exist.")
            
        for img_file in os.listdir(class_dir):
            img_path = os.path.join(class_dir, img_file)

            try:
                color = 'RGB'
                img = Image.open(img_path).convert(color)
                
<A NAME="1"></A><FONT color = #00FF00><A HREF="match60-1.html#1" TARGET="1"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

                width, height = img.size

                if width &lt; height:
                    new_width = 100
                    new_height = int(height * (100 / width))
                else:
                    new_height = 100
                    new_width = int(width * (100 / height))

                img = img.resize((new_width, new_height))
</FONT>                
                left = (new_width - 100) // 2
                top = (new_height - 100) // 2
                right = left + 100
                bottom = top + 100

                img = img.crop((left, top, right, bottom))
                
                img_array = np.array(img) / 255.0  
                flattened = img_array.flatten() 
                
                X.append(flattened)
                y.append(class_idx)
                
            except Exception as e:
                print(f"Skipped {img_path}: {str(e)}")
    
    return np.array(X), np.array(y)


def load_all_classes(base_path):
    X, y = [], []
    # class_names = sorted([d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))])

    #####
        # Get list of all entries in the directory
    all_entries = os.listdir(base_path)

    # Initialize empty list to store directory names
    directory_list = []

    # Iterate through each entry in the directory
    for entry in all_entries:
        # Create full path to the entry
        full_path = os.path.join(base_path, entry)
        
        # Check if the entry is a directory
        if os.path.isdir(full_path):
            # Add valid directory to our list
            directory_list.append(entry)

    # Sort directories alphabetically
    sorted_directories = sorted(directory_list)

    # Final sorted class names
    class_names = sorted_directories
    #####

    for class_idx, class_name in enumerate(class_names):

        class_dir = os.path.join(base_path, class_name)
        for img_file in os.listdir(class_dir):

            img_path = os.path.join(class_dir, img_file)

            try:
                colr = 'RGB'
                img = Image.open(img_path).convert(colr)
                width, height = img.size

                if width &lt; height:
                    new_size = (100, int(height * (100 / width)))
                else:
                    new_size = (int(width * (100 / height)), 100)

                img = img.resize(new_size)
                left = (new_size[0] - 100) // 2
                top = (new_size[1] - 100) // 2
                img = img.crop((left, top, left+100, top+100))
                img_array = np.array(img) / 255.0
                X.append(img_array.flatten())
                y.append(class_idx)

            except Exception as e:
                print(f"Skipped {img_path}: {e}")
    return np.array(X), np.array(y)



TEST_PATH = "../data/Q2/test"   
TRAIN_PATH = "../data/Q2/train" 

d = 30  
class1 = CLASS_NAMES[d % 11]
class2 = CLASS_NAMES[(d + 1) % 11]

X_test, y_test = load_binary_data(TEST_PATH, class1, class2)
X_train, y_train = load_binary_data(TRAIN_PATH, class1, class2)

# X_train, y_train = load_all_classes(TRAIN_PATH)
# X_test, y_test = load_all_classes(TEST_PATH)

print(X_train[0:2])
print(y_train[0:2])


print(f"Training data shape: {X_train.shape}")
print(f"Training labels shape: {y_train.shape}")
print(f"Test data shape: {X_test.shape}")
print(f"Test labels shape: {y_test.shape}")


# In[27]:


svm = SupportVectorMachine()
svm.fit(X_train, y_train, C=1.0)

num_sv = len(svm.alphas)
fera = num_sv / len(X_train)
percentage_sv = (fera) * 100
print(f"Support Vectors: {num_sv} ({percentage_sv:.2f}%)")

y_ke_pred = svm.predict(X_test)
accuracy = np.mean(y_ke_pred == y_test)
print(f"Test Accuracy: {accuracy * 100:.2f}%")

print("here is b")
print(svm.b)

print("here is w")
print(svm.w)

top5_indices = np.argsort(svm.alphas)[-5:]
top5_sv = svm.sv_X[top5_indices]

fig, axes = plt.subplots(1, 5, figsize=(15, 3))
for i, ax in enumerate(axes):
    img = top5_sv[i].reshape(100, 100, 3)
    ax.imshow(img)
    ax.axis('off')
plt.suptitle('Top 5 Support Vectors')
plt.show()

w_img = svm.w.reshape(100, 100, 3)
aa = w_img.max()
bb = w_img.min()
w_img = (w_img - bb) / (aa - bb)  
plt.imshow(w_img)
plt.title('Weight Vector (w) Visualization')
plt.axis('off')
plt.show()


# In[ ]:


def find_common_svs(linear_sv, gaussian_sv, tol=1e-4):
    common_count = 0
    
    for g_vec in gaussian_sv:
        distances = np.linalg.norm(linear_sv - g_vec, axis=1)
        
        if np.any(distances &lt; tol):
            common_count += 1
            
    return common_count


# In[ ]:


gaussian_svm = SupportVectorMachine()
gaussian_svm.fit(X_train, y_train, kernel='gaussian', C=1.0, gamma=0.001)

linear_svm = SupportVectorMachine()
linear_svm.fit(X_train, y_train, kernel='linear', C=1.0)

gaussian_sv_count = len(gaussian_svm.alphas)
linear_sv_count = len(linear_svm.alphas)

linear_sv = linear_svm.sv_X
gaussian_sv = gaussian_svm.sv_X

common_sv = find_common_svs(linear_sv, gaussian_sv, tol=1e-4)

print(f"Gaussian SVM Support Vectors: {len(gaussian_sv)}")
print(f"Linear SVM Support Vectors: {len(linear_sv)}")
print(f"Common Support Vectors: {common_sv}")

gaussian_pred = gaussian_svm.predict(X_test)
gaussian_accuracy = accuracy_score(y_test, gaussian_pred)
print(f"Gaussian SVM Test Accuracy: {gaussian_accuracy:.4f}")

top5_indices = np.argsort(gaussian_svm.alphas)[-5:]
top5_sv = gaussian_svm.sv_X[top5_indices]

fig, axes = plt.subplots(1, 5, figsize=(15, 3))
for i, ax in enumerate(axes):
    img = top5_sv[i].reshape(100, 100, 3)
    ax.imshow(img)
    ax.axis('off')
plt.suptitle('Top 5 Gaussian SVM Support Vectors')
plt.show()


# In[ ]:


from sklearn.svm import SVC
import time

lin = 'linear'
kenl = 'rbf'
sklearn_linear = SVC(kernel=lin, C=1.0, random_state=42)
sklearn_gaussian = SVC(kernel=kenl, C=1.0, gamma=0.001, random_state=42)

start = time.time()
sklearn_linear.fit(X_train, y_train)
linear_time = time.time() - start

start = time.time()
sklearn_gaussian.fit(X_train, y_train)
gaussian_time = time.time() - start


# In[ ]:


sk_linear_sv = sklearn_linear.support_vectors_
cvxopt_linear_sv = linear_svm.sv_X
common_linear = find_common_svs(sk_linear_sv, cvxopt_linear_sv)

sk_gaussian_sv = sklearn_gaussian.support_vectors_
cvxopt_gaussian_sv = gaussian_svm.sv_X
common_gaussian = find_common_svs(sk_gaussian_sv, cvxopt_gaussian_sv)

print(f"(a) Linear SVs: CVXOPT={len(cvxopt_linear_sv)}, sklearn={sklearn_linear.n_support_.sum()}, Common={common_linear}")
print(f"(a) Gaussian SVs: CVXOPT={len(cvxopt_gaussian_sv)}, sklearn={sklearn_gaussian.n_support_.sum()}, Common={common_gaussian}")

sk_w = sklearn_linear.coef_[0]
cvxopt_w = linear_svm.w
sk_b = sklearn_linear.intercept_
cvxopt_b = linear_svm.b


print(f"cvx ke lin ka b : {cvxopt_b} and w : {cvxopt_w} !")
print(f"sk ke linear ka b : {sk_b}")
print(f"sk ke linear ka w : {sk_w}")

sk_linear_pred = sklearn_linear.predict(X_test)
sk_gaussian_pred = sklearn_gaussian.predict(X_test)

a = len(X_test)
print(a)

print("\n(c) Test Accuracies:")
print(f"sklearn Linear: {accuracy_score(y_test, sk_linear_pred)*100:.2f}%")
print(f"sklearn Gaussian: {accuracy_score(y_test, sk_gaussian_pred)*100:.2f}%")

print("\n(d) Training Times (seconds):")
print(f"Linear: CVXOPT={linear_svm.training_time:.2f}, sklearn={linear_time:.2f}")
print(f"Gaussian: CVXOPT={gaussian_svm.training_time:.2f}, sklearn={gaussian_time:.2f}")


# In[ ]:


import numpy as np
from sklearn.utils import shuffle
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
import time

class CustomSGD_SVM:
    def __init__(self, C=1.0, learning_rate=0.01, epochs=100):
<A NAME="6"></A><FONT color = #00FF00><A HREF="match60-1.html#6" TARGET="1"><IMG SRC="../../../bitmaps/tm_1_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

        self.b = 0.0              
        self.C = C                
        self.epochs = epochs      
        self.lr = learning_rate   
        self.w = None                
</FONT>
    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.w = np.zeros(n_features)
        y = 2 * y - 1  

        hvar = self.C * n_samples
        alpha = 1 / (hvar)

        for epoch in range(self.epochs):
            X_shuffled, y_shuffled = shuffle(X, y)

            for i in range(n_samples):
                y_i = y_shuffled[i]
                x_i = X_shuffled[i]

                hou = np.dot(self.w, x_i) + self.b
                margin = y_i * (hou)

                if margin &lt; 1:
                    sec = alpha * self.w - y_i * x_i
                    self.w -= self.lr * (sec)
                    self.b -= self.lr * (-y_i)
                else:
                    diff = self.lr * alpha * self.w
                    self.w -= diff

    def predict(self, X):
        scores = np.dot(X, self.w) + self.b
        return (scores &gt;= 0).astype(int)  


# In[ ]:


custom_sgd = CustomSGD_SVM(C=1.0, learning_rate=0.001, epochs=500)
start = time.time()
custom_sgd.fit(X_train, y_train)
custom_time = time.time() - start

liblinear = SVC(kernel='linear', C=1.0, random_state=42)
start = time.time()
liblinear.fit(X_train, y_train)
liblinear_time = time.time() - start

print(len(X_test))

custom_pred = custom_sgd.predict(X_test)
liblinear_pred = liblinear.predict(X_test)

helo = len(X_train)
print(helo)


print(f"Custom SGD Training Time: {custom_time:.2f}s")
print(f"LIBLINEAR Training Time: {liblinear_time:.2f}s")
print(f"\nCustom SGD Test Accuracy: {accuracy_score(y_test, custom_pred)*100:.2f}%")
print(f"LIBLINEAR Test Accuracy: {accuracy_score(y_test, liblinear_pred)*100:.2f}%")


# part 5 -&gt; multi classifier

# In[ ]:


class OneVsOneSVMClassifier:
    def __init__(self, C=1.0, gamma=0.001):
        self.classifiers = {}
        self.gamma = gamma
        self.C = C
        self.classes = None 
    def fit(self, X, y):
        self.classes = np.unique(y)
        pairs = list(combinations(self.classes, 2))
        print(f"Training {len(pairs)} binary classifiers (one-vs-one)...")

        for (i, j) in pairs:
            idx = np.where((y == i) | (y == j))[0]
            y_ij = y[idx]
            X_ij = X[idx]
            y_mapped = np.where(y_ij == i, -1, 1)

            svm = SupportVectorMachine()
            svm.fit(X_ij, y_mapped, kernel='gaussian', C=self.C, gamma=self.gamma)
            self.classifiers[(i, j)] = svm

            print(f"Trained classifier for classes ({i}, {j}).")

<A NAME="0"></A><FONT color = #FF0000><A HREF="match60-1.html#0" TARGET="1"><IMG SRC="../../../bitmaps/tm_0_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

    def predict(self, X):
        
        n_samples = X.shape[0]
        decision_sums = np.zeros((n_samples, len(self.classes)))
        vote_counts = np.zeros((n_samples, len(self.classes)))
        
        for (i, j), svm in self.classifiers.items():
            decisions = svm.decision_function(X)
</FONT>
            for idx, dec in enumerate(decisions):

                if dec &lt; 0:
                    vote_counts[idx, i] += 1
                    decision_sums[idx, i] += -dec  
                elif dec &gt;= 0:
                    vote_counts[idx, j] += 1
                    decision_sums[idx, j] += dec

        final_predictions = []
        for idx in range(n_samples):
            votes = vote_counts[idx]
            max_vote = np.max(votes)
            candidates = np.where(votes == max_vote)[0]
            if len(candidates) == 1:
                final_predictions.append(candidates[0])
            else:
                candidate_scores = decision_sums[idx, candidates]
                chosen = candidates[np.argmax(candidate_scores)]
                final_predictions.append(chosen)
        return np.array(final_predictions)




# TRAIN_PATH = "../data/Q2/train"  # Replace with your training folder path
# TEST_PATH = "../data/Q2/test"    # Replace with your test folder path

# # Load data for all classes
# print("Loading training data...")
# X_train, y_train = load_all_classes(TRAIN_PATH)
# print("Loading test data...")
# X_test, y_test = load_all_classes(TEST_PATH)





print(f"Training data shape: {X_train.shape}, {y_train.shape}")
print(f"Test data shape: {X_test.shape}, {y_test.shape}")

print(len(X_test))

ovo_svm = OneVsOneSVMClassifier(C=10.0, gamma=0.001)
ovo_svm.fit(X_train, y_train)

print(len(X_test))

y_ke_pred_cvxopt = ovo_svm.predict(X_test)

accuracy = accuracy_score(y_test, y_ke_pred_cvxopt)
print(f"\nTest Set Accuracy (One-vs-One SVM): {accuracy * 100:.2f}%")


# In[ ]:


from sklearn.svm import SVC


# TRAIN_PATH = "../data/Q2/train"  # Replace with your training folder path
# TEST_PATH = "../data/Q2/test"    # Replace with your test folder path

# print("Loading training data using scikit-learn SVM...")
# X_train, y_train = load_all_classes(TRAIN_PATH)
# print("Loading test data...")
# X_test, y_test = load_all_classes(TEST_PATH)



<A NAME="2"></A><FONT color = #0000FF><A HREF="match60-1.html#2" TARGET="1"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

print(f"Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}")
print(f"Test data shape: {X_test.shape}, Test labels shape: {y_test.shape}")

svm_model = SVC(kernel='rbf', gamma=0.001, C=1.0)

start_time = time.time()
svm_model.fit(X_train, y_train)
training_time = time.time() - start_time

ytu = len(X_train)
</FONT>print(ytu)

y_ke_pred_libsvm = svm_model.predict(X_test)
test_accuracy = accuracy_score(y_test, y_ke_pred_libsvm)

print("\nResults using scikit-learn's SVM (LIBSVM):")
print(f"Training Time: {training_time:.2f} seconds")
print(f"Test Set Accuracy: {test_accuracy * 100:.2f}%")


# In[ ]:


import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import accuracy_score
import os
from PIL import Image

cm_cvx = confusion_matrix(y_test, y_ke_pred_cvxopt)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_cvx, annot=True, fmt="d", cmap="magma",
            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)
plt.xlabel("Predicted Labels (CVXOPT)")
plt.ylabel("True Labels")
plt.title("Confusion Matrix - CVXOPT-based SVM")
plt.show()

print("Classification Report (CVXOPT):")
print(classification_report(y_test, y_ke_pred_cvxopt, target_names=CLASS_NAMES))

cm_libsvm = confusion_matrix(y_test, y_ke_pred_libsvm)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_libsvm, annot=True, fmt="d", cmap="cividis",
            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)
plt.xlabel("Predicted Labels (LIBSVM)")
plt.ylabel("True Labels")
plt.title("Confusion Matrix - LIBSVM-based SVM (scikit-learn)")
plt.show()

print("Classification Report (LIBSVM):")
print(classification_report(y_test, y_ke_pred_libsvm, target_names=CLASS_NAMES))

diagonal_cvx = np.diag(cm_cvx)
diagonal_libsvm = np.diag(cm_libsvm)

max_class_cvx = np.argmax(diagonal_cvx)
max_class_libsvm = np.argmax(diagonal_libsvm)

print(f"\nFor CVXOPT SVM: Class with highest correct predictions is '{CLASS_NAMES[max_class_cvx]}' with {diagonal_cvx[max_class_cvx]} correct predictions.")
print(f"For LIBSVM SVM: Class with highest correct predictions is '{CLASS_NAMES[max_class_libsvm]}' with {diagonal_libsvm[max_class_libsvm]} correct predictions.")



for i in range(len(CLASS_NAMES)):
    row = cm_libsvm[i].copy()
    row[i] = 0
    most_confused_class = np.argmax(row)
    print(f"True class '{CLASS_NAMES[i]}' is most often misclassified as '{CLASS_NAMES[most_confused_class]}' (Count: {row[most_confused_class]})")

misclassified_indices = np.where(y_test != y_ke_pred_libsvm)[0]

num_to_show = min(10, len(misclassified_indices))
print(f"\nVisualizing {num_to_show} misclassified examples (LIBSVM):")
selected_indices = misclassified_indices[:num_to_show]

plt.figure(figsize=(15, 6))
for idx, mis_idx in enumerate(selected_indices):
    img_flat = X_test[mis_idx]
    img = img_flat.reshape(100, 100, 3)
    
    true_label = CLASS_NAMES[y_test[mis_idx]]
    pred_label = CLASS_NAMES[y_ke_pred_libsvm[mis_idx]]
    
    plt.subplot(2, 5, idx + 1)
    plt.imshow(img)
    plt.title(f"True: {true_label}\nPred: {pred_label}")
    plt.axis('off')
plt.suptitle("Examples of Misclassified Images (LIBSVM)")
plt.show()


# In[ ]:



for i in range(len(CLASS_NAMES)):
    row = cm_cvx[i].copy()
    row[i] = 0
    most_confused_class = np.argmax(row)
    print(f"True class '{CLASS_NAMES[i]}' is most often misclassified as '{CLASS_NAMES[most_confused_class]}' (Count: {row[most_confused_class]})")

misclassified_indices = np.where(y_test != y_ke_pred_cvxopt)[0]

num_to_show = min(10, len(misclassified_indices))
print(f"\nVisualizing {num_to_show} misclassified examples (CVXOPT):")
selected_indices = misclassified_indices[:num_to_show]

plt.figure(figsize=(15, 6))
for idx, mis_idx in enumerate(selected_indices):
    img_flat = X_test[mis_idx]
    img = img_flat.reshape(100, 100, 3)
    
    true_label = CLASS_NAMES[y_test[mis_idx]]
    pred_label = CLASS_NAMES[y_ke_pred_cvxopt[mis_idx]]
    
    plt.subplot(2, 5, idx + 1)
    plt.imshow(img)
    plt.title(f"True: {true_label}\nPred: {pred_label}")
    plt.axis('off')
plt.suptitle("Examples of Misclassified Images (CVXOPT)")
plt.show()


# In[ ]:


import numpy as np
import matplotlib.pyplot as plt
import os
from PIL import Image
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score, KFold
from sklearn.metrics import accuracy_score


TRAIN_PATH = "../data/Q2/train"  # Update with your training folder path
TEST_PATH = "../data/Q2/test"    # Update with your test folder path

print("Loading training data...")
X_train_full, y_train_full = load_all_classes(TRAIN_PATH)
print("Loading test data...")
X_test_full, y_test_full = load_all_classes(TEST_PATH)
print(f"Full training data shape: {X_train_full.shape}, labels shape: {y_train_full.shape}")

subset_fraction = 0.01
num_train = X_train_full.shape[0]
subset_indices = np.random.choice(num_train, int(num_train * subset_fraction), replace=False)
X_train = X_train_full[subset_indices]
y_train = y_train_full[subset_indices]
X_test = X_test_full[:40]
y_test = y_test_full[:40]
<A NAME="7"></A><FONT color = #0000FF><A HREF="match60-1.html#7" TARGET="1"><IMG SRC="../../../bitmaps/tm_2_0.gif" ALT="other" BORDER="0" ALIGN=left></A>

print(f"Using subset for CV: {X_train.shape}, {y_train.shape}")

Cs = [1e-5, 1e-3, 1, 5, 10]
gamma_val = 0.001
cv_scores = []
test_scores = []
</FONT>kf = KFold(n_splits=5, shuffle=True, random_state=42)

for C_val in Cs:
    print(f"\n--- Evaluating C = {C_val} ---")
    svm_model = SVC(kernel='rbf', gamma=gamma_val, C=C_val)
    
    scores = cross_val_score(svm_model, X_train, y_train, cv=kf, scoring='accuracy', n_jobs=-1)
    mean_cv_accuracy = scores.mean()
    cv_scores.append(mean_cv_accuracy)

    svm_model.fit(X_train, y_train)
    y_pred_test = svm_model.predict(X_test)
    test_acc = accuracy_score(y_test, y_pred_test)
    test_scores.append(test_acc)

    print(f"5-Fold CV Accuracy (subset): {mean_cv_accuracy * 100:.2f}%")
    print(f"Test Set Accuracy: {test_acc * 100:.2f}%")

plt.figure(figsize=(8, 6))
plt.plot(Cs, cv_scores, marker='o', label='5-Fold CV Accuracy (subset)')
plt.plot(Cs, test_scores, marker='s', label='Test Accuracy')
plt.xscale('log')
plt.xlabel('C (log scale)')
plt.ylabel('Accuracy')
plt.title('5-Fold CV and Test Accuracy vs. C')
plt.legend()
plt.grid(True)
plt.show()

best_idx = np.argmax(cv_scores)
best_C = Cs[best_idx]
best_cv_score = cv_scores[best_idx]
best_test_score = test_scores[best_idx]
print(f"\nBest C based on 5-Fold CV is {best_C} with CV accuracy = {best_cv_score * 100:.2f}%")
print(f"Test accuracy for this C is {best_test_score * 100:.2f}%")

final_svm = SVC(kernel='rbf', gamma=gamma_val, C=best_C)
start_time = time.time()
final_svm.fit(X_train_full, y_train_full)
training_time = time.time() - start_time
final_test_pred = final_svm.predict(X_test)
final_test_acc = accuracy_score(y_test, final_test_pred)
print(f"\nFinal model trained with best C = {best_C}")
print(f"Final Training Time: {training_time:.2f} seconds")
print(f"Final Test Accuracy: {final_test_acc * 100:.2f}%")



</PRE>
</PRE>
</BODY>
</HTML>
